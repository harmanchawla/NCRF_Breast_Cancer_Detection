INFO:root:2019-05-10 16:27:20, Epoch : 1, Step : 1, Training Loss : 0.93996, Training Acc : 0.172, Run Time : 377.10
INFO:root:2019-05-10 16:31:37, Epoch : 1, Step : 2, Training Loss : 0.84703, Training Acc : 0.211, Run Time : 256.54
INFO:root:2019-05-10 16:31:43, Epoch : 1, Step : 3, Training Loss : 0.73431, Training Acc : 0.394, Run Time : 6.33
INFO:root:2019-05-10 16:31:43, Epoch : 1, Step : 4, Training Loss : 0.60123, Training Acc : 0.722, Run Time : 0.26
INFO:root:2019-05-10 16:31:45, Epoch : 1, Step : 5, Training Loss : 0.57824, Training Acc : 0.706, Run Time : 1.55
INFO:root:2019-05-10 16:36:10, Epoch : 1, Step : 6, Training Loss : 0.58383, Training Acc : 0.700, Run Time : 265.50
INFO:root:2019-05-10 16:38:11, Epoch : 1, Step : 7, Training Loss : 0.55229, Training Acc : 0.706, Run Time : 120.52
INFO:root:2019-05-10 16:38:17, Epoch : 1, Step : 8, Training Loss : 0.74122, Training Acc : 0.689, Run Time : 6.08
INFO:root:2019-05-10 16:38:17, Epoch : 1, Step : 9, Training Loss : 0.65261, Training Acc : 0.678, Run Time : 0.24
INFO:root:2019-05-10 16:38:35, Epoch : 1, Step : 10, Training Loss : 0.68227, Training Acc : 0.689, Run Time : 18.14
INFO:root:2019-05-10 16:38:36, Epoch : 1, Step : 11, Training Loss : 0.57781, Training Acc : 0.728, Run Time : 0.64
INFO:root:2019-05-10 16:39:37, Epoch : 1, Step : 12, Training Loss : 0.77923, Training Acc : 0.661, Run Time : 61.66
INFO:root:2019-05-10 16:40:12, Epoch : 1, Step : 13, Training Loss : 0.67045, Training Acc : 0.644, Run Time : 34.28
INFO:root:2019-05-10 16:40:17, Epoch : 1, Step : 14, Training Loss : 0.74557, Training Acc : 0.622, Run Time : 5.14
INFO:root:2019-05-10 16:40:17, Epoch : 1, Step : 15, Training Loss : 0.71904, Training Acc : 0.594, Run Time : 0.30
INFO:root:2019-05-10 16:40:17, Epoch : 1, Step : 16, Training Loss : 0.68576, Training Acc : 0.611, Run Time : 0.24
INFO:root:2019-05-10 16:40:19, Epoch : 1, Step : 17, Training Loss : 0.78235, Training Acc : 0.561, Run Time : 1.57
INFO:root:2019-05-10 16:40:37, Epoch : 1, Step : 18, Training Loss : 0.61674, Training Acc : 0.639, Run Time : 17.84
INFO:root:2019-05-10 16:40:37, Epoch : 1, Step : 19, Training Loss : 0.57881, Training Acc : 0.600, Run Time : 0.67
INFO:root:2019-05-10 16:40:38, Epoch : 1, Step : 20, Training Loss : 0.62971, Training Acc : 0.633, Run Time : 0.25
INFO:root:2019-05-10 16:40:38, Epoch : 1, Step : 21, Training Loss : 0.53228, Training Acc : 0.800, Run Time : 0.21
INFO:root:2019-05-10 16:40:38, Epoch : 1, Step : 22, Training Loss : 0.58523, Training Acc : 0.711, Run Time : 0.34
INFO:root:2019-05-10 16:42:17, Epoch : 1, Step : 23, Training Loss : 0.67715, Training Acc : 0.539, Run Time : 99.20
INFO:root:2019-05-10 16:42:23, Epoch : 1, Step : 24, Training Loss : 0.64791, Training Acc : 0.606, Run Time : 5.82
INFO:root:2019-05-10 16:42:24, Epoch : 1, Step : 25, Training Loss : 0.61305, Training Acc : 0.672, Run Time : 0.24
INFO:root:2019-05-10 16:42:25, Epoch : 1, Step : 26, Training Loss : 0.66562, Training Acc : 0.628, Run Time : 1.70
INFO:root:2019-05-10 16:43:22, Epoch : 1, Step : 27, Training Loss : 0.62076, Training Acc : 0.650, Run Time : 56.35
INFO:root:2019-05-10 16:43:23, Epoch : 1, Step : 28, Training Loss : 0.59675, Training Acc : 0.706, Run Time : 1.36
INFO:root:2019-05-10 16:43:23, Epoch : 1, Step : 29, Training Loss : 0.63010, Training Acc : 0.644, Run Time : 0.40
INFO:root:2019-05-10 16:43:25, Epoch : 1, Step : 30, Training Loss : 0.54446, Training Acc : 0.711, Run Time : 1.83
INFO:root:2019-05-10 16:43:50, Epoch : 1, Step : 31, Training Loss : 0.55321, Training Acc : 0.672, Run Time : 24.50
INFO:root:2019-05-10 16:43:51, Epoch : 1, Step : 32, Training Loss : 0.51779, Training Acc : 0.828, Run Time : 1.03
INFO:root:2019-05-10 16:43:51, Epoch : 1, Step : 33, Training Loss : 0.49384, Training Acc : 0.822, Run Time : 0.56
INFO:root:2019-05-10 16:45:20, Epoch : 1, Step : 34, Training Loss : 0.54709, Training Acc : 0.728, Run Time : 88.33
INFO:root:2019-05-10 16:45:29, Epoch : 1, Step : 35, Training Loss : 0.52005, Training Acc : 0.794, Run Time : 9.28
INFO:root:2019-05-10 16:45:49, Epoch : 1, Step : 36, Training Loss : 0.43378, Training Acc : 0.883, Run Time : 20.29
INFO:root:2019-05-10 16:46:34, Epoch : 1, Step : 37, Training Loss : 0.54850, Training Acc : 0.683, Run Time : 44.86
INFO:root:2019-05-10 16:49:04, Epoch : 1, Step : 38, Training Loss : 0.48848, Training Acc : 0.767, Run Time : 149.59
INFO:root:2019-05-10 16:53:58, Epoch : 1, Step : 39, Training Loss : 0.40988, Training Acc : 0.867, Run Time : 294.26
INFO:root:2019-05-10 16:54:13, Epoch : 1, Step : 40, Training Loss : 0.44731, Training Acc : 0.833, Run Time : 14.82
INFO:root:2019-05-10 16:55:53, Epoch : 1, Step : 41, Training Loss : 0.47296, Training Acc : 0.806, Run Time : 100.67
INFO:root:2019-05-10 17:00:24, Epoch : 1, Step : 42, Training Loss : 0.43167, Training Acc : 0.833, Run Time : 271.10
INFO:root:2019-05-10 17:03:30, Epoch : 1, Step : 43, Training Loss : 0.56520, Training Acc : 0.694, Run Time : 185.28
INFO:root:2019-05-10 17:03:36, Epoch : 1, Step : 44, Training Loss : 0.49358, Training Acc : 0.806, Run Time : 6.07
INFO:root:2019-05-10 17:03:36, Epoch : 1, Step : 45, Training Loss : 0.54442, Training Acc : 0.744, Run Time : 0.33
INFO:root:2019-05-10 17:03:37, Epoch : 1, Step : 46, Training Loss : 0.40792, Training Acc : 0.911, Run Time : 0.52
INFO:root:2019-05-10 17:04:47, Epoch : 1, Step : 47, Training Loss : 0.39243, Training Acc : 0.844, Run Time : 70.79
INFO:root:2019-05-10 17:04:49, Epoch : 1, Step : 48, Training Loss : 0.43797, Training Acc : 0.783, Run Time : 1.30
INFO:root:2019-05-10 17:04:49, Epoch : 1, Step : 49, Training Loss : 0.31169, Training Acc : 0.917, Run Time : 0.50
INFO:root:2019-05-10 17:04:50, Epoch : 1, Step : 50, Training Loss : 0.45846, Training Acc : 0.783, Run Time : 0.49
INFO:root:2019-05-10 17:04:50, Epoch : 1, Step : 51, Training Loss : 0.41043, Training Acc : 0.833, Run Time : 0.50
INFO:root:2019-05-10 17:05:11, Epoch : 1, Step : 52, Training Loss : 0.32504, Training Acc : 0.900, Run Time : 21.02
INFO:root:2019-05-10 17:05:13, Epoch : 1, Step : 53, Training Loss : 0.50103, Training Acc : 0.733, Run Time : 1.66
INFO:root:2019-05-10 17:05:13, Epoch : 1, Step : 54, Training Loss : 0.27055, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-10 17:05:14, Epoch : 1, Step : 55, Training Loss : 0.65971, Training Acc : 0.606, Run Time : 0.62
INFO:root:2019-05-10 17:05:27, Epoch : 1, Step : 56, Training Loss : 1.30742, Training Acc : 0.239, Run Time : 12.63
INFO:root:2019-05-10 17:05:27, Epoch : 1, Step : 57, Training Loss : 1.03716, Training Acc : 0.511, Run Time : 0.22
INFO:root:2019-05-10 17:05:27, Epoch : 1, Step : 58, Training Loss : 1.03897, Training Acc : 0.433, Run Time : 0.40
INFO:root:2019-05-10 17:05:28, Epoch : 1, Step : 59, Training Loss : 0.70946, Training Acc : 0.594, Run Time : 0.52
INFO:root:2019-05-10 17:05:28, Epoch : 1, Step : 60, Training Loss : 0.44669, Training Acc : 0.789, Run Time : 0.35
INFO:root:2019-05-10 17:05:44, Epoch : 1, Step : 61, Training Loss : 0.53460, Training Acc : 0.750, Run Time : 16.26
INFO:root:2019-05-10 17:05:45, Epoch : 1, Step : 62, Training Loss : 0.49734, Training Acc : 0.789, Run Time : 0.94
INFO:root:2019-05-10 17:05:59, Epoch : 1, Step : 63, Training Loss : 0.51654, Training Acc : 0.783, Run Time : 13.45
INFO:root:2019-05-10 17:06:00, Epoch : 1, Step : 64, Training Loss : 0.53386, Training Acc : 0.789, Run Time : 0.89
INFO:root:2019-05-10 17:06:00, Epoch : 1, Step : 65, Training Loss : 0.50900, Training Acc : 0.811, Run Time : 0.50
INFO:root:2019-05-10 17:06:01, Epoch : 1, Step : 66, Training Loss : 0.55021, Training Acc : 0.783, Run Time : 0.70
INFO:root:2019-05-10 17:06:01, Epoch : 1, Step : 67, Training Loss : 0.52473, Training Acc : 0.728, Run Time : 0.48
INFO:root:2019-05-10 17:06:17, Epoch : 1, Step : 68, Training Loss : 0.55446, Training Acc : 0.706, Run Time : 15.36
INFO:root:2019-05-10 17:06:17, Epoch : 1, Step : 69, Training Loss : 0.55265, Training Acc : 0.783, Run Time : 0.21
INFO:root:2019-05-10 17:06:17, Epoch : 1, Step : 70, Training Loss : 0.66545, Training Acc : 0.617, Run Time : 0.29
INFO:root:2019-05-10 17:06:18, Epoch : 1, Step : 71, Training Loss : 0.53740, Training Acc : 0.778, Run Time : 0.47
INFO:root:2019-05-10 17:06:18, Epoch : 1, Step : 72, Training Loss : 0.40682, Training Acc : 0.806, Run Time : 0.66
INFO:root:2019-05-10 17:06:38, Epoch : 1, Step : 73, Training Loss : 0.48946, Training Acc : 0.756, Run Time : 19.78
INFO:root:2019-05-10 17:06:38, Epoch : 1, Step : 74, Training Loss : 0.52541, Training Acc : 0.700, Run Time : 0.23
INFO:root:2019-05-10 17:06:39, Epoch : 1, Step : 75, Training Loss : 0.46637, Training Acc : 0.794, Run Time : 0.50
INFO:root:2019-05-10 17:06:39, Epoch : 1, Step : 76, Training Loss : 0.54790, Training Acc : 0.728, Run Time : 0.61
INFO:root:2019-05-10 17:06:40, Epoch : 1, Step : 77, Training Loss : 0.59064, Training Acc : 0.778, Run Time : 0.48
INFO:root:2019-05-10 17:06:58, Epoch : 1, Step : 78, Training Loss : 0.55214, Training Acc : 0.694, Run Time : 17.66
INFO:root:2019-05-10 17:06:58, Epoch : 1, Step : 79, Training Loss : 0.37734, Training Acc : 0.839, Run Time : 0.21
INFO:root:2019-05-10 17:06:58, Epoch : 1, Step : 80, Training Loss : 0.37595, Training Acc : 0.878, Run Time : 0.40
INFO:root:2019-05-10 17:06:59, Epoch : 1, Step : 81, Training Loss : 0.39919, Training Acc : 0.878, Run Time : 0.44
INFO:root:2019-05-10 17:06:59, Epoch : 1, Step : 82, Training Loss : 0.53014, Training Acc : 0.733, Run Time : 0.47
INFO:root:2019-05-10 17:07:18, Epoch : 1, Step : 83, Training Loss : 0.46363, Training Acc : 0.811, Run Time : 18.34
INFO:root:2019-05-10 17:07:18, Epoch : 1, Step : 84, Training Loss : 0.58029, Training Acc : 0.756, Run Time : 0.57
INFO:root:2019-05-10 17:07:19, Epoch : 1, Step : 85, Training Loss : 0.59027, Training Acc : 0.728, Run Time : 0.47
INFO:root:2019-05-10 17:07:30, Epoch : 1, Step : 86, Training Loss : 0.55075, Training Acc : 0.661, Run Time : 11.40
INFO:root:2019-05-10 17:07:31, Epoch : 1, Step : 87, Training Loss : 0.50079, Training Acc : 0.778, Run Time : 0.97
INFO:root:2019-05-10 17:07:31, Epoch : 1, Step : 88, Training Loss : 0.44707, Training Acc : 0.794, Run Time : 0.43
INFO:root:2019-05-10 17:07:32, Epoch : 1, Step : 89, Training Loss : 0.43684, Training Acc : 0.817, Run Time : 0.47
INFO:root:2019-05-10 17:07:44, Epoch : 1, Step : 90, Training Loss : 0.45312, Training Acc : 0.789, Run Time : 12.17
INFO:root:2019-05-10 17:07:45, Epoch : 1, Step : 91, Training Loss : 0.42830, Training Acc : 0.856, Run Time : 0.59
INFO:root:2019-05-10 17:07:57, Epoch : 1, Step : 92, Training Loss : 0.41291, Training Acc : 0.839, Run Time : 12.61
INFO:root:2019-05-10 17:07:58, Epoch : 1, Step : 93, Training Loss : 0.34206, Training Acc : 0.889, Run Time : 1.01
INFO:root:2019-05-10 17:07:59, Epoch : 1, Step : 94, Training Loss : 0.42745, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-10 17:07:59, Epoch : 1, Step : 95, Training Loss : 0.36400, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-10 17:08:00, Epoch : 1, Step : 96, Training Loss : 0.44079, Training Acc : 0.789, Run Time : 0.50
INFO:root:2019-05-10 17:08:06, Epoch : 1, Step : 97, Training Loss : 0.32049, Training Acc : 0.889, Run Time : 6.79
INFO:root:2019-05-10 17:08:17, Epoch : 1, Step : 98, Training Loss : 0.28607, Training Acc : 0.911, Run Time : 10.68
INFO:root:2019-05-10 17:08:17, Epoch : 1, Step : 99, Training Loss : 0.46407, Training Acc : 0.772, Run Time : 0.28
INFO:root:2019-05-10 17:08:18, Epoch : 1, Step : 100, Training Loss : 0.55284, Training Acc : 0.689, Run Time : 0.21
INFO:root:2019-05-10 17:08:18, Epoch : 1, Step : 101, Training Loss : 0.35274, Training Acc : 0.839, Run Time : 0.82
INFO:root:2019-05-10 17:08:33, Epoch : 1, Step : 102, Training Loss : 0.38708, Training Acc : 0.783, Run Time : 14.60
INFO:root:2019-05-10 17:08:34, Epoch : 1, Step : 103, Training Loss : 0.35343, Training Acc : 0.856, Run Time : 0.60
INFO:root:2019-05-10 17:08:34, Epoch : 1, Step : 104, Training Loss : 0.57003, Training Acc : 0.717, Run Time : 0.43
INFO:root:2019-05-10 17:08:34, Epoch : 1, Step : 105, Training Loss : 0.54942, Training Acc : 0.794, Run Time : 0.48
INFO:root:2019-05-10 17:08:47, Epoch : 1, Step : 106, Training Loss : 0.27678, Training Acc : 0.867, Run Time : 12.35
INFO:root:2019-05-10 17:08:47, Epoch : 1, Step : 107, Training Loss : 0.34215, Training Acc : 0.839, Run Time : 0.46
INFO:root:2019-05-10 17:08:48, Epoch : 1, Step : 108, Training Loss : 0.44285, Training Acc : 0.783, Run Time : 0.29
INFO:root:2019-05-10 17:09:00, Epoch : 1, Step : 109, Training Loss : 0.24075, Training Acc : 0.933, Run Time : 12.00
INFO:root:2019-05-10 17:09:00, Epoch : 1, Step : 110, Training Loss : 0.44768, Training Acc : 0.767, Run Time : 0.88
INFO:root:2019-05-10 17:09:01, Epoch : 1, Step : 111, Training Loss : 0.36938, Training Acc : 0.872, Run Time : 0.43
INFO:root:2019-05-10 17:09:01, Epoch : 1, Step : 112, Training Loss : 0.40825, Training Acc : 0.767, Run Time : 0.43
INFO:root:2019-05-10 17:09:02, Epoch : 1, Step : 113, Training Loss : 0.39937, Training Acc : 0.806, Run Time : 0.46
INFO:root:2019-05-10 17:09:05, Epoch : 1, Step : 114, Training Loss : 0.41596, Training Acc : 0.806, Run Time : 2.99
INFO:root:2019-05-10 17:09:21, Epoch : 1, Step : 115, Training Loss : 0.26633, Training Acc : 0.917, Run Time : 16.48
INFO:root:2019-05-10 17:09:22, Epoch : 1, Step : 116, Training Loss : 0.32593, Training Acc : 0.856, Run Time : 0.64
INFO:root:2019-05-10 17:09:22, Epoch : 1, Step : 117, Training Loss : 0.28168, Training Acc : 0.861, Run Time : 0.29
INFO:root:2019-05-10 17:09:23, Epoch : 1, Step : 118, Training Loss : 0.30427, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 17:09:23, Epoch : 1, Step : 119, Training Loss : 0.29852, Training Acc : 0.889, Run Time : 0.62
INFO:root:2019-05-10 17:09:40, Epoch : 1, Step : 120, Training Loss : 0.41786, Training Acc : 0.778, Run Time : 17.13
INFO:root:2019-05-10 17:09:42, Epoch : 1, Step : 121, Training Loss : 0.38982, Training Acc : 0.833, Run Time : 1.72
INFO:root:2019-05-10 17:09:55, Epoch : 1, Step : 122, Training Loss : 0.41748, Training Acc : 0.806, Run Time : 12.69
INFO:root:2019-05-10 17:09:55, Epoch : 1, Step : 123, Training Loss : 0.34556, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-10 17:09:56, Epoch : 1, Step : 124, Training Loss : 0.31541, Training Acc : 0.867, Run Time : 0.45
INFO:root:2019-05-10 17:09:56, Epoch : 1, Step : 125, Training Loss : 0.33836, Training Acc : 0.867, Run Time : 0.48
INFO:root:2019-05-10 17:09:57, Epoch : 1, Step : 126, Training Loss : 0.59326, Training Acc : 0.706, Run Time : 0.57
INFO:root:2019-05-10 17:10:00, Epoch : 1, Step : 127, Training Loss : 0.77241, Training Acc : 0.639, Run Time : 3.32
INFO:root:2019-05-10 17:10:01, Epoch : 1, Step : 128, Training Loss : 0.49551, Training Acc : 0.733, Run Time : 0.86
INFO:root:2019-05-10 17:10:19, Epoch : 1, Step : 129, Training Loss : 0.50105, Training Acc : 0.767, Run Time : 18.02
INFO:root:2019-05-10 17:10:19, Epoch : 1, Step : 130, Training Loss : 0.43237, Training Acc : 0.778, Run Time : 0.49
INFO:root:2019-05-10 17:10:20, Epoch : 1, Step : 131, Training Loss : 0.40777, Training Acc : 0.783, Run Time : 0.52
INFO:root:2019-05-10 17:10:20, Epoch : 1, Step : 132, Training Loss : 0.31331, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-10 17:10:21, Epoch : 1, Step : 133, Training Loss : 0.40507, Training Acc : 0.806, Run Time : 1.02
INFO:root:2019-05-10 17:10:40, Epoch : 1, Step : 134, Training Loss : 0.51688, Training Acc : 0.761, Run Time : 19.01
INFO:root:2019-05-10 17:10:41, Epoch : 1, Step : 135, Training Loss : 0.36930, Training Acc : 0.839, Run Time : 0.28
INFO:root:2019-05-10 17:10:41, Epoch : 1, Step : 136, Training Loss : 0.42269, Training Acc : 0.811, Run Time : 0.31
INFO:root:2019-05-10 17:10:41, Epoch : 1, Step : 137, Training Loss : 0.51300, Training Acc : 0.683, Run Time : 0.47
INFO:root:2019-05-10 17:10:42, Epoch : 1, Step : 138, Training Loss : 0.57570, Training Acc : 0.728, Run Time : 0.46
INFO:root:2019-05-10 17:11:11, Epoch : 1, Step : 139, Training Loss : 0.49940, Training Acc : 0.733, Run Time : 29.07
INFO:root:2019-05-10 17:11:22, Epoch : 1, Step : 140, Training Loss : 0.62639, Training Acc : 0.706, Run Time : 10.75
INFO:root:2019-05-10 17:11:23, Epoch : 1, Step : 141, Training Loss : 0.47718, Training Acc : 0.739, Run Time : 1.22
INFO:root:2019-05-10 17:11:24, Epoch : 1, Step : 142, Training Loss : 0.46569, Training Acc : 0.806, Run Time : 0.55
INFO:root:2019-05-10 17:11:24, Epoch : 1, Step : 143, Training Loss : 0.37304, Training Acc : 0.833, Run Time : 0.44
INFO:root:2019-05-10 17:11:24, Epoch : 1, Step : 144, Training Loss : 0.29482, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-10 17:11:43, Epoch : 1, Step : 145, Training Loss : 0.46109, Training Acc : 0.822, Run Time : 18.56
INFO:root:2019-05-10 17:11:43, Epoch : 1, Step : 146, Training Loss : 0.28831, Training Acc : 0.906, Run Time : 0.32
INFO:root:2019-05-10 17:11:44, Epoch : 1, Step : 147, Training Loss : 0.44369, Training Acc : 0.767, Run Time : 0.44
INFO:root:2019-05-10 17:11:44, Epoch : 1, Step : 148, Training Loss : 1.28930, Training Acc : 0.483, Run Time : 0.47
INFO:root:2019-05-10 17:11:45, Epoch : 1, Step : 149, Training Loss : 0.98391, Training Acc : 0.483, Run Time : 0.46
INFO:root:2019-05-10 17:12:01, Epoch : 1, Step : 150, Training Loss : 0.31651, Training Acc : 0.900, Run Time : 16.53
INFO:root:2019-05-10 17:12:02, Epoch : 1, Step : 151, Training Loss : 0.31578, Training Acc : 0.911, Run Time : 0.31
INFO:root:2019-05-10 17:12:02, Epoch : 1, Step : 152, Training Loss : 0.38990, Training Acc : 0.811, Run Time : 0.43
INFO:root:2019-05-10 17:12:02, Epoch : 1, Step : 153, Training Loss : 0.39397, Training Acc : 0.789, Run Time : 0.45
INFO:root:2019-05-10 17:12:15, Epoch : 1, Step : 154, Training Loss : 0.44052, Training Acc : 0.806, Run Time : 12.64
INFO:root:2019-05-10 17:12:16, Epoch : 1, Step : 155, Training Loss : 0.52313, Training Acc : 0.761, Run Time : 0.74
INFO:root:2019-05-10 17:12:16, Epoch : 1, Step : 156, Training Loss : 0.57577, Training Acc : 0.744, Run Time : 0.44
INFO:root:2019-05-10 17:12:17, Epoch : 1, Step : 157, Training Loss : 0.46946, Training Acc : 0.739, Run Time : 0.48
INFO:root:2019-05-10 17:12:17, Epoch : 1, Step : 158, Training Loss : 0.37277, Training Acc : 0.822, Run Time : 0.44
INFO:root:2019-05-10 17:12:34, Epoch : 1, Step : 159, Training Loss : 0.40545, Training Acc : 0.850, Run Time : 16.92
INFO:root:2019-05-10 17:12:35, Epoch : 1, Step : 160, Training Loss : 0.40692, Training Acc : 0.850, Run Time : 0.73
INFO:root:2019-05-10 17:12:35, Epoch : 1, Step : 161, Training Loss : 0.43434, Training Acc : 0.750, Run Time : 0.52
INFO:root:2019-05-10 17:12:37, Epoch : 1, Step : 162, Training Loss : 0.33030, Training Acc : 0.900, Run Time : 1.90
INFO:root:2019-05-10 17:12:50, Epoch : 1, Step : 163, Training Loss : 0.25915, Training Acc : 0.956, Run Time : 12.34
INFO:root:2019-05-10 17:12:50, Epoch : 1, Step : 164, Training Loss : 0.37544, Training Acc : 0.817, Run Time : 0.65
INFO:root:2019-05-10 17:12:51, Epoch : 1, Step : 165, Training Loss : 0.31406, Training Acc : 0.878, Run Time : 0.40
INFO:root:2019-05-10 17:12:51, Epoch : 1, Step : 166, Training Loss : 0.83622, Training Acc : 0.539, Run Time : 0.43
INFO:root:2019-05-10 17:13:04, Epoch : 1, Step : 167, Training Loss : 0.31380, Training Acc : 0.861, Run Time : 12.74
INFO:root:2019-05-10 17:13:08, Epoch : 1, Step : 168, Training Loss : 0.29857, Training Acc : 0.861, Run Time : 4.22
INFO:root:2019-05-10 17:13:08, Epoch : 1, Step : 169, Training Loss : 0.29874, Training Acc : 0.889, Run Time : 0.30
INFO:root:2019-05-10 17:13:09, Epoch : 1, Step : 170, Training Loss : 0.28607, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-10 17:13:23, Epoch : 1, Step : 171, Training Loss : 0.39813, Training Acc : 0.839, Run Time : 14.63
INFO:root:2019-05-10 17:13:24, Epoch : 1, Step : 172, Training Loss : 0.35724, Training Acc : 0.811, Run Time : 0.49
INFO:root:2019-05-10 17:13:24, Epoch : 1, Step : 173, Training Loss : 0.37347, Training Acc : 0.844, Run Time : 0.29
INFO:root:2019-05-10 17:13:38, Epoch : 1, Step : 174, Training Loss : 0.37284, Training Acc : 0.844, Run Time : 13.90
INFO:root:2019-05-10 17:13:39, Epoch : 1, Step : 175, Training Loss : 0.51920, Training Acc : 0.772, Run Time : 0.44
INFO:root:2019-05-10 17:13:39, Epoch : 1, Step : 176, Training Loss : 0.27922, Training Acc : 0.900, Run Time : 0.21
INFO:root:2019-05-10 17:13:39, Epoch : 1, Step : 177, Training Loss : 0.38676, Training Acc : 0.822, Run Time : 0.40
INFO:root:2019-05-10 17:13:51, Epoch : 1, Step : 178, Training Loss : 0.27752, Training Acc : 0.917, Run Time : 11.78
INFO:root:2019-05-10 17:13:52, Epoch : 1, Step : 179, Training Loss : 0.26606, Training Acc : 0.900, Run Time : 0.74
INFO:root:2019-05-10 17:13:52, Epoch : 1, Step : 180, Training Loss : 0.29961, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-10 17:13:53, Epoch : 1, Step : 181, Training Loss : 0.35898, Training Acc : 0.844, Run Time : 0.60
INFO:root:2019-05-10 17:13:53, Epoch : 1, Step : 182, Training Loss : 0.36076, Training Acc : 0.844, Run Time : 0.37
INFO:root:2019-05-10 17:14:11, Epoch : 1, Step : 183, Training Loss : 0.34404, Training Acc : 0.850, Run Time : 18.25
INFO:root:2019-05-10 17:14:12, Epoch : 1, Step : 184, Training Loss : 0.39470, Training Acc : 0.822, Run Time : 0.23
INFO:root:2019-05-10 17:14:12, Epoch : 1, Step : 185, Training Loss : 0.32619, Training Acc : 0.856, Run Time : 0.40
INFO:root:2019-05-10 17:14:12, Epoch : 1, Step : 186, Training Loss : 0.31516, Training Acc : 0.878, Run Time : 0.45
INFO:root:2019-05-10 17:14:13, Epoch : 1, Step : 187, Training Loss : 0.32223, Training Acc : 0.856, Run Time : 0.39
INFO:root:2019-05-10 17:14:30, Epoch : 1, Step : 188, Training Loss : 0.48557, Training Acc : 0.778, Run Time : 17.68
INFO:root:2019-05-10 17:14:31, Epoch : 1, Step : 189, Training Loss : 0.34386, Training Acc : 0.894, Run Time : 0.31
INFO:root:2019-05-10 17:14:31, Epoch : 1, Step : 190, Training Loss : 0.33222, Training Acc : 0.878, Run Time : 0.45
INFO:root:2019-05-10 17:14:32, Epoch : 1, Step : 191, Training Loss : 0.45690, Training Acc : 0.811, Run Time : 0.46
INFO:root:2019-05-10 17:14:32, Epoch : 1, Step : 192, Training Loss : 0.32323, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 17:14:51, Epoch : 1, Step : 193, Training Loss : 0.41354, Training Acc : 0.822, Run Time : 18.75
INFO:root:2019-05-10 17:14:51, Epoch : 1, Step : 194, Training Loss : 0.49810, Training Acc : 0.711, Run Time : 0.25
INFO:root:2019-05-10 17:14:52, Epoch : 1, Step : 195, Training Loss : 0.45903, Training Acc : 0.761, Run Time : 0.61
INFO:root:2019-05-10 17:14:52, Epoch : 1, Step : 196, Training Loss : 0.37071, Training Acc : 0.822, Run Time : 0.45
INFO:root:2019-05-10 17:14:53, Epoch : 1, Step : 197, Training Loss : 0.41475, Training Acc : 0.767, Run Time : 0.50
INFO:root:2019-05-10 17:15:10, Epoch : 1, Step : 198, Training Loss : 0.42075, Training Acc : 0.778, Run Time : 17.18
INFO:root:2019-05-10 17:15:10, Epoch : 1, Step : 199, Training Loss : 0.35528, Training Acc : 0.828, Run Time : 0.30
INFO:root:2019-05-10 17:15:10, Epoch : 1, Step : 200, Training Loss : 0.43304, Training Acc : 0.756, Run Time : 0.33
INFO:root:2019-05-10 17:15:13, Epoch : 1, Step : 201, Training Loss : 0.57758, Training Acc : 0.656, Run Time : 2.96
INFO:root:2019-05-10 17:15:27, Epoch : 1, Step : 202, Training Loss : 0.54722, Training Acc : 0.644, Run Time : 13.80
INFO:root:2019-05-10 17:15:28, Epoch : 1, Step : 203, Training Loss : 0.55887, Training Acc : 0.700, Run Time : 1.16
INFO:root:2019-05-10 17:15:29, Epoch : 1, Step : 204, Training Loss : 0.47862, Training Acc : 0.789, Run Time : 0.41
INFO:root:2019-05-10 17:15:29, Epoch : 1, Step : 205, Training Loss : 0.47955, Training Acc : 0.722, Run Time : 0.46
INFO:root:2019-05-10 17:15:41, Epoch : 1, Step : 206, Training Loss : 0.42360, Training Acc : 0.778, Run Time : 11.83
INFO:root:2019-05-10 17:15:42, Epoch : 1, Step : 207, Training Loss : 0.43625, Training Acc : 0.728, Run Time : 0.51
INFO:root:2019-05-10 17:15:42, Epoch : 1, Step : 208, Training Loss : 0.38000, Training Acc : 0.806, Run Time : 0.23
INFO:root:2019-05-10 17:15:42, Epoch : 1, Step : 209, Training Loss : 0.32620, Training Acc : 0.806, Run Time : 0.46
INFO:root:2019-05-10 17:15:43, Epoch : 1, Step : 210, Training Loss : 0.52886, Training Acc : 0.789, Run Time : 0.48
INFO:root:2019-05-10 17:16:01, Epoch : 1, Step : 211, Training Loss : 0.45406, Training Acc : 0.811, Run Time : 18.39
INFO:root:2019-05-10 17:16:02, Epoch : 1, Step : 212, Training Loss : 0.43925, Training Acc : 0.806, Run Time : 0.63
INFO:root:2019-05-10 17:16:03, Epoch : 1, Step : 213, Training Loss : 0.39118, Training Acc : 0.811, Run Time : 0.78
INFO:root:2019-05-10 17:16:03, Epoch : 1, Step : 214, Training Loss : 0.36748, Training Acc : 0.844, Run Time : 0.43
INFO:root:2019-05-10 17:16:19, Epoch : 1, Step : 215, Training Loss : 0.44175, Training Acc : 0.817, Run Time : 15.71
INFO:root:2019-05-10 17:16:19, Epoch : 1, Step : 216, Training Loss : 0.40603, Training Acc : 0.817, Run Time : 0.60
INFO:root:2019-05-10 17:16:20, Epoch : 1, Step : 217, Training Loss : 0.38242, Training Acc : 0.833, Run Time : 0.43
INFO:root:2019-05-10 17:16:20, Epoch : 1, Step : 218, Training Loss : 0.33252, Training Acc : 0.856, Run Time : 0.42
INFO:root:2019-05-10 17:16:31, Epoch : 1, Step : 219, Training Loss : 0.36608, Training Acc : 0.806, Run Time : 10.80
INFO:root:2019-05-10 17:16:33, Epoch : 1, Step : 220, Training Loss : 0.36061, Training Acc : 0.822, Run Time : 2.10
INFO:root:2019-05-10 17:16:45, Epoch : 1, Step : 221, Training Loss : 0.39639, Training Acc : 0.817, Run Time : 11.94
INFO:root:2019-05-10 17:16:46, Epoch : 1, Step : 222, Training Loss : 0.39353, Training Acc : 0.794, Run Time : 0.47
INFO:root:2019-05-10 17:16:46, Epoch : 1, Step : 223, Training Loss : 0.75766, Training Acc : 0.800, Run Time : 0.43
INFO:root:2019-05-10 17:16:46, Epoch : 1, Step : 224, Training Loss : 0.43000, Training Acc : 0.778, Run Time : 0.46
INFO:root:2019-05-10 17:16:47, Epoch : 1, Step : 225, Training Loss : 0.43502, Training Acc : 0.750, Run Time : 0.47
INFO:root:2019-05-10 17:16:55, Epoch : 1, Step : 226, Training Loss : 0.44826, Training Acc : 0.772, Run Time : 7.88
INFO:root:2019-05-10 17:17:07, Epoch : 1, Step : 227, Training Loss : 0.40752, Training Acc : 0.800, Run Time : 12.22
INFO:root:2019-05-10 17:17:08, Epoch : 1, Step : 228, Training Loss : 0.43881, Training Acc : 0.811, Run Time : 0.63
INFO:root:2019-05-10 17:17:08, Epoch : 1, Step : 229, Training Loss : 0.53661, Training Acc : 0.783, Run Time : 0.28
INFO:root:2019-05-10 17:17:09, Epoch : 1, Step : 230, Training Loss : 0.59424, Training Acc : 0.683, Run Time : 0.92
INFO:root:2019-05-10 17:17:10, Epoch : 1, Step : 231, Training Loss : 0.40049, Training Acc : 0.767, Run Time : 1.69
INFO:root:2019-05-10 17:17:28, Epoch : 1, Step : 232, Training Loss : 0.45502, Training Acc : 0.744, Run Time : 17.09
INFO:root:2019-05-10 17:17:28, Epoch : 1, Step : 233, Training Loss : 0.41345, Training Acc : 0.717, Run Time : 0.78
INFO:root:2019-05-10 17:17:29, Epoch : 1, Step : 234, Training Loss : 0.49103, Training Acc : 0.711, Run Time : 0.43
INFO:root:2019-05-10 17:17:29, Epoch : 1, Step : 235, Training Loss : 0.39234, Training Acc : 0.817, Run Time : 0.44
INFO:root:2019-05-10 17:17:44, Epoch : 1, Step : 236, Training Loss : 0.42619, Training Acc : 0.756, Run Time : 14.44
INFO:root:2019-05-10 17:17:44, Epoch : 1, Step : 237, Training Loss : 0.43623, Training Acc : 0.728, Run Time : 0.48
INFO:root:2019-05-10 17:17:44, Epoch : 1, Step : 238, Training Loss : 0.59407, Training Acc : 0.750, Run Time : 0.29
INFO:root:2019-05-10 17:17:49, Epoch : 1, Step : 239, Training Loss : 0.43567, Training Acc : 0.778, Run Time : 4.77
INFO:root:2019-05-10 17:18:01, Epoch : 1, Step : 240, Training Loss : 0.49505, Training Acc : 0.794, Run Time : 12.01
INFO:root:2019-05-10 17:18:02, Epoch : 1, Step : 241, Training Loss : 0.39330, Training Acc : 0.828, Run Time : 0.46
INFO:root:2019-05-10 17:18:02, Epoch : 1, Step : 242, Training Loss : 0.45888, Training Acc : 0.783, Run Time : 0.53
INFO:root:2019-05-10 17:18:03, Epoch : 1, Step : 243, Training Loss : 0.44830, Training Acc : 0.772, Run Time : 0.47
INFO:root:2019-05-10 17:18:03, Epoch : 1, Step : 244, Training Loss : 0.44287, Training Acc : 0.739, Run Time : 0.50
INFO:root:2019-05-10 17:18:26, Epoch : 1, Step : 245, Training Loss : 0.41049, Training Acc : 0.806, Run Time : 22.80
INFO:root:2019-05-10 17:18:27, Epoch : 1, Step : 246, Training Loss : 0.41243, Training Acc : 0.806, Run Time : 0.64
INFO:root:2019-05-10 17:18:27, Epoch : 1, Step : 247, Training Loss : 0.40854, Training Acc : 0.811, Run Time : 0.35
INFO:root:2019-05-10 17:18:39, Epoch : 1, Step : 248, Training Loss : 0.33841, Training Acc : 0.850, Run Time : 12.45
INFO:root:2019-05-10 17:18:40, Epoch : 1, Step : 249, Training Loss : 0.37797, Training Acc : 0.806, Run Time : 0.70
INFO:root:2019-05-10 17:18:41, Epoch : 1, Step : 250, Training Loss : 0.33231, Training Acc : 0.878, Run Time : 0.57
INFO:root:2019-05-10 17:18:52, Epoch : 1, Step : 251, Training Loss : 0.40129, Training Acc : 0.789, Run Time : 11.58
INFO:root:2019-05-10 17:18:53, Epoch : 1, Step : 252, Training Loss : 0.38829, Training Acc : 0.794, Run Time : 0.76
INFO:root:2019-05-10 17:18:53, Epoch : 1, Step : 253, Training Loss : 0.36610, Training Acc : 0.783, Run Time : 0.46
INFO:root:2019-05-10 17:18:54, Epoch : 1, Step : 254, Training Loss : 0.34724, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-10 17:18:54, Epoch : 1, Step : 255, Training Loss : 0.39729, Training Acc : 0.783, Run Time : 0.24
INFO:root:2019-05-10 17:19:14, Epoch : 1, Step : 256, Training Loss : 0.38731, Training Acc : 0.794, Run Time : 19.70
INFO:root:2019-05-10 17:19:15, Epoch : 1, Step : 257, Training Loss : 0.39055, Training Acc : 0.767, Run Time : 0.89
INFO:root:2019-05-10 17:19:27, Epoch : 1, Step : 258, Training Loss : 0.34447, Training Acc : 0.839, Run Time : 12.44
INFO:root:2019-05-10 17:19:28, Epoch : 1, Step : 259, Training Loss : 0.35661, Training Acc : 0.789, Run Time : 0.81
INFO:root:2019-05-10 17:19:29, Epoch : 1, Step : 260, Training Loss : 0.31104, Training Acc : 0.839, Run Time : 0.50
INFO:root:2019-05-10 17:19:29, Epoch : 1, Step : 261, Training Loss : 0.36265, Training Acc : 0.822, Run Time : 0.52
INFO:root:2019-05-10 17:19:30, Epoch : 1, Step : 262, Training Loss : 0.35691, Training Acc : 0.817, Run Time : 0.50
INFO:root:2019-05-10 17:19:44, Epoch : 1, Step : 263, Training Loss : 0.30958, Training Acc : 0.844, Run Time : 14.73
INFO:root:2019-05-10 17:19:45, Epoch : 1, Step : 264, Training Loss : 0.32203, Training Acc : 0.828, Run Time : 0.33
INFO:root:2019-05-10 17:19:45, Epoch : 1, Step : 265, Training Loss : 0.35441, Training Acc : 0.789, Run Time : 0.58
INFO:root:2019-05-10 17:19:54, Epoch : 1, Step : 266, Training Loss : 0.37787, Training Acc : 0.828, Run Time : 9.26
INFO:root:2019-05-10 17:20:06, Epoch : 1, Step : 267, Training Loss : 0.32437, Training Acc : 0.833, Run Time : 11.90
INFO:root:2019-05-10 17:20:07, Epoch : 1, Step : 268, Training Loss : 0.31589, Training Acc : 0.839, Run Time : 0.43
INFO:root:2019-05-10 17:20:09, Epoch : 1, Step : 269, Training Loss : 0.30555, Training Acc : 0.833, Run Time : 1.91
INFO:root:2019-05-10 17:20:18, Epoch : 1, Step : 270, Training Loss : 0.31835, Training Acc : 0.844, Run Time : 9.60
INFO:root:2019-05-10 17:20:19, Epoch : 1, Step : 271, Training Loss : 0.39434, Training Acc : 0.761, Run Time : 0.38
INFO:root:2019-05-10 17:20:19, Epoch : 1, Step : 272, Training Loss : 0.37419, Training Acc : 0.789, Run Time : 0.21
INFO:root:2019-05-10 17:20:19, Epoch : 1, Step : 273, Training Loss : 0.31663, Training Acc : 0.839, Run Time : 0.34
INFO:root:2019-05-10 17:20:20, Epoch : 1, Step : 274, Training Loss : 0.36068, Training Acc : 0.789, Run Time : 0.31
INFO:root:2019-05-10 17:20:44, Epoch : 1, Step : 275, Training Loss : 0.35069, Training Acc : 0.778, Run Time : 24.17
INFO:root:2019-05-10 17:20:44, Epoch : 1, Step : 276, Training Loss : 0.31933, Training Acc : 0.828, Run Time : 0.62
INFO:root:2019-05-10 17:20:45, Epoch : 1, Step : 277, Training Loss : 0.33529, Training Acc : 0.833, Run Time : 0.42
INFO:root:2019-05-10 17:20:58, Epoch : 1, Step : 278, Training Loss : 0.38322, Training Acc : 0.756, Run Time : 13.58
INFO:root:2019-05-10 17:20:59, Epoch : 1, Step : 279, Training Loss : 0.38083, Training Acc : 0.806, Run Time : 0.52
INFO:root:2019-05-10 17:20:59, Epoch : 1, Step : 280, Training Loss : 0.43817, Training Acc : 0.761, Run Time : 0.42
INFO:root:2019-05-10 17:21:00, Epoch : 1, Step : 281, Training Loss : 0.36369, Training Acc : 0.800, Run Time : 0.45
INFO:root:2019-05-10 17:21:01, Epoch : 1, Step : 282, Training Loss : 0.79093, Training Acc : 0.672, Run Time : 1.27
INFO:root:2019-05-10 17:21:16, Epoch : 1, Step : 283, Training Loss : 0.81905, Training Acc : 0.683, Run Time : 15.37
INFO:root:2019-05-10 17:21:17, Epoch : 1, Step : 284, Training Loss : 0.36603, Training Acc : 0.839, Run Time : 0.24
INFO:root:2019-05-10 17:21:17, Epoch : 1, Step : 285, Training Loss : 0.59371, Training Acc : 0.728, Run Time : 0.45
INFO:root:2019-05-10 17:21:18, Epoch : 1, Step : 286, Training Loss : 0.54506, Training Acc : 0.783, Run Time : 0.45
INFO:root:2019-05-10 17:21:18, Epoch : 1, Step : 287, Training Loss : 0.49416, Training Acc : 0.811, Run Time : 0.47
INFO:root:2019-05-10 17:21:22, Epoch : 1, Step : 288, Training Loss : 0.39903, Training Acc : 0.822, Run Time : 4.08
INFO:root:2019-05-10 17:21:23, Epoch : 1, Step : 289, Training Loss : 0.44479, Training Acc : 0.811, Run Time : 0.49
INFO:root:2019-05-10 17:21:41, Epoch : 1, Step : 290, Training Loss : 0.50084, Training Acc : 0.683, Run Time : 18.89
INFO:root:2019-05-10 17:21:42, Epoch : 1, Step : 291, Training Loss : 0.33048, Training Acc : 0.861, Run Time : 0.23
INFO:root:2019-05-10 17:21:42, Epoch : 1, Step : 292, Training Loss : 0.39838, Training Acc : 0.833, Run Time : 0.43
INFO:root:2019-05-10 17:21:44, Epoch : 1, Step : 293, Training Loss : 0.37433, Training Acc : 0.778, Run Time : 2.05
INFO:root:2019-05-10 17:21:50, Epoch : 1, Step : 294, Training Loss : 0.43293, Training Acc : 0.750, Run Time : 5.66
INFO:root:2019-05-10 17:21:51, Epoch : 1, Step : 295, Training Loss : 0.37214, Training Acc : 0.822, Run Time : 0.68
INFO:root:2019-05-10 17:21:51, Epoch : 1, Step : 296, Training Loss : 0.34597, Training Acc : 0.867, Run Time : 0.53
INFO:root:2019-05-10 17:21:52, Epoch : 1, Step : 297, Training Loss : 0.33989, Training Acc : 0.800, Run Time : 1.35
INFO:root:2019-05-10 17:22:05, Epoch : 1, Step : 298, Training Loss : 0.36683, Training Acc : 0.844, Run Time : 12.27
INFO:root:2019-05-10 17:22:05, Epoch : 1, Step : 299, Training Loss : 0.42722, Training Acc : 0.839, Run Time : 0.76
INFO:root:2019-05-10 17:22:06, Epoch : 1, Step : 300, Training Loss : 0.37385, Training Acc : 0.794, Run Time : 0.32
INFO:root:2019-05-10 17:22:07, Epoch : 1, Step : 301, Training Loss : 0.37757, Training Acc : 0.783, Run Time : 0.87
INFO:root:2019-05-10 17:22:07, Epoch : 1, Step : 302, Training Loss : 0.40542, Training Acc : 0.789, Run Time : 0.41
INFO:root:2019-05-10 17:22:25, Epoch : 1, Step : 303, Training Loss : 0.27223, Training Acc : 0.911, Run Time : 17.79
INFO:root:2019-05-10 17:22:25, Epoch : 1, Step : 304, Training Loss : 0.32029, Training Acc : 0.828, Run Time : 0.63
INFO:root:2019-05-10 17:22:26, Epoch : 1, Step : 305, Training Loss : 0.29497, Training Acc : 0.867, Run Time : 0.61
INFO:root:2019-05-10 17:22:26, Epoch : 1, Step : 306, Training Loss : 0.27688, Training Acc : 0.883, Run Time : 0.21
INFO:root:2019-05-10 17:22:26, Epoch : 1, Step : 307, Training Loss : 0.35758, Training Acc : 0.839, Run Time : 0.21
INFO:root:2019-05-10 17:22:46, Epoch : 1, Step : 308, Training Loss : 0.29429, Training Acc : 0.894, Run Time : 19.45
INFO:root:2019-05-10 17:22:46, Epoch : 1, Step : 309, Training Loss : 0.37225, Training Acc : 0.839, Run Time : 0.23
INFO:root:2019-05-10 17:22:46, Epoch : 1, Step : 310, Training Loss : 0.24899, Training Acc : 0.906, Run Time : 0.31
INFO:root:2019-05-10 17:22:47, Epoch : 1, Step : 311, Training Loss : 0.39114, Training Acc : 0.794, Run Time : 0.43
INFO:root:2019-05-10 17:22:47, Epoch : 1, Step : 312, Training Loss : 0.29088, Training Acc : 0.867, Run Time : 0.51
INFO:root:2019-05-10 17:23:04, Epoch : 1, Step : 313, Training Loss : 0.34179, Training Acc : 0.828, Run Time : 17.03
INFO:root:2019-05-10 17:23:05, Epoch : 1, Step : 314, Training Loss : 0.32390, Training Acc : 0.861, Run Time : 0.32
INFO:root:2019-05-10 17:23:05, Epoch : 1, Step : 315, Training Loss : 0.29237, Training Acc : 0.861, Run Time : 0.37
INFO:root:2019-05-10 17:23:06, Epoch : 1, Step : 316, Training Loss : 0.24361, Training Acc : 0.911, Run Time : 0.74
INFO:root:2019-05-10 17:23:07, Epoch : 1, Step : 317, Training Loss : 0.32526, Training Acc : 0.822, Run Time : 1.07
INFO:root:2019-05-10 17:23:21, Epoch : 1, Step : 318, Training Loss : 0.27145, Training Acc : 0.878, Run Time : 13.84
INFO:root:2019-05-10 17:23:22, Epoch : 1, Step : 319, Training Loss : 0.34026, Training Acc : 0.817, Run Time : 0.81
INFO:root:2019-05-10 17:23:22, Epoch : 1, Step : 320, Training Loss : 0.27690, Training Acc : 0.867, Run Time : 0.43
INFO:root:2019-05-10 17:23:22, Epoch : 1, Step : 321, Training Loss : 0.27663, Training Acc : 0.867, Run Time : 0.41
INFO:root:2019-05-10 17:23:23, Epoch : 1, Step : 322, Training Loss : 0.27214, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-10 17:23:41, Epoch : 1, Step : 323, Training Loss : 0.27661, Training Acc : 0.872, Run Time : 17.63
INFO:root:2019-05-10 17:23:41, Epoch : 1, Step : 324, Training Loss : 0.24958, Training Acc : 0.911, Run Time : 0.28
INFO:root:2019-05-10 17:23:41, Epoch : 1, Step : 325, Training Loss : 0.23176, Training Acc : 0.900, Run Time : 0.45
INFO:root:2019-05-10 17:23:42, Epoch : 1, Step : 326, Training Loss : 0.28823, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 17:23:55, Epoch : 1, Step : 327, Training Loss : 0.37097, Training Acc : 0.806, Run Time : 12.84
INFO:root:2019-05-10 17:23:55, Epoch : 1, Step : 328, Training Loss : 0.21558, Training Acc : 0.917, Run Time : 0.90
INFO:root:2019-05-10 17:23:56, Epoch : 1, Step : 329, Training Loss : 0.31580, Training Acc : 0.856, Run Time : 0.23
INFO:root:2019-05-10 17:23:56, Epoch : 1, Step : 330, Training Loss : 0.24912, Training Acc : 0.922, Run Time : 0.43
INFO:root:2019-05-10 17:24:07, Epoch : 1, Step : 331, Training Loss : 0.28258, Training Acc : 0.883, Run Time : 10.83
INFO:root:2019-05-10 17:24:08, Epoch : 1, Step : 332, Training Loss : 0.25458, Training Acc : 0.872, Run Time : 0.68
INFO:root:2019-05-10 17:24:08, Epoch : 1, Step : 333, Training Loss : 0.31042, Training Acc : 0.817, Run Time : 0.41
INFO:root:2019-05-10 17:24:08, Epoch : 1, Step : 334, Training Loss : 0.29390, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 17:24:09, Epoch : 1, Step : 335, Training Loss : 0.41369, Training Acc : 0.872, Run Time : 0.31
INFO:root:2019-05-10 17:24:26, Epoch : 1, Step : 336, Training Loss : 0.24041, Training Acc : 0.928, Run Time : 17.03
INFO:root:2019-05-10 17:24:27, Epoch : 1, Step : 337, Training Loss : 0.29939, Training Acc : 0.850, Run Time : 0.88
INFO:root:2019-05-10 17:24:27, Epoch : 1, Step : 338, Training Loss : 0.32772, Training Acc : 0.883, Run Time : 0.44
INFO:root:2019-05-10 17:24:28, Epoch : 1, Step : 339, Training Loss : 0.29692, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-10 17:24:28, Epoch : 1, Step : 340, Training Loss : 0.33950, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-10 17:24:47, Epoch : 1, Step : 341, Training Loss : 0.20030, Training Acc : 0.894, Run Time : 18.50
INFO:root:2019-05-10 17:24:47, Epoch : 1, Step : 342, Training Loss : 0.31320, Training Acc : 0.850, Run Time : 0.24
INFO:root:2019-05-10 17:24:47, Epoch : 1, Step : 343, Training Loss : 0.24750, Training Acc : 0.906, Run Time : 0.27
INFO:root:2019-05-10 17:24:48, Epoch : 1, Step : 344, Training Loss : 0.23883, Training Acc : 0.889, Run Time : 0.87
INFO:root:2019-05-10 17:24:59, Epoch : 1, Step : 345, Training Loss : 0.27932, Training Acc : 0.850, Run Time : 10.97
INFO:root:2019-05-10 17:25:01, Epoch : 1, Step : 346, Training Loss : 0.31951, Training Acc : 0.839, Run Time : 1.77
INFO:root:2019-05-10 17:25:01, Epoch : 1, Step : 347, Training Loss : 0.25632, Training Acc : 0.889, Run Time : 0.43
INFO:root:2019-05-10 17:25:02, Epoch : 1, Step : 348, Training Loss : 0.22776, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-10 17:25:02, Epoch : 1, Step : 349, Training Loss : 0.27355, Training Acc : 0.872, Run Time : 0.45
INFO:root:2019-05-10 17:25:15, Epoch : 1, Step : 350, Training Loss : 0.30526, Training Acc : 0.839, Run Time : 13.43
INFO:root:2019-05-10 17:25:16, Epoch : 1, Step : 351, Training Loss : 0.25025, Training Acc : 0.867, Run Time : 0.56
INFO:root:2019-05-10 17:25:16, Epoch : 1, Step : 352, Training Loss : 0.21533, Training Acc : 0.878, Run Time : 0.23
INFO:root:2019-05-10 17:25:23, Epoch : 1, Step : 353, Training Loss : 0.21433, Training Acc : 0.894, Run Time : 6.35
INFO:root:2019-05-10 17:25:27, Epoch : 1, Step : 354, Training Loss : 0.21433, Training Acc : 0.911, Run Time : 4.44
INFO:root:2019-05-10 17:25:27, Epoch : 1, Step : 355, Training Loss : 0.28232, Training Acc : 0.878, Run Time : 0.40
INFO:root:2019-05-10 17:25:28, Epoch : 1, Step : 356, Training Loss : 0.26082, Training Acc : 0.917, Run Time : 0.33
INFO:root:2019-05-10 17:25:40, Epoch : 1, Step : 357, Training Loss : 0.22234, Training Acc : 0.906, Run Time : 11.89
INFO:root:2019-05-10 17:25:41, Epoch : 1, Step : 358, Training Loss : 0.20795, Training Acc : 0.928, Run Time : 1.15
INFO:root:2019-05-10 17:25:41, Epoch : 1, Step : 359, Training Loss : 0.22986, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-10 17:25:42, Epoch : 1, Step : 360, Training Loss : 0.27531, Training Acc : 0.889, Run Time : 0.72
INFO:root:2019-05-10 17:25:42, Epoch : 1, Step : 361, Training Loss : 0.24937, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-10 17:26:03, Epoch : 1, Step : 362, Training Loss : 0.19713, Training Acc : 0.939, Run Time : 20.23
INFO:root:2019-05-10 17:26:03, Epoch : 1, Step : 363, Training Loss : 0.19534, Training Acc : 0.933, Run Time : 0.68
INFO:root:2019-05-10 17:26:04, Epoch : 1, Step : 364, Training Loss : 0.21744, Training Acc : 0.933, Run Time : 0.78
INFO:root:2019-05-10 17:26:04, Epoch : 1, Step : 365, Training Loss : 0.16985, Training Acc : 0.933, Run Time : 0.45
INFO:root:2019-05-10 17:26:05, Epoch : 1, Step : 366, Training Loss : 0.20537, Training Acc : 0.911, Run Time : 0.44
INFO:root:2019-05-10 17:26:21, Epoch : 1, Step : 367, Training Loss : 0.18301, Training Acc : 0.928, Run Time : 15.88
INFO:root:2019-05-10 17:26:21, Epoch : 1, Step : 368, Training Loss : 0.27240, Training Acc : 0.844, Run Time : 0.31
INFO:root:2019-05-10 17:26:22, Epoch : 1, Step : 369, Training Loss : 0.15769, Training Acc : 0.961, Run Time : 0.42
INFO:root:2019-05-10 17:26:22, Epoch : 1, Step : 370, Training Loss : 0.23095, Training Acc : 0.922, Run Time : 0.36
INFO:root:2019-05-10 17:26:22, Epoch : 1, Step : 371, Training Loss : 0.16417, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-10 17:26:41, Epoch : 1, Step : 372, Training Loss : 0.18982, Training Acc : 0.928, Run Time : 18.75
INFO:root:2019-05-10 17:26:41, Epoch : 1, Step : 373, Training Loss : 0.19591, Training Acc : 0.894, Run Time : 0.24
INFO:root:2019-05-10 17:26:42, Epoch : 1, Step : 374, Training Loss : 0.13809, Training Acc : 0.972, Run Time : 0.21
INFO:root:2019-05-10 17:26:42, Epoch : 1, Step : 375, Training Loss : 0.15864, Training Acc : 0.944, Run Time : 0.31
INFO:root:2019-05-10 17:26:42, Epoch : 1, Step : 376, Training Loss : 0.25161, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-10 17:26:59, Epoch : 1, Step : 377, Training Loss : 0.14347, Training Acc : 0.939, Run Time : 17.15
INFO:root:2019-05-10 17:27:00, Epoch : 1, Step : 378, Training Loss : 0.19855, Training Acc : 0.928, Run Time : 0.29
INFO:root:2019-05-10 17:27:00, Epoch : 1, Step : 379, Training Loss : 0.18425, Training Acc : 0.906, Run Time : 0.40
INFO:root:2019-05-10 17:27:01, Epoch : 1, Step : 380, Training Loss : 0.17105, Training Acc : 0.944, Run Time : 0.56
INFO:root:2019-05-10 17:27:01, Epoch : 1, Step : 381, Training Loss : 0.23079, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 17:27:21, Epoch : 1, Step : 382, Training Loss : 0.15764, Training Acc : 0.939, Run Time : 19.61
INFO:root:2019-05-10 17:27:22, Epoch : 1, Step : 383, Training Loss : 0.17361, Training Acc : 0.944, Run Time : 0.92
INFO:root:2019-05-10 17:27:22, Epoch : 1, Step : 384, Training Loss : 0.17185, Training Acc : 0.928, Run Time : 0.42
INFO:root:2019-05-10 17:27:23, Epoch : 1, Step : 385, Training Loss : 0.22498, Training Acc : 0.911, Run Time : 0.44
INFO:root:2019-05-10 17:27:23, Epoch : 1, Step : 386, Training Loss : 0.17735, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-10 17:27:42, Epoch : 1, Step : 387, Training Loss : 0.17413, Training Acc : 0.944, Run Time : 18.97
INFO:root:2019-05-10 17:27:42, Epoch : 1, Step : 388, Training Loss : 0.43600, Training Acc : 0.861, Run Time : 0.32
INFO:root:2019-05-10 17:27:43, Epoch : 1, Step : 389, Training Loss : 0.74979, Training Acc : 0.744, Run Time : 0.42
INFO:root:2019-05-10 17:27:43, Epoch : 1, Step : 390, Training Loss : 0.25905, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-10 17:27:43, Epoch : 1, Step : 391, Training Loss : 0.18357, Training Acc : 0.933, Run Time : 0.39
INFO:root:2019-05-10 17:28:05, Epoch : 1, Step : 392, Training Loss : 0.27177, Training Acc : 0.900, Run Time : 21.84
INFO:root:2019-05-10 17:28:06, Epoch : 1, Step : 393, Training Loss : 0.29945, Training Acc : 0.883, Run Time : 0.40
INFO:root:2019-05-10 17:28:06, Epoch : 1, Step : 394, Training Loss : 0.37224, Training Acc : 0.883, Run Time : 0.42
INFO:root:2019-05-10 17:28:07, Epoch : 1, Step : 395, Training Loss : 0.24485, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-10 17:28:07, Epoch : 1, Step : 396, Training Loss : 0.26786, Training Acc : 0.889, Run Time : 0.49
INFO:root:2019-05-10 17:28:30, Epoch : 1, Step : 397, Training Loss : 0.25208, Training Acc : 0.883, Run Time : 22.69
INFO:root:2019-05-10 17:28:30, Epoch : 1, Step : 398, Training Loss : 0.29765, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-10 17:28:31, Epoch : 1, Step : 399, Training Loss : 0.19458, Training Acc : 0.911, Run Time : 0.43
INFO:root:2019-05-10 17:28:44, Epoch : 1, Step : 400, Training Loss : 0.40594, Training Acc : 0.839, Run Time : 13.37
INFO:root:2019-05-10 17:28:46, Epoch : 1, Step : 401, Training Loss : 0.56617, Training Acc : 0.717, Run Time : 1.92
INFO:root:2019-05-10 17:28:59, Epoch : 1, Step : 402, Training Loss : 0.36495, Training Acc : 0.767, Run Time : 13.44
INFO:root:2019-05-10 17:29:00, Epoch : 1, Step : 403, Training Loss : 0.43884, Training Acc : 0.783, Run Time : 0.50
INFO:root:2019-05-10 17:29:01, Epoch : 1, Step : 404, Training Loss : 0.43854, Training Acc : 0.794, Run Time : 0.69
INFO:root:2019-05-10 17:29:01, Epoch : 1, Step : 405, Training Loss : 0.38795, Training Acc : 0.806, Run Time : 0.51
INFO:root:2019-05-10 17:29:02, Epoch : 1, Step : 406, Training Loss : 0.36031, Training Acc : 0.844, Run Time : 0.49
INFO:root:2019-05-10 17:29:20, Epoch : 1, Step : 407, Training Loss : 0.38476, Training Acc : 0.811, Run Time : 18.69
INFO:root:2019-05-10 17:29:21, Epoch : 1, Step : 408, Training Loss : 0.35898, Training Acc : 0.883, Run Time : 0.23
INFO:root:2019-05-10 17:29:21, Epoch : 1, Step : 409, Training Loss : 0.39506, Training Acc : 0.850, Run Time : 0.24
INFO:root:2019-05-10 17:29:21, Epoch : 1, Step : 410, Training Loss : 0.33893, Training Acc : 0.833, Run Time : 0.27
INFO:root:2019-05-10 17:29:31, Epoch : 1, Step : 411, Training Loss : 0.26654, Training Acc : 0.878, Run Time : 10.31
INFO:root:2019-05-10 17:29:36, Epoch : 1, Step : 412, Training Loss : 0.41431, Training Acc : 0.767, Run Time : 4.31
INFO:root:2019-05-10 17:29:47, Epoch : 1, Step : 413, Training Loss : 0.40839, Training Acc : 0.778, Run Time : 11.75
INFO:root:2019-05-10 17:29:49, Epoch : 1, Step : 414, Training Loss : 0.29159, Training Acc : 0.878, Run Time : 1.59
INFO:root:2019-05-10 17:29:49, Epoch : 1, Step : 415, Training Loss : 0.55163, Training Acc : 0.694, Run Time : 0.42
INFO:root:2019-05-10 17:29:50, Epoch : 1, Step : 416, Training Loss : 0.34462, Training Acc : 0.817, Run Time : 0.52
INFO:root:2019-05-10 17:29:50, Epoch : 1, Step : 417, Training Loss : 0.29027, Training Acc : 0.878, Run Time : 0.49
INFO:root:2019-05-10 17:30:08, Epoch : 1, Step : 418, Training Loss : 0.34331, Training Acc : 0.806, Run Time : 17.86
INFO:root:2019-05-10 17:30:09, Epoch : 1, Step : 419, Training Loss : 0.38657, Training Acc : 0.778, Run Time : 0.22
INFO:root:2019-05-10 17:30:09, Epoch : 1, Step : 420, Training Loss : 0.29446, Training Acc : 0.861, Run Time : 0.22
INFO:root:2019-05-10 17:30:09, Epoch : 1, Step : 421, Training Loss : 0.31539, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-10 17:30:10, Epoch : 1, Step : 422, Training Loss : 0.28087, Training Acc : 0.889, Run Time : 0.94
INFO:root:2019-05-10 17:30:26, Epoch : 1, Step : 423, Training Loss : 0.24614, Training Acc : 0.906, Run Time : 15.81
INFO:root:2019-05-10 17:30:27, Epoch : 1, Step : 424, Training Loss : 0.21110, Training Acc : 0.928, Run Time : 0.74
INFO:root:2019-05-10 17:30:27, Epoch : 1, Step : 425, Training Loss : 0.23527, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-10 17:30:28, Epoch : 1, Step : 426, Training Loss : 0.18878, Training Acc : 0.967, Run Time : 0.49
INFO:root:2019-05-10 17:31:00, Epoch : 1, Step : 427, Training Loss : 0.18666, Training Acc : 0.944, Run Time : 32.65
INFO:root:2019-05-10 17:31:21, Epoch : 1, Step : 428, Training Loss : 0.25091, Training Acc : 0.911, Run Time : 20.62
INFO:root:2019-05-10 17:31:32, Epoch : 1, Step : 429, Training Loss : 0.28817, Training Acc : 0.856, Run Time : 11.09
INFO:root:2019-05-10 17:31:38, Epoch : 1, Step : 430, Training Loss : 0.25461, Training Acc : 0.894, Run Time : 6.54
INFO:root:2019-05-10 17:31:39, Epoch : 1, Step : 431, Training Loss : 0.36140, Training Acc : 0.828, Run Time : 0.51
INFO:root:2019-05-10 17:31:40, Epoch : 1, Step : 432, Training Loss : 0.47133, Training Acc : 0.783, Run Time : 0.61
INFO:root:2019-05-10 17:31:40, Epoch : 1, Step : 433, Training Loss : 0.28304, Training Acc : 0.878, Run Time : 0.49
INFO:root:2019-05-10 17:31:41, Epoch : 1, Step : 434, Training Loss : 0.30541, Training Acc : 0.800, Run Time : 0.50
INFO:root:2019-05-10 17:31:59, Epoch : 1, Step : 435, Training Loss : 0.18459, Training Acc : 0.950, Run Time : 18.71
INFO:root:2019-05-10 17:32:00, Epoch : 1, Step : 436, Training Loss : 0.23556, Training Acc : 0.911, Run Time : 0.22
INFO:root:2019-05-10 17:32:00, Epoch : 1, Step : 437, Training Loss : 0.17447, Training Acc : 0.950, Run Time : 0.33
INFO:root:2019-05-10 17:32:00, Epoch : 1, Step : 438, Training Loss : 0.18505, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-10 17:32:01, Epoch : 1, Step : 439, Training Loss : 0.19123, Training Acc : 0.933, Run Time : 0.49
INFO:root:2019-05-10 17:32:22, Epoch : 1, Step : 440, Training Loss : 0.18240, Training Acc : 0.933, Run Time : 20.90
INFO:root:2019-05-10 17:32:22, Epoch : 1, Step : 441, Training Loss : 0.42161, Training Acc : 0.800, Run Time : 0.29
INFO:root:2019-05-10 17:32:22, Epoch : 1, Step : 442, Training Loss : 0.72035, Training Acc : 0.694, Run Time : 0.44
INFO:root:2019-05-10 17:32:23, Epoch : 1, Step : 443, Training Loss : 0.51021, Training Acc : 0.789, Run Time : 0.49
INFO:root:2019-05-10 17:32:23, Epoch : 1, Step : 444, Training Loss : 0.36154, Training Acc : 0.833, Run Time : 0.50
INFO:root:2019-05-10 17:32:41, Epoch : 1, Step : 445, Training Loss : 0.61509, Training Acc : 0.711, Run Time : 18.03
INFO:root:2019-05-10 17:32:42, Epoch : 1, Step : 446, Training Loss : 0.39551, Training Acc : 0.828, Run Time : 0.31
INFO:root:2019-05-10 17:32:42, Epoch : 1, Step : 447, Training Loss : 0.33414, Training Acc : 0.844, Run Time : 0.43
INFO:root:2019-05-10 17:32:43, Epoch : 1, Step : 448, Training Loss : 0.33420, Training Acc : 0.861, Run Time : 0.47
INFO:root:2019-05-10 17:32:43, Epoch : 1, Step : 449, Training Loss : 0.55854, Training Acc : 0.728, Run Time : 0.50
INFO:root:2019-05-10 17:33:00, Epoch : 1, Step : 450, Training Loss : 0.32012, Training Acc : 0.828, Run Time : 17.32
INFO:root:2019-05-10 17:33:01, Epoch : 1, Step : 451, Training Loss : 0.37644, Training Acc : 0.811, Run Time : 0.71
INFO:root:2019-05-10 17:33:16, Epoch : 1, Step : 452, Training Loss : 0.36810, Training Acc : 0.789, Run Time : 14.69
INFO:root:2019-05-10 17:33:16, Epoch : 1, Step : 453, Training Loss : 0.40656, Training Acc : 0.844, Run Time : 0.46
INFO:root:2019-05-10 17:33:17, Epoch : 1, Step : 454, Training Loss : 0.33450, Training Acc : 0.850, Run Time : 0.44
INFO:root:2019-05-10 17:33:26, Epoch : 1, Step : 455, Training Loss : 0.40569, Training Acc : 0.794, Run Time : 9.32
INFO:root:2019-05-10 17:33:32, Epoch : 1, Step : 456, Training Loss : 0.32198, Training Acc : 0.844, Run Time : 5.48
INFO:root:2019-05-10 17:33:32, Epoch : 1, Step : 457, Training Loss : 0.39060, Training Acc : 0.783, Run Time : 0.87
INFO:root:2019-05-10 17:33:33, Epoch : 1, Step : 458, Training Loss : 0.29458, Training Acc : 0.867, Run Time : 0.40
INFO:root:2019-05-10 17:33:33, Epoch : 1, Step : 459, Training Loss : 0.29450, Training Acc : 0.889, Run Time : 0.27
INFO:root:2019-05-10 17:33:34, Epoch : 1, Step : 460, Training Loss : 0.31411, Training Acc : 0.839, Run Time : 0.81
INFO:root:2019-05-10 17:33:50, Epoch : 1, Step : 461, Training Loss : 0.29815, Training Acc : 0.850, Run Time : 15.95
INFO:root:2019-05-10 17:33:50, Epoch : 1, Step : 462, Training Loss : 0.28962, Training Acc : 0.844, Run Time : 0.28
INFO:root:2019-05-10 17:33:51, Epoch : 1, Step : 463, Training Loss : 0.26441, Training Acc : 0.856, Run Time : 0.35
INFO:root:2019-05-10 17:33:51, Epoch : 1, Step : 464, Training Loss : 0.29011, Training Acc : 0.861, Run Time : 0.21
INFO:root:2019-05-10 17:33:52, Epoch : 1, Step : 465, Training Loss : 0.24544, Training Acc : 0.939, Run Time : 1.17
INFO:root:2019-05-10 17:34:12, Epoch : 1, Step : 466, Training Loss : 0.17035, Training Acc : 0.961, Run Time : 19.81
INFO:root:2019-05-10 17:34:13, Epoch : 1, Step : 467, Training Loss : 0.17862, Training Acc : 0.961, Run Time : 0.82
INFO:root:2019-05-10 17:34:13, Epoch : 1, Step : 468, Training Loss : 0.16648, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-10 17:34:13, Epoch : 1, Step : 469, Training Loss : 0.17840, Training Acc : 0.961, Run Time : 0.31
INFO:root:2019-05-10 17:34:16, Epoch : 1, Step : 470, Training Loss : 0.24368, Training Acc : 0.906, Run Time : 2.63
INFO:root:2019-05-10 17:34:30, Epoch : 1, Step : 471, Training Loss : 0.18468, Training Acc : 0.922, Run Time : 14.37
INFO:root:2019-05-10 17:34:31, Epoch : 1, Step : 472, Training Loss : 0.17766, Training Acc : 0.922, Run Time : 0.33
INFO:root:2019-05-10 17:34:31, Epoch : 1, Step : 473, Training Loss : 0.20284, Training Acc : 0.900, Run Time : 0.30
INFO:root:2019-05-10 17:34:31, Epoch : 1, Step : 474, Training Loss : 0.16024, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-10 17:34:33, Epoch : 1, Step : 475, Training Loss : 0.17683, Training Acc : 0.922, Run Time : 1.31
INFO:root:2019-05-10 17:34:51, Epoch : 1, Step : 476, Training Loss : 0.10323, Training Acc : 0.978, Run Time : 18.09
INFO:root:2019-05-10 17:34:52, Epoch : 1, Step : 477, Training Loss : 0.13004, Training Acc : 0.956, Run Time : 0.94
INFO:root:2019-05-10 17:34:52, Epoch : 1, Step : 478, Training Loss : 0.16916, Training Acc : 0.933, Run Time : 0.45
INFO:root:2019-05-10 17:34:53, Epoch : 1, Step : 479, Training Loss : 0.05806, Training Acc : 1.000, Run Time : 0.50
INFO:root:2019-05-10 17:34:53, Epoch : 1, Step : 480, Training Loss : 0.13771, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 17:35:15, Epoch : 1, Step : 481, Training Loss : 0.20510, Training Acc : 0.922, Run Time : 22.26
INFO:root:2019-05-10 17:35:16, Epoch : 1, Step : 482, Training Loss : 0.09339, Training Acc : 0.972, Run Time : 0.23
INFO:root:2019-05-10 17:35:16, Epoch : 1, Step : 483, Training Loss : 0.14113, Training Acc : 0.950, Run Time : 0.23
INFO:root:2019-05-10 17:35:16, Epoch : 1, Step : 484, Training Loss : 0.15544, Training Acc : 0.928, Run Time : 0.44
INFO:root:2019-05-10 17:35:28, Epoch : 1, Step : 485, Training Loss : 0.07245, Training Acc : 0.978, Run Time : 11.52
INFO:root:2019-05-10 17:35:28, Epoch : 1, Step : 486, Training Loss : 0.05740, Training Acc : 0.994, Run Time : 0.64
INFO:root:2019-05-10 17:35:29, Epoch : 1, Step : 487, Training Loss : 0.17859, Training Acc : 0.922, Run Time : 0.86
INFO:root:2019-05-10 17:35:33, Epoch : 1, Step : 488, Training Loss : 0.11305, Training Acc : 0.956, Run Time : 3.41
INFO:root:2019-05-10 17:35:43, Epoch : 1, Step : 489, Training Loss : 0.09855, Training Acc : 0.972, Run Time : 10.01
INFO:root:2019-05-10 17:35:44, Epoch : 1, Step : 490, Training Loss : 0.17561, Training Acc : 0.944, Run Time : 0.86
INFO:root:2019-05-10 17:35:44, Epoch : 1, Step : 491, Training Loss : 0.20153, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-10 17:35:44, Epoch : 1, Step : 492, Training Loss : 0.07345, Training Acc : 0.994, Run Time : 0.33
INFO:root:2019-05-10 17:35:45, Epoch : 1, Step : 493, Training Loss : 0.12268, Training Acc : 0.944, Run Time : 0.49
INFO:root:2019-05-10 17:36:02, Epoch : 1, Step : 494, Training Loss : 0.07733, Training Acc : 0.978, Run Time : 17.51
INFO:root:2019-05-10 17:36:03, Epoch : 1, Step : 495, Training Loss : 0.22149, Training Acc : 0.900, Run Time : 0.26
INFO:root:2019-05-10 17:36:03, Epoch : 1, Step : 496, Training Loss : 0.07671, Training Acc : 0.978, Run Time : 0.46
INFO:root:2019-05-10 17:36:04, Epoch : 1, Step : 497, Training Loss : 0.07189, Training Acc : 0.972, Run Time : 0.46
INFO:root:2019-05-10 17:36:04, Epoch : 1, Step : 498, Training Loss : 0.09527, Training Acc : 0.978, Run Time : 0.50
INFO:root:2019-05-10 17:36:21, Epoch : 1, Step : 499, Training Loss : 0.07071, Training Acc : 0.983, Run Time : 17.39
INFO:root:2019-05-10 17:36:22, Epoch : 1, Step : 500, Training Loss : 0.21139, Training Acc : 0.939, Run Time : 0.24
INFO:root:2019-05-10 17:36:23, Epoch : 1, Step : 501, Training Loss : 0.20739, Training Acc : 0.883, Run Time : 1.06
INFO:root:2019-05-10 17:36:23, Epoch : 1, Step : 502, Training Loss : 0.46199, Training Acc : 0.817, Run Time : 0.41
INFO:root:2019-05-10 17:36:25, Epoch : 1, Step : 503, Training Loss : 0.20956, Training Acc : 0.900, Run Time : 1.61
INFO:root:2019-05-10 17:36:40, Epoch : 1, Step : 504, Training Loss : 0.11444, Training Acc : 0.967, Run Time : 15.19
INFO:root:2019-05-10 17:36:41, Epoch : 1, Step : 505, Training Loss : 0.27191, Training Acc : 0.867, Run Time : 0.62
INFO:root:2019-05-10 17:36:41, Epoch : 1, Step : 506, Training Loss : 0.35038, Training Acc : 0.822, Run Time : 0.48
INFO:root:2019-05-10 17:36:42, Epoch : 1, Step : 507, Training Loss : 0.21392, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-10 17:36:45, Epoch : 1, Step : 508, Training Loss : 0.20208, Training Acc : 0.917, Run Time : 3.50
INFO:root:2019-05-10 17:36:55, Epoch : 1, Step : 509, Training Loss : 0.18957, Training Acc : 0.928, Run Time : 9.45
INFO:root:2019-05-10 17:37:06, Epoch : 1, Step : 510, Training Loss : 0.22267, Training Acc : 0.911, Run Time : 11.88
INFO:root:2019-05-10 17:37:10, Epoch : 1, Step : 511, Training Loss : 0.30540, Training Acc : 0.872, Run Time : 3.27
INFO:root:2019-05-10 17:37:10, Epoch : 1, Step : 512, Training Loss : 0.07281, Training Acc : 0.972, Run Time : 0.46
INFO:root:2019-05-10 17:37:10, Epoch : 1, Step : 513, Training Loss : 0.16747, Training Acc : 0.917, Run Time : 0.37
INFO:root:2019-05-10 17:37:11, Epoch : 1, Step : 514, Training Loss : 0.22952, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-10 17:37:12, Epoch : 1, Step : 515, Training Loss : 0.18829, Training Acc : 0.950, Run Time : 1.07
INFO:root:2019-05-10 17:37:27, Epoch : 1, Step : 516, Training Loss : 0.21081, Training Acc : 0.894, Run Time : 15.42
INFO:root:2019-05-10 17:37:28, Epoch : 1, Step : 517, Training Loss : 0.14022, Training Acc : 0.933, Run Time : 0.58
INFO:root:2019-05-10 17:37:29, Epoch : 1, Step : 518, Training Loss : 0.18352, Training Acc : 0.928, Run Time : 0.57
INFO:root:2019-05-10 17:37:29, Epoch : 1, Step : 519, Training Loss : 0.16897, Training Acc : 0.939, Run Time : 0.47
INFO:root:2019-05-10 17:37:30, Epoch : 1, Step : 520, Training Loss : 0.43376, Training Acc : 0.800, Run Time : 0.52
INFO:root:2019-05-10 17:37:47, Epoch : 1, Step : 521, Training Loss : 0.14721, Training Acc : 0.928, Run Time : 17.50
INFO:root:2019-05-10 17:37:48, Epoch : 1, Step : 522, Training Loss : 0.04399, Training Acc : 0.994, Run Time : 0.89
INFO:root:2019-05-10 17:37:48, Epoch : 1, Step : 523, Training Loss : 0.08560, Training Acc : 0.978, Run Time : 0.47
INFO:root:2019-05-10 17:37:49, Epoch : 1, Step : 524, Training Loss : 0.16128, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 17:37:49, Epoch : 1, Step : 525, Training Loss : 0.08143, Training Acc : 0.983, Run Time : 0.48
INFO:root:2019-05-10 17:38:09, Epoch : 1, Step : 526, Training Loss : 0.08533, Training Acc : 0.972, Run Time : 19.09
INFO:root:2019-05-10 17:38:09, Epoch : 1, Step : 527, Training Loss : 0.06872, Training Acc : 0.983, Run Time : 0.23
INFO:root:2019-05-10 17:38:09, Epoch : 1, Step : 528, Training Loss : 0.14941, Training Acc : 0.950, Run Time : 0.51
INFO:root:2019-05-10 17:38:10, Epoch : 1, Step : 529, Training Loss : 0.14047, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-10 17:38:21, Epoch : 1, Step : 530, Training Loss : 0.78498, Training Acc : 0.672, Run Time : 11.73
INFO:root:2019-05-10 17:38:23, Epoch : 1, Step : 531, Training Loss : 0.37130, Training Acc : 0.817, Run Time : 1.51
INFO:root:2019-05-10 17:38:23, Epoch : 1, Step : 532, Training Loss : 0.11433, Training Acc : 0.967, Run Time : 0.42
INFO:root:2019-05-10 17:38:24, Epoch : 1, Step : 533, Training Loss : 0.19787, Training Acc : 0.922, Run Time : 0.45
INFO:root:2019-05-10 17:38:25, Epoch : 1, Step : 534, Training Loss : 0.14860, Training Acc : 0.939, Run Time : 0.97
INFO:root:2019-05-10 17:38:41, Epoch : 1, Step : 535, Training Loss : 0.21954, Training Acc : 0.889, Run Time : 16.10
INFO:root:2019-05-10 17:38:41, Epoch : 1, Step : 536, Training Loss : 0.14074, Training Acc : 0.950, Run Time : 0.36
INFO:root:2019-05-10 17:38:42, Epoch : 1, Step : 537, Training Loss : 0.46408, Training Acc : 0.811, Run Time : 0.49
INFO:root:2019-05-10 17:38:42, Epoch : 1, Step : 538, Training Loss : 0.12610, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 17:38:55, Epoch : 1, Step : 539, Training Loss : 0.24903, Training Acc : 0.878, Run Time : 12.82
INFO:root:2019-05-10 17:38:55, Epoch : 1, Step : 540, Training Loss : 0.15193, Training Acc : 0.939, Run Time : 0.32
INFO:root:2019-05-10 17:38:56, Epoch : 1, Step : 541, Training Loss : 0.25033, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-10 17:38:56, Epoch : 1, Step : 542, Training Loss : 0.37475, Training Acc : 0.872, Run Time : 0.35
INFO:root:2019-05-10 17:38:58, Epoch : 1, Step : 543, Training Loss : 0.20791, Training Acc : 0.922, Run Time : 1.38
INFO:root:2019-05-10 17:39:15, Epoch : 1, Step : 544, Training Loss : 0.25324, Training Acc : 0.867, Run Time : 17.29
INFO:root:2019-05-10 17:39:15, Epoch : 1, Step : 545, Training Loss : 0.21939, Training Acc : 0.922, Run Time : 0.62
INFO:root:2019-05-10 17:39:16, Epoch : 1, Step : 546, Training Loss : 0.20520, Training Acc : 0.922, Run Time : 0.44
INFO:root:2019-05-10 17:39:24, Epoch : 1, Step : 547, Training Loss : 0.19193, Training Acc : 0.911, Run Time : 8.05
INFO:root:2019-05-10 17:39:36, Epoch : 1, Step : 548, Training Loss : 0.57721, Training Acc : 0.789, Run Time : 12.28
INFO:root:2019-05-10 17:39:37, Epoch : 1, Step : 549, Training Loss : 0.24712, Training Acc : 0.900, Run Time : 1.15
INFO:root:2019-05-10 17:39:38, Epoch : 1, Step : 550, Training Loss : 0.58271, Training Acc : 0.811, Run Time : 0.56
INFO:root:2019-05-10 17:39:38, Epoch : 1, Step : 551, Training Loss : 0.51405, Training Acc : 0.794, Run Time : 0.49
INFO:root:2019-05-10 17:39:49, Epoch : 1, Step : 552, Training Loss : 0.46555, Training Acc : 0.811, Run Time : 10.60
INFO:root:2019-05-10 17:39:49, Epoch : 1, Step : 553, Training Loss : 0.30918, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-10 17:39:50, Epoch : 1, Step : 554, Training Loss : 0.21217, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-10 17:39:50, Epoch : 1, Step : 555, Training Loss : 0.24308, Training Acc : 0.872, Run Time : 0.50
INFO:root:2019-05-10 17:39:51, Epoch : 1, Step : 556, Training Loss : 0.31518, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 17:40:09, Epoch : 1, Step : 557, Training Loss : 0.23042, Training Acc : 0.867, Run Time : 17.80
INFO:root:2019-05-10 17:40:09, Epoch : 1, Step : 558, Training Loss : 0.20983, Training Acc : 0.956, Run Time : 0.22
INFO:root:2019-05-10 17:40:09, Epoch : 1, Step : 559, Training Loss : 0.11914, Training Acc : 0.967, Run Time : 0.47
INFO:root:2019-05-10 17:40:10, Epoch : 1, Step : 560, Training Loss : 0.32874, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-10 17:40:25, Epoch : 1, Step : 561, Training Loss : 0.34347, Training Acc : 0.817, Run Time : 14.98
INFO:root:2019-05-10 17:40:26, Epoch : 1, Step : 562, Training Loss : 0.32899, Training Acc : 0.844, Run Time : 1.10
INFO:root:2019-05-10 17:40:26, Epoch : 1, Step : 563, Training Loss : 0.14752, Training Acc : 0.956, Run Time : 0.45
INFO:root:2019-05-10 17:40:27, Epoch : 1, Step : 564, Training Loss : 0.20547, Training Acc : 0.917, Run Time : 0.49
INFO:root:2019-05-10 17:40:27, Epoch : 1, Step : 565, Training Loss : 0.37028, Training Acc : 0.850, Run Time : 0.51
INFO:root:2019-05-10 17:40:44, Epoch : 1, Step : 566, Training Loss : 0.22935, Training Acc : 0.900, Run Time : 16.35
INFO:root:2019-05-10 17:40:44, Epoch : 1, Step : 567, Training Loss : 0.28230, Training Acc : 0.900, Run Time : 0.24
INFO:root:2019-05-10 17:40:45, Epoch : 1, Step : 568, Training Loss : 0.13523, Training Acc : 0.961, Run Time : 0.55
INFO:root:2019-05-10 17:40:53, Epoch : 1, Step : 569, Training Loss : 0.24363, Training Acc : 0.894, Run Time : 8.90
INFO:root:2019-05-10 17:40:57, Epoch : 1, Step : 570, Training Loss : 0.22951, Training Acc : 0.917, Run Time : 3.39
INFO:root:2019-05-10 17:40:57, Epoch : 1, Step : 571, Training Loss : 0.15929, Training Acc : 0.928, Run Time : 0.30
INFO:root:2019-05-10 17:40:58, Epoch : 1, Step : 572, Training Loss : 0.17402, Training Acc : 0.944, Run Time : 0.43
INFO:root:2019-05-10 17:40:58, Epoch : 1, Step : 573, Training Loss : 0.28551, Training Acc : 0.889, Run Time : 0.50
INFO:root:2019-05-10 17:40:59, Epoch : 1, Step : 574, Training Loss : 0.23395, Training Acc : 0.856, Run Time : 0.49
INFO:root:2019-05-10 17:41:16, Epoch : 1, Step : 575, Training Loss : 0.20304, Training Acc : 0.911, Run Time : 17.31
INFO:root:2019-05-10 17:41:17, Epoch : 1, Step : 576, Training Loss : 0.17226, Training Acc : 0.956, Run Time : 1.01
INFO:root:2019-05-10 17:41:17, Epoch : 1, Step : 577, Training Loss : 0.33769, Training Acc : 0.794, Run Time : 0.59
INFO:root:2019-05-10 17:41:18, Epoch : 1, Step : 578, Training Loss : 0.24442, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 17:41:18, Epoch : 1, Step : 579, Training Loss : 0.25691, Training Acc : 0.878, Run Time : 0.51
INFO:root:2019-05-10 17:41:35, Epoch : 1, Step : 580, Training Loss : 0.20159, Training Acc : 0.917, Run Time : 16.60
INFO:root:2019-05-10 17:41:35, Epoch : 1, Step : 581, Training Loss : 0.18397, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-10 17:41:36, Epoch : 1, Step : 582, Training Loss : 0.18053, Training Acc : 0.933, Run Time : 0.53
INFO:root:2019-05-10 17:41:37, Epoch : 1, Step : 583, Training Loss : 0.23660, Training Acc : 0.911, Run Time : 0.65
INFO:root:2019-05-10 17:41:37, Epoch : 1, Step : 584, Training Loss : 0.22822, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-10 17:41:53, Epoch : 1, Step : 585, Training Loss : 0.30712, Training Acc : 0.856, Run Time : 15.48
INFO:root:2019-05-10 17:41:53, Epoch : 1, Step : 586, Training Loss : 0.24069, Training Acc : 0.894, Run Time : 0.33
INFO:root:2019-05-10 17:41:53, Epoch : 1, Step : 587, Training Loss : 0.33806, Training Acc : 0.828, Run Time : 0.44
INFO:root:2019-05-10 17:41:54, Epoch : 1, Step : 588, Training Loss : 0.35488, Training Acc : 0.828, Run Time : 0.44
INFO:root:2019-05-10 17:41:54, Epoch : 1, Step : 589, Training Loss : 0.20290, Training Acc : 0.911, Run Time : 0.22
INFO:root:2019-05-10 17:42:21, Epoch : 1, Step : 590, Training Loss : 0.23767, Training Acc : 0.906, Run Time : 26.60
INFO:root:2019-05-10 17:42:37, Epoch : 1, Step : 591, Training Loss : 0.27155, Training Acc : 0.883, Run Time : 15.98
INFO:root:2019-05-10 17:42:38, Epoch : 1, Step : 592, Training Loss : 0.27601, Training Acc : 0.889, Run Time : 1.49
INFO:root:2019-05-10 17:42:38, Epoch : 1, Step : 593, Training Loss : 0.23465, Training Acc : 0.917, Run Time : 0.29
INFO:root:2019-05-10 17:42:39, Epoch : 1, Step : 594, Training Loss : 0.21305, Training Acc : 0.917, Run Time : 0.48
INFO:root:2019-05-10 17:42:39, Epoch : 1, Step : 595, Training Loss : 0.31636, Training Acc : 0.861, Run Time : 0.48
INFO:root:2019-05-10 17:42:55, Epoch : 1, Step : 596, Training Loss : 0.34513, Training Acc : 0.817, Run Time : 15.15
INFO:root:2019-05-10 17:42:55, Epoch : 1, Step : 597, Training Loss : 0.35619, Training Acc : 0.828, Run Time : 0.32
INFO:root:2019-05-10 17:42:55, Epoch : 1, Step : 598, Training Loss : 0.31783, Training Acc : 0.839, Run Time : 0.58
INFO:root:2019-05-10 17:43:09, Epoch : 1, Step : 599, Training Loss : 0.23499, Training Acc : 0.900, Run Time : 13.87
INFO:root:2019-05-10 17:43:10, Epoch : 1, Step : 600, Training Loss : 0.26686, Training Acc : 0.872, Run Time : 0.42
INFO:root:2019-05-10 17:43:15, Epoch : 1, Step : 601, Training Loss : 0.41154, Training Acc : 0.783, Run Time : 4.82
INFO:root:2019-05-10 17:43:21, Epoch : 1, Step : 602, Training Loss : 0.56807, Training Acc : 0.783, Run Time : 6.40
INFO:root:2019-05-10 17:43:26, Epoch : 1, Step : 603, Training Loss : 0.53786, Training Acc : 0.728, Run Time : 4.70
INFO:root:2019-05-10 17:43:33, Epoch : 1, Step : 604, Training Loss : 0.33655, Training Acc : 0.844, Run Time : 7.20
INFO:root:2019-05-10 17:43:33, Epoch : 1, Step : 605, Training Loss : 0.29778, Training Acc : 0.839, Run Time : 0.31
INFO:root:2019-05-10 17:43:34, Epoch : 1, Step : 606, Training Loss : 0.43460, Training Acc : 0.789, Run Time : 0.45
INFO:root:2019-05-10 17:43:34, Epoch : 1, Step : 607, Training Loss : 0.25722, Training Acc : 0.872, Run Time : 0.54
INFO:root:2019-05-10 17:43:35, Epoch : 1, Step : 608, Training Loss : 0.28224, Training Acc : 0.883, Run Time : 0.60
INFO:root:2019-05-10 17:43:53, Epoch : 1, Step : 609, Training Loss : 0.27057, Training Acc : 0.850, Run Time : 17.78
INFO:root:2019-05-10 17:43:53, Epoch : 1, Step : 610, Training Loss : 0.25973, Training Acc : 0.861, Run Time : 0.32
INFO:root:2019-05-10 17:43:53, Epoch : 1, Step : 611, Training Loss : 0.22067, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 17:43:54, Epoch : 1, Step : 612, Training Loss : 0.22353, Training Acc : 0.911, Run Time : 0.52
INFO:root:2019-05-10 17:44:07, Epoch : 1, Step : 613, Training Loss : 0.39010, Training Acc : 0.828, Run Time : 13.31
INFO:root:2019-05-10 17:44:08, Epoch : 1, Step : 614, Training Loss : 0.42082, Training Acc : 0.772, Run Time : 0.66
INFO:root:2019-05-10 17:44:08, Epoch : 1, Step : 615, Training Loss : 0.19119, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-10 17:44:09, Epoch : 1, Step : 616, Training Loss : 0.25834, Training Acc : 0.911, Run Time : 0.49
INFO:root:2019-05-10 17:44:25, Epoch : 1, Step : 617, Training Loss : 0.36002, Training Acc : 0.861, Run Time : 16.37
INFO:root:2019-05-10 17:44:27, Epoch : 1, Step : 618, Training Loss : 0.40752, Training Acc : 0.867, Run Time : 1.40
INFO:root:2019-05-10 17:44:27, Epoch : 1, Step : 619, Training Loss : 0.36280, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-10 17:44:27, Epoch : 1, Step : 620, Training Loss : 0.47320, Training Acc : 0.783, Run Time : 0.48
INFO:root:2019-05-10 17:44:28, Epoch : 1, Step : 621, Training Loss : 0.30883, Training Acc : 0.889, Run Time : 0.98
INFO:root:2019-05-10 17:44:44, Epoch : 1, Step : 622, Training Loss : 0.40780, Training Acc : 0.811, Run Time : 15.07
INFO:root:2019-05-10 17:44:44, Epoch : 1, Step : 623, Training Loss : 0.56260, Training Acc : 0.783, Run Time : 0.70
INFO:root:2019-05-10 17:44:45, Epoch : 1, Step : 624, Training Loss : 0.32667, Training Acc : 0.872, Run Time : 0.53
INFO:root:2019-05-10 17:44:47, Epoch : 1, Step : 625, Training Loss : 0.23693, Training Acc : 0.917, Run Time : 2.02
INFO:root:2019-05-10 17:45:00, Epoch : 1, Step : 626, Training Loss : 0.33454, Training Acc : 0.856, Run Time : 13.68
INFO:root:2019-05-10 17:45:01, Epoch : 1, Step : 627, Training Loss : 0.23973, Training Acc : 0.889, Run Time : 0.22
INFO:root:2019-05-10 17:45:01, Epoch : 1, Step : 628, Training Loss : 0.38828, Training Acc : 0.828, Run Time : 0.39
INFO:root:2019-05-10 17:45:02, Epoch : 1, Step : 629, Training Loss : 0.34630, Training Acc : 0.844, Run Time : 0.49
INFO:root:2019-05-10 17:45:02, Epoch : 1, Step : 630, Training Loss : 0.21080, Training Acc : 0.911, Run Time : 0.52
INFO:root:2019-05-10 17:45:22, Epoch : 1, Step : 631, Training Loss : 0.35939, Training Acc : 0.806, Run Time : 20.26
INFO:root:2019-05-10 17:45:23, Epoch : 1, Step : 632, Training Loss : 0.23017, Training Acc : 0.867, Run Time : 0.29
INFO:root:2019-05-10 17:45:23, Epoch : 1, Step : 633, Training Loss : 0.40743, Training Acc : 0.794, Run Time : 0.34
INFO:root:2019-05-10 17:45:24, Epoch : 1, Step : 634, Training Loss : 0.21423, Training Acc : 0.944, Run Time : 0.65
INFO:root:2019-05-10 17:45:24, Epoch : 1, Step : 635, Training Loss : 0.25030, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 17:45:41, Epoch : 1, Step : 636, Training Loss : 0.16906, Training Acc : 0.939, Run Time : 16.86
INFO:root:2019-05-10 17:45:42, Epoch : 1, Step : 637, Training Loss : 0.28945, Training Acc : 0.883, Run Time : 0.82
INFO:root:2019-05-10 17:45:42, Epoch : 1, Step : 638, Training Loss : 0.23954, Training Acc : 0.906, Run Time : 0.45
INFO:root:2019-05-10 17:45:50, Epoch : 1, Step : 639, Training Loss : 0.31109, Training Acc : 0.861, Run Time : 7.88
INFO:root:2019-05-10 17:45:54, Epoch : 1, Step : 640, Training Loss : 0.19600, Training Acc : 0.939, Run Time : 3.89
INFO:root:2019-05-10 17:45:54, Epoch : 1, Step : 641, Training Loss : 0.22666, Training Acc : 0.900, Run Time : 0.33
INFO:root:2019-05-10 17:45:55, Epoch : 1, Step : 642, Training Loss : 0.36456, Training Acc : 0.844, Run Time : 0.50
INFO:root:2019-05-10 17:46:04, Epoch : 1, Step : 643, Training Loss : 0.28477, Training Acc : 0.894, Run Time : 9.09
INFO:root:2019-05-10 17:46:07, Epoch : 1, Step : 644, Training Loss : 0.29563, Training Acc : 0.872, Run Time : 3.50
INFO:root:2019-05-10 17:46:08, Epoch : 1, Step : 645, Training Loss : 0.31845, Training Acc : 0.844, Run Time : 0.31
INFO:root:2019-05-10 17:46:08, Epoch : 1, Step : 646, Training Loss : 0.20926, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 17:46:09, Epoch : 1, Step : 647, Training Loss : 0.29215, Training Acc : 0.850, Run Time : 0.51
INFO:root:2019-05-10 17:46:11, Epoch : 1, Step : 648, Training Loss : 0.16747, Training Acc : 0.922, Run Time : 2.24
INFO:root:2019-05-10 17:46:13, Epoch : 1, Step : 649, Training Loss : 0.39926, Training Acc : 0.833, Run Time : 2.22
INFO:root:2019-05-10 17:46:14, Epoch : 1, Step : 650, Training Loss : 0.51983, Training Acc : 0.722, Run Time : 0.48
INFO:root:2019-05-10 17:46:33, Epoch : 1, Step : 651, Training Loss : 0.32474, Training Acc : 0.844, Run Time : 19.31
INFO:root:2019-05-10 17:46:33, Epoch : 1, Step : 652, Training Loss : 0.22925, Training Acc : 0.906, Run Time : 0.48
INFO:root:2019-05-10 17:46:34, Epoch : 1, Step : 653, Training Loss : 0.14975, Training Acc : 0.939, Run Time : 0.59
INFO:root:2019-05-10 17:46:34, Epoch : 1, Step : 654, Training Loss : 0.25693, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 17:46:50, Epoch : 1, Step : 655, Training Loss : 0.24155, Training Acc : 0.928, Run Time : 15.59
INFO:root:2019-05-10 17:46:50, Epoch : 1, Step : 656, Training Loss : 0.27877, Training Acc : 0.872, Run Time : 0.26
INFO:root:2019-05-10 17:46:51, Epoch : 1, Step : 657, Training Loss : 0.26437, Training Acc : 0.889, Run Time : 0.23
INFO:root:2019-05-10 17:46:51, Epoch : 1, Step : 658, Training Loss : 0.33839, Training Acc : 0.844, Run Time : 0.66
INFO:root:2019-05-10 17:46:52, Epoch : 1, Step : 659, Training Loss : 0.26889, Training Acc : 0.878, Run Time : 0.43
INFO:root:2019-05-10 17:47:07, Epoch : 1, Step : 660, Training Loss : 0.26825, Training Acc : 0.878, Run Time : 15.21
INFO:root:2019-05-10 17:47:07, Epoch : 1, Step : 661, Training Loss : 0.27508, Training Acc : 0.867, Run Time : 0.22
INFO:root:2019-05-10 17:47:07, Epoch : 1, Step : 662, Training Loss : 0.21562, Training Acc : 0.922, Run Time : 0.22
INFO:root:2019-05-10 17:47:08, Epoch : 1, Step : 663, Training Loss : 0.59166, Training Acc : 0.722, Run Time : 0.34
INFO:root:2019-05-10 17:47:22, Epoch : 1, Step : 664, Training Loss : 0.74675, Training Acc : 0.678, Run Time : 14.23
INFO:root:2019-05-10 17:47:22, Epoch : 1, Step : 665, Training Loss : 0.45923, Training Acc : 0.772, Run Time : 0.50
INFO:root:2019-05-10 17:47:23, Epoch : 1, Step : 666, Training Loss : 0.50478, Training Acc : 0.761, Run Time : 0.35
INFO:root:2019-05-10 17:47:39, Epoch : 1, Step : 667, Training Loss : 0.38463, Training Acc : 0.839, Run Time : 15.97
INFO:root:2019-05-10 17:47:39, Epoch : 1, Step : 668, Training Loss : 0.30718, Training Acc : 0.883, Run Time : 0.23
INFO:root:2019-05-10 17:47:39, Epoch : 1, Step : 669, Training Loss : 0.60194, Training Acc : 0.750, Run Time : 0.58
INFO:root:2019-05-10 17:47:40, Epoch : 1, Step : 670, Training Loss : 0.43970, Training Acc : 0.794, Run Time : 0.48
INFO:root:2019-05-10 17:47:40, Epoch : 1, Step : 671, Training Loss : 0.24056, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 17:47:58, Epoch : 1, Step : 672, Training Loss : 0.30196, Training Acc : 0.883, Run Time : 17.20
INFO:root:2019-05-10 17:47:58, Epoch : 1, Step : 673, Training Loss : 0.33229, Training Acc : 0.828, Run Time : 0.58
INFO:root:2019-05-10 17:47:58, Epoch : 1, Step : 674, Training Loss : 0.39418, Training Acc : 0.867, Run Time : 0.25
INFO:root:2019-05-10 17:47:59, Epoch : 1, Step : 675, Training Loss : 0.27003, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-10 17:48:13, Epoch : 1, Step : 676, Training Loss : 0.29388, Training Acc : 0.906, Run Time : 14.06
INFO:root:2019-05-10 17:48:14, Epoch : 1, Step : 677, Training Loss : 0.39449, Training Acc : 0.789, Run Time : 0.59
INFO:root:2019-05-10 17:48:14, Epoch : 1, Step : 678, Training Loss : 0.39202, Training Acc : 0.822, Run Time : 0.56
INFO:root:2019-05-10 17:48:15, Epoch : 1, Step : 679, Training Loss : 0.38543, Training Acc : 0.833, Run Time : 0.50
INFO:root:2019-05-10 17:48:15, Epoch : 1, Step : 680, Training Loss : 0.35834, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-10 17:48:33, Epoch : 1, Step : 681, Training Loss : 0.42077, Training Acc : 0.778, Run Time : 17.79
INFO:root:2019-05-10 17:48:33, Epoch : 1, Step : 682, Training Loss : 0.35589, Training Acc : 0.878, Run Time : 0.34
INFO:root:2019-05-10 17:48:34, Epoch : 1, Step : 683, Training Loss : 0.45384, Training Acc : 0.750, Run Time : 0.38
INFO:root:2019-05-10 17:48:35, Epoch : 1, Step : 684, Training Loss : 0.55574, Training Acc : 0.722, Run Time : 1.09
INFO:root:2019-05-10 17:48:44, Epoch : 1, Step : 685, Training Loss : 0.34453, Training Acc : 0.817, Run Time : 9.12
INFO:root:2019-05-10 17:48:44, Epoch : 1, Step : 686, Training Loss : 0.34510, Training Acc : 0.828, Run Time : 0.23
INFO:root:2019-05-10 17:48:45, Epoch : 1, Step : 687, Training Loss : 0.42532, Training Acc : 0.839, Run Time : 0.62
INFO:root:2019-05-10 17:48:46, Epoch : 1, Step : 688, Training Loss : 0.39535, Training Acc : 0.833, Run Time : 1.48
INFO:root:2019-05-10 17:48:57, Epoch : 1, Step : 689, Training Loss : 0.36544, Training Acc : 0.806, Run Time : 10.63
INFO:root:2019-05-10 17:48:57, Epoch : 1, Step : 690, Training Loss : 0.28136, Training Acc : 0.883, Run Time : 0.22
INFO:root:2019-05-10 17:48:57, Epoch : 1, Step : 691, Training Loss : 0.22594, Training Acc : 0.917, Run Time : 0.22
INFO:root:2019-05-10 17:48:58, Epoch : 1, Step : 692, Training Loss : 0.31915, Training Acc : 0.867, Run Time : 0.50
INFO:root:2019-05-10 17:48:58, Epoch : 1, Step : 693, Training Loss : 0.33595, Training Acc : 0.822, Run Time : 0.50
INFO:root:2019-05-10 17:49:18, Epoch : 1, Step : 694, Training Loss : 0.26939, Training Acc : 0.906, Run Time : 20.19
INFO:root:2019-05-10 17:49:20, Epoch : 1, Step : 695, Training Loss : 0.31859, Training Acc : 0.861, Run Time : 1.46
INFO:root:2019-05-10 17:49:20, Epoch : 1, Step : 696, Training Loss : 0.27731, Training Acc : 0.900, Run Time : 0.34
INFO:root:2019-05-10 17:49:21, Epoch : 1, Step : 697, Training Loss : 0.31031, Training Acc : 0.856, Run Time : 0.48
INFO:root:2019-05-10 17:49:22, Epoch : 1, Step : 698, Training Loss : 0.32281, Training Acc : 0.872, Run Time : 1.16
INFO:root:2019-05-10 17:49:39, Epoch : 1, Step : 699, Training Loss : 0.21450, Training Acc : 0.922, Run Time : 17.30
INFO:root:2019-05-10 17:49:39, Epoch : 1, Step : 700, Training Loss : 0.24057, Training Acc : 0.906, Run Time : 0.22
INFO:root:2019-05-10 17:49:41, Epoch : 1, Step : 701, Training Loss : 0.15822, Training Acc : 0.944, Run Time : 1.22
INFO:root:2019-05-10 17:49:54, Epoch : 1, Step : 702, Training Loss : 0.19005, Training Acc : 0.917, Run Time : 13.31
INFO:root:2019-05-10 17:49:54, Epoch : 1, Step : 703, Training Loss : 0.18111, Training Acc : 0.939, Run Time : 0.53
INFO:root:2019-05-10 17:49:55, Epoch : 1, Step : 704, Training Loss : 0.29321, Training Acc : 0.867, Run Time : 1.02
INFO:root:2019-05-10 17:50:09, Epoch : 1, Step : 705, Training Loss : 0.19950, Training Acc : 0.917, Run Time : 13.42
INFO:root:2019-05-10 17:50:09, Epoch : 1, Step : 706, Training Loss : 0.20912, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-10 17:50:10, Epoch : 1, Step : 707, Training Loss : 0.14629, Training Acc : 0.939, Run Time : 0.27
INFO:root:2019-05-10 17:50:10, Epoch : 1, Step : 708, Training Loss : 0.24974, Training Acc : 0.911, Run Time : 0.21
INFO:root:2019-05-10 17:50:10, Epoch : 1, Step : 709, Training Loss : 0.31657, Training Acc : 0.856, Run Time : 0.49
INFO:root:2019-05-10 17:50:30, Epoch : 1, Step : 710, Training Loss : 0.26663, Training Acc : 0.917, Run Time : 19.22
INFO:root:2019-05-10 17:50:30, Epoch : 1, Step : 711, Training Loss : 0.15492, Training Acc : 0.939, Run Time : 0.22
INFO:root:2019-05-10 17:50:30, Epoch : 1, Step : 712, Training Loss : 0.28205, Training Acc : 0.883, Run Time : 0.44
INFO:root:2019-05-10 17:50:31, Epoch : 1, Step : 713, Training Loss : 0.30183, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-10 17:50:31, Epoch : 1, Step : 714, Training Loss : 0.25732, Training Acc : 0.911, Run Time : 0.63
INFO:root:2019-05-10 17:50:47, Epoch : 1, Step : 715, Training Loss : 0.14383, Training Acc : 0.961, Run Time : 15.25
INFO:root:2019-05-10 17:50:47, Epoch : 1, Step : 716, Training Loss : 0.78397, Training Acc : 0.633, Run Time : 0.22
INFO:root:2019-05-10 17:50:47, Epoch : 1, Step : 717, Training Loss : 0.89671, Training Acc : 0.544, Run Time : 0.44
INFO:root:2019-05-10 17:50:48, Epoch : 1, Step : 718, Training Loss : 0.22133, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-10 17:50:48, Epoch : 1, Step : 719, Training Loss : 0.39814, Training Acc : 0.861, Run Time : 0.47
INFO:root:2019-05-10 17:50:58, Epoch : 1, Step : 720, Training Loss : 0.20498, Training Acc : 0.917, Run Time : 9.70
INFO:root:2019-05-10 17:51:05, Epoch : 1, Step : 721, Training Loss : 0.19563, Training Acc : 0.922, Run Time : 6.95
INFO:root:2019-05-10 17:51:15, Epoch : 1, Step : 722, Training Loss : 0.09759, Training Acc : 0.983, Run Time : 9.77
INFO:root:2019-05-10 17:51:17, Epoch : 1, Step : 723, Training Loss : 0.27118, Training Acc : 0.917, Run Time : 2.08
INFO:root:2019-05-10 17:51:17, Epoch : 1, Step : 724, Training Loss : 0.17022, Training Acc : 0.961, Run Time : 0.67
INFO:root:2019-05-10 17:51:18, Epoch : 1, Step : 725, Training Loss : 0.25408, Training Acc : 0.894, Run Time : 0.58
INFO:root:2019-05-10 17:51:18, Epoch : 1, Step : 726, Training Loss : 0.24417, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-10 17:51:19, Epoch : 1, Step : 727, Training Loss : 0.21390, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 17:51:36, Epoch : 1, Step : 728, Training Loss : 0.35238, Training Acc : 0.861, Run Time : 17.04
INFO:root:2019-05-10 17:51:36, Epoch : 1, Step : 729, Training Loss : 0.40557, Training Acc : 0.833, Run Time : 0.24
INFO:root:2019-05-10 17:51:36, Epoch : 1, Step : 730, Training Loss : 0.52236, Training Acc : 0.822, Run Time : 0.39
INFO:root:2019-05-10 17:51:37, Epoch : 1, Step : 731, Training Loss : 0.14269, Training Acc : 0.956, Run Time : 0.63
INFO:root:2019-05-10 17:51:39, Epoch : 1, Step : 732, Training Loss : 0.17875, Training Acc : 0.933, Run Time : 1.80
INFO:root:2019-05-10 17:51:56, Epoch : 1, Step : 733, Training Loss : 0.20799, Training Acc : 0.906, Run Time : 17.56
INFO:root:2019-05-10 17:51:57, Epoch : 1, Step : 734, Training Loss : 0.26984, Training Acc : 0.883, Run Time : 0.55
INFO:root:2019-05-10 17:51:57, Epoch : 1, Step : 735, Training Loss : 0.12609, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-10 17:51:58, Epoch : 1, Step : 736, Training Loss : 0.09123, Training Acc : 0.983, Run Time : 0.52
INFO:root:2019-05-10 17:51:58, Epoch : 1, Step : 737, Training Loss : 0.16048, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 17:52:14, Epoch : 1, Step : 738, Training Loss : 0.18395, Training Acc : 0.939, Run Time : 15.95
INFO:root:2019-05-10 17:52:15, Epoch : 1, Step : 739, Training Loss : 0.22120, Training Acc : 0.900, Run Time : 0.35
INFO:root:2019-05-10 17:52:15, Epoch : 1, Step : 740, Training Loss : 0.12846, Training Acc : 0.961, Run Time : 0.33
INFO:root:2019-05-10 17:52:27, Epoch : 1, Step : 741, Training Loss : 0.47573, Training Acc : 0.800, Run Time : 12.38
INFO:root:2019-05-10 17:52:28, Epoch : 1, Step : 742, Training Loss : 0.96776, Training Acc : 0.689, Run Time : 0.92
INFO:root:2019-05-10 17:52:29, Epoch : 1, Step : 743, Training Loss : 0.59298, Training Acc : 0.778, Run Time : 0.44
INFO:root:2019-05-10 17:52:29, Epoch : 1, Step : 744, Training Loss : 0.18957, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-10 17:52:33, Epoch : 1, Step : 745, Training Loss : 0.13222, Training Acc : 0.961, Run Time : 3.61
INFO:root:2019-05-10 17:52:34, Epoch : 1, Step : 746, Training Loss : 0.14595, Training Acc : 0.967, Run Time : 1.06
INFO:root:2019-05-10 17:52:34, Epoch : 1, Step : 747, Training Loss : 0.19917, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 17:52:52, Epoch : 1, Step : 748, Training Loss : 0.13480, Training Acc : 0.967, Run Time : 17.75
INFO:root:2019-05-10 17:52:52, Epoch : 1, Step : 749, Training Loss : 0.15082, Training Acc : 0.961, Run Time : 0.27
INFO:root:2019-05-10 17:52:53, Epoch : 1, Step : 750, Training Loss : 0.11208, Training Acc : 0.967, Run Time : 0.47
INFO:root:2019-05-10 17:52:55, Epoch : 1, Step : 751, Training Loss : 0.05534, Training Acc : 1.000, Run Time : 1.63
INFO:root:2019-05-10 17:53:08, Epoch : 1, Step : 752, Training Loss : 0.07710, Training Acc : 0.989, Run Time : 13.34
INFO:root:2019-05-10 17:53:08, Epoch : 1, Step : 753, Training Loss : 0.13365, Training Acc : 0.950, Run Time : 0.23
INFO:root:2019-05-10 17:53:08, Epoch : 1, Step : 754, Training Loss : 0.08685, Training Acc : 0.978, Run Time : 0.38
INFO:root:2019-05-10 17:53:13, Epoch : 1, Step : 755, Training Loss : 0.16942, Training Acc : 0.906, Run Time : 4.22
INFO:root:2019-05-10 17:53:13, Epoch : 1, Step : 756, Training Loss : 0.14700, Training Acc : 0.967, Run Time : 0.57
INFO:root:2019-05-10 17:53:14, Epoch : 1, Step : 757, Training Loss : 0.07595, Training Acc : 0.967, Run Time : 0.43
INFO:root:2019-05-10 17:53:14, Epoch : 1, Step : 758, Training Loss : 0.11928, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-10 17:53:31, Epoch : 1, Step : 759, Training Loss : 0.05829, Training Acc : 1.000, Run Time : 17.26
INFO:root:2019-05-10 17:53:32, Epoch : 1, Step : 760, Training Loss : 0.10107, Training Acc : 0.961, Run Time : 0.54
INFO:root:2019-05-10 17:53:32, Epoch : 1, Step : 761, Training Loss : 0.08909, Training Acc : 0.967, Run Time : 0.47
INFO:root:2019-05-10 17:53:33, Epoch : 1, Step : 762, Training Loss : 0.18089, Training Acc : 0.911, Run Time : 0.60
INFO:root:2019-05-10 17:53:34, Epoch : 1, Step : 763, Training Loss : 0.08207, Training Acc : 0.961, Run Time : 0.51
INFO:root:2019-05-10 17:53:51, Epoch : 1, Step : 764, Training Loss : 0.08237, Training Acc : 0.967, Run Time : 17.28
INFO:root:2019-05-10 17:53:52, Epoch : 1, Step : 765, Training Loss : 0.16514, Training Acc : 0.933, Run Time : 0.69
INFO:root:2019-05-10 17:53:52, Epoch : 1, Step : 766, Training Loss : 0.04854, Training Acc : 0.989, Run Time : 0.52
INFO:root:2019-05-10 17:53:53, Epoch : 1, Step : 767, Training Loss : 0.09800, Training Acc : 0.956, Run Time : 0.59
INFO:root:2019-05-10 17:53:53, Epoch : 1, Step : 768, Training Loss : 0.08179, Training Acc : 0.972, Run Time : 0.60
INFO:root:2019-05-10 17:54:09, Epoch : 1, Step : 769, Training Loss : 0.18047, Training Acc : 0.933, Run Time : 15.37
INFO:root:2019-05-10 17:54:09, Epoch : 1, Step : 770, Training Loss : 0.17782, Training Acc : 0.939, Run Time : 0.22
INFO:root:2019-05-10 17:54:09, Epoch : 1, Step : 771, Training Loss : 1.03603, Training Acc : 0.589, Run Time : 0.54
INFO:root:2019-05-10 17:54:10, Epoch : 1, Step : 772, Training Loss : 0.18924, Training Acc : 0.922, Run Time : 0.44
INFO:root:2019-05-10 17:54:24, Epoch : 1, Step : 773, Training Loss : 0.39543, Training Acc : 0.856, Run Time : 14.22
INFO:root:2019-05-10 17:54:25, Epoch : 1, Step : 774, Training Loss : 0.25883, Training Acc : 0.889, Run Time : 0.86
INFO:root:2019-05-10 17:54:27, Epoch : 1, Step : 775, Training Loss : 0.49453, Training Acc : 0.839, Run Time : 1.86
INFO:root:2019-05-10 17:54:40, Epoch : 1, Step : 776, Training Loss : 0.19279, Training Acc : 0.933, Run Time : 13.15
INFO:root:2019-05-10 17:54:40, Epoch : 1, Step : 777, Training Loss : 0.30174, Training Acc : 0.867, Run Time : 0.23
INFO:root:2019-05-10 17:54:40, Epoch : 1, Step : 778, Training Loss : 0.19064, Training Acc : 0.922, Run Time : 0.32
INFO:root:2019-05-10 17:54:41, Epoch : 1, Step : 779, Training Loss : 0.23947, Training Acc : 0.894, Run Time : 0.43
INFO:root:2019-05-10 17:54:41, Epoch : 1, Step : 780, Training Loss : 0.21989, Training Acc : 0.911, Run Time : 0.51
INFO:root:2019-05-10 17:54:58, Epoch : 1, Step : 781, Training Loss : 0.37006, Training Acc : 0.822, Run Time : 16.88
INFO:root:2019-05-10 17:54:58, Epoch : 1, Step : 782, Training Loss : 0.45860, Training Acc : 0.867, Run Time : 0.21
INFO:root:2019-05-10 17:54:59, Epoch : 1, Step : 783, Training Loss : 0.30476, Training Acc : 0.850, Run Time : 0.34
INFO:root:2019-05-10 17:54:59, Epoch : 1, Step : 784, Training Loss : 0.40502, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-10 17:55:00, Epoch : 1, Step : 785, Training Loss : 0.19293, Training Acc : 0.933, Run Time : 0.94
INFO:root:2019-05-10 17:55:15, Epoch : 1, Step : 786, Training Loss : 0.30051, Training Acc : 0.872, Run Time : 14.74
INFO:root:2019-05-10 17:55:16, Epoch : 1, Step : 787, Training Loss : 0.14874, Training Acc : 0.961, Run Time : 0.61
INFO:root:2019-05-10 17:55:16, Epoch : 1, Step : 788, Training Loss : 0.25234, Training Acc : 0.894, Run Time : 0.50
INFO:root:2019-05-10 17:55:17, Epoch : 1, Step : 789, Training Loss : 0.18477, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 17:55:17, Epoch : 1, Step : 790, Training Loss : 0.34023, Training Acc : 0.844, Run Time : 0.50
INFO:root:2019-05-10 17:55:32, Epoch : 1, Step : 791, Training Loss : 0.36820, Training Acc : 0.794, Run Time : 15.13
INFO:root:2019-05-10 17:55:33, Epoch : 1, Step : 792, Training Loss : 0.33266, Training Acc : 0.861, Run Time : 0.66
INFO:root:2019-05-10 17:55:33, Epoch : 1, Step : 793, Training Loss : 0.21997, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-10 17:55:34, Epoch : 1, Step : 794, Training Loss : 0.24870, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 17:55:34, Epoch : 1, Step : 795, Training Loss : 0.25685, Training Acc : 0.867, Run Time : 0.39
INFO:root:2019-05-10 17:55:53, Epoch : 1, Step : 796, Training Loss : 0.24947, Training Acc : 0.900, Run Time : 18.49
INFO:root:2019-05-10 17:55:53, Epoch : 1, Step : 797, Training Loss : 0.44804, Training Acc : 0.789, Run Time : 0.46
INFO:root:2019-05-10 17:55:54, Epoch : 1, Step : 798, Training Loss : 0.31374, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-10 17:55:54, Epoch : 1, Step : 799, Training Loss : 0.32774, Training Acc : 0.856, Run Time : 0.49
INFO:root:2019-05-10 17:55:55, Epoch : 1, Step : 800, Training Loss : 0.39960, Training Acc : 0.800, Run Time : 0.51
INFO:root:2019-05-10 17:56:11, Epoch : 1, Step : 801, Training Loss : 0.44023, Training Acc : 0.806, Run Time : 16.56
INFO:root:2019-05-10 17:56:11, Epoch : 1, Step : 802, Training Loss : 0.38283, Training Acc : 0.839, Run Time : 0.22
INFO:root:2019-05-10 17:56:12, Epoch : 1, Step : 803, Training Loss : 0.56593, Training Acc : 0.756, Run Time : 0.55
INFO:root:2019-05-10 17:56:12, Epoch : 1, Step : 804, Training Loss : 0.39329, Training Acc : 0.817, Run Time : 0.47
INFO:root:2019-05-10 17:56:13, Epoch : 1, Step : 805, Training Loss : 0.41610, Training Acc : 0.800, Run Time : 0.48
INFO:root:2019-05-10 17:56:31, Epoch : 1, Step : 806, Training Loss : 0.36507, Training Acc : 0.822, Run Time : 17.91
INFO:root:2019-05-10 17:56:31, Epoch : 1, Step : 807, Training Loss : 0.33796, Training Acc : 0.839, Run Time : 0.31
INFO:root:2019-05-10 17:56:32, Epoch : 1, Step : 808, Training Loss : 0.36645, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-10 17:56:32, Epoch : 1, Step : 809, Training Loss : 0.29293, Training Acc : 0.861, Run Time : 0.45
INFO:root:2019-05-10 17:56:32, Epoch : 1, Step : 810, Training Loss : 0.28964, Training Acc : 0.850, Run Time : 0.48
INFO:root:2019-05-10 17:56:49, Epoch : 1, Step : 811, Training Loss : 0.23103, Training Acc : 0.889, Run Time : 16.65
INFO:root:2019-05-10 17:56:49, Epoch : 1, Step : 812, Training Loss : 0.31013, Training Acc : 0.828, Run Time : 0.26
INFO:root:2019-05-10 17:56:50, Epoch : 1, Step : 813, Training Loss : 0.50149, Training Acc : 0.772, Run Time : 0.49
INFO:root:2019-05-10 17:56:50, Epoch : 1, Step : 814, Training Loss : 0.27177, Training Acc : 0.867, Run Time : 0.49
INFO:root:2019-05-10 17:56:51, Epoch : 1, Step : 815, Training Loss : 0.24328, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-10 17:57:07, Epoch : 1, Step : 816, Training Loss : 0.37551, Training Acc : 0.822, Run Time : 15.91
INFO:root:2019-05-10 17:57:07, Epoch : 1, Step : 817, Training Loss : 0.32100, Training Acc : 0.872, Run Time : 0.35
INFO:root:2019-05-10 17:57:07, Epoch : 1, Step : 818, Training Loss : 0.57378, Training Acc : 0.739, Run Time : 0.36
INFO:root:2019-05-10 17:57:08, Epoch : 1, Step : 819, Training Loss : 0.43476, Training Acc : 0.817, Run Time : 0.45
INFO:root:2019-05-10 17:57:09, Epoch : 1, Step : 820, Training Loss : 0.40240, Training Acc : 0.867, Run Time : 1.29
INFO:root:2019-05-10 17:57:29, Epoch : 1, Step : 821, Training Loss : 0.40035, Training Acc : 0.822, Run Time : 19.40
INFO:root:2019-05-10 17:57:29, Epoch : 1, Step : 822, Training Loss : 0.44429, Training Acc : 0.783, Run Time : 0.23
INFO:root:2019-05-10 17:57:29, Epoch : 1, Step : 823, Training Loss : 0.36042, Training Acc : 0.861, Run Time : 0.25
INFO:root:2019-05-10 17:57:29, Epoch : 1, Step : 824, Training Loss : 0.51083, Training Acc : 0.789, Run Time : 0.33
INFO:root:2019-05-10 17:57:42, Epoch : 1, Step : 825, Training Loss : 0.70524, Training Acc : 0.744, Run Time : 12.53
INFO:root:2019-05-10 17:57:43, Epoch : 1, Step : 826, Training Loss : 0.85972, Training Acc : 0.672, Run Time : 0.59
INFO:root:2019-05-10 17:57:43, Epoch : 1, Step : 827, Training Loss : 0.49160, Training Acc : 0.800, Run Time : 0.50
INFO:root:2019-05-10 17:57:44, Epoch : 1, Step : 828, Training Loss : 0.54812, Training Acc : 0.756, Run Time : 0.51
INFO:root:2019-05-10 17:57:44, Epoch : 1, Step : 829, Training Loss : 0.34713, Training Acc : 0.806, Run Time : 0.30
INFO:root:2019-05-10 17:58:01, Epoch : 1, Step : 830, Training Loss : 0.22323, Training Acc : 0.906, Run Time : 16.78
INFO:root:2019-05-10 17:58:01, Epoch : 1, Step : 831, Training Loss : 0.24500, Training Acc : 0.894, Run Time : 0.29
INFO:root:2019-05-10 17:58:01, Epoch : 1, Step : 832, Training Loss : 0.19391, Training Acc : 0.933, Run Time : 0.51
INFO:root:2019-05-10 17:58:02, Epoch : 1, Step : 833, Training Loss : 0.43303, Training Acc : 0.794, Run Time : 0.28
INFO:root:2019-05-10 17:58:02, Epoch : 1, Step : 834, Training Loss : 0.14429, Training Acc : 0.956, Run Time : 0.51
INFO:root:2019-05-10 17:58:18, Epoch : 1, Step : 835, Training Loss : 0.39441, Training Acc : 0.839, Run Time : 16.15
INFO:root:2019-05-10 17:58:19, Epoch : 1, Step : 836, Training Loss : 0.27218, Training Acc : 0.894, Run Time : 0.24
INFO:root:2019-05-10 17:58:19, Epoch : 1, Step : 837, Training Loss : 0.33836, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-10 17:58:20, Epoch : 1, Step : 838, Training Loss : 0.23333, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 17:58:30, Epoch : 1, Step : 839, Training Loss : 0.35244, Training Acc : 0.839, Run Time : 10.34
INFO:root:2019-05-10 17:58:33, Epoch : 1, Step : 840, Training Loss : 0.26433, Training Acc : 0.889, Run Time : 2.90
INFO:root:2019-05-10 17:58:33, Epoch : 1, Step : 841, Training Loss : 0.25469, Training Acc : 0.878, Run Time : 0.32
INFO:root:2019-05-10 17:58:34, Epoch : 1, Step : 842, Training Loss : 0.21940, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-10 17:58:34, Epoch : 1, Step : 843, Training Loss : 0.14901, Training Acc : 0.972, Run Time : 0.48
INFO:root:2019-05-10 17:58:35, Epoch : 1, Step : 844, Training Loss : 0.22620, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 17:58:51, Epoch : 1, Step : 845, Training Loss : 0.13310, Training Acc : 0.972, Run Time : 16.84
INFO:root:2019-05-10 17:58:52, Epoch : 1, Step : 846, Training Loss : 0.23407, Training Acc : 0.900, Run Time : 0.26
INFO:root:2019-05-10 17:58:52, Epoch : 1, Step : 847, Training Loss : 0.13234, Training Acc : 0.972, Run Time : 0.40
INFO:root:2019-05-10 17:58:53, Epoch : 1, Step : 848, Training Loss : 0.15478, Training Acc : 0.956, Run Time : 1.18
INFO:root:2019-05-10 17:58:54, Epoch : 1, Step : 849, Training Loss : 0.21601, Training Acc : 0.933, Run Time : 0.59
INFO:root:2019-05-10 17:59:10, Epoch : 1, Step : 850, Training Loss : 0.11832, Training Acc : 0.972, Run Time : 16.57
INFO:root:2019-05-10 17:59:11, Epoch : 1, Step : 851, Training Loss : 0.09417, Training Acc : 0.978, Run Time : 0.77
INFO:root:2019-05-10 17:59:12, Epoch : 1, Step : 852, Training Loss : 0.22336, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 17:59:12, Epoch : 1, Step : 853, Training Loss : 0.19489, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 17:59:13, Epoch : 1, Step : 854, Training Loss : 0.33082, Training Acc : 0.850, Run Time : 0.49
INFO:root:2019-05-10 17:59:28, Epoch : 1, Step : 855, Training Loss : 0.28905, Training Acc : 0.856, Run Time : 15.66
INFO:root:2019-05-10 17:59:29, Epoch : 1, Step : 856, Training Loss : 0.29926, Training Acc : 0.889, Run Time : 0.44
INFO:root:2019-05-10 17:59:29, Epoch : 1, Step : 857, Training Loss : 0.32995, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-10 17:59:30, Epoch : 1, Step : 858, Training Loss : 0.39657, Training Acc : 0.839, Run Time : 0.48
INFO:root:2019-05-10 17:59:30, Epoch : 1, Step : 859, Training Loss : 0.38170, Training Acc : 0.800, Run Time : 0.48
INFO:root:2019-05-10 17:59:47, Epoch : 1, Step : 860, Training Loss : 0.25125, Training Acc : 0.878, Run Time : 17.22
INFO:root:2019-05-10 17:59:48, Epoch : 1, Step : 861, Training Loss : 0.13450, Training Acc : 0.978, Run Time : 0.57
INFO:root:2019-05-10 17:59:48, Epoch : 1, Step : 862, Training Loss : 0.15208, Training Acc : 0.972, Run Time : 0.51
INFO:root:2019-05-10 17:59:49, Epoch : 1, Step : 863, Training Loss : 0.27422, Training Acc : 0.861, Run Time : 0.47
INFO:root:2019-05-10 18:00:04, Epoch : 1, Step : 864, Training Loss : 0.35250, Training Acc : 0.850, Run Time : 15.06
INFO:root:2019-05-10 18:00:07, Epoch : 1, Step : 865, Training Loss : 0.36308, Training Acc : 0.839, Run Time : 2.73
INFO:root:2019-05-10 18:00:07, Epoch : 1, Step : 866, Training Loss : 0.18631, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-10 18:00:08, Epoch : 1, Step : 867, Training Loss : 0.17394, Training Acc : 0.928, Run Time : 0.70
INFO:root:2019-05-10 18:00:08, Epoch : 1, Step : 868, Training Loss : 0.21804, Training Acc : 0.900, Run Time : 0.52
INFO:root:2019-05-10 18:00:09, Epoch : 1, Step : 869, Training Loss : 0.21328, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-10 18:00:26, Epoch : 1, Step : 870, Training Loss : 0.25846, Training Acc : 0.906, Run Time : 17.03
INFO:root:2019-05-10 18:00:27, Epoch : 1, Step : 871, Training Loss : 0.16710, Training Acc : 0.944, Run Time : 0.96
INFO:root:2019-05-10 18:00:27, Epoch : 1, Step : 872, Training Loss : 0.11032, Training Acc : 0.967, Run Time : 0.65
INFO:root:2019-05-10 18:00:28, Epoch : 1, Step : 873, Training Loss : 0.20850, Training Acc : 0.900, Run Time : 0.48
INFO:root:2019-05-10 18:00:29, Epoch : 1, Step : 874, Training Loss : 0.34229, Training Acc : 0.850, Run Time : 0.64
INFO:root:2019-05-10 18:00:47, Epoch : 1, Step : 875, Training Loss : 0.15529, Training Acc : 0.944, Run Time : 18.79
INFO:root:2019-05-10 18:00:48, Epoch : 1, Step : 876, Training Loss : 0.29085, Training Acc : 0.872, Run Time : 0.23
INFO:root:2019-05-10 18:00:48, Epoch : 1, Step : 877, Training Loss : 0.23490, Training Acc : 0.900, Run Time : 0.39
INFO:root:2019-05-10 18:00:48, Epoch : 1, Step : 878, Training Loss : 0.20240, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-10 18:00:49, Epoch : 1, Step : 879, Training Loss : 0.11709, Training Acc : 0.944, Run Time : 0.50
INFO:root:2019-05-10 18:01:05, Epoch : 1, Step : 880, Training Loss : 0.20914, Training Acc : 0.911, Run Time : 16.05
INFO:root:2019-05-10 18:01:06, Epoch : 1, Step : 881, Training Loss : 0.10009, Training Acc : 0.961, Run Time : 0.93
INFO:root:2019-05-10 18:01:07, Epoch : 1, Step : 882, Training Loss : 0.15972, Training Acc : 0.922, Run Time : 0.62
INFO:root:2019-05-10 18:01:18, Epoch : 1, Step : 883, Training Loss : 0.09688, Training Acc : 0.978, Run Time : 11.96
INFO:root:2019-05-10 18:01:19, Epoch : 1, Step : 884, Training Loss : 0.18222, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 18:01:19, Epoch : 1, Step : 885, Training Loss : 0.11941, Training Acc : 0.967, Run Time : 0.41
INFO:root:2019-05-10 18:01:20, Epoch : 1, Step : 886, Training Loss : 0.27332, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-10 18:01:22, Epoch : 1, Step : 887, Training Loss : 0.10406, Training Acc : 0.961, Run Time : 1.95
INFO:root:2019-05-10 18:01:34, Epoch : 1, Step : 888, Training Loss : 0.12932, Training Acc : 0.956, Run Time : 12.18
INFO:root:2019-05-10 18:01:38, Epoch : 1, Step : 889, Training Loss : 0.13348, Training Acc : 0.944, Run Time : 4.05
INFO:root:2019-05-10 18:01:39, Epoch : 1, Step : 890, Training Loss : 0.16315, Training Acc : 0.933, Run Time : 0.57
INFO:root:2019-05-10 18:01:39, Epoch : 1, Step : 891, Training Loss : 0.16645, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-10 18:01:39, Epoch : 1, Step : 892, Training Loss : 0.10132, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-10 18:01:40, Epoch : 1, Step : 893, Training Loss : 0.11716, Training Acc : 0.967, Run Time : 0.48
INFO:root:2019-05-10 18:01:51, Epoch : 1, Step : 894, Training Loss : 0.15444, Training Acc : 0.950, Run Time : 11.38
INFO:root:2019-05-10 18:01:57, Epoch : 1, Step : 895, Training Loss : 0.17870, Training Acc : 0.933, Run Time : 5.53
INFO:root:2019-05-10 18:01:57, Epoch : 1, Step : 896, Training Loss : 0.23101, Training Acc : 0.911, Run Time : 0.25
INFO:root:2019-05-10 18:01:57, Epoch : 1, Step : 897, Training Loss : 0.12513, Training Acc : 0.956, Run Time : 0.27
INFO:root:2019-05-10 18:01:58, Epoch : 1, Step : 898, Training Loss : 0.09933, Training Acc : 0.978, Run Time : 0.47
INFO:root:2019-05-10 18:01:59, Epoch : 1, Step : 899, Training Loss : 0.15596, Training Acc : 0.933, Run Time : 1.38
INFO:root:2019-05-10 18:02:15, Epoch : 1, Step : 900, Training Loss : 0.14427, Training Acc : 0.944, Run Time : 15.71
INFO:root:2019-05-10 18:02:27, Epoch : 1, Step : 901, Training Loss : 0.12252, Training Acc : 0.944, Run Time : 12.38
INFO:root:2019-05-10 18:02:28, Epoch : 1, Step : 902, Training Loss : 0.13276, Training Acc : 0.944, Run Time : 0.86
INFO:root:2019-05-10 18:02:29, Epoch : 1, Step : 903, Training Loss : 0.11905, Training Acc : 0.978, Run Time : 0.41
INFO:root:2019-05-10 18:02:38, Epoch : 1, Step : 904, Training Loss : 0.14626, Training Acc : 0.928, Run Time : 9.64
INFO:root:2019-05-10 18:02:40, Epoch : 1, Step : 905, Training Loss : 0.15797, Training Acc : 0.939, Run Time : 1.49
INFO:root:2019-05-10 18:02:40, Epoch : 1, Step : 906, Training Loss : 0.14415, Training Acc : 0.944, Run Time : 0.43
INFO:root:2019-05-10 18:02:42, Epoch : 1, Step : 907, Training Loss : 0.18468, Training Acc : 0.939, Run Time : 1.61
INFO:root:2019-05-10 18:02:42, Epoch : 1, Step : 908, Training Loss : 0.13921, Training Acc : 0.933, Run Time : 0.51
INFO:root:2019-05-10 18:02:43, Epoch : 1, Step : 909, Training Loss : 0.13013, Training Acc : 0.933, Run Time : 0.70
INFO:root:2019-05-10 18:02:58, Epoch : 1, Step : 910, Training Loss : 0.14060, Training Acc : 0.944, Run Time : 14.57
INFO:root:2019-05-10 18:02:58, Epoch : 1, Step : 911, Training Loss : 0.12170, Training Acc : 0.950, Run Time : 0.22
INFO:root:2019-05-10 18:02:58, Epoch : 1, Step : 912, Training Loss : 0.16436, Training Acc : 0.933, Run Time : 0.50
INFO:root:2019-05-10 18:02:59, Epoch : 1, Step : 913, Training Loss : 0.15683, Training Acc : 0.944, Run Time : 0.43
INFO:root:2019-05-10 18:02:59, Epoch : 1, Step : 914, Training Loss : 0.12384, Training Acc : 0.956, Run Time : 0.51
INFO:root:2019-05-10 18:03:19, Epoch : 1, Step : 915, Training Loss : 0.12037, Training Acc : 0.950, Run Time : 19.87
INFO:root:2019-05-10 18:03:19, Epoch : 1, Step : 916, Training Loss : 0.17279, Training Acc : 0.933, Run Time : 0.23
INFO:root:2019-05-10 18:03:20, Epoch : 1, Step : 917, Training Loss : 0.21052, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 18:03:20, Epoch : 1, Step : 918, Training Loss : 0.24290, Training Acc : 0.878, Run Time : 0.50
INFO:root:2019-05-10 18:03:21, Epoch : 1, Step : 919, Training Loss : 0.12749, Training Acc : 0.944, Run Time : 0.49
INFO:root:2019-05-10 18:03:38, Epoch : 1, Step : 920, Training Loss : 0.17386, Training Acc : 0.939, Run Time : 17.31
INFO:root:2019-05-10 18:03:38, Epoch : 1, Step : 921, Training Loss : 0.07688, Training Acc : 0.983, Run Time : 0.22
INFO:root:2019-05-10 18:03:39, Epoch : 1, Step : 922, Training Loss : 0.10531, Training Acc : 0.950, Run Time : 0.30
INFO:root:2019-05-10 18:03:39, Epoch : 1, Step : 923, Training Loss : 0.14060, Training Acc : 0.933, Run Time : 0.49
INFO:root:2019-05-10 18:03:40, Epoch : 1, Step : 924, Training Loss : 0.10876, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-10 18:03:56, Epoch : 1, Step : 925, Training Loss : 0.13915, Training Acc : 0.939, Run Time : 15.99
INFO:root:2019-05-10 18:03:56, Epoch : 1, Step : 926, Training Loss : 0.16397, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-10 18:03:56, Epoch : 1, Step : 927, Training Loss : 0.19138, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-10 18:03:57, Epoch : 1, Step : 928, Training Loss : 0.10446, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-10 18:03:57, Epoch : 1, Step : 929, Training Loss : 0.07354, Training Acc : 0.972, Run Time : 0.48
INFO:root:2019-05-10 18:04:13, Epoch : 1, Step : 930, Training Loss : 0.06999, Training Acc : 0.983, Run Time : 16.07
INFO:root:2019-05-10 18:04:14, Epoch : 1, Step : 931, Training Loss : 0.08933, Training Acc : 0.967, Run Time : 0.63
INFO:root:2019-05-10 18:04:14, Epoch : 1, Step : 932, Training Loss : 0.08542, Training Acc : 0.972, Run Time : 0.46
INFO:root:2019-05-10 18:04:15, Epoch : 1, Step : 933, Training Loss : 0.10534, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-10 18:04:28, Epoch : 1, Step : 934, Training Loss : 0.18321, Training Acc : 0.939, Run Time : 12.58
INFO:root:2019-05-10 18:04:28, Epoch : 1, Step : 935, Training Loss : 0.13804, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-10 18:04:28, Epoch : 1, Step : 936, Training Loss : 0.12880, Training Acc : 0.956, Run Time : 0.42
INFO:root:2019-05-10 18:04:29, Epoch : 1, Step : 937, Training Loss : 0.38751, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-10 18:04:29, Epoch : 1, Step : 938, Training Loss : 0.15637, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-10 18:04:47, Epoch : 1, Step : 939, Training Loss : 0.08981, Training Acc : 0.972, Run Time : 17.58
INFO:root:2019-05-10 18:04:47, Epoch : 1, Step : 940, Training Loss : 0.10189, Training Acc : 0.956, Run Time : 0.26
INFO:root:2019-05-10 18:04:48, Epoch : 1, Step : 941, Training Loss : 0.11889, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-10 18:04:48, Epoch : 1, Step : 942, Training Loss : 0.14605, Training Acc : 0.906, Run Time : 0.60
INFO:root:2019-05-10 18:04:49, Epoch : 1, Step : 943, Training Loss : 0.27659, Training Acc : 0.889, Run Time : 0.49
INFO:root:2019-05-10 18:05:06, Epoch : 1, Step : 944, Training Loss : 0.59678, Training Acc : 0.817, Run Time : 16.87
INFO:root:2019-05-10 18:05:06, Epoch : 1, Step : 945, Training Loss : 0.08077, Training Acc : 0.978, Run Time : 0.67
INFO:root:2019-05-10 18:05:07, Epoch : 1, Step : 946, Training Loss : 0.09532, Training Acc : 0.978, Run Time : 0.49
INFO:root:2019-05-10 18:05:07, Epoch : 1, Step : 947, Training Loss : 0.14839, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 18:05:08, Epoch : 1, Step : 948, Training Loss : 0.09928, Training Acc : 0.967, Run Time : 1.28
INFO:root:2019-05-10 18:05:22, Epoch : 1, Step : 949, Training Loss : 0.13579, Training Acc : 0.956, Run Time : 13.72
INFO:root:2019-05-10 18:05:23, Epoch : 1, Step : 950, Training Loss : 0.24869, Training Acc : 0.850, Run Time : 0.69
INFO:root:2019-05-10 18:05:23, Epoch : 1, Step : 951, Training Loss : 0.22504, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-10 18:05:24, Epoch : 1, Step : 952, Training Loss : 0.23458, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 18:05:24, Epoch : 1, Step : 953, Training Loss : 0.34225, Training Acc : 0.844, Run Time : 0.59
INFO:root:2019-05-10 18:05:41, Epoch : 1, Step : 954, Training Loss : 0.24285, Training Acc : 0.894, Run Time : 16.42
INFO:root:2019-05-10 18:05:41, Epoch : 1, Step : 955, Training Loss : 0.16033, Training Acc : 0.922, Run Time : 0.32
INFO:root:2019-05-10 18:05:41, Epoch : 1, Step : 956, Training Loss : 0.15939, Training Acc : 0.950, Run Time : 0.23
INFO:root:2019-05-10 18:05:42, Epoch : 1, Step : 957, Training Loss : 0.22143, Training Acc : 0.906, Run Time : 0.39
INFO:root:2019-05-10 18:05:42, Epoch : 1, Step : 958, Training Loss : 0.13218, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-10 18:05:59, Epoch : 1, Step : 959, Training Loss : 0.44082, Training Acc : 0.856, Run Time : 17.02
INFO:root:2019-05-10 18:06:00, Epoch : 1, Step : 960, Training Loss : 0.30839, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-10 18:06:00, Epoch : 1, Step : 961, Training Loss : 0.34424, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-10 18:06:00, Epoch : 1, Step : 962, Training Loss : 0.18266, Training Acc : 0.917, Run Time : 0.35
INFO:root:2019-05-10 18:06:14, Epoch : 1, Step : 963, Training Loss : 0.45002, Training Acc : 0.828, Run Time : 13.78
INFO:root:2019-05-10 18:06:18, Epoch : 1, Step : 964, Training Loss : 0.29407, Training Acc : 0.894, Run Time : 3.60
INFO:root:2019-05-10 18:06:18, Epoch : 1, Step : 965, Training Loss : 0.25470, Training Acc : 0.883, Run Time : 0.32
INFO:root:2019-05-10 18:06:18, Epoch : 1, Step : 966, Training Loss : 0.33719, Training Acc : 0.850, Run Time : 0.35
INFO:root:2019-05-10 18:06:33, Epoch : 1, Step : 967, Training Loss : 0.47753, Training Acc : 0.800, Run Time : 14.41
INFO:root:2019-05-10 18:06:34, Epoch : 1, Step : 968, Training Loss : 0.25039, Training Acc : 0.894, Run Time : 1.19
INFO:root:2019-05-10 18:06:35, Epoch : 1, Step : 969, Training Loss : 0.35436, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-10 18:06:35, Epoch : 1, Step : 970, Training Loss : 0.32500, Training Acc : 0.861, Run Time : 0.65
INFO:root:2019-05-10 18:06:46, Epoch : 1, Step : 971, Training Loss : 0.13381, Training Acc : 0.956, Run Time : 10.63
INFO:root:2019-05-10 18:06:46, Epoch : 1, Step : 972, Training Loss : 0.29155, Training Acc : 0.861, Run Time : 0.24
INFO:root:2019-05-10 18:06:47, Epoch : 1, Step : 973, Training Loss : 0.28242, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-10 18:06:47, Epoch : 1, Step : 974, Training Loss : 0.32255, Training Acc : 0.850, Run Time : 0.43
INFO:root:2019-05-10 18:06:47, Epoch : 1, Step : 975, Training Loss : 0.23621, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-10 18:07:04, Epoch : 1, Step : 976, Training Loss : 0.28815, Training Acc : 0.856, Run Time : 16.62
INFO:root:2019-05-10 18:07:04, Epoch : 1, Step : 977, Training Loss : 0.21613, Training Acc : 0.900, Run Time : 0.43
INFO:root:2019-05-10 18:07:05, Epoch : 1, Step : 978, Training Loss : 0.11725, Training Acc : 0.972, Run Time : 0.62
INFO:root:2019-05-10 18:07:16, Epoch : 1, Step : 979, Training Loss : 0.18585, Training Acc : 0.928, Run Time : 10.90
INFO:root:2019-05-10 18:07:17, Epoch : 1, Step : 980, Training Loss : 0.15218, Training Acc : 0.933, Run Time : 0.69
INFO:root:2019-05-10 18:07:17, Epoch : 1, Step : 981, Training Loss : 0.19158, Training Acc : 0.933, Run Time : 0.45
INFO:root:2019-05-10 18:07:18, Epoch : 1, Step : 982, Training Loss : 0.13076, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 18:07:18, Epoch : 1, Step : 983, Training Loss : 0.18780, Training Acc : 0.917, Run Time : 0.48
INFO:root:2019-05-10 18:07:22, Epoch : 1, Step : 984, Training Loss : 0.22084, Training Acc : 0.906, Run Time : 3.95
INFO:root:2019-05-10 18:07:23, Epoch : 1, Step : 985, Training Loss : 0.18875, Training Acc : 0.917, Run Time : 1.15
INFO:root:2019-05-10 18:07:41, Epoch : 1, Step : 986, Training Loss : 0.16849, Training Acc : 0.922, Run Time : 18.17
INFO:root:2019-05-10 18:07:42, Epoch : 1, Step : 987, Training Loss : 0.23978, Training Acc : 0.889, Run Time : 0.43
INFO:root:2019-05-10 18:07:42, Epoch : 1, Step : 988, Training Loss : 0.18934, Training Acc : 0.894, Run Time : 0.52
INFO:root:2019-05-10 18:07:55, Epoch : 1, Step : 989, Training Loss : 0.16612, Training Acc : 0.922, Run Time : 12.47
INFO:root:2019-05-10 18:07:56, Epoch : 1, Step : 990, Training Loss : 0.18925, Training Acc : 0.911, Run Time : 1.37
INFO:root:2019-05-10 18:07:57, Epoch : 1, Step : 991, Training Loss : 0.21995, Training Acc : 0.894, Run Time : 0.44
INFO:root:2019-05-10 18:07:57, Epoch : 1, Step : 992, Training Loss : 0.35573, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 18:08:11, Epoch : 1, Step : 993, Training Loss : 0.21792, Training Acc : 0.900, Run Time : 13.66
INFO:root:2019-05-10 18:08:11, Epoch : 1, Step : 994, Training Loss : 0.45569, Training Acc : 0.817, Run Time : 0.28
INFO:root:2019-05-10 18:08:11, Epoch : 1, Step : 995, Training Loss : 0.27948, Training Acc : 0.889, Run Time : 0.43
INFO:root:2019-05-10 18:08:12, Epoch : 1, Step : 996, Training Loss : 0.26344, Training Acc : 0.911, Run Time : 0.43
INFO:root:2019-05-10 18:08:22, Epoch : 1, Step : 997, Training Loss : 0.29047, Training Acc : 0.872, Run Time : 10.20
INFO:root:2019-05-10 18:08:23, Epoch : 1, Step : 998, Training Loss : 0.32836, Training Acc : 0.839, Run Time : 0.69
INFO:root:2019-05-10 18:08:23, Epoch : 1, Step : 999, Training Loss : 0.18942, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-10 18:08:24, Epoch : 1, Step : 1000, Training Loss : 0.43433, Training Acc : 0.856, Run Time : 0.50
INFO:root:2019-05-10 18:08:40, Epoch : 1, Step : 1001, Training Loss : 1.20263, Training Acc : 0.706, Run Time : 16.18
INFO:root:2019-05-10 18:08:41, Epoch : 1, Step : 1002, Training Loss : 1.27811, Training Acc : 0.689, Run Time : 0.69
INFO:root:2019-05-10 18:08:41, Epoch : 1, Step : 1003, Training Loss : 1.28180, Training Acc : 0.711, Run Time : 0.47
INFO:root:2019-05-10 18:08:55, Epoch : 1, Step : 1004, Training Loss : 1.34228, Training Acc : 0.678, Run Time : 13.58
INFO:root:2019-05-10 18:08:56, Epoch : 1, Step : 1005, Training Loss : 1.07711, Training Acc : 0.761, Run Time : 1.47
INFO:root:2019-05-10 18:09:07, Epoch : 1, Step : 1006, Training Loss : 1.16932, Training Acc : 0.700, Run Time : 11.38
INFO:root:2019-05-10 18:09:09, Epoch : 1, Step : 1007, Training Loss : 0.84403, Training Acc : 0.722, Run Time : 1.07
INFO:root:2019-05-10 18:09:09, Epoch : 1, Step : 1008, Training Loss : 0.67542, Training Acc : 0.739, Run Time : 0.69
INFO:root:2019-05-10 18:09:10, Epoch : 1, Step : 1009, Training Loss : 0.63105, Training Acc : 0.750, Run Time : 0.48
INFO:root:2019-05-10 18:09:10, Epoch : 1, Step : 1010, Training Loss : 0.67428, Training Acc : 0.717, Run Time : 0.50
INFO:root:2019-05-10 18:09:24, Epoch : 1, Step : 1011, Training Loss : 0.90244, Training Acc : 0.744, Run Time : 13.76
INFO:root:2019-05-10 18:09:25, Epoch : 1, Step : 1012, Training Loss : 0.68744, Training Acc : 0.733, Run Time : 0.58
INFO:root:2019-05-10 18:09:25, Epoch : 1, Step : 1013, Training Loss : 0.53216, Training Acc : 0.694, Run Time : 0.59
INFO:root:2019-05-10 18:09:40, Epoch : 1, Step : 1014, Training Loss : 0.58443, Training Acc : 0.767, Run Time : 14.95
INFO:root:2019-05-10 18:09:40, Epoch : 1, Step : 1015, Training Loss : 0.46800, Training Acc : 0.750, Run Time : 0.22
INFO:root:2019-05-10 18:09:41, Epoch : 1, Step : 1016, Training Loss : 0.47891, Training Acc : 0.767, Run Time : 0.55
INFO:root:2019-05-10 18:09:41, Epoch : 1, Step : 1017, Training Loss : 0.47620, Training Acc : 0.717, Run Time : 0.44
INFO:root:2019-05-10 18:09:53, Epoch : 1, Step : 1018, Training Loss : 0.40920, Training Acc : 0.822, Run Time : 11.78
INFO:root:2019-05-10 18:09:54, Epoch : 1, Step : 1019, Training Loss : 0.41125, Training Acc : 0.806, Run Time : 0.70
INFO:root:2019-05-10 18:09:54, Epoch : 1, Step : 1020, Training Loss : 0.48016, Training Acc : 0.761, Run Time : 0.42
INFO:root:2019-05-10 18:09:55, Epoch : 1, Step : 1021, Training Loss : 0.42161, Training Acc : 0.811, Run Time : 0.49
INFO:root:2019-05-10 18:09:55, Epoch : 1, Step : 1022, Training Loss : 0.42281, Training Acc : 0.761, Run Time : 0.49
INFO:root:2019-05-10 18:10:12, Epoch : 1, Step : 1023, Training Loss : 0.30476, Training Acc : 0.883, Run Time : 16.38
INFO:root:2019-05-10 18:10:12, Epoch : 1, Step : 1024, Training Loss : 0.33286, Training Acc : 0.883, Run Time : 0.86
INFO:root:2019-05-10 18:10:13, Epoch : 1, Step : 1025, Training Loss : 0.35655, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-10 18:10:14, Epoch : 1, Step : 1026, Training Loss : 0.32648, Training Acc : 0.872, Run Time : 0.97
INFO:root:2019-05-10 18:10:32, Epoch : 1, Step : 1027, Training Loss : 0.35079, Training Acc : 0.867, Run Time : 18.46
INFO:root:2019-05-10 18:10:34, Epoch : 1, Step : 1028, Training Loss : 0.28875, Training Acc : 0.900, Run Time : 1.22
INFO:root:2019-05-10 18:10:34, Epoch : 1, Step : 1029, Training Loss : 0.33561, Training Acc : 0.828, Run Time : 0.50
INFO:root:2019-05-10 18:10:35, Epoch : 1, Step : 1030, Training Loss : 0.37183, Training Acc : 0.789, Run Time : 0.77
INFO:root:2019-05-10 18:10:35, Epoch : 1, Step : 1031, Training Loss : 0.34100, Training Acc : 0.867, Run Time : 0.50
INFO:root:2019-05-10 18:10:51, Epoch : 1, Step : 1032, Training Loss : 0.36230, Training Acc : 0.817, Run Time : 16.13
INFO:root:2019-05-10 18:10:52, Epoch : 1, Step : 1033, Training Loss : 0.29422, Training Acc : 0.872, Run Time : 0.85
INFO:root:2019-05-10 18:10:53, Epoch : 1, Step : 1034, Training Loss : 0.46980, Training Acc : 0.772, Run Time : 0.45
INFO:root:2019-05-10 18:10:53, Epoch : 1, Step : 1035, Training Loss : 0.30945, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-10 18:11:04, Epoch : 1, Step : 1036, Training Loss : 0.44730, Training Acc : 0.761, Run Time : 11.26
INFO:root:2019-05-10 18:11:06, Epoch : 1, Step : 1037, Training Loss : 0.40768, Training Acc : 0.772, Run Time : 1.14
INFO:root:2019-05-10 18:11:16, Epoch : 1, Step : 1038, Training Loss : 0.39469, Training Acc : 0.822, Run Time : 10.71
INFO:root:2019-05-10 18:11:17, Epoch : 1, Step : 1039, Training Loss : 0.32258, Training Acc : 0.844, Run Time : 0.95
INFO:root:2019-05-10 18:11:18, Epoch : 1, Step : 1040, Training Loss : 0.31752, Training Acc : 0.839, Run Time : 0.45
INFO:root:2019-05-10 18:11:18, Epoch : 1, Step : 1041, Training Loss : 0.42889, Training Acc : 0.783, Run Time : 0.47
INFO:root:2019-05-10 18:11:37, Epoch : 1, Step : 1042, Training Loss : 0.29195, Training Acc : 0.883, Run Time : 18.38
INFO:root:2019-05-10 18:11:37, Epoch : 1, Step : 1043, Training Loss : 0.26440, Training Acc : 0.906, Run Time : 0.89
INFO:root:2019-05-10 18:11:38, Epoch : 1, Step : 1044, Training Loss : 0.33425, Training Acc : 0.850, Run Time : 0.48
INFO:root:2019-05-10 18:11:39, Epoch : 1, Step : 1045, Training Loss : 0.26417, Training Acc : 0.917, Run Time : 0.68
INFO:root:2019-05-10 18:11:39, Epoch : 1, Step : 1046, Training Loss : 0.42360, Training Acc : 0.778, Run Time : 0.48
INFO:root:2019-05-10 18:11:56, Epoch : 1, Step : 1047, Training Loss : 0.49341, Training Acc : 0.728, Run Time : 16.97
INFO:root:2019-05-10 18:11:59, Epoch : 1, Step : 1048, Training Loss : 1.07999, Training Acc : 0.472, Run Time : 2.88
INFO:root:2019-05-10 18:11:59, Epoch : 1, Step : 1049, Training Loss : 0.51944, Training Acc : 0.722, Run Time : 0.45
INFO:root:2019-05-10 18:12:00, Epoch : 1, Step : 1050, Training Loss : 0.47650, Training Acc : 0.750, Run Time : 0.48
INFO:root:2019-05-10 18:12:03, Epoch : 1, Step : 1051, Training Loss : 0.40537, Training Acc : 0.817, Run Time : 2.66
INFO:root:2019-05-10 18:12:03, Epoch : 1, Step : 1052, Training Loss : 0.39182, Training Acc : 0.800, Run Time : 0.41
INFO:root:2019-05-10 18:12:20, Epoch : 1, Step : 1053, Training Loss : 0.57381, Training Acc : 0.706, Run Time : 17.52
INFO:root:2019-05-10 18:12:22, Epoch : 1, Step : 1054, Training Loss : 0.51744, Training Acc : 0.739, Run Time : 1.22
INFO:root:2019-05-10 18:12:22, Epoch : 1, Step : 1055, Training Loss : 0.48107, Training Acc : 0.733, Run Time : 0.53
INFO:root:2019-05-10 18:12:23, Epoch : 1, Step : 1056, Training Loss : 0.69574, Training Acc : 0.650, Run Time : 0.44
INFO:root:2019-05-10 18:12:25, Epoch : 1, Step : 1057, Training Loss : 0.57531, Training Acc : 0.717, Run Time : 1.99
INFO:root:2019-05-10 18:12:39, Epoch : 1, Step : 1058, Training Loss : 0.48391, Training Acc : 0.778, Run Time : 14.78
INFO:root:2019-05-10 18:12:53, Epoch : 1, Step : 1059, Training Loss : 0.63807, Training Acc : 0.656, Run Time : 13.58
INFO:root:2019-05-10 18:12:54, Epoch : 1, Step : 1060, Training Loss : 0.52975, Training Acc : 0.767, Run Time : 1.05
INFO:root:2019-05-10 18:12:54, Epoch : 1, Step : 1061, Training Loss : 0.50348, Training Acc : 0.817, Run Time : 0.44
INFO:root:2019-05-10 18:12:55, Epoch : 1, Step : 1062, Training Loss : 0.45310, Training Acc : 0.739, Run Time : 0.47
INFO:root:2019-05-10 18:13:08, Epoch : 1, Step : 1063, Training Loss : 0.45874, Training Acc : 0.761, Run Time : 12.70
INFO:root:2019-05-10 18:13:08, Epoch : 1, Step : 1064, Training Loss : 0.37181, Training Acc : 0.844, Run Time : 0.24
INFO:root:2019-05-10 18:13:08, Epoch : 1, Step : 1065, Training Loss : 0.38106, Training Acc : 0.828, Run Time : 0.35
INFO:root:2019-05-10 18:13:09, Epoch : 1, Step : 1066, Training Loss : 0.42918, Training Acc : 0.806, Run Time : 0.50
INFO:root:2019-05-10 18:13:09, Epoch : 1, Step : 1067, Training Loss : 0.36138, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-10 18:13:13, Epoch : 1, Step : 1068, Training Loss : 0.36561, Training Acc : 0.839, Run Time : 3.94
INFO:root:2019-05-10 18:13:14, Epoch : 1, Step : 1069, Training Loss : 0.36868, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 18:13:32, Epoch : 1, Step : 1070, Training Loss : 0.35623, Training Acc : 0.900, Run Time : 18.44
INFO:root:2019-05-10 18:13:32, Epoch : 1, Step : 1071, Training Loss : 0.27632, Training Acc : 0.928, Run Time : 0.31
INFO:root:2019-05-10 18:13:33, Epoch : 1, Step : 1072, Training Loss : 0.30425, Training Acc : 0.878, Run Time : 0.46
INFO:root:2019-05-10 18:13:44, Epoch : 1, Step : 1073, Training Loss : 0.29877, Training Acc : 0.872, Run Time : 11.33
INFO:root:2019-05-10 18:13:45, Epoch : 1, Step : 1074, Training Loss : 0.30317, Training Acc : 0.878, Run Time : 0.96
INFO:root:2019-05-10 18:13:46, Epoch : 1, Step : 1075, Training Loss : 0.26134, Training Acc : 0.867, Run Time : 0.89
INFO:root:2019-05-10 18:14:00, Epoch : 1, Step : 1076, Training Loss : 0.40691, Training Acc : 0.817, Run Time : 14.27
INFO:root:2019-05-10 18:14:01, Epoch : 1, Step : 1077, Training Loss : 0.30515, Training Acc : 0.861, Run Time : 0.47
INFO:root:2019-05-10 18:14:01, Epoch : 1, Step : 1078, Training Loss : 0.34145, Training Acc : 0.811, Run Time : 0.55
INFO:root:2019-05-10 18:14:02, Epoch : 1, Step : 1079, Training Loss : 0.34968, Training Acc : 0.850, Run Time : 0.48
INFO:root:2019-05-10 18:14:02, Epoch : 1, Step : 1080, Training Loss : 0.35631, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 18:14:16, Epoch : 1, Step : 1081, Training Loss : 0.32245, Training Acc : 0.856, Run Time : 13.68
INFO:root:2019-05-10 18:14:17, Epoch : 1, Step : 1082, Training Loss : 0.30280, Training Acc : 0.889, Run Time : 0.88
INFO:root:2019-05-10 18:14:17, Epoch : 1, Step : 1083, Training Loss : 0.28910, Training Acc : 0.861, Run Time : 0.46
INFO:root:2019-05-10 18:14:18, Epoch : 1, Step : 1084, Training Loss : 0.24988, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-10 18:14:19, Epoch : 1, Step : 1085, Training Loss : 0.28962, Training Acc : 0.878, Run Time : 1.35
INFO:root:2019-05-10 18:14:35, Epoch : 1, Step : 1086, Training Loss : 0.34664, Training Acc : 0.811, Run Time : 16.03
INFO:root:2019-05-10 18:14:36, Epoch : 1, Step : 1087, Training Loss : 0.30124, Training Acc : 0.872, Run Time : 1.16
INFO:root:2019-05-10 18:14:37, Epoch : 1, Step : 1088, Training Loss : 0.30440, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-10 18:14:37, Epoch : 1, Step : 1089, Training Loss : 0.33242, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-10 18:14:38, Epoch : 1, Step : 1090, Training Loss : 0.26277, Training Acc : 0.872, Run Time : 0.87
INFO:root:2019-05-10 18:14:43, Epoch : 1, Step : 1091, Training Loss : 0.26701, Training Acc : 0.867, Run Time : 4.64
INFO:root:2019-05-10 18:14:43, Epoch : 1, Step : 1092, Training Loss : 0.33538, Training Acc : 0.839, Run Time : 0.22
INFO:root:2019-05-10 18:15:03, Epoch : 1, Step : 1093, Training Loss : 0.29925, Training Acc : 0.861, Run Time : 19.95
INFO:root:2019-05-10 18:15:03, Epoch : 1, Step : 1094, Training Loss : 0.26165, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-10 18:15:04, Epoch : 1, Step : 1095, Training Loss : 0.24117, Training Acc : 0.889, Run Time : 0.24
INFO:root:2019-05-10 18:15:04, Epoch : 1, Step : 1096, Training Loss : 0.21199, Training Acc : 0.894, Run Time : 0.52
INFO:root:2019-05-10 18:15:05, Epoch : 1, Step : 1097, Training Loss : 0.26211, Training Acc : 0.883, Run Time : 0.55
INFO:root:2019-05-10 18:15:25, Epoch : 1, Step : 1098, Training Loss : 0.23016, Training Acc : 0.906, Run Time : 19.83
INFO:root:2019-05-10 18:15:25, Epoch : 1, Step : 1099, Training Loss : 0.54194, Training Acc : 0.750, Run Time : 0.59
INFO:root:2019-05-10 18:15:40, Epoch : 1, Step : 1100, Training Loss : 0.47844, Training Acc : 0.772, Run Time : 14.89
INFO:root:2019-05-10 18:15:41, Epoch : 1, Step : 1101, Training Loss : 0.40454, Training Acc : 0.817, Run Time : 1.08
INFO:root:2019-05-10 18:15:41, Epoch : 1, Step : 1102, Training Loss : 0.34961, Training Acc : 0.833, Run Time : 0.39
INFO:root:2019-05-10 18:15:42, Epoch : 1, Step : 1103, Training Loss : 0.36324, Training Acc : 0.828, Run Time : 0.49
INFO:root:2019-05-10 18:15:42, Epoch : 1, Step : 1104, Training Loss : 0.22034, Training Acc : 0.883, Run Time : 0.41
INFO:root:2019-05-10 18:16:02, Epoch : 1, Step : 1105, Training Loss : 0.31295, Training Acc : 0.856, Run Time : 20.13
INFO:root:2019-05-10 18:16:03, Epoch : 1, Step : 1106, Training Loss : 0.36514, Training Acc : 0.828, Run Time : 0.93
INFO:root:2019-05-10 18:16:04, Epoch : 1, Step : 1107, Training Loss : 0.34808, Training Acc : 0.822, Run Time : 0.44
INFO:root:2019-05-10 18:16:04, Epoch : 1, Step : 1108, Training Loss : 0.43283, Training Acc : 0.772, Run Time : 0.49
INFO:root:2019-05-10 18:16:05, Epoch : 1, Step : 1109, Training Loss : 0.43234, Training Acc : 0.783, Run Time : 0.46
INFO:root:2019-05-10 18:16:24, Epoch : 1, Step : 1110, Training Loss : 0.52846, Training Acc : 0.739, Run Time : 19.52
INFO:root:2019-05-10 18:16:25, Epoch : 1, Step : 1111, Training Loss : 0.45540, Training Acc : 0.800, Run Time : 0.26
INFO:root:2019-05-10 18:16:25, Epoch : 1, Step : 1112, Training Loss : 0.40669, Training Acc : 0.789, Run Time : 0.47
INFO:root:2019-05-10 18:16:38, Epoch : 1, Step : 1113, Training Loss : 0.46360, Training Acc : 0.783, Run Time : 12.79
INFO:root:2019-05-10 18:16:38, Epoch : 1, Step : 1114, Training Loss : 0.46948, Training Acc : 0.733, Run Time : 0.56
INFO:root:2019-05-10 18:16:39, Epoch : 1, Step : 1115, Training Loss : 0.36903, Training Acc : 0.861, Run Time : 0.50
INFO:root:2019-05-10 18:16:39, Epoch : 1, Step : 1116, Training Loss : 0.50541, Training Acc : 0.783, Run Time : 0.48
INFO:root:2019-05-10 18:16:52, Epoch : 1, Step : 1117, Training Loss : 0.42830, Training Acc : 0.750, Run Time : 12.68
INFO:root:2019-05-10 18:16:53, Epoch : 1, Step : 1118, Training Loss : 0.42180, Training Acc : 0.806, Run Time : 0.87
INFO:root:2019-05-10 18:16:53, Epoch : 1, Step : 1119, Training Loss : 0.47132, Training Acc : 0.711, Run Time : 0.43
INFO:root:2019-05-10 18:16:54, Epoch : 1, Step : 1120, Training Loss : 0.26749, Training Acc : 0.856, Run Time : 0.49
INFO:root:2019-05-10 18:16:54, Epoch : 1, Step : 1121, Training Loss : 0.36574, Training Acc : 0.822, Run Time : 0.48
INFO:root:2019-05-10 18:17:10, Epoch : 1, Step : 1122, Training Loss : 0.39030, Training Acc : 0.778, Run Time : 15.38
INFO:root:2019-05-10 18:17:10, Epoch : 1, Step : 1123, Training Loss : 0.35539, Training Acc : 0.806, Run Time : 0.33
INFO:root:2019-05-10 18:17:10, Epoch : 1, Step : 1124, Training Loss : 0.22826, Training Acc : 0.889, Run Time : 0.44
INFO:root:2019-05-10 18:17:11, Epoch : 1, Step : 1125, Training Loss : 0.33221, Training Acc : 0.856, Run Time : 0.50
INFO:root:2019-05-10 18:17:11, Epoch : 1, Step : 1126, Training Loss : 0.35253, Training Acc : 0.833, Run Time : 0.49
INFO:root:2019-05-10 18:17:29, Epoch : 1, Step : 1127, Training Loss : 0.30722, Training Acc : 0.878, Run Time : 17.97
INFO:root:2019-05-10 18:17:31, Epoch : 1, Step : 1128, Training Loss : 0.30599, Training Acc : 0.850, Run Time : 1.65
INFO:root:2019-05-10 18:17:37, Epoch : 1, Step : 1129, Training Loss : 0.25430, Training Acc : 0.911, Run Time : 6.06
INFO:root:2019-05-10 18:17:44, Epoch : 1, Step : 1130, Training Loss : 0.20651, Training Acc : 0.944, Run Time : 6.64
INFO:root:2019-05-10 18:17:44, Epoch : 1, Step : 1131, Training Loss : 0.28465, Training Acc : 0.883, Run Time : 0.26
INFO:root:2019-05-10 18:17:53, Epoch : 1, Step : 1132, Training Loss : 0.31779, Training Acc : 0.833, Run Time : 9.26
INFO:root:2019-05-10 18:17:54, Epoch : 1, Step : 1133, Training Loss : 0.22531, Training Acc : 0.922, Run Time : 0.60
INFO:root:2019-05-10 18:17:54, Epoch : 1, Step : 1134, Training Loss : 0.21510, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-10 18:17:55, Epoch : 1, Step : 1135, Training Loss : 0.22178, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 18:17:55, Epoch : 1, Step : 1136, Training Loss : 0.19621, Training Acc : 0.939, Run Time : 0.31
INFO:root:2019-05-10 18:18:15, Epoch : 1, Step : 1137, Training Loss : 0.28970, Training Acc : 0.867, Run Time : 19.77
INFO:root:2019-05-10 18:18:15, Epoch : 1, Step : 1138, Training Loss : 0.23056, Training Acc : 0.917, Run Time : 0.37
INFO:root:2019-05-10 18:18:16, Epoch : 1, Step : 1139, Training Loss : 0.18812, Training Acc : 0.933, Run Time : 0.65
INFO:root:2019-05-10 18:18:29, Epoch : 1, Step : 1140, Training Loss : 0.28727, Training Acc : 0.867, Run Time : 12.84
INFO:root:2019-05-10 18:18:29, Epoch : 1, Step : 1141, Training Loss : 0.26810, Training Acc : 0.872, Run Time : 0.29
INFO:root:2019-05-10 18:18:30, Epoch : 1, Step : 1142, Training Loss : 0.26343, Training Acc : 0.867, Run Time : 0.43
INFO:root:2019-05-10 18:18:30, Epoch : 1, Step : 1143, Training Loss : 0.23884, Training Acc : 0.883, Run Time : 0.50
INFO:root:2019-05-10 18:18:31, Epoch : 1, Step : 1144, Training Loss : 0.20020, Training Acc : 0.950, Run Time : 0.63
INFO:root:2019-05-10 18:18:34, Epoch : 1, Step : 1145, Training Loss : 0.22103, Training Acc : 0.911, Run Time : 3.79
INFO:root:2019-05-10 18:18:35, Epoch : 1, Step : 1146, Training Loss : 0.23605, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-10 18:18:52, Epoch : 1, Step : 1147, Training Loss : 0.16588, Training Acc : 0.956, Run Time : 16.80
INFO:root:2019-05-10 18:18:52, Epoch : 1, Step : 1148, Training Loss : 0.18893, Training Acc : 0.939, Run Time : 0.32
INFO:root:2019-05-10 18:18:53, Epoch : 1, Step : 1149, Training Loss : 0.22771, Training Acc : 0.944, Run Time : 0.54
INFO:root:2019-05-10 18:19:03, Epoch : 1, Step : 1150, Training Loss : 0.19455, Training Acc : 0.928, Run Time : 10.39
INFO:root:2019-05-10 18:19:07, Epoch : 1, Step : 1151, Training Loss : 0.18988, Training Acc : 0.961, Run Time : 4.25
INFO:root:2019-05-10 18:19:07, Epoch : 1, Step : 1152, Training Loss : 0.18853, Training Acc : 0.950, Run Time : 0.24
INFO:root:2019-05-10 18:19:21, Epoch : 1, Step : 1153, Training Loss : 0.58941, Training Acc : 0.783, Run Time : 13.52
INFO:root:2019-05-10 18:19:22, Epoch : 1, Step : 1154, Training Loss : 0.84595, Training Acc : 0.728, Run Time : 0.64
INFO:root:2019-05-10 18:19:22, Epoch : 1, Step : 1155, Training Loss : 0.26941, Training Acc : 0.900, Run Time : 0.48
INFO:root:2019-05-10 18:19:23, Epoch : 1, Step : 1156, Training Loss : 0.27929, Training Acc : 0.867, Run Time : 0.49
INFO:root:2019-05-10 18:19:23, Epoch : 1, Step : 1157, Training Loss : 0.28461, Training Acc : 0.889, Run Time : 0.50
INFO:root:2019-05-10 18:19:59, Epoch : 1, Step : 1158, Training Loss : 0.27756, Training Acc : 0.911, Run Time : 36.21
INFO:root:2019-05-10 18:19:59, Epoch : 1, Step : 1159, Training Loss : 0.44451, Training Acc : 0.761, Run Time : 0.23
INFO:root:2019-05-10 18:20:00, Epoch : 1, Step : 1160, Training Loss : 0.52841, Training Acc : 0.756, Run Time : 0.39
INFO:root:2019-05-10 18:20:00, Epoch : 1, Step : 1161, Training Loss : 0.49647, Training Acc : 0.783, Run Time : 0.53
INFO:root:2019-05-10 18:20:01, Epoch : 1, Step : 1162, Training Loss : 0.44958, Training Acc : 0.783, Run Time : 0.49
INFO:root:2019-05-10 18:20:22, Epoch : 1, Step : 1163, Training Loss : 0.52667, Training Acc : 0.728, Run Time : 21.34
INFO:root:2019-05-10 18:20:22, Epoch : 1, Step : 1164, Training Loss : 0.40286, Training Acc : 0.794, Run Time : 0.23
INFO:root:2019-05-10 18:20:23, Epoch : 1, Step : 1165, Training Loss : 0.33431, Training Acc : 0.839, Run Time : 0.22
INFO:root:2019-05-10 18:20:23, Epoch : 1, Step : 1166, Training Loss : 0.37521, Training Acc : 0.839, Run Time : 0.53
INFO:root:2019-05-10 18:20:24, Epoch : 1, Step : 1167, Training Loss : 0.34337, Training Acc : 0.856, Run Time : 0.45
INFO:root:2019-05-10 18:20:52, Epoch : 1, Step : 1168, Training Loss : 0.28974, Training Acc : 0.867, Run Time : 28.69
INFO:root:2019-05-10 18:20:53, Epoch : 1, Step : 1169, Training Loss : 0.30878, Training Acc : 0.867, Run Time : 0.39
INFO:root:2019-05-10 18:20:53, Epoch : 1, Step : 1170, Training Loss : 0.33884, Training Acc : 0.828, Run Time : 0.46
INFO:root:2019-05-10 18:20:54, Epoch : 1, Step : 1171, Training Loss : 0.41994, Training Acc : 0.783, Run Time : 0.47
INFO:root:2019-05-10 18:20:54, Epoch : 1, Step : 1172, Training Loss : 0.41219, Training Acc : 0.800, Run Time : 0.41
INFO:root:2019-05-10 18:21:19, Epoch : 1, Step : 1173, Training Loss : 0.38229, Training Acc : 0.822, Run Time : 24.66
INFO:root:2019-05-10 18:21:19, Epoch : 1, Step : 1174, Training Loss : 0.58737, Training Acc : 0.722, Run Time : 0.22
INFO:root:2019-05-10 18:21:19, Epoch : 1, Step : 1175, Training Loss : 0.43854, Training Acc : 0.800, Run Time : 0.29
INFO:root:2019-05-10 18:21:20, Epoch : 1, Step : 1176, Training Loss : 0.44069, Training Acc : 0.794, Run Time : 0.46
INFO:root:2019-05-10 18:21:20, Epoch : 1, Step : 1177, Training Loss : 0.33101, Training Acc : 0.844, Run Time : 0.51
INFO:root:2019-05-10 18:21:39, Epoch : 1, Step : 1178, Training Loss : 0.27646, Training Acc : 0.889, Run Time : 18.65
INFO:root:2019-05-10 18:21:39, Epoch : 1, Step : 1179, Training Loss : 0.35347, Training Acc : 0.867, Run Time : 0.22
INFO:root:2019-05-10 18:21:39, Epoch : 1, Step : 1180, Training Loss : 0.37952, Training Acc : 0.817, Run Time : 0.26
INFO:root:2019-05-10 18:21:40, Epoch : 1, Step : 1181, Training Loss : 0.29054, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 18:21:40, Epoch : 1, Step : 1182, Training Loss : 0.32146, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 18:21:58, Epoch : 1, Step : 1183, Training Loss : 0.42402, Training Acc : 0.828, Run Time : 18.03
INFO:root:2019-05-10 18:21:59, Epoch : 1, Step : 1184, Training Loss : 0.32873, Training Acc : 0.883, Run Time : 0.22
INFO:root:2019-05-10 18:21:59, Epoch : 1, Step : 1185, Training Loss : 0.32337, Training Acc : 0.861, Run Time : 0.48
INFO:root:2019-05-10 18:21:59, Epoch : 1, Step : 1186, Training Loss : 0.36157, Training Acc : 0.828, Run Time : 0.48
INFO:root:2019-05-10 18:22:01, Epoch : 1, Step : 1187, Training Loss : 0.34232, Training Acc : 0.844, Run Time : 1.40
INFO:root:2019-05-10 18:22:17, Epoch : 1, Step : 1188, Training Loss : 0.30936, Training Acc : 0.839, Run Time : 15.68
INFO:root:2019-05-10 18:22:17, Epoch : 1, Step : 1189, Training Loss : 0.29552, Training Acc : 0.850, Run Time : 0.23
INFO:root:2019-05-10 18:22:17, Epoch : 1, Step : 1190, Training Loss : 0.30195, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 18:22:28, Epoch : 1, Step : 1191, Training Loss : 0.29073, Training Acc : 0.883, Run Time : 10.58
INFO:root:2019-05-10 18:22:29, Epoch : 1, Step : 1192, Training Loss : 0.28935, Training Acc : 0.872, Run Time : 1.03
INFO:root:2019-05-10 18:22:29, Epoch : 1, Step : 1193, Training Loss : 0.28173, Training Acc : 0.906, Run Time : 0.45
INFO:root:2019-05-10 18:22:30, Epoch : 1, Step : 1194, Training Loss : 0.24704, Training Acc : 0.900, Run Time : 1.13
INFO:root:2019-05-10 18:22:42, Epoch : 1, Step : 1195, Training Loss : 0.34962, Training Acc : 0.883, Run Time : 11.91
INFO:root:2019-05-10 18:22:43, Epoch : 1, Step : 1196, Training Loss : 0.37409, Training Acc : 0.844, Run Time : 0.89
INFO:root:2019-05-10 18:22:44, Epoch : 1, Step : 1197, Training Loss : 0.29754, Training Acc : 0.872, Run Time : 0.57
INFO:root:2019-05-10 18:22:44, Epoch : 1, Step : 1198, Training Loss : 0.40677, Training Acc : 0.839, Run Time : 0.50
INFO:root:2019-05-10 18:22:45, Epoch : 1, Step : 1199, Training Loss : 0.30776, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 18:23:02, Epoch : 1, Step : 1200, Training Loss : 0.27107, Training Acc : 0.883, Run Time : 16.91
INFO:root:2019-05-10 18:23:02, Epoch : 1, Step : 1201, Training Loss : 0.46748, Training Acc : 0.833, Run Time : 0.62
INFO:root:2019-05-10 18:23:04, Epoch : 1, Step : 1202, Training Loss : 0.41077, Training Acc : 0.867, Run Time : 2.10
INFO:root:2019-05-10 18:23:06, Epoch : 1, Step : 1203, Training Loss : 0.32239, Training Acc : 0.872, Run Time : 1.68
INFO:root:2019-05-10 18:23:17, Epoch : 1, Step : 1204, Training Loss : 0.34043, Training Acc : 0.861, Run Time : 10.64
INFO:root:2019-05-10 18:23:17, Epoch : 1, Step : 1205, Training Loss : 0.36962, Training Acc : 0.778, Run Time : 0.22
INFO:root:2019-05-10 18:23:17, Epoch : 1, Step : 1206, Training Loss : 0.35338, Training Acc : 0.778, Run Time : 0.22
INFO:root:2019-05-10 18:23:18, Epoch : 1, Step : 1207, Training Loss : 0.39428, Training Acc : 0.811, Run Time : 0.58
INFO:root:2019-05-10 18:23:19, Epoch : 1, Step : 1208, Training Loss : 0.60884, Training Acc : 0.756, Run Time : 0.74
INFO:root:2019-05-10 18:23:23, Epoch : 1, Step : 1209, Training Loss : 0.41952, Training Acc : 0.778, Run Time : 4.71
INFO:root:2019-05-10 18:23:24, Epoch : 1, Step : 1210, Training Loss : 0.30623, Training Acc : 0.850, Run Time : 0.48
INFO:root:2019-05-10 18:23:45, Epoch : 1, Step : 1211, Training Loss : 0.35203, Training Acc : 0.822, Run Time : 21.14
INFO:root:2019-05-10 18:23:45, Epoch : 1, Step : 1212, Training Loss : 0.32691, Training Acc : 0.867, Run Time : 0.34
INFO:root:2019-05-10 18:23:46, Epoch : 1, Step : 1213, Training Loss : 0.21184, Training Acc : 0.983, Run Time : 1.25
INFO:root:2019-05-10 18:23:50, Epoch : 1, Step : 1214, Training Loss : 0.22420, Training Acc : 0.928, Run Time : 3.20
INFO:root:2019-05-10 18:24:00, Epoch : 1, Step : 1215, Training Loss : 0.29390, Training Acc : 0.911, Run Time : 9.90
INFO:root:2019-05-10 18:24:00, Epoch : 1, Step : 1216, Training Loss : 0.27092, Training Acc : 0.900, Run Time : 0.60
INFO:root:2019-05-10 18:24:01, Epoch : 1, Step : 1217, Training Loss : 0.17351, Training Acc : 0.978, Run Time : 0.45
INFO:root:2019-05-10 18:24:01, Epoch : 1, Step : 1218, Training Loss : 0.17100, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 18:24:02, Epoch : 1, Step : 1219, Training Loss : 0.25652, Training Acc : 0.928, Run Time : 0.50
INFO:root:2019-05-10 18:24:19, Epoch : 1, Step : 1220, Training Loss : 0.17122, Training Acc : 0.939, Run Time : 17.84
INFO:root:2019-05-10 18:24:20, Epoch : 1, Step : 1221, Training Loss : 0.24511, Training Acc : 0.889, Run Time : 0.22
INFO:root:2019-05-10 18:24:20, Epoch : 1, Step : 1222, Training Loss : 0.18043, Training Acc : 0.956, Run Time : 0.45
INFO:root:2019-05-10 18:24:21, Epoch : 1, Step : 1223, Training Loss : 0.14483, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-10 18:24:21, Epoch : 1, Step : 1224, Training Loss : 0.22689, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 18:24:37, Epoch : 1, Step : 1225, Training Loss : 0.20729, Training Acc : 0.933, Run Time : 16.19
INFO:root:2019-05-10 18:24:37, Epoch : 1, Step : 1226, Training Loss : 0.16581, Training Acc : 0.933, Run Time : 0.26
INFO:root:2019-05-10 18:24:38, Epoch : 1, Step : 1227, Training Loss : 0.26088, Training Acc : 0.894, Run Time : 0.44
INFO:root:2019-05-10 18:24:38, Epoch : 1, Step : 1228, Training Loss : 0.17365, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 18:24:39, Epoch : 1, Step : 1229, Training Loss : 0.18783, Training Acc : 0.922, Run Time : 0.57
INFO:root:2019-05-10 18:25:04, Epoch : 1, Step : 1230, Training Loss : 0.19052, Training Acc : 0.911, Run Time : 24.87
INFO:root:2019-05-10 18:25:04, Epoch : 1, Step : 1231, Training Loss : 0.17245, Training Acc : 0.911, Run Time : 0.33
INFO:root:2019-05-10 18:25:04, Epoch : 1, Step : 1232, Training Loss : 0.18041, Training Acc : 0.933, Run Time : 0.27
INFO:root:2019-05-10 18:25:05, Epoch : 1, Step : 1233, Training Loss : 0.19851, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-10 18:25:05, Epoch : 1, Step : 1234, Training Loss : 0.20219, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-10 18:25:20, Epoch : 1, Step : 1235, Training Loss : 0.18543, Training Acc : 0.933, Run Time : 14.52
INFO:root:2019-05-10 18:25:20, Epoch : 1, Step : 1236, Training Loss : 0.17776, Training Acc : 0.917, Run Time : 0.27
INFO:root:2019-05-10 18:25:21, Epoch : 1, Step : 1237, Training Loss : 0.19416, Training Acc : 0.922, Run Time : 0.44
INFO:root:2019-05-10 18:25:33, Epoch : 1, Step : 1238, Training Loss : 0.23693, Training Acc : 0.900, Run Time : 12.41
INFO:root:2019-05-10 18:25:34, Epoch : 1, Step : 1239, Training Loss : 0.25401, Training Acc : 0.883, Run Time : 0.76
INFO:root:2019-05-10 18:25:34, Epoch : 1, Step : 1240, Training Loss : 0.16061, Training Acc : 0.956, Run Time : 0.45
INFO:root:2019-05-10 18:25:46, Epoch : 1, Step : 1241, Training Loss : 0.17651, Training Acc : 0.917, Run Time : 11.44
INFO:root:2019-05-10 18:25:46, Epoch : 1, Step : 1242, Training Loss : 0.18912, Training Acc : 0.933, Run Time : 0.82
INFO:root:2019-05-10 18:25:47, Epoch : 1, Step : 1243, Training Loss : 0.18530, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-10 18:25:47, Epoch : 1, Step : 1244, Training Loss : 0.19001, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-10 18:25:49, Epoch : 1, Step : 1245, Training Loss : 0.15655, Training Acc : 0.944, Run Time : 1.41
INFO:root:2019-05-10 18:26:03, Epoch : 1, Step : 1246, Training Loss : 0.28857, Training Acc : 0.867, Run Time : 14.65
INFO:root:2019-05-10 18:26:04, Epoch : 1, Step : 1247, Training Loss : 0.13581, Training Acc : 0.956, Run Time : 0.56
INFO:root:2019-05-10 18:26:05, Epoch : 1, Step : 1248, Training Loss : 0.19505, Training Acc : 0.933, Run Time : 0.47
INFO:root:2019-05-10 18:26:05, Epoch : 1, Step : 1249, Training Loss : 0.23337, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-10 18:26:17, Epoch : 1, Step : 1250, Training Loss : 0.26284, Training Acc : 0.883, Run Time : 12.34
INFO:root:2019-05-10 18:26:18, Epoch : 1, Step : 1251, Training Loss : 0.22567, Training Acc : 0.900, Run Time : 0.44
INFO:root:2019-05-10 18:26:18, Epoch : 1, Step : 1252, Training Loss : 0.31632, Training Acc : 0.889, Run Time : 0.22
INFO:root:2019-05-10 18:26:18, Epoch : 1, Step : 1253, Training Loss : 0.30257, Training Acc : 0.850, Run Time : 0.37
INFO:root:2019-05-10 18:26:19, Epoch : 1, Step : 1254, Training Loss : 0.17516, Training Acc : 0.928, Run Time : 0.66
INFO:root:2019-05-10 18:26:24, Epoch : 1, Step : 1255, Training Loss : 0.32525, Training Acc : 0.856, Run Time : 5.49
INFO:root:2019-05-10 18:26:25, Epoch : 1, Step : 1256, Training Loss : 0.25384, Training Acc : 0.850, Run Time : 0.35
INFO:root:2019-05-10 18:26:43, Epoch : 1, Step : 1257, Training Loss : 0.22713, Training Acc : 0.911, Run Time : 17.81
INFO:root:2019-05-10 18:26:43, Epoch : 1, Step : 1258, Training Loss : 0.42017, Training Acc : 0.767, Run Time : 0.68
INFO:root:2019-05-10 18:26:44, Epoch : 1, Step : 1259, Training Loss : 0.20134, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 18:26:44, Epoch : 1, Step : 1260, Training Loss : 0.29730, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 18:26:45, Epoch : 1, Step : 1261, Training Loss : 0.41054, Training Acc : 0.839, Run Time : 0.49
INFO:root:2019-05-10 18:27:02, Epoch : 1, Step : 1262, Training Loss : 0.55618, Training Acc : 0.783, Run Time : 17.02
INFO:root:2019-05-10 18:27:03, Epoch : 1, Step : 1263, Training Loss : 0.74329, Training Acc : 0.761, Run Time : 0.74
INFO:root:2019-05-10 18:27:03, Epoch : 1, Step : 1264, Training Loss : 0.38491, Training Acc : 0.794, Run Time : 0.37
INFO:root:2019-05-10 18:27:15, Epoch : 1, Step : 1265, Training Loss : 0.24964, Training Acc : 0.883, Run Time : 11.93
INFO:root:2019-05-10 18:27:16, Epoch : 1, Step : 1266, Training Loss : 0.62725, Training Acc : 0.728, Run Time : 1.03
INFO:root:2019-05-10 18:27:26, Epoch : 1, Step : 1267, Training Loss : 0.24881, Training Acc : 0.911, Run Time : 9.77
INFO:root:2019-05-10 18:27:27, Epoch : 1, Step : 1268, Training Loss : 0.56789, Training Acc : 0.800, Run Time : 0.89
INFO:root:2019-05-10 18:27:27, Epoch : 1, Step : 1269, Training Loss : 0.63983, Training Acc : 0.733, Run Time : 0.40
INFO:root:2019-05-10 18:27:27, Epoch : 1, Step : 1270, Training Loss : 0.41510, Training Acc : 0.794, Run Time : 0.48
INFO:root:2019-05-10 18:27:28, Epoch : 1, Step : 1271, Training Loss : 0.33494, Training Acc : 0.839, Run Time : 0.60
INFO:root:2019-05-10 18:27:43, Epoch : 1, Step : 1272, Training Loss : 0.25566, Training Acc : 0.889, Run Time : 14.92
INFO:root:2019-05-10 18:27:43, Epoch : 1, Step : 1273, Training Loss : 0.28186, Training Acc : 0.844, Run Time : 0.37
INFO:root:2019-05-10 18:27:44, Epoch : 1, Step : 1274, Training Loss : 0.36141, Training Acc : 0.828, Run Time : 0.79
INFO:root:2019-05-10 18:28:02, Epoch : 1, Step : 1275, Training Loss : 0.25507, Training Acc : 0.856, Run Time : 17.50
INFO:root:2019-05-10 18:28:02, Epoch : 1, Step : 1276, Training Loss : 0.38087, Training Acc : 0.833, Run Time : 0.71
INFO:root:2019-05-10 18:28:03, Epoch : 1, Step : 1277, Training Loss : 0.23221, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-10 18:28:03, Epoch : 1, Step : 1278, Training Loss : 0.32606, Training Acc : 0.856, Run Time : 0.42
INFO:root:2019-05-10 18:28:04, Epoch : 1, Step : 1279, Training Loss : 0.34985, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 18:28:27, Epoch : 1, Step : 1280, Training Loss : 0.30044, Training Acc : 0.856, Run Time : 23.73
INFO:root:2019-05-10 18:28:28, Epoch : 1, Step : 1281, Training Loss : 0.29845, Training Acc : 0.894, Run Time : 0.70
INFO:root:2019-05-10 18:28:28, Epoch : 1, Step : 1282, Training Loss : 0.37414, Training Acc : 0.806, Run Time : 0.48
INFO:root:2019-05-10 18:28:29, Epoch : 1, Step : 1283, Training Loss : 0.18926, Training Acc : 0.933, Run Time : 0.50
INFO:root:2019-05-10 18:28:30, Epoch : 1, Step : 1284, Training Loss : 0.27924, Training Acc : 0.883, Run Time : 0.81
INFO:root:2019-05-10 18:28:33, Epoch : 1, Step : 1285, Training Loss : 0.33070, Training Acc : 0.828, Run Time : 3.40
INFO:root:2019-05-10 18:28:34, Epoch : 1, Step : 1286, Training Loss : 0.34120, Training Acc : 0.861, Run Time : 0.50
INFO:root:2019-05-10 18:28:53, Epoch : 1, Step : 1287, Training Loss : 0.32937, Training Acc : 0.878, Run Time : 19.20
INFO:root:2019-05-10 18:28:54, Epoch : 1, Step : 1288, Training Loss : 0.34600, Training Acc : 0.889, Run Time : 0.75
INFO:root:2019-05-10 18:28:54, Epoch : 1, Step : 1289, Training Loss : 0.37020, Training Acc : 0.861, Run Time : 0.46
INFO:root:2019-05-10 18:28:55, Epoch : 1, Step : 1290, Training Loss : 0.34156, Training Acc : 0.861, Run Time : 0.48
INFO:root:2019-05-10 18:28:55, Epoch : 1, Step : 1291, Training Loss : 0.27347, Training Acc : 0.872, Run Time : 0.52
INFO:root:2019-05-10 18:29:15, Epoch : 1, Step : 1292, Training Loss : 0.26876, Training Acc : 0.906, Run Time : 19.93
INFO:root:2019-05-10 18:29:16, Epoch : 1, Step : 1293, Training Loss : 0.22080, Training Acc : 0.933, Run Time : 1.46
INFO:root:2019-05-10 18:29:17, Epoch : 1, Step : 1294, Training Loss : 0.26419, Training Acc : 0.894, Run Time : 0.26
INFO:root:2019-05-10 18:29:17, Epoch : 1, Step : 1295, Training Loss : 0.27134, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 18:29:18, Epoch : 1, Step : 1296, Training Loss : 0.35812, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-10 18:29:36, Epoch : 1, Step : 1297, Training Loss : 0.27735, Training Acc : 0.906, Run Time : 17.94
INFO:root:2019-05-10 18:29:36, Epoch : 1, Step : 1298, Training Loss : 0.35525, Training Acc : 0.867, Run Time : 0.36
INFO:root:2019-05-10 18:29:36, Epoch : 1, Step : 1299, Training Loss : 0.33618, Training Acc : 0.872, Run Time : 0.39
INFO:root:2019-05-10 18:29:37, Epoch : 1, Step : 1300, Training Loss : 0.29781, Training Acc : 0.883, Run Time : 0.50
INFO:root:2019-05-10 18:29:43, Epoch : 1, Step : 1301, Training Loss : 0.32115, Training Acc : 0.867, Run Time : 5.65
INFO:root:2019-05-10 18:29:45, Epoch : 1, Step : 1302, Training Loss : 0.24617, Training Acc : 0.906, Run Time : 2.04
INFO:root:2019-05-10 18:29:45, Epoch : 1, Step : 1303, Training Loss : 0.20139, Training Acc : 0.939, Run Time : 0.47
INFO:root:2019-05-10 18:29:58, Epoch : 1, Step : 1304, Training Loss : 0.23809, Training Acc : 0.917, Run Time : 13.16
INFO:root:2019-05-10 18:29:58, Epoch : 1, Step : 1305, Training Loss : 0.29900, Training Acc : 0.856, Run Time : 0.21
INFO:root:2019-05-10 18:29:59, Epoch : 1, Step : 1306, Training Loss : 0.24638, Training Acc : 0.883, Run Time : 0.35
INFO:root:2019-05-10 18:29:59, Epoch : 1, Step : 1307, Training Loss : 0.40395, Training Acc : 0.800, Run Time : 0.46
INFO:root:2019-05-10 18:30:00, Epoch : 1, Step : 1308, Training Loss : 0.25323, Training Acc : 0.894, Run Time : 0.54
INFO:root:2019-05-10 18:30:17, Epoch : 1, Step : 1309, Training Loss : 0.32252, Training Acc : 0.883, Run Time : 17.59
INFO:root:2019-05-10 18:30:18, Epoch : 1, Step : 1310, Training Loss : 0.39828, Training Acc : 0.822, Run Time : 0.55
INFO:root:2019-05-10 18:30:18, Epoch : 1, Step : 1311, Training Loss : 0.32623, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-10 18:30:19, Epoch : 1, Step : 1312, Training Loss : 0.44385, Training Acc : 0.789, Run Time : 0.48
INFO:root:2019-05-10 18:30:19, Epoch : 1, Step : 1313, Training Loss : 0.41500, Training Acc : 0.794, Run Time : 0.51
INFO:root:2019-05-10 18:30:37, Epoch : 1, Step : 1314, Training Loss : 0.70544, Training Acc : 0.667, Run Time : 17.21
INFO:root:2019-05-10 18:30:37, Epoch : 1, Step : 1315, Training Loss : 0.68095, Training Acc : 0.717, Run Time : 0.65
INFO:root:2019-05-10 18:30:38, Epoch : 1, Step : 1316, Training Loss : 0.66855, Training Acc : 0.706, Run Time : 0.45
INFO:root:2019-05-10 18:30:38, Epoch : 1, Step : 1317, Training Loss : 0.39635, Training Acc : 0.778, Run Time : 0.56
INFO:root:2019-05-10 18:30:39, Epoch : 1, Step : 1318, Training Loss : 0.37816, Training Acc : 0.811, Run Time : 0.48
INFO:root:2019-05-10 18:30:42, Epoch : 1, Step : 1319, Training Loss : 0.49489, Training Acc : 0.744, Run Time : 3.61
INFO:root:2019-05-10 18:30:44, Epoch : 1, Step : 1320, Training Loss : 0.58458, Training Acc : 0.717, Run Time : 1.76
INFO:root:2019-05-10 18:31:08, Epoch : 1, Step : 1321, Training Loss : 0.36145, Training Acc : 0.839, Run Time : 23.74
INFO:root:2019-05-10 18:31:08, Epoch : 1, Step : 1322, Training Loss : 0.36755, Training Acc : 0.844, Run Time : 0.25
INFO:root:2019-05-10 18:31:09, Epoch : 1, Step : 1323, Training Loss : 0.31251, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 18:31:10, Epoch : 1, Step : 1324, Training Loss : 0.31776, Training Acc : 0.861, Run Time : 1.61
INFO:root:2019-05-10 18:31:21, Epoch : 1, Step : 1325, Training Loss : 0.35328, Training Acc : 0.844, Run Time : 10.88
INFO:root:2019-05-10 18:31:21, Epoch : 1, Step : 1326, Training Loss : 0.33114, Training Acc : 0.856, Run Time : 0.35
INFO:root:2019-05-10 18:31:22, Epoch : 1, Step : 1327, Training Loss : 0.43698, Training Acc : 0.806, Run Time : 0.44
INFO:root:2019-05-10 18:31:42, Epoch : 1, Step : 1328, Training Loss : 0.56522, Training Acc : 0.733, Run Time : 20.22
INFO:root:2019-05-10 18:31:43, Epoch : 1, Step : 1329, Training Loss : 0.46391, Training Acc : 0.778, Run Time : 0.66
INFO:root:2019-05-10 18:31:43, Epoch : 1, Step : 1330, Training Loss : 0.41691, Training Acc : 0.817, Run Time : 0.55
INFO:root:2019-05-10 18:31:44, Epoch : 1, Step : 1331, Training Loss : 0.41572, Training Acc : 0.817, Run Time : 0.50
INFO:root:2019-05-10 18:31:45, Epoch : 1, Step : 1332, Training Loss : 0.57034, Training Acc : 0.706, Run Time : 1.12
INFO:root:2019-05-10 18:32:01, Epoch : 1, Step : 1333, Training Loss : 0.41911, Training Acc : 0.806, Run Time : 15.77
INFO:root:2019-05-10 18:32:01, Epoch : 1, Step : 1334, Training Loss : 0.40518, Training Acc : 0.783, Run Time : 0.33
INFO:root:2019-05-10 18:32:01, Epoch : 1, Step : 1335, Training Loss : 0.41041, Training Acc : 0.822, Run Time : 0.46
INFO:root:2019-05-10 18:32:02, Epoch : 1, Step : 1336, Training Loss : 0.37603, Training Acc : 0.817, Run Time : 0.48
INFO:root:2019-05-10 18:32:02, Epoch : 1, Step : 1337, Training Loss : 0.33966, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-10 18:32:18, Epoch : 1, Step : 1338, Training Loss : 0.40899, Training Acc : 0.789, Run Time : 15.58
INFO:root:2019-05-10 18:32:18, Epoch : 1, Step : 1339, Training Loss : 0.41100, Training Acc : 0.744, Run Time : 0.25
INFO:root:2019-05-10 18:32:18, Epoch : 1, Step : 1340, Training Loss : 0.43723, Training Acc : 0.750, Run Time : 0.24
INFO:root:2019-05-10 18:32:19, Epoch : 1, Step : 1341, Training Loss : 0.51912, Training Acc : 0.756, Run Time : 0.76
INFO:root:2019-05-10 18:32:20, Epoch : 1, Step : 1342, Training Loss : 0.40452, Training Acc : 0.806, Run Time : 1.17
INFO:root:2019-05-10 18:32:36, Epoch : 1, Step : 1343, Training Loss : 0.41483, Training Acc : 0.800, Run Time : 15.70
INFO:root:2019-05-10 18:32:36, Epoch : 1, Step : 1344, Training Loss : 0.35272, Training Acc : 0.822, Run Time : 0.24
INFO:root:2019-05-10 18:32:37, Epoch : 1, Step : 1345, Training Loss : 0.26441, Training Acc : 0.889, Run Time : 0.42
INFO:root:2019-05-10 18:32:37, Epoch : 1, Step : 1346, Training Loss : 0.28373, Training Acc : 0.883, Run Time : 0.50
INFO:root:2019-05-10 18:32:38, Epoch : 1, Step : 1347, Training Loss : 0.30229, Training Acc : 0.872, Run Time : 0.49
INFO:root:2019-05-10 18:32:45, Epoch : 1, Step : 1348, Training Loss : 0.30498, Training Acc : 0.867, Run Time : 7.06
INFO:root:2019-05-10 18:32:45, Epoch : 1, Step : 1349, Training Loss : 0.27937, Training Acc : 0.878, Run Time : 0.31
INFO:root:2019-05-10 18:33:00, Epoch : 1, Step : 1350, Training Loss : 0.23848, Training Acc : 0.906, Run Time : 15.06
INFO:root:2019-05-10 18:33:00, Epoch : 1, Step : 1351, Training Loss : 0.26630, Training Acc : 0.906, Run Time : 0.30
INFO:root:2019-05-10 18:33:01, Epoch : 1, Step : 1352, Training Loss : 0.40641, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-10 18:33:01, Epoch : 1, Step : 1353, Training Loss : 0.39731, Training Acc : 0.839, Run Time : 0.51
INFO:root:2019-05-10 18:33:02, Epoch : 1, Step : 1354, Training Loss : 0.40253, Training Acc : 0.822, Run Time : 0.41
INFO:root:2019-05-10 18:33:19, Epoch : 1, Step : 1355, Training Loss : 0.34542, Training Acc : 0.861, Run Time : 17.57
INFO:root:2019-05-10 18:33:20, Epoch : 1, Step : 1356, Training Loss : 0.32732, Training Acc : 0.839, Run Time : 0.26
INFO:root:2019-05-10 18:33:20, Epoch : 1, Step : 1357, Training Loss : 0.36718, Training Acc : 0.811, Run Time : 0.31
INFO:root:2019-05-10 18:33:20, Epoch : 1, Step : 1358, Training Loss : 0.35576, Training Acc : 0.833, Run Time : 0.50
INFO:root:2019-05-10 18:33:21, Epoch : 1, Step : 1359, Training Loss : 0.32329, Training Acc : 0.856, Run Time : 0.51
INFO:root:2019-05-10 18:33:38, Epoch : 1, Step : 1360, Training Loss : 0.35540, Training Acc : 0.850, Run Time : 16.70
INFO:root:2019-05-10 18:33:38, Epoch : 1, Step : 1361, Training Loss : 0.35283, Training Acc : 0.839, Run Time : 0.22
INFO:root:2019-05-10 18:33:38, Epoch : 1, Step : 1362, Training Loss : 0.32557, Training Acc : 0.828, Run Time : 0.32
INFO:root:2019-05-10 18:33:39, Epoch : 1, Step : 1363, Training Loss : 0.39023, Training Acc : 0.811, Run Time : 0.48
INFO:root:2019-05-10 18:33:39, Epoch : 1, Step : 1364, Training Loss : 0.35928, Training Acc : 0.828, Run Time : 0.48
INFO:root:2019-05-10 18:33:43, Epoch : 1, Step : 1365, Training Loss : 0.31426, Training Acc : 0.844, Run Time : 4.17
INFO:root:2019-05-10 18:33:44, Epoch : 1, Step : 1366, Training Loss : 0.41167, Training Acc : 0.789, Run Time : 0.45
INFO:root:2019-05-10 18:34:00, Epoch : 1, Step : 1367, Training Loss : 0.34214, Training Acc : 0.872, Run Time : 16.06
INFO:root:2019-05-10 18:34:00, Epoch : 1, Step : 1368, Training Loss : 0.37907, Training Acc : 0.789, Run Time : 0.35
INFO:root:2019-05-10 18:34:00, Epoch : 1, Step : 1369, Training Loss : 0.27740, Training Acc : 0.911, Run Time : 0.28
INFO:root:2019-05-10 18:34:01, Epoch : 1, Step : 1370, Training Loss : 0.40159, Training Acc : 0.794, Run Time : 0.47
INFO:root:2019-05-10 18:34:01, Epoch : 1, Step : 1371, Training Loss : 0.40533, Training Acc : 0.794, Run Time : 0.51
INFO:root:2019-05-10 18:34:19, Epoch : 1, Step : 1372, Training Loss : 0.32627, Training Acc : 0.833, Run Time : 17.82
INFO:root:2019-05-10 18:34:20, Epoch : 1, Step : 1373, Training Loss : 0.38673, Training Acc : 0.817, Run Time : 0.22
INFO:root:2019-05-10 18:34:20, Epoch : 1, Step : 1374, Training Loss : 0.34633, Training Acc : 0.833, Run Time : 0.44
INFO:root:2019-05-10 18:34:20, Epoch : 1, Step : 1375, Training Loss : 0.37190, Training Acc : 0.794, Run Time : 0.47
INFO:root:2019-05-10 18:34:31, Epoch : 1, Step : 1376, Training Loss : 0.34212, Training Acc : 0.856, Run Time : 10.62
INFO:root:2019-05-10 18:34:32, Epoch : 1, Step : 1377, Training Loss : 0.29138, Training Acc : 0.894, Run Time : 0.69
INFO:root:2019-05-10 18:34:32, Epoch : 1, Step : 1378, Training Loss : 0.34610, Training Acc : 0.817, Run Time : 0.55
INFO:root:2019-05-10 18:34:44, Epoch : 1, Step : 1379, Training Loss : 0.32134, Training Acc : 0.828, Run Time : 11.31
INFO:root:2019-05-10 18:34:45, Epoch : 1, Step : 1380, Training Loss : 0.27374, Training Acc : 0.894, Run Time : 1.25
INFO:root:2019-05-10 18:34:46, Epoch : 1, Step : 1381, Training Loss : 0.29631, Training Acc : 0.861, Run Time : 1.19
INFO:root:2019-05-10 18:35:08, Epoch : 1, Step : 1382, Training Loss : 0.33049, Training Acc : 0.844, Run Time : 21.87
INFO:root:2019-05-10 18:35:08, Epoch : 1, Step : 1383, Training Loss : 0.25101, Training Acc : 0.883, Run Time : 0.33
INFO:root:2019-05-10 18:35:09, Epoch : 1, Step : 1384, Training Loss : 0.20458, Training Acc : 0.939, Run Time : 0.40
INFO:root:2019-05-10 18:35:09, Epoch : 1, Step : 1385, Training Loss : 0.31615, Training Acc : 0.828, Run Time : 0.48
INFO:root:2019-05-10 18:35:10, Epoch : 1, Step : 1386, Training Loss : 0.22597, Training Acc : 0.894, Run Time : 0.43
INFO:root:2019-05-10 18:35:31, Epoch : 1, Step : 1387, Training Loss : 0.26544, Training Acc : 0.883, Run Time : 21.57
INFO:root:2019-05-10 18:35:31, Epoch : 1, Step : 1388, Training Loss : 0.27480, Training Acc : 0.883, Run Time : 0.30
INFO:root:2019-05-10 18:35:32, Epoch : 1, Step : 1389, Training Loss : 0.24479, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-10 18:35:32, Epoch : 1, Step : 1390, Training Loss : 0.25602, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-10 18:35:44, Epoch : 1, Step : 1391, Training Loss : 0.21818, Training Acc : 0.900, Run Time : 11.86
INFO:root:2019-05-10 18:35:45, Epoch : 1, Step : 1392, Training Loss : 0.19700, Training Acc : 0.922, Run Time : 1.03
INFO:root:2019-05-10 18:35:51, Epoch : 1, Step : 1393, Training Loss : 0.27362, Training Acc : 0.872, Run Time : 5.72
INFO:root:2019-05-10 18:35:52, Epoch : 1, Step : 1394, Training Loss : 0.24043, Training Acc : 0.894, Run Time : 0.72
INFO:root:2019-05-10 18:35:52, Epoch : 1, Step : 1395, Training Loss : 0.25710, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-10 18:35:53, Epoch : 1, Step : 1396, Training Loss : 0.24811, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-10 18:35:53, Epoch : 1, Step : 1397, Training Loss : 0.24282, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-10 18:36:09, Epoch : 1, Step : 1398, Training Loss : 0.26547, Training Acc : 0.889, Run Time : 15.66
INFO:root:2019-05-10 18:36:09, Epoch : 1, Step : 1399, Training Loss : 0.24650, Training Acc : 0.889, Run Time : 0.23
INFO:root:2019-05-10 18:36:09, Epoch : 1, Step : 1400, Training Loss : 0.19131, Training Acc : 0.939, Run Time : 0.36
INFO:root:2019-05-10 18:36:20, Epoch : 1, Step : 1401, Training Loss : 0.28349, Training Acc : 0.833, Run Time : 11.08
INFO:root:2019-05-10 18:36:21, Epoch : 1, Step : 1402, Training Loss : 0.30433, Training Acc : 0.822, Run Time : 0.80
INFO:root:2019-05-10 18:36:22, Epoch : 1, Step : 1403, Training Loss : 0.36620, Training Acc : 0.822, Run Time : 0.43
INFO:root:2019-05-10 18:36:22, Epoch : 1, Step : 1404, Training Loss : 0.25607, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-10 18:36:23, Epoch : 1, Step : 1405, Training Loss : 0.28239, Training Acc : 0.850, Run Time : 0.75
INFO:root:2019-05-10 18:36:39, Epoch : 1, Step : 1406, Training Loss : 0.33367, Training Acc : 0.856, Run Time : 16.21
INFO:root:2019-05-10 18:36:39, Epoch : 1, Step : 1407, Training Loss : 0.33738, Training Acc : 0.817, Run Time : 0.22
INFO:root:2019-05-10 18:36:40, Epoch : 1, Step : 1408, Training Loss : 0.25212, Training Acc : 0.900, Run Time : 0.45
INFO:root:2019-05-10 18:36:40, Epoch : 1, Step : 1409, Training Loss : 0.32764, Training Acc : 0.878, Run Time : 0.64
INFO:root:2019-05-10 18:36:42, Epoch : 1, Step : 1410, Training Loss : 0.21408, Training Acc : 0.889, Run Time : 1.26
INFO:root:2019-05-10 18:36:55, Epoch : 1, Step : 1411, Training Loss : 0.25158, Training Acc : 0.894, Run Time : 13.10
INFO:root:2019-05-10 18:36:59, Epoch : 1, Step : 1412, Training Loss : 0.28014, Training Acc : 0.856, Run Time : 4.43
INFO:root:2019-05-10 18:37:00, Epoch : 1, Step : 1413, Training Loss : 0.38148, Training Acc : 0.839, Run Time : 0.34
INFO:root:2019-05-10 18:37:00, Epoch : 1, Step : 1414, Training Loss : 0.30106, Training Acc : 0.850, Run Time : 0.25
INFO:root:2019-05-10 18:37:00, Epoch : 1, Step : 1415, Training Loss : 0.30873, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-10 18:37:01, Epoch : 1, Step : 1416, Training Loss : 0.18594, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 18:37:18, Epoch : 1, Step : 1417, Training Loss : 0.34116, Training Acc : 0.828, Run Time : 17.60
INFO:root:2019-05-10 18:37:20, Epoch : 1, Step : 1418, Training Loss : 0.27514, Training Acc : 0.872, Run Time : 2.04
INFO:root:2019-05-10 18:37:21, Epoch : 1, Step : 1419, Training Loss : 0.29858, Training Acc : 0.844, Run Time : 0.44
INFO:root:2019-05-10 18:37:21, Epoch : 1, Step : 1420, Training Loss : 0.23337, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-10 18:37:22, Epoch : 1, Step : 1421, Training Loss : 0.21949, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 18:37:23, Epoch : 1, Step : 1422, Training Loss : 0.34225, Training Acc : 0.817, Run Time : 1.27
INFO:root:2019-05-10 18:37:47, Epoch : 1, Step : 1423, Training Loss : 0.22575, Training Acc : 0.894, Run Time : 24.16
INFO:root:2019-05-10 18:37:47, Epoch : 1, Step : 1424, Training Loss : 0.41651, Training Acc : 0.833, Run Time : 0.22
INFO:root:2019-05-10 18:37:48, Epoch : 1, Step : 1425, Training Loss : 0.26001, Training Acc : 0.917, Run Time : 0.30
INFO:root:2019-05-10 18:37:48, Epoch : 1, Step : 1426, Training Loss : 0.35850, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 18:37:49, Epoch : 1, Step : 1427, Training Loss : 0.23923, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 18:38:15, Epoch : 1, Step : 1428, Training Loss : 0.30862, Training Acc : 0.844, Run Time : 26.07
INFO:root:2019-05-10 18:38:15, Epoch : 1, Step : 1429, Training Loss : 0.43734, Training Acc : 0.800, Run Time : 0.58
INFO:root:2019-05-10 18:38:17, Epoch : 1, Step : 1430, Training Loss : 0.30216, Training Acc : 0.839, Run Time : 1.81
INFO:root:2019-05-10 18:38:18, Epoch : 1, Step : 1431, Training Loss : 0.31336, Training Acc : 0.839, Run Time : 0.51
INFO:root:2019-05-10 18:38:18, Epoch : 1, Step : 1432, Training Loss : 0.29924, Training Acc : 0.867, Run Time : 0.52
INFO:root:2019-05-10 18:38:22, Epoch : 1, Step : 1433, Training Loss : 0.34196, Training Acc : 0.828, Run Time : 3.68
INFO:root:2019-05-10 18:38:22, Epoch : 1, Step : 1434, Training Loss : 0.29653, Training Acc : 0.861, Run Time : 0.47
INFO:root:2019-05-10 18:38:37, Epoch : 1, Step : 1435, Training Loss : 0.23759, Training Acc : 0.906, Run Time : 14.45
INFO:root:2019-05-10 18:38:37, Epoch : 1, Step : 1436, Training Loss : 0.31121, Training Acc : 0.883, Run Time : 0.24
INFO:root:2019-05-10 18:38:37, Epoch : 1, Step : 1437, Training Loss : 0.31865, Training Acc : 0.867, Run Time : 0.48
INFO:root:2019-05-10 18:38:38, Epoch : 1, Step : 1438, Training Loss : 0.24135, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 18:38:38, Epoch : 1, Step : 1439, Training Loss : 0.24858, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-10 18:38:55, Epoch : 1, Step : 1440, Training Loss : 0.38714, Training Acc : 0.850, Run Time : 16.67
INFO:root:2019-05-10 18:38:56, Epoch : 1, Step : 1441, Training Loss : 0.26530, Training Acc : 0.906, Run Time : 1.26
INFO:root:2019-05-10 18:38:57, Epoch : 1, Step : 1442, Training Loss : 0.35583, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-10 18:38:57, Epoch : 1, Step : 1443, Training Loss : 0.24806, Training Acc : 0.900, Run Time : 0.50
INFO:root:2019-05-10 18:38:58, Epoch : 1, Step : 1444, Training Loss : 0.31622, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 18:39:03, Epoch : 1, Step : 1445, Training Loss : 0.27212, Training Acc : 0.872, Run Time : 5.15
INFO:root:2019-05-10 18:39:03, Epoch : 1, Step : 1446, Training Loss : 0.22172, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 18:39:18, Epoch : 1, Step : 1447, Training Loss : 0.24800, Training Acc : 0.883, Run Time : 15.12
INFO:root:2019-05-10 18:39:19, Epoch : 1, Step : 1448, Training Loss : 0.21252, Training Acc : 0.906, Run Time : 0.21
INFO:root:2019-05-10 18:39:19, Epoch : 1, Step : 1449, Training Loss : 0.23812, Training Acc : 0.900, Run Time : 0.22
INFO:root:2019-05-10 18:39:19, Epoch : 1, Step : 1450, Training Loss : 0.21674, Training Acc : 0.933, Run Time : 0.60
INFO:root:2019-05-10 18:39:20, Epoch : 1, Step : 1451, Training Loss : 0.24800, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-10 18:39:32, Epoch : 1, Step : 1452, Training Loss : 0.20970, Training Acc : 0.917, Run Time : 11.71
INFO:root:2019-05-10 18:39:32, Epoch : 1, Step : 1453, Training Loss : 0.22139, Training Acc : 0.911, Run Time : 0.39
INFO:root:2019-05-10 18:39:33, Epoch : 1, Step : 1454, Training Loss : 0.19192, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-10 18:39:33, Epoch : 1, Step : 1455, Training Loss : 0.28879, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-10 18:39:34, Epoch : 1, Step : 1456, Training Loss : 0.21271, Training Acc : 0.911, Run Time : 1.31
INFO:root:2019-05-10 18:39:49, Epoch : 1, Step : 1457, Training Loss : 0.18374, Training Acc : 0.944, Run Time : 15.06
INFO:root:2019-05-10 18:39:50, Epoch : 1, Step : 1458, Training Loss : 0.18424, Training Acc : 0.922, Run Time : 0.23
INFO:root:2019-05-10 18:39:50, Epoch : 1, Step : 1459, Training Loss : 0.26180, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 18:39:51, Epoch : 1, Step : 1460, Training Loss : 0.18875, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-10 18:39:51, Epoch : 1, Step : 1461, Training Loss : 0.30696, Training Acc : 0.867, Run Time : 0.48
INFO:root:2019-05-10 18:40:07, Epoch : 1, Step : 1462, Training Loss : 0.29537, Training Acc : 0.861, Run Time : 16.26
INFO:root:2019-05-10 18:40:08, Epoch : 1, Step : 1463, Training Loss : 0.29022, Training Acc : 0.867, Run Time : 0.25
INFO:root:2019-05-10 18:40:08, Epoch : 1, Step : 1464, Training Loss : 0.25806, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-10 18:40:09, Epoch : 1, Step : 1465, Training Loss : 0.29083, Training Acc : 0.861, Run Time : 0.50
INFO:root:2019-05-10 18:40:09, Epoch : 1, Step : 1466, Training Loss : 0.23927, Training Acc : 0.906, Run Time : 0.50
INFO:root:2019-05-10 18:40:15, Epoch : 1, Step : 1467, Training Loss : 0.34313, Training Acc : 0.872, Run Time : 6.42
INFO:root:2019-05-10 18:40:27, Epoch : 1, Step : 1468, Training Loss : 0.20505, Training Acc : 0.911, Run Time : 11.81
INFO:root:2019-05-10 18:40:28, Epoch : 1, Step : 1469, Training Loss : 0.32787, Training Acc : 0.878, Run Time : 1.15
INFO:root:2019-05-10 18:40:29, Epoch : 1, Step : 1470, Training Loss : 0.27440, Training Acc : 0.906, Run Time : 0.44
INFO:root:2019-05-10 18:40:29, Epoch : 1, Step : 1471, Training Loss : 0.20568, Training Acc : 0.906, Run Time : 0.50
INFO:root:2019-05-10 18:40:40, Epoch : 1, Step : 1472, Training Loss : 0.31918, Training Acc : 0.839, Run Time : 10.64
INFO:root:2019-05-10 18:40:41, Epoch : 1, Step : 1473, Training Loss : 0.34176, Training Acc : 0.872, Run Time : 0.54
INFO:root:2019-05-10 18:40:41, Epoch : 1, Step : 1474, Training Loss : 0.22557, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-10 18:40:41, Epoch : 1, Step : 1475, Training Loss : 0.17052, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-10 18:40:42, Epoch : 1, Step : 1476, Training Loss : 0.22766, Training Acc : 0.917, Run Time : 0.61
INFO:root:2019-05-10 18:40:58, Epoch : 1, Step : 1477, Training Loss : 0.21983, Training Acc : 0.939, Run Time : 16.01
INFO:root:2019-05-10 18:40:58, Epoch : 1, Step : 1478, Training Loss : 0.19251, Training Acc : 0.933, Run Time : 0.24
INFO:root:2019-05-10 18:40:59, Epoch : 1, Step : 1479, Training Loss : 0.22625, Training Acc : 0.883, Run Time : 0.36
INFO:root:2019-05-10 18:40:59, Epoch : 1, Step : 1480, Training Loss : 0.26698, Training Acc : 0.889, Run Time : 0.56
INFO:root:2019-05-10 18:41:00, Epoch : 1, Step : 1481, Training Loss : 0.24884, Training Acc : 0.906, Run Time : 0.48
INFO:root:2019-05-10 18:41:15, Epoch : 1, Step : 1482, Training Loss : 0.29104, Training Acc : 0.906, Run Time : 15.59
INFO:root:2019-05-10 18:41:16, Epoch : 1, Step : 1483, Training Loss : 0.27031, Training Acc : 0.889, Run Time : 0.84
INFO:root:2019-05-10 18:41:17, Epoch : 1, Step : 1484, Training Loss : 0.29843, Training Acc : 0.889, Run Time : 0.49
INFO:root:2019-05-10 18:41:17, Epoch : 1, Step : 1485, Training Loss : 0.31637, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-10 18:41:18, Epoch : 1, Step : 1486, Training Loss : 0.26444, Training Acc : 0.900, Run Time : 0.49
INFO:root:2019-05-10 18:41:37, Epoch : 1, Step : 1487, Training Loss : 0.24085, Training Acc : 0.883, Run Time : 19.56
INFO:root:2019-05-10 18:41:37, Epoch : 1, Step : 1488, Training Loss : 0.17150, Training Acc : 0.933, Run Time : 0.27
INFO:root:2019-05-10 18:41:38, Epoch : 1, Step : 1489, Training Loss : 0.20306, Training Acc : 0.922, Run Time : 0.50
INFO:root:2019-05-10 18:41:38, Epoch : 1, Step : 1490, Training Loss : 0.27040, Training Acc : 0.867, Run Time : 0.48
INFO:root:2019-05-10 18:41:40, Epoch : 1, Step : 1491, Training Loss : 0.19510, Training Acc : 0.900, Run Time : 1.23
INFO:root:2019-05-10 18:41:54, Epoch : 1, Step : 1492, Training Loss : 0.20501, Training Acc : 0.911, Run Time : 14.67
INFO:root:2019-05-10 18:41:55, Epoch : 1, Step : 1493, Training Loss : 0.21412, Training Acc : 0.894, Run Time : 0.81
INFO:root:2019-05-10 18:41:57, Epoch : 1, Step : 1494, Training Loss : 0.26036, Training Acc : 0.867, Run Time : 1.80
INFO:root:2019-05-10 18:42:10, Epoch : 1, Step : 1495, Training Loss : 0.26122, Training Acc : 0.872, Run Time : 12.63
INFO:root:2019-05-10 18:42:10, Epoch : 1, Step : 1496, Training Loss : 0.32716, Training Acc : 0.861, Run Time : 0.39
INFO:root:2019-05-10 18:42:10, Epoch : 1, Step : 1497, Training Loss : 0.25562, Training Acc : 0.872, Run Time : 0.35
INFO:root:2019-05-10 18:42:11, Epoch : 1, Step : 1498, Training Loss : 0.41358, Training Acc : 0.789, Run Time : 0.44
INFO:root:2019-05-10 18:42:11, Epoch : 1, Step : 1499, Training Loss : 0.24917, Training Acc : 0.878, Run Time : 0.53
INFO:root:2019-05-10 18:42:30, Epoch : 1, Step : 1500, Training Loss : 0.18556, Training Acc : 0.917, Run Time : 18.69
INFO:root:2019-05-10 18:42:31, Epoch : 1, Step : 1501, Training Loss : 0.28091, Training Acc : 0.850, Run Time : 0.53
INFO:root:2019-05-10 18:42:31, Epoch : 1, Step : 1502, Training Loss : 0.26569, Training Acc : 0.883, Run Time : 0.22
INFO:root:2019-05-10 18:42:31, Epoch : 1, Step : 1503, Training Loss : 0.21922, Training Acc : 0.917, Run Time : 0.49
INFO:root:2019-05-10 18:42:32, Epoch : 1, Step : 1504, Training Loss : 0.29215, Training Acc : 0.867, Run Time : 0.44
INFO:root:2019-05-10 18:42:50, Epoch : 1, Step : 1505, Training Loss : 0.29170, Training Acc : 0.850, Run Time : 18.05
INFO:root:2019-05-10 18:42:50, Epoch : 1, Step : 1506, Training Loss : 0.26337, Training Acc : 0.894, Run Time : 0.23
INFO:root:2019-05-10 18:42:50, Epoch : 1, Step : 1507, Training Loss : 0.21912, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-10 18:42:51, Epoch : 1, Step : 1508, Training Loss : 0.26381, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-10 18:42:51, Epoch : 1, Step : 1509, Training Loss : 0.20477, Training Acc : 0.917, Run Time : 0.48
INFO:root:2019-05-10 18:43:13, Epoch : 1, Step : 1510, Training Loss : 0.18603, Training Acc : 0.939, Run Time : 21.53
INFO:root:2019-05-10 18:43:13, Epoch : 1, Step : 1511, Training Loss : 0.21863, Training Acc : 0.911, Run Time : 0.26
INFO:root:2019-05-10 18:43:14, Epoch : 1, Step : 1512, Training Loss : 0.21390, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 18:43:25, Epoch : 1, Step : 1513, Training Loss : 0.23863, Training Acc : 0.883, Run Time : 11.77
INFO:root:2019-05-10 18:43:37, Epoch : 1, Step : 1514, Training Loss : 0.20088, Training Acc : 0.894, Run Time : 11.63
INFO:root:2019-05-10 18:43:52, Epoch : 1, Step : 1515, Training Loss : 0.24491, Training Acc : 0.883, Run Time : 15.07
INFO:root:2019-05-10 18:43:53, Epoch : 1, Step : 1516, Training Loss : 0.19761, Training Acc : 0.911, Run Time : 0.61
INFO:root:2019-05-10 18:43:53, Epoch : 1, Step : 1517, Training Loss : 0.19629, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 18:43:54, Epoch : 1, Step : 1518, Training Loss : 0.23468, Training Acc : 0.872, Run Time : 0.53
INFO:root:2019-05-10 18:43:54, Epoch : 1, Step : 1519, Training Loss : 0.23172, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-10 18:44:12, Epoch : 1, Step : 1520, Training Loss : 0.26112, Training Acc : 0.872, Run Time : 18.27
INFO:root:2019-05-10 18:44:13, Epoch : 1, Step : 1521, Training Loss : 0.24406, Training Acc : 0.889, Run Time : 0.55
INFO:root:2019-05-10 18:44:13, Epoch : 1, Step : 1522, Training Loss : 0.23417, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 18:44:14, Epoch : 1, Step : 1523, Training Loss : 0.34346, Training Acc : 0.833, Run Time : 0.45
INFO:root:2019-05-10 18:44:14, Epoch : 1, Step : 1524, Training Loss : 0.27136, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-10 18:44:33, Epoch : 1, Step : 1525, Training Loss : 0.27299, Training Acc : 0.867, Run Time : 18.55
INFO:root:2019-05-10 18:44:34, Epoch : 1, Step : 1526, Training Loss : 0.24727, Training Acc : 0.883, Run Time : 0.80
INFO:root:2019-05-10 18:44:36, Epoch : 1, Step : 1527, Training Loss : 0.20355, Training Acc : 0.922, Run Time : 1.84
INFO:root:2019-05-10 18:44:47, Epoch : 1, Step : 1528, Training Loss : 0.22130, Training Acc : 0.894, Run Time : 11.88
INFO:root:2019-05-10 18:44:48, Epoch : 1, Step : 1529, Training Loss : 0.19567, Training Acc : 0.911, Run Time : 0.82
INFO:root:2019-05-10 18:44:49, Epoch : 1, Step : 1530, Training Loss : 0.18672, Training Acc : 0.933, Run Time : 0.34
INFO:root:2019-05-10 18:44:49, Epoch : 1, Step : 1531, Training Loss : 0.15058, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-10 18:44:50, Epoch : 1, Step : 1532, Training Loss : 0.14344, Training Acc : 0.961, Run Time : 0.55
INFO:root:2019-05-10 18:45:12, Epoch : 1, Step : 1533, Training Loss : 0.23145, Training Acc : 0.922, Run Time : 22.57
INFO:root:2019-05-10 18:45:12, Epoch : 1, Step : 1534, Training Loss : 0.19299, Training Acc : 0.933, Run Time : 0.23
INFO:root:2019-05-10 18:45:13, Epoch : 1, Step : 1535, Training Loss : 0.25111, Training Acc : 0.906, Run Time : 0.27
INFO:root:2019-05-10 18:45:13, Epoch : 1, Step : 1536, Training Loss : 0.22066, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-10 18:45:14, Epoch : 1, Step : 1537, Training Loss : 0.17901, Training Acc : 0.911, Run Time : 0.50
INFO:root:2019-05-10 18:45:37, Epoch : 1, Step : 1538, Training Loss : 0.29849, Training Acc : 0.856, Run Time : 23.63
INFO:root:2019-05-10 18:45:38, Epoch : 1, Step : 1539, Training Loss : 0.29464, Training Acc : 0.856, Run Time : 0.56
INFO:root:2019-05-10 18:45:38, Epoch : 1, Step : 1540, Training Loss : 0.32406, Training Acc : 0.856, Run Time : 0.45
INFO:root:2019-05-10 18:45:39, Epoch : 1, Step : 1541, Training Loss : 0.34128, Training Acc : 0.867, Run Time : 0.48
INFO:root:2019-05-10 18:45:40, Epoch : 1, Step : 1542, Training Loss : 0.22171, Training Acc : 0.867, Run Time : 1.27
INFO:root:2019-05-10 18:45:55, Epoch : 1, Step : 1543, Training Loss : 0.28826, Training Acc : 0.867, Run Time : 14.97
INFO:root:2019-05-10 18:45:56, Epoch : 1, Step : 1544, Training Loss : 0.36377, Training Acc : 0.861, Run Time : 0.96
INFO:root:2019-05-10 18:45:56, Epoch : 1, Step : 1545, Training Loss : 0.27599, Training Acc : 0.867, Run Time : 0.36
INFO:root:2019-05-10 18:46:09, Epoch : 1, Step : 1546, Training Loss : 0.23673, Training Acc : 0.883, Run Time : 12.32
INFO:root:2019-05-10 18:46:09, Epoch : 1, Step : 1547, Training Loss : 0.22486, Training Acc : 0.889, Run Time : 0.79
INFO:root:2019-05-10 18:46:10, Epoch : 1, Step : 1548, Training Loss : 0.24983, Training Acc : 0.906, Run Time : 0.44
INFO:root:2019-05-10 18:46:10, Epoch : 1, Step : 1549, Training Loss : 0.30994, Training Acc : 0.822, Run Time : 0.47
INFO:root:2019-05-10 18:46:11, Epoch : 1, Step : 1550, Training Loss : 0.27286, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-10 18:46:15, Epoch : 1, Step : 1551, Training Loss : 0.33416, Training Acc : 0.811, Run Time : 4.57
INFO:root:2019-05-10 18:46:17, Epoch : 1, Step : 1552, Training Loss : 0.20626, Training Acc : 0.894, Run Time : 1.76
INFO:root:2019-05-10 18:46:32, Epoch : 1, Step : 1553, Training Loss : 0.25779, Training Acc : 0.872, Run Time : 15.26
INFO:root:2019-05-10 18:46:33, Epoch : 1, Step : 1554, Training Loss : 0.27140, Training Acc : 0.850, Run Time : 0.66
INFO:root:2019-05-10 18:46:34, Epoch : 1, Step : 1555, Training Loss : 0.26800, Training Acc : 0.872, Run Time : 0.62
INFO:root:2019-05-10 18:46:34, Epoch : 1, Step : 1556, Training Loss : 0.24776, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-10 18:46:34, Epoch : 1, Step : 1557, Training Loss : 0.26219, Training Acc : 0.889, Run Time : 0.21
INFO:root:2019-05-10 18:46:54, Epoch : 1, Step : 1558, Training Loss : 0.26887, Training Acc : 0.900, Run Time : 19.66
INFO:root:2019-05-10 18:46:54, Epoch : 1, Step : 1559, Training Loss : 0.23986, Training Acc : 0.883, Run Time : 0.44
INFO:root:2019-05-10 18:46:55, Epoch : 1, Step : 1560, Training Loss : 0.22226, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-10 18:46:55, Epoch : 1, Step : 1561, Training Loss : 0.15530, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-10 18:47:09, Epoch : 1, Step : 1562, Training Loss : 0.19500, Training Acc : 0.928, Run Time : 13.43
INFO:root:2019-05-10 18:47:09, Epoch : 1, Step : 1563, Training Loss : 0.17178, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-10 18:47:09, Epoch : 1, Step : 1564, Training Loss : 0.37503, Training Acc : 0.817, Run Time : 0.22
INFO:root:2019-05-10 18:47:10, Epoch : 1, Step : 1565, Training Loss : 0.20780, Training Acc : 0.906, Run Time : 0.96
INFO:root:2019-05-10 18:47:12, Epoch : 1, Step : 1566, Training Loss : 0.15701, Training Acc : 0.944, Run Time : 1.49
INFO:root:2019-05-10 18:47:26, Epoch : 1, Step : 1567, Training Loss : 0.22129, Training Acc : 0.861, Run Time : 14.16
INFO:root:2019-05-10 18:47:27, Epoch : 1, Step : 1568, Training Loss : 0.28099, Training Acc : 0.867, Run Time : 1.03
INFO:root:2019-05-10 18:47:27, Epoch : 1, Step : 1569, Training Loss : 0.28537, Training Acc : 0.844, Run Time : 0.44
INFO:root:2019-05-10 18:47:28, Epoch : 1, Step : 1570, Training Loss : 0.21605, Training Acc : 0.911, Run Time : 0.49
INFO:root:2019-05-10 18:47:29, Epoch : 1, Step : 1571, Training Loss : 0.24546, Training Acc : 0.883, Run Time : 0.91
INFO:root:2019-05-10 18:47:42, Epoch : 1, Step : 1572, Training Loss : 0.22255, Training Acc : 0.889, Run Time : 13.13
INFO:root:2019-05-10 18:47:43, Epoch : 1, Step : 1573, Training Loss : 0.23927, Training Acc : 0.872, Run Time : 0.86
INFO:root:2019-05-10 18:47:43, Epoch : 1, Step : 1574, Training Loss : 0.21193, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-10 18:47:44, Epoch : 1, Step : 1575, Training Loss : 0.18402, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-10 18:47:45, Epoch : 1, Step : 1576, Training Loss : 0.17511, Training Acc : 0.933, Run Time : 1.04
INFO:root:2019-05-10 18:48:01, Epoch : 1, Step : 1577, Training Loss : 0.26577, Training Acc : 0.878, Run Time : 16.26
INFO:root:2019-05-10 18:48:01, Epoch : 1, Step : 1578, Training Loss : 0.23911, Training Acc : 0.889, Run Time : 0.22
INFO:root:2019-05-10 18:48:02, Epoch : 1, Step : 1579, Training Loss : 0.28185, Training Acc : 0.894, Run Time : 0.83
INFO:root:2019-05-10 18:48:02, Epoch : 1, Step : 1580, Training Loss : 0.23712, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 18:48:03, Epoch : 1, Step : 1581, Training Loss : 0.20977, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-10 18:48:22, Epoch : 1, Step : 1582, Training Loss : 0.23520, Training Acc : 0.917, Run Time : 18.97
INFO:root:2019-05-10 18:48:22, Epoch : 1, Step : 1583, Training Loss : 0.18198, Training Acc : 0.928, Run Time : 0.31
INFO:root:2019-05-10 18:48:22, Epoch : 1, Step : 1584, Training Loss : 0.20115, Training Acc : 0.917, Run Time : 0.26
INFO:root:2019-05-10 18:48:23, Epoch : 1, Step : 1585, Training Loss : 0.22668, Training Acc : 0.922, Run Time : 0.76
INFO:root:2019-05-10 18:48:35, Epoch : 1, Step : 1586, Training Loss : 0.20942, Training Acc : 0.933, Run Time : 12.05
INFO:root:2019-05-10 18:48:36, Epoch : 1, Step : 1587, Training Loss : 0.26424, Training Acc : 0.922, Run Time : 1.24
INFO:root:2019-05-10 18:48:37, Epoch : 1, Step : 1588, Training Loss : 0.30518, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-10 18:48:46, Epoch : 1, Step : 1589, Training Loss : 0.30696, Training Acc : 0.917, Run Time : 9.32
INFO:root:2019-05-10 18:48:47, Epoch : 1, Step : 1590, Training Loss : 0.25573, Training Acc : 0.911, Run Time : 0.93
INFO:root:2019-05-10 18:48:48, Epoch : 1, Step : 1591, Training Loss : 0.21170, Training Acc : 0.900, Run Time : 0.36
INFO:root:2019-05-10 18:48:48, Epoch : 1, Step : 1592, Training Loss : 0.26878, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 18:48:49, Epoch : 1, Step : 1593, Training Loss : 0.16304, Training Acc : 0.939, Run Time : 1.30
INFO:root:2019-05-10 18:49:02, Epoch : 1, Step : 1594, Training Loss : 0.17270, Training Acc : 0.939, Run Time : 12.92
INFO:root:2019-05-10 18:49:03, Epoch : 1, Step : 1595, Training Loss : 0.16390, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-10 18:49:03, Epoch : 1, Step : 1596, Training Loss : 0.20435, Training Acc : 0.928, Run Time : 0.34
INFO:root:2019-05-10 18:49:05, Epoch : 1, Step : 1597, Training Loss : 0.31961, Training Acc : 0.889, Run Time : 1.61
INFO:root:2019-05-10 18:49:05, Epoch : 1, Step : 1598, Training Loss : 0.26281, Training Acc : 0.906, Run Time : 0.57
INFO:root:2019-05-10 18:49:19, Epoch : 1, Step : 1599, Training Loss : 0.32406, Training Acc : 0.883, Run Time : 14.28
INFO:root:2019-05-10 18:49:20, Epoch : 1, Step : 1600, Training Loss : 0.28165, Training Acc : 0.894, Run Time : 0.31
INFO:root:2019-05-10 18:49:31, Epoch : 1, Step : 1601, Training Loss : 0.90756, Training Acc : 0.694, Run Time : 11.42
INFO:root:2019-05-10 18:49:32, Epoch : 1, Step : 1602, Training Loss : 1.14845, Training Acc : 0.667, Run Time : 0.89
INFO:root:2019-05-10 18:49:44, Epoch : 1, Step : 1603, Training Loss : 1.05502, Training Acc : 0.600, Run Time : 11.91
INFO:root:2019-05-10 18:49:45, Epoch : 1, Step : 1604, Training Loss : 0.91787, Training Acc : 0.656, Run Time : 0.76
INFO:root:2019-05-10 18:49:45, Epoch : 1, Step : 1605, Training Loss : 0.93442, Training Acc : 0.683, Run Time : 0.63
INFO:root:2019-05-10 18:49:58, Epoch : 1, Step : 1606, Training Loss : 0.85082, Training Acc : 0.639, Run Time : 13.11
INFO:root:2019-05-10 18:49:59, Epoch : 1, Step : 1607, Training Loss : 0.58498, Training Acc : 0.706, Run Time : 0.24
INFO:root:2019-05-10 18:49:59, Epoch : 1, Step : 1608, Training Loss : 0.49481, Training Acc : 0.800, Run Time : 0.32
INFO:root:2019-05-10 18:50:00, Epoch : 1, Step : 1609, Training Loss : 0.56161, Training Acc : 0.717, Run Time : 0.46
INFO:root:2019-05-10 18:50:00, Epoch : 1, Step : 1610, Training Loss : 0.36096, Training Acc : 0.817, Run Time : 0.51
INFO:root:2019-05-10 18:50:21, Epoch : 1, Step : 1611, Training Loss : 0.25401, Training Acc : 0.950, Run Time : 21.31
INFO:root:2019-05-10 18:50:22, Epoch : 1, Step : 1612, Training Loss : 0.34342, Training Acc : 0.872, Run Time : 0.25
INFO:root:2019-05-10 18:50:22, Epoch : 1, Step : 1613, Training Loss : 0.63609, Training Acc : 0.728, Run Time : 0.33
INFO:root:2019-05-10 18:50:22, Epoch : 1, Step : 1614, Training Loss : 0.50832, Training Acc : 0.856, Run Time : 0.57
INFO:root:2019-05-10 18:50:23, Epoch : 1, Step : 1615, Training Loss : 0.51124, Training Acc : 0.761, Run Time : 0.46
INFO:root:2019-05-10 18:50:45, Epoch : 1, Step : 1616, Training Loss : 0.46750, Training Acc : 0.800, Run Time : 21.84
INFO:root:2019-05-10 18:50:45, Epoch : 1, Step : 1617, Training Loss : 0.24029, Training Acc : 0.911, Run Time : 0.40
INFO:root:2019-05-10 18:50:47, Epoch : 1, Step : 1618, Training Loss : 0.32407, Training Acc : 0.861, Run Time : 1.37
INFO:root:2019-05-10 18:50:49, Epoch : 1, Step : 1619, Training Loss : 0.37120, Training Acc : 0.833, Run Time : 1.99
INFO:root:2019-05-10 18:50:49, Epoch : 1, Step : 1620, Training Loss : 0.44064, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 18:51:02, Epoch : 1, Step : 1621, Training Loss : 0.57918, Training Acc : 0.817, Run Time : 12.96
INFO:root:2019-05-10 18:51:03, Epoch : 1, Step : 1622, Training Loss : 0.39501, Training Acc : 0.850, Run Time : 0.74
INFO:root:2019-05-10 18:51:03, Epoch : 1, Step : 1623, Training Loss : 0.30408, Training Acc : 0.850, Run Time : 0.37
INFO:root:2019-05-10 18:51:04, Epoch : 1, Step : 1624, Training Loss : 0.33075, Training Acc : 0.844, Run Time : 0.50
INFO:root:2019-05-10 18:51:04, Epoch : 1, Step : 1625, Training Loss : 0.48629, Training Acc : 0.783, Run Time : 0.65
INFO:root:2019-05-10 18:51:19, Epoch : 1, Step : 1626, Training Loss : 0.54818, Training Acc : 0.722, Run Time : 15.00
INFO:root:2019-05-10 18:51:19, Epoch : 1, Step : 1627, Training Loss : 0.65436, Training Acc : 0.767, Run Time : 0.24
INFO:root:2019-05-10 18:51:20, Epoch : 1, Step : 1628, Training Loss : 0.41239, Training Acc : 0.806, Run Time : 0.46
INFO:root:2019-05-10 18:51:20, Epoch : 1, Step : 1629, Training Loss : 0.28932, Training Acc : 0.883, Run Time : 0.50
INFO:root:2019-05-10 18:51:21, Epoch : 1, Step : 1630, Training Loss : 0.14214, Training Acc : 0.967, Run Time : 0.36
INFO:root:2019-05-10 18:51:39, Epoch : 1, Step : 1631, Training Loss : 0.44427, Training Acc : 0.767, Run Time : 18.17
INFO:root:2019-05-10 18:51:39, Epoch : 1, Step : 1632, Training Loss : 0.38609, Training Acc : 0.822, Run Time : 0.29
INFO:root:2019-05-10 18:51:40, Epoch : 1, Step : 1633, Training Loss : 0.15209, Training Acc : 0.972, Run Time : 0.45
INFO:root:2019-05-10 18:51:40, Epoch : 1, Step : 1634, Training Loss : 0.26847, Training Acc : 0.922, Run Time : 0.69
INFO:root:2019-05-10 18:51:41, Epoch : 1, Step : 1635, Training Loss : 0.26603, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-10 18:51:56, Epoch : 1, Step : 1636, Training Loss : 0.19248, Training Acc : 0.933, Run Time : 15.38
INFO:root:2019-05-10 18:51:57, Epoch : 1, Step : 1637, Training Loss : 0.23103, Training Acc : 0.928, Run Time : 0.27
INFO:root:2019-05-10 18:51:57, Epoch : 1, Step : 1638, Training Loss : 0.22936, Training Acc : 0.922, Run Time : 0.22
INFO:root:2019-05-10 18:51:57, Epoch : 1, Step : 1639, Training Loss : 0.22055, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-10 18:52:09, Epoch : 1, Step : 1640, Training Loss : 0.17520, Training Acc : 0.922, Run Time : 11.94
INFO:root:2019-05-10 18:52:10, Epoch : 1, Step : 1641, Training Loss : 0.10992, Training Acc : 0.978, Run Time : 0.52
INFO:root:2019-05-10 18:52:10, Epoch : 1, Step : 1642, Training Loss : 0.09623, Training Acc : 0.994, Run Time : 0.41
INFO:root:2019-05-10 18:52:10, Epoch : 1, Step : 1643, Training Loss : 0.25693, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 18:52:11, Epoch : 1, Step : 1644, Training Loss : 0.15342, Training Acc : 0.956, Run Time : 0.55
INFO:root:2019-05-10 18:52:30, Epoch : 1, Step : 1645, Training Loss : 0.26793, Training Acc : 0.906, Run Time : 18.85
INFO:root:2019-05-10 18:52:30, Epoch : 1, Step : 1646, Training Loss : 0.21152, Training Acc : 0.894, Run Time : 0.33
INFO:root:2019-05-10 18:52:31, Epoch : 1, Step : 1647, Training Loss : 0.26857, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 18:52:31, Epoch : 1, Step : 1648, Training Loss : 0.20025, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-10 18:52:32, Epoch : 1, Step : 1649, Training Loss : 0.37450, Training Acc : 0.828, Run Time : 0.51
INFO:root:2019-05-10 18:52:48, Epoch : 1, Step : 1650, Training Loss : 0.26719, Training Acc : 0.906, Run Time : 16.57
INFO:root:2019-05-10 18:52:48, Epoch : 1, Step : 1651, Training Loss : 0.20600, Training Acc : 0.933, Run Time : 0.22
INFO:root:2019-05-10 18:52:49, Epoch : 1, Step : 1652, Training Loss : 0.16390, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-10 18:52:49, Epoch : 1, Step : 1653, Training Loss : 0.15993, Training Acc : 0.956, Run Time : 0.48
INFO:root:2019-05-10 18:53:01, Epoch : 1, Step : 1654, Training Loss : 0.14825, Training Acc : 0.950, Run Time : 11.27
INFO:root:2019-05-10 18:53:02, Epoch : 1, Step : 1655, Training Loss : 0.18571, Training Acc : 0.933, Run Time : 0.86
INFO:root:2019-05-10 18:53:02, Epoch : 1, Step : 1656, Training Loss : 0.20058, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-10 18:53:02, Epoch : 1, Step : 1657, Training Loss : 0.13610, Training Acc : 0.972, Run Time : 0.49
INFO:root:2019-05-10 18:53:03, Epoch : 1, Step : 1658, Training Loss : 0.19147, Training Acc : 0.933, Run Time : 0.26
INFO:root:2019-05-10 18:53:20, Epoch : 1, Step : 1659, Training Loss : 0.09942, Training Acc : 0.978, Run Time : 17.29
INFO:root:2019-05-10 18:53:20, Epoch : 1, Step : 1660, Training Loss : 0.42768, Training Acc : 0.794, Run Time : 0.29
INFO:root:2019-05-10 18:53:21, Epoch : 1, Step : 1661, Training Loss : 0.17895, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-10 18:53:22, Epoch : 1, Step : 1662, Training Loss : 0.16039, Training Acc : 0.917, Run Time : 1.20
INFO:root:2019-05-10 18:53:23, Epoch : 1, Step : 1663, Training Loss : 0.06747, Training Acc : 0.989, Run Time : 0.83
INFO:root:2019-05-10 18:53:25, Epoch : 1, Step : 1664, Training Loss : 0.41952, Training Acc : 0.778, Run Time : 2.76
INFO:root:2019-05-10 18:53:38, Epoch : 1, Step : 1665, Training Loss : 0.59399, Training Acc : 0.733, Run Time : 12.85
INFO:root:2019-05-10 18:53:39, Epoch : 1, Step : 1666, Training Loss : 0.15604, Training Acc : 0.961, Run Time : 0.29
INFO:root:2019-05-10 18:53:39, Epoch : 1, Step : 1667, Training Loss : 0.14074, Training Acc : 0.961, Run Time : 0.34
INFO:root:2019-05-10 18:53:39, Epoch : 1, Step : 1668, Training Loss : 0.30756, Training Acc : 0.839, Run Time : 0.46
INFO:root:2019-05-10 18:53:40, Epoch : 1, Step : 1669, Training Loss : 0.25521, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-10 18:53:55, Epoch : 1, Step : 1670, Training Loss : 0.12549, Training Acc : 0.961, Run Time : 15.05
INFO:root:2019-05-10 18:53:55, Epoch : 1, Step : 1671, Training Loss : 0.54277, Training Acc : 0.867, Run Time : 0.44
INFO:root:2019-05-10 18:54:05, Epoch : 1, Step : 1672, Training Loss : 0.44488, Training Acc : 0.794, Run Time : 10.04
INFO:root:2019-05-10 18:54:07, Epoch : 1, Step : 1673, Training Loss : 0.21468, Training Acc : 0.917, Run Time : 1.08
INFO:root:2019-05-10 18:54:07, Epoch : 1, Step : 1674, Training Loss : 0.26487, Training Acc : 0.928, Run Time : 0.50
INFO:root:2019-05-10 18:54:07, Epoch : 1, Step : 1675, Training Loss : 0.19540, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-10 18:54:17, Epoch : 1, Step : 1676, Training Loss : 0.16328, Training Acc : 0.950, Run Time : 9.52
INFO:root:2019-05-10 18:54:18, Epoch : 1, Step : 1677, Training Loss : 0.10956, Training Acc : 0.967, Run Time : 0.90
INFO:root:2019-05-10 18:54:18, Epoch : 1, Step : 1678, Training Loss : 0.16560, Training Acc : 0.950, Run Time : 0.43
INFO:root:2019-05-10 18:54:19, Epoch : 1, Step : 1679, Training Loss : 0.12490, Training Acc : 0.983, Run Time : 0.51
INFO:root:2019-05-10 18:54:33, Epoch : 1, Step : 1680, Training Loss : 0.07946, Training Acc : 0.989, Run Time : 14.22
INFO:root:2019-05-10 18:54:36, Epoch : 1, Step : 1681, Training Loss : 0.19467, Training Acc : 0.933, Run Time : 2.45
INFO:root:2019-05-10 18:54:36, Epoch : 1, Step : 1682, Training Loss : 0.10886, Training Acc : 0.950, Run Time : 0.54
INFO:root:2019-05-10 18:54:37, Epoch : 1, Step : 1683, Training Loss : 0.08778, Training Acc : 0.994, Run Time : 0.45
INFO:root:2019-05-10 18:54:37, Epoch : 1, Step : 1684, Training Loss : 0.10804, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-10 18:54:37, Epoch : 1, Step : 1685, Training Loss : 0.18824, Training Acc : 0.894, Run Time : 0.50
INFO:root:2019-05-10 18:54:42, Epoch : 1, Step : 1686, Training Loss : 0.18959, Training Acc : 0.917, Run Time : 4.66
INFO:root:2019-05-10 18:54:43, Epoch : 1, Step : 1687, Training Loss : 0.13281, Training Acc : 0.944, Run Time : 0.51
INFO:root:2019-05-10 18:54:59, Epoch : 1, Step : 1688, Training Loss : 0.18397, Training Acc : 0.933, Run Time : 16.11
INFO:root:2019-05-10 18:54:59, Epoch : 1, Step : 1689, Training Loss : 0.16717, Training Acc : 0.956, Run Time : 0.25
INFO:root:2019-05-10 18:55:00, Epoch : 1, Step : 1690, Training Loss : 0.24970, Training Acc : 0.878, Run Time : 0.49
INFO:root:2019-05-10 18:55:00, Epoch : 1, Step : 1691, Training Loss : 0.17405, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-10 18:55:00, Epoch : 1, Step : 1692, Training Loss : 0.20309, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 18:55:18, Epoch : 1, Step : 1693, Training Loss : 0.30849, Training Acc : 0.900, Run Time : 17.94
INFO:root:2019-05-10 18:55:19, Epoch : 1, Step : 1694, Training Loss : 0.14777, Training Acc : 0.950, Run Time : 0.39
INFO:root:2019-05-10 18:55:19, Epoch : 1, Step : 1695, Training Loss : 0.13213, Training Acc : 0.939, Run Time : 0.22
INFO:root:2019-05-10 18:55:19, Epoch : 1, Step : 1696, Training Loss : 0.12190, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-10 18:55:20, Epoch : 1, Step : 1697, Training Loss : 0.52728, Training Acc : 0.744, Run Time : 0.39
INFO:root:2019-05-10 18:55:37, Epoch : 1, Step : 1698, Training Loss : 0.28414, Training Acc : 0.878, Run Time : 17.03
INFO:root:2019-05-10 18:55:37, Epoch : 1, Step : 1699, Training Loss : 0.18542, Training Acc : 0.922, Run Time : 0.31
INFO:root:2019-05-10 18:55:37, Epoch : 1, Step : 1700, Training Loss : 0.30722, Training Acc : 0.850, Run Time : 0.28
INFO:root:2019-05-10 18:55:38, Epoch : 1, Step : 1701, Training Loss : 0.45775, Training Acc : 0.817, Run Time : 0.82
INFO:root:2019-05-10 18:55:50, Epoch : 1, Step : 1702, Training Loss : 0.30113, Training Acc : 0.883, Run Time : 11.53
INFO:root:2019-05-10 18:55:50, Epoch : 1, Step : 1703, Training Loss : 0.34221, Training Acc : 0.878, Run Time : 0.58
INFO:root:2019-05-10 18:55:51, Epoch : 1, Step : 1704, Training Loss : 0.33941, Training Acc : 0.850, Run Time : 0.49
INFO:root:2019-05-10 18:55:51, Epoch : 1, Step : 1705, Training Loss : 0.32796, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 18:55:52, Epoch : 1, Step : 1706, Training Loss : 0.14086, Training Acc : 0.967, Run Time : 0.47
INFO:root:2019-05-10 18:56:06, Epoch : 1, Step : 1707, Training Loss : 0.22344, Training Acc : 0.883, Run Time : 14.31
INFO:root:2019-05-10 18:56:06, Epoch : 1, Step : 1708, Training Loss : 0.27373, Training Acc : 0.861, Run Time : 0.24
INFO:root:2019-05-10 18:56:07, Epoch : 1, Step : 1709, Training Loss : 0.27826, Training Acc : 0.906, Run Time : 0.26
INFO:root:2019-05-10 18:56:07, Epoch : 1, Step : 1710, Training Loss : 0.23845, Training Acc : 0.889, Run Time : 0.49
INFO:root:2019-05-10 18:56:08, Epoch : 1, Step : 1711, Training Loss : 0.16116, Training Acc : 0.917, Run Time : 0.52
INFO:root:2019-05-10 18:56:21, Epoch : 1, Step : 1712, Training Loss : 0.36072, Training Acc : 0.844, Run Time : 13.71
INFO:root:2019-05-10 18:56:22, Epoch : 1, Step : 1713, Training Loss : 0.50063, Training Acc : 0.806, Run Time : 0.61
INFO:root:2019-05-10 18:56:23, Epoch : 1, Step : 1714, Training Loss : 0.47302, Training Acc : 0.800, Run Time : 0.76
INFO:root:2019-05-10 18:56:23, Epoch : 1, Step : 1715, Training Loss : 0.17707, Training Acc : 0.950, Run Time : 0.51
INFO:root:2019-05-10 18:56:24, Epoch : 1, Step : 1716, Training Loss : 0.49518, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-10 18:56:38, Epoch : 1, Step : 1717, Training Loss : 0.41186, Training Acc : 0.850, Run Time : 14.14
INFO:root:2019-05-10 18:56:38, Epoch : 1, Step : 1718, Training Loss : 0.21515, Training Acc : 0.939, Run Time : 0.28
INFO:root:2019-05-10 18:56:39, Epoch : 1, Step : 1719, Training Loss : 0.21086, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 18:56:39, Epoch : 1, Step : 1720, Training Loss : 0.14766, Training Acc : 0.950, Run Time : 0.42
INFO:root:2019-05-10 18:56:40, Epoch : 1, Step : 1721, Training Loss : 0.15572, Training Acc : 0.950, Run Time : 0.51
INFO:root:2019-05-10 18:56:55, Epoch : 1, Step : 1722, Training Loss : 0.14811, Training Acc : 0.944, Run Time : 15.79
INFO:root:2019-05-10 18:56:56, Epoch : 1, Step : 1723, Training Loss : 0.31985, Training Acc : 0.833, Run Time : 0.92
INFO:root:2019-05-10 18:56:57, Epoch : 1, Step : 1724, Training Loss : 0.16787, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-10 18:56:57, Epoch : 1, Step : 1725, Training Loss : 0.21273, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 18:56:58, Epoch : 1, Step : 1726, Training Loss : 0.12124, Training Acc : 0.944, Run Time : 1.12
INFO:root:2019-05-10 18:57:02, Epoch : 1, Step : 1727, Training Loss : 0.20616, Training Acc : 0.933, Run Time : 3.23
INFO:root:2019-05-10 18:57:02, Epoch : 1, Step : 1728, Training Loss : 0.34666, Training Acc : 0.844, Run Time : 0.41
INFO:root:2019-05-10 18:57:18, Epoch : 1, Step : 1729, Training Loss : 0.15940, Training Acc : 0.950, Run Time : 16.25
INFO:root:2019-05-10 18:57:19, Epoch : 1, Step : 1730, Training Loss : 0.07473, Training Acc : 0.989, Run Time : 0.31
INFO:root:2019-05-10 18:57:19, Epoch : 1, Step : 1731, Training Loss : 0.12882, Training Acc : 0.978, Run Time : 0.47
INFO:root:2019-05-10 18:57:19, Epoch : 1, Step : 1732, Training Loss : 0.13517, Training Acc : 0.956, Run Time : 0.46
INFO:root:2019-05-10 18:57:20, Epoch : 1, Step : 1733, Training Loss : 0.11244, Training Acc : 0.983, Run Time : 0.48
INFO:root:2019-05-10 18:57:35, Epoch : 1, Step : 1734, Training Loss : 0.15653, Training Acc : 0.939, Run Time : 15.19
INFO:root:2019-05-10 18:57:36, Epoch : 1, Step : 1735, Training Loss : 0.36227, Training Acc : 0.850, Run Time : 1.13
INFO:root:2019-05-10 18:57:38, Epoch : 1, Step : 1736, Training Loss : 0.25286, Training Acc : 0.922, Run Time : 1.50
INFO:root:2019-05-10 18:57:45, Epoch : 1, Step : 1737, Training Loss : 0.07659, Training Acc : 0.983, Run Time : 7.50
INFO:root:2019-05-10 18:57:46, Epoch : 1, Step : 1738, Training Loss : 0.16765, Training Acc : 0.961, Run Time : 0.87
INFO:root:2019-05-10 18:57:47, Epoch : 1, Step : 1739, Training Loss : 0.15881, Training Acc : 0.944, Run Time : 0.92
INFO:root:2019-05-10 18:57:48, Epoch : 1, Step : 1740, Training Loss : 0.15238, Training Acc : 0.928, Run Time : 1.11
INFO:root:2019-05-10 18:57:50, Epoch : 1, Step : 1741, Training Loss : 0.22035, Training Acc : 0.906, Run Time : 1.80
INFO:root:2019-05-10 18:57:51, Epoch : 1, Step : 1742, Training Loss : 0.06476, Training Acc : 0.994, Run Time : 0.77
INFO:root:2019-05-10 18:57:52, Epoch : 1, Step : 1743, Training Loss : 0.09581, Training Acc : 0.972, Run Time : 0.93
INFO:root:2019-05-10 18:58:07, Epoch : 1, Step : 1744, Training Loss : 0.22660, Training Acc : 0.894, Run Time : 14.91
INFO:root:2019-05-10 18:58:07, Epoch : 1, Step : 1745, Training Loss : 0.07946, Training Acc : 0.983, Run Time : 0.28
INFO:root:2019-05-10 18:58:07, Epoch : 1, Step : 1746, Training Loss : 0.18493, Training Acc : 0.917, Run Time : 0.33
INFO:root:2019-05-10 18:58:08, Epoch : 1, Step : 1747, Training Loss : 0.16374, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-10 18:58:15, Epoch : 1, Step : 1748, Training Loss : 0.38774, Training Acc : 0.778, Run Time : 7.76
INFO:root:2019-05-10 18:58:18, Epoch : 1, Step : 1749, Training Loss : 0.13061, Training Acc : 0.939, Run Time : 2.40
INFO:root:2019-05-10 18:58:18, Epoch : 1, Step : 1750, Training Loss : 1.01015, Training Acc : 0.622, Run Time : 0.48
INFO:root:2019-05-10 18:58:19, Epoch : 1, Step : 1751, Training Loss : 0.32428, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 18:58:19, Epoch : 1, Step : 1752, Training Loss : 0.11591, Training Acc : 0.972, Run Time : 0.49
INFO:root:2019-05-10 18:58:23, Epoch : 1, Step : 1753, Training Loss : 0.20465, Training Acc : 0.928, Run Time : 3.83
INFO:root:2019-05-10 18:58:30, Epoch : 1, Step : 1754, Training Loss : 0.31536, Training Acc : 0.822, Run Time : 7.26
INFO:root:2019-05-10 18:58:31, Epoch : 1, Step : 1755, Training Loss : 0.21991, Training Acc : 0.933, Run Time : 1.01
INFO:root:2019-05-10 18:58:32, Epoch : 1, Step : 1756, Training Loss : 0.15807, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-10 18:58:32, Epoch : 1, Step : 1757, Training Loss : 0.13125, Training Acc : 0.950, Run Time : 0.51
INFO:root:2019-05-10 18:58:33, Epoch : 1, Step : 1758, Training Loss : 0.17238, Training Acc : 0.933, Run Time : 0.50
INFO:root:2019-05-10 18:58:48, Epoch : 1, Step : 1759, Training Loss : 0.24579, Training Acc : 0.872, Run Time : 14.87
INFO:root:2019-05-10 18:58:48, Epoch : 1, Step : 1760, Training Loss : 0.24897, Training Acc : 0.933, Run Time : 0.23
INFO:root:2019-05-10 18:58:48, Epoch : 1, Step : 1761, Training Loss : 0.28793, Training Acc : 0.828, Run Time : 0.41
INFO:root:2019-05-10 18:58:49, Epoch : 1, Step : 1762, Training Loss : 0.09198, Training Acc : 0.989, Run Time : 0.48
INFO:root:2019-05-10 18:58:49, Epoch : 1, Step : 1763, Training Loss : 0.20061, Training Acc : 0.922, Run Time : 0.43
INFO:root:2019-05-10 18:59:04, Epoch : 1, Step : 1764, Training Loss : 0.36271, Training Acc : 0.783, Run Time : 14.36
INFO:root:2019-05-10 18:59:04, Epoch : 1, Step : 1765, Training Loss : 0.19185, Training Acc : 0.911, Run Time : 0.50
INFO:root:2019-05-10 18:59:05, Epoch : 1, Step : 1766, Training Loss : 0.04024, Training Acc : 1.000, Run Time : 0.44
INFO:root:2019-05-10 18:59:21, Epoch : 1, Step : 1767, Training Loss : 0.12550, Training Acc : 0.961, Run Time : 16.93
INFO:root:2019-05-10 18:59:32, Epoch : 1, Step : 1768, Training Loss : 0.09778, Training Acc : 0.944, Run Time : 10.58
INFO:root:2019-05-10 18:59:34, Epoch : 1, Step : 1769, Training Loss : 0.16113, Training Acc : 0.911, Run Time : 1.74
INFO:root:2019-05-10 18:59:34, Epoch : 1, Step : 1770, Training Loss : 0.15478, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-10 18:59:35, Epoch : 1, Step : 1771, Training Loss : 0.22731, Training Acc : 0.900, Run Time : 0.49
INFO:root:2019-05-10 18:59:38, Epoch : 1, Step : 1772, Training Loss : 0.11176, Training Acc : 0.961, Run Time : 3.36
INFO:root:2019-05-10 18:59:39, Epoch : 1, Step : 1773, Training Loss : 0.31573, Training Acc : 0.900, Run Time : 0.67
INFO:root:2019-05-10 18:59:39, Epoch : 1, Step : 1774, Training Loss : 0.22819, Training Acc : 0.906, Run Time : 0.48
INFO:root:2019-05-10 18:59:58, Epoch : 1, Step : 1775, Training Loss : 0.09671, Training Acc : 0.978, Run Time : 18.42
INFO:root:2019-05-10 18:59:58, Epoch : 1, Step : 1776, Training Loss : 0.41092, Training Acc : 0.783, Run Time : 0.68
INFO:root:2019-05-10 18:59:59, Epoch : 1, Step : 1777, Training Loss : 0.08859, Training Acc : 0.983, Run Time : 0.50
INFO:root:2019-05-10 18:59:59, Epoch : 1, Step : 1778, Training Loss : 0.17491, Training Acc : 0.917, Run Time : 0.52
INFO:root:2019-05-10 19:00:00, Epoch : 1, Step : 1779, Training Loss : 0.13504, Training Acc : 0.972, Run Time : 0.48
INFO:root:2019-05-10 19:00:14, Epoch : 1, Step : 1780, Training Loss : 0.17190, Training Acc : 0.928, Run Time : 13.92
INFO:root:2019-05-10 19:00:14, Epoch : 1, Step : 1781, Training Loss : 0.34663, Training Acc : 0.889, Run Time : 0.66
INFO:root:2019-05-10 19:00:15, Epoch : 1, Step : 1782, Training Loss : 0.19932, Training Acc : 0.900, Run Time : 0.43
INFO:root:2019-05-10 19:00:27, Epoch : 1, Step : 1783, Training Loss : 0.23346, Training Acc : 0.906, Run Time : 11.80
INFO:root:2019-05-10 19:00:27, Epoch : 1, Step : 1784, Training Loss : 0.10185, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-10 19:00:27, Epoch : 1, Step : 1785, Training Loss : 0.16832, Training Acc : 0.950, Run Time : 0.24
INFO:root:2019-05-10 19:00:28, Epoch : 1, Step : 1786, Training Loss : 0.23699, Training Acc : 0.900, Run Time : 0.52
INFO:root:2019-05-10 19:00:28, Epoch : 1, Step : 1787, Training Loss : 0.14917, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-10 19:00:44, Epoch : 1, Step : 1788, Training Loss : 0.20209, Training Acc : 0.906, Run Time : 16.16
INFO:root:2019-05-10 19:00:45, Epoch : 1, Step : 1789, Training Loss : 0.16365, Training Acc : 0.944, Run Time : 0.31
INFO:root:2019-05-10 19:00:45, Epoch : 1, Step : 1790, Training Loss : 0.09092, Training Acc : 0.989, Run Time : 0.48
INFO:root:2019-05-10 19:00:57, Epoch : 1, Step : 1791, Training Loss : 0.11556, Training Acc : 0.967, Run Time : 12.01
INFO:root:2019-05-10 19:00:58, Epoch : 1, Step : 1792, Training Loss : 0.14636, Training Acc : 0.967, Run Time : 0.42
INFO:root:2019-05-10 19:00:58, Epoch : 1, Step : 1793, Training Loss : 0.16218, Training Acc : 0.961, Run Time : 0.22
INFO:root:2019-05-10 19:00:58, Epoch : 1, Step : 1794, Training Loss : 0.06986, Training Acc : 1.000, Run Time : 0.35
INFO:root:2019-05-10 19:00:59, Epoch : 1, Step : 1795, Training Loss : 0.25145, Training Acc : 0.911, Run Time : 0.43
INFO:root:2019-05-10 19:01:14, Epoch : 1, Step : 1796, Training Loss : 0.15316, Training Acc : 0.950, Run Time : 14.82
INFO:root:2019-05-10 19:01:14, Epoch : 1, Step : 1797, Training Loss : 0.37116, Training Acc : 0.806, Run Time : 0.33
INFO:root:2019-05-10 19:01:14, Epoch : 1, Step : 1798, Training Loss : 0.19550, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 19:01:23, Epoch : 1, Step : 1799, Training Loss : 0.12853, Training Acc : 0.956, Run Time : 8.64
INFO:root:2019-05-10 19:01:24, Epoch : 1, Step : 1800, Training Loss : 0.41668, Training Acc : 0.850, Run Time : 0.53
INFO:root:2019-05-10 19:01:24, Epoch : 1, Step : 1801, Training Loss : 0.90248, Training Acc : 0.611, Run Time : 0.83
INFO:root:2019-05-10 19:01:25, Epoch : 1, Step : 1802, Training Loss : 0.77345, Training Acc : 0.683, Run Time : 0.48
INFO:root:2019-05-10 19:01:25, Epoch : 1, Step : 1803, Training Loss : 0.68220, Training Acc : 0.733, Run Time : 0.49
INFO:root:2019-05-10 19:01:40, Epoch : 1, Step : 1804, Training Loss : 0.62007, Training Acc : 0.717, Run Time : 14.98
INFO:root:2019-05-10 19:01:41, Epoch : 1, Step : 1805, Training Loss : 0.71667, Training Acc : 0.728, Run Time : 0.46
INFO:root:2019-05-10 19:01:41, Epoch : 1, Step : 1806, Training Loss : 0.62054, Training Acc : 0.733, Run Time : 0.47
INFO:root:2019-05-10 19:01:50, Epoch : 1, Step : 1807, Training Loss : 0.42555, Training Acc : 0.817, Run Time : 9.08
INFO:root:2019-05-10 19:01:51, Epoch : 1, Step : 1808, Training Loss : 0.29462, Training Acc : 0.861, Run Time : 0.84
INFO:root:2019-05-10 19:01:52, Epoch : 1, Step : 1809, Training Loss : 0.28988, Training Acc : 0.872, Run Time : 0.44
INFO:root:2019-05-10 19:01:52, Epoch : 1, Step : 1810, Training Loss : 0.17511, Training Acc : 0.933, Run Time : 0.50
INFO:root:2019-05-10 19:02:04, Epoch : 1, Step : 1811, Training Loss : 0.15587, Training Acc : 0.928, Run Time : 11.98
INFO:root:2019-05-10 19:02:05, Epoch : 1, Step : 1812, Training Loss : 0.22023, Training Acc : 0.917, Run Time : 0.65
INFO:root:2019-05-10 19:02:05, Epoch : 1, Step : 1813, Training Loss : 0.22044, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 19:02:07, Epoch : 1, Step : 1814, Training Loss : 0.19825, Training Acc : 0.933, Run Time : 2.03
INFO:root:2019-05-10 19:02:18, Epoch : 1, Step : 1815, Training Loss : 0.23520, Training Acc : 0.911, Run Time : 10.58
INFO:root:2019-05-10 19:02:19, Epoch : 1, Step : 1816, Training Loss : 0.20320, Training Acc : 0.928, Run Time : 1.00
INFO:root:2019-05-10 19:02:21, Epoch : 1, Step : 1817, Training Loss : 0.19269, Training Acc : 0.917, Run Time : 1.75
INFO:root:2019-05-10 19:02:21, Epoch : 1, Step : 1818, Training Loss : 0.21475, Training Acc : 0.917, Run Time : 0.51
INFO:root:2019-05-10 19:02:22, Epoch : 1, Step : 1819, Training Loss : 0.18176, Training Acc : 0.922, Run Time : 1.32
INFO:root:2019-05-10 19:02:34, Epoch : 1, Step : 1820, Training Loss : 0.22541, Training Acc : 0.917, Run Time : 11.34
INFO:root:2019-05-10 19:02:35, Epoch : 1, Step : 1821, Training Loss : 0.19539, Training Acc : 0.917, Run Time : 0.91
INFO:root:2019-05-10 19:02:35, Epoch : 1, Step : 1822, Training Loss : 0.19530, Training Acc : 0.917, Run Time : 0.48
INFO:root:2019-05-10 19:02:36, Epoch : 1, Step : 1823, Training Loss : 0.17693, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 19:02:48, Epoch : 1, Step : 1824, Training Loss : 0.16788, Training Acc : 0.928, Run Time : 12.60
INFO:root:2019-05-10 19:02:48, Epoch : 1, Step : 1825, Training Loss : 0.12684, Training Acc : 0.939, Run Time : 0.22
INFO:root:2019-05-10 19:02:49, Epoch : 1, Step : 1826, Training Loss : 0.16801, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-10 19:02:49, Epoch : 1, Step : 1827, Training Loss : 0.12821, Training Acc : 0.933, Run Time : 0.43
INFO:root:2019-05-10 19:02:50, Epoch : 1, Step : 1828, Training Loss : 0.14328, Training Acc : 0.928, Run Time : 0.32
INFO:root:2019-05-10 19:03:07, Epoch : 1, Step : 1829, Training Loss : 0.12524, Training Acc : 0.939, Run Time : 17.33
INFO:root:2019-05-10 19:03:07, Epoch : 1, Step : 1830, Training Loss : 0.06983, Training Acc : 0.978, Run Time : 0.57
INFO:root:2019-05-10 19:03:08, Epoch : 1, Step : 1831, Training Loss : 0.08677, Training Acc : 0.961, Run Time : 0.43
INFO:root:2019-05-10 19:03:08, Epoch : 1, Step : 1832, Training Loss : 0.08683, Training Acc : 0.978, Run Time : 0.52
INFO:root:2019-05-10 19:03:09, Epoch : 1, Step : 1833, Training Loss : 0.08371, Training Acc : 0.967, Run Time : 0.48
INFO:root:2019-05-10 19:03:25, Epoch : 1, Step : 1834, Training Loss : 0.08501, Training Acc : 0.978, Run Time : 16.43
INFO:root:2019-05-10 19:03:26, Epoch : 1, Step : 1835, Training Loss : 0.08877, Training Acc : 0.961, Run Time : 0.67
INFO:root:2019-05-10 19:03:26, Epoch : 1, Step : 1836, Training Loss : 0.11028, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-10 19:03:27, Epoch : 1, Step : 1837, Training Loss : 0.13944, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 19:03:40, Epoch : 1, Step : 1838, Training Loss : 0.11523, Training Acc : 0.956, Run Time : 13.22
INFO:root:2019-05-10 19:03:41, Epoch : 1, Step : 1839, Training Loss : 0.20593, Training Acc : 0.889, Run Time : 0.60
INFO:root:2019-05-10 19:03:41, Epoch : 1, Step : 1840, Training Loss : 0.30882, Training Acc : 0.872, Run Time : 0.24
INFO:root:2019-05-10 19:03:42, Epoch : 1, Step : 1841, Training Loss : 0.38427, Training Acc : 0.833, Run Time : 1.49
INFO:root:2019-05-10 19:03:57, Epoch : 1, Step : 1842, Training Loss : 0.34803, Training Acc : 0.844, Run Time : 14.33
INFO:root:2019-05-10 19:03:58, Epoch : 1, Step : 1843, Training Loss : 0.17731, Training Acc : 0.933, Run Time : 0.83
INFO:root:2019-05-10 19:03:58, Epoch : 1, Step : 1844, Training Loss : 0.20749, Training Acc : 0.900, Run Time : 0.45
INFO:root:2019-05-10 19:03:59, Epoch : 1, Step : 1845, Training Loss : 0.14007, Training Acc : 0.939, Run Time : 0.50
INFO:root:2019-05-10 19:03:59, Epoch : 1, Step : 1846, Training Loss : 0.26450, Training Acc : 0.856, Run Time : 0.49
INFO:root:2019-05-10 19:04:14, Epoch : 1, Step : 1847, Training Loss : 0.18073, Training Acc : 0.917, Run Time : 14.46
INFO:root:2019-05-10 19:04:14, Epoch : 1, Step : 1848, Training Loss : 0.19425, Training Acc : 0.917, Run Time : 0.55
INFO:root:2019-05-10 19:04:14, Epoch : 1, Step : 1849, Training Loss : 0.14135, Training Acc : 0.956, Run Time : 0.29
INFO:root:2019-05-10 19:04:15, Epoch : 1, Step : 1850, Training Loss : 0.17240, Training Acc : 0.900, Run Time : 0.56
INFO:root:2019-05-10 19:04:15, Epoch : 1, Step : 1851, Training Loss : 0.10039, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-10 19:04:30, Epoch : 1, Step : 1852, Training Loss : 0.21092, Training Acc : 0.889, Run Time : 14.99
INFO:root:2019-05-10 19:04:31, Epoch : 1, Step : 1853, Training Loss : 0.08686, Training Acc : 0.972, Run Time : 0.32
INFO:root:2019-05-10 19:04:31, Epoch : 1, Step : 1854, Training Loss : 0.19107, Training Acc : 0.928, Run Time : 0.52
INFO:root:2019-05-10 19:04:32, Epoch : 1, Step : 1855, Training Loss : 0.21492, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-10 19:04:39, Epoch : 1, Step : 1856, Training Loss : 0.17771, Training Acc : 0.917, Run Time : 6.89
INFO:root:2019-05-10 19:04:41, Epoch : 1, Step : 1857, Training Loss : 0.17253, Training Acc : 0.922, Run Time : 2.23
INFO:root:2019-05-10 19:04:41, Epoch : 1, Step : 1858, Training Loss : 0.26095, Training Acc : 0.878, Run Time : 0.46
INFO:root:2019-05-10 19:04:42, Epoch : 1, Step : 1859, Training Loss : 0.18627, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 19:04:42, Epoch : 1, Step : 1860, Training Loss : 0.21546, Training Acc : 0.894, Run Time : 0.63
INFO:root:2019-05-10 19:04:57, Epoch : 1, Step : 1861, Training Loss : 0.37805, Training Acc : 0.839, Run Time : 14.96
INFO:root:2019-05-10 19:04:58, Epoch : 1, Step : 1862, Training Loss : 0.42973, Training Acc : 0.822, Run Time : 0.23
INFO:root:2019-05-10 19:04:58, Epoch : 1, Step : 1863, Training Loss : 0.44106, Training Acc : 0.811, Run Time : 0.43
INFO:root:2019-05-10 19:04:59, Epoch : 1, Step : 1864, Training Loss : 0.52418, Training Acc : 0.789, Run Time : 0.49
INFO:root:2019-05-10 19:04:59, Epoch : 1, Step : 1865, Training Loss : 0.54052, Training Acc : 0.800, Run Time : 0.49
INFO:root:2019-05-10 19:05:03, Epoch : 1, Step : 1866, Training Loss : 0.43154, Training Acc : 0.794, Run Time : 4.07
INFO:root:2019-05-10 19:05:04, Epoch : 1, Step : 1867, Training Loss : 0.59778, Training Acc : 0.761, Run Time : 0.48
INFO:root:2019-05-10 19:05:21, Epoch : 1, Step : 1868, Training Loss : 0.34129, Training Acc : 0.856, Run Time : 17.59
INFO:root:2019-05-10 19:05:21, Epoch : 1, Step : 1869, Training Loss : 0.30833, Training Acc : 0.850, Run Time : 0.34
INFO:root:2019-05-10 19:05:22, Epoch : 1, Step : 1870, Training Loss : 0.25183, Training Acc : 0.867, Run Time : 0.48
INFO:root:2019-05-10 19:05:22, Epoch : 1, Step : 1871, Training Loss : 0.21524, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-10 19:05:38, Epoch : 1, Step : 1872, Training Loss : 0.44376, Training Acc : 0.833, Run Time : 15.36
INFO:root:2019-05-10 19:05:38, Epoch : 1, Step : 1873, Training Loss : 0.46232, Training Acc : 0.833, Run Time : 0.47
INFO:root:2019-05-10 19:05:39, Epoch : 1, Step : 1874, Training Loss : 0.42591, Training Acc : 0.811, Run Time : 0.30
INFO:root:2019-05-10 19:05:40, Epoch : 1, Step : 1875, Training Loss : 0.44193, Training Acc : 0.872, Run Time : 1.38
INFO:root:2019-05-10 19:05:53, Epoch : 1, Step : 1876, Training Loss : 0.50222, Training Acc : 0.844, Run Time : 12.68
INFO:root:2019-05-10 19:05:53, Epoch : 1, Step : 1877, Training Loss : 0.29742, Training Acc : 0.872, Run Time : 0.35
INFO:root:2019-05-10 19:05:54, Epoch : 1, Step : 1878, Training Loss : 0.30573, Training Acc : 0.872, Run Time : 0.51
INFO:root:2019-05-10 19:06:06, Epoch : 1, Step : 1879, Training Loss : 0.30958, Training Acc : 0.878, Run Time : 12.12
INFO:root:2019-05-10 19:06:06, Epoch : 1, Step : 1880, Training Loss : 0.39445, Training Acc : 0.850, Run Time : 0.70
INFO:root:2019-05-10 19:06:07, Epoch : 1, Step : 1881, Training Loss : 0.37093, Training Acc : 0.867, Run Time : 0.43
INFO:root:2019-05-10 19:06:07, Epoch : 1, Step : 1882, Training Loss : 0.31896, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-10 19:06:08, Epoch : 1, Step : 1883, Training Loss : 0.20289, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 19:06:23, Epoch : 1, Step : 1884, Training Loss : 0.26449, Training Acc : 0.889, Run Time : 14.93
INFO:root:2019-05-10 19:06:23, Epoch : 1, Step : 1885, Training Loss : 0.25954, Training Acc : 0.867, Run Time : 0.37
INFO:root:2019-05-10 19:06:23, Epoch : 1, Step : 1886, Training Loss : 0.25298, Training Acc : 0.928, Run Time : 0.36
INFO:root:2019-05-10 19:06:33, Epoch : 1, Step : 1887, Training Loss : 0.21603, Training Acc : 0.894, Run Time : 9.87
INFO:root:2019-05-10 19:06:35, Epoch : 1, Step : 1888, Training Loss : 0.23861, Training Acc : 0.861, Run Time : 2.25
INFO:root:2019-05-10 19:06:37, Epoch : 1, Step : 1889, Training Loss : 0.18974, Training Acc : 0.928, Run Time : 1.58
INFO:root:2019-05-10 19:06:38, Epoch : 1, Step : 1890, Training Loss : 0.31004, Training Acc : 0.822, Run Time : 0.47
INFO:root:2019-05-10 19:06:50, Epoch : 1, Step : 1891, Training Loss : 0.18940, Training Acc : 0.922, Run Time : 12.38
INFO:root:2019-05-10 19:06:50, Epoch : 1, Step : 1892, Training Loss : 0.19791, Training Acc : 0.922, Run Time : 0.23
INFO:root:2019-05-10 19:06:50, Epoch : 1, Step : 1893, Training Loss : 0.21173, Training Acc : 0.922, Run Time : 0.21
INFO:root:2019-05-10 19:06:51, Epoch : 1, Step : 1894, Training Loss : 0.21931, Training Acc : 0.911, Run Time : 0.23
INFO:root:2019-05-10 19:06:51, Epoch : 1, Step : 1895, Training Loss : 0.24167, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-10 19:07:10, Epoch : 1, Step : 1896, Training Loss : 0.20722, Training Acc : 0.922, Run Time : 19.31
INFO:root:2019-05-10 19:07:11, Epoch : 1, Step : 1897, Training Loss : 0.21607, Training Acc : 0.889, Run Time : 0.22
INFO:root:2019-05-10 19:07:11, Epoch : 1, Step : 1898, Training Loss : 0.19281, Training Acc : 0.911, Run Time : 0.22
INFO:root:2019-05-10 19:07:11, Epoch : 1, Step : 1899, Training Loss : 0.18822, Training Acc : 0.911, Run Time : 0.21
INFO:root:2019-05-10 19:07:11, Epoch : 1, Step : 1900, Training Loss : 0.20873, Training Acc : 0.917, Run Time : 0.21
INFO:root:2019-05-10 19:07:39, Epoch : 1, Step : 1901, Training Loss : 0.18602, Training Acc : 0.917, Run Time : 27.77
INFO:root:2019-05-10 19:07:39, Epoch : 1, Step : 1902, Training Loss : 0.22072, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-10 19:07:40, Epoch : 1, Step : 1903, Training Loss : 0.21670, Training Acc : 0.883, Run Time : 1.05
INFO:root:2019-05-10 19:07:52, Epoch : 1, Step : 1904, Training Loss : 0.16262, Training Acc : 0.928, Run Time : 11.33
INFO:root:2019-05-10 19:07:53, Epoch : 1, Step : 1905, Training Loss : 0.19535, Training Acc : 0.922, Run Time : 0.77
INFO:root:2019-05-10 19:07:53, Epoch : 1, Step : 1906, Training Loss : 0.18252, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-10 19:07:53, Epoch : 1, Step : 1907, Training Loss : 0.21747, Training Acc : 0.906, Run Time : 0.39
INFO:root:2019-05-10 19:07:54, Epoch : 1, Step : 1908, Training Loss : 0.43498, Training Acc : 0.828, Run Time : 0.48
INFO:root:2019-05-10 19:08:19, Epoch : 1, Step : 1909, Training Loss : 0.22669, Training Acc : 0.906, Run Time : 24.76
INFO:root:2019-05-10 19:08:19, Epoch : 1, Step : 1910, Training Loss : 0.39733, Training Acc : 0.867, Run Time : 0.24
INFO:root:2019-05-10 19:08:19, Epoch : 1, Step : 1911, Training Loss : 0.29401, Training Acc : 0.856, Run Time : 0.35
INFO:root:2019-05-10 19:08:20, Epoch : 1, Step : 1912, Training Loss : 0.31870, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 19:08:33, Epoch : 1, Step : 1913, Training Loss : 0.23327, Training Acc : 0.894, Run Time : 13.69
INFO:root:2019-05-10 19:08:34, Epoch : 1, Step : 1914, Training Loss : 0.20186, Training Acc : 0.906, Run Time : 0.60
INFO:root:2019-05-10 19:08:34, Epoch : 1, Step : 1915, Training Loss : 0.23750, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-10 19:08:35, Epoch : 1, Step : 1916, Training Loss : 0.16832, Training Acc : 0.922, Run Time : 0.56
INFO:root:2019-05-10 19:08:47, Epoch : 1, Step : 1917, Training Loss : 0.17192, Training Acc : 0.944, Run Time : 11.96
INFO:root:2019-05-10 19:08:48, Epoch : 1, Step : 1918, Training Loss : 0.19051, Training Acc : 0.900, Run Time : 0.78
INFO:root:2019-05-10 19:08:48, Epoch : 1, Step : 1919, Training Loss : 0.24100, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-10 19:08:49, Epoch : 1, Step : 1920, Training Loss : 0.23309, Training Acc : 0.944, Run Time : 0.50
INFO:root:2019-05-10 19:08:49, Epoch : 1, Step : 1921, Training Loss : 0.15726, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-10 19:09:06, Epoch : 1, Step : 1922, Training Loss : 0.18680, Training Acc : 0.922, Run Time : 17.14
INFO:root:2019-05-10 19:09:07, Epoch : 1, Step : 1923, Training Loss : 0.17964, Training Acc : 0.922, Run Time : 0.62
INFO:root:2019-05-10 19:09:07, Epoch : 1, Step : 1924, Training Loss : 0.16230, Training Acc : 0.944, Run Time : 0.24
INFO:root:2019-05-10 19:09:08, Epoch : 1, Step : 1925, Training Loss : 0.20101, Training Acc : 0.939, Run Time : 0.49
INFO:root:2019-05-10 19:09:21, Epoch : 1, Step : 1926, Training Loss : 0.17273, Training Acc : 0.933, Run Time : 13.11
INFO:root:2019-05-10 19:09:22, Epoch : 1, Step : 1927, Training Loss : 0.14469, Training Acc : 0.928, Run Time : 1.05
INFO:root:2019-05-10 19:09:22, Epoch : 1, Step : 1928, Training Loss : 0.18899, Training Acc : 0.928, Run Time : 0.53
INFO:root:2019-05-10 19:09:23, Epoch : 1, Step : 1929, Training Loss : 0.15735, Training Acc : 0.939, Run Time : 0.51
INFO:root:2019-05-10 19:09:43, Epoch : 1, Step : 1930, Training Loss : 0.16656, Training Acc : 0.928, Run Time : 19.69
INFO:root:2019-05-10 19:09:43, Epoch : 1, Step : 1931, Training Loss : 0.18844, Training Acc : 0.911, Run Time : 0.59
INFO:root:2019-05-10 19:09:44, Epoch : 1, Step : 1932, Training Loss : 0.16742, Training Acc : 0.917, Run Time : 0.88
INFO:root:2019-05-10 19:09:44, Epoch : 1, Step : 1933, Training Loss : 0.15592, Training Acc : 0.956, Run Time : 0.43
INFO:root:2019-05-10 19:09:45, Epoch : 1, Step : 1934, Training Loss : 0.13310, Training Acc : 0.972, Run Time : 0.71
INFO:root:2019-05-10 19:10:02, Epoch : 1, Step : 1935, Training Loss : 0.15520, Training Acc : 0.928, Run Time : 16.79
INFO:root:2019-05-10 19:10:03, Epoch : 1, Step : 1936, Training Loss : 0.15611, Training Acc : 0.928, Run Time : 0.79
INFO:root:2019-05-10 19:10:03, Epoch : 1, Step : 1937, Training Loss : 0.16649, Training Acc : 0.911, Run Time : 0.56
INFO:root:2019-05-10 19:10:04, Epoch : 1, Step : 1938, Training Loss : 0.20571, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-10 19:10:29, Epoch : 1, Step : 1939, Training Loss : 0.18519, Training Acc : 0.906, Run Time : 24.87
INFO:root:2019-05-10 19:10:29, Epoch : 1, Step : 1940, Training Loss : 0.14509, Training Acc : 0.933, Run Time : 0.86
INFO:root:2019-05-10 19:10:30, Epoch : 1, Step : 1941, Training Loss : 0.20861, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-10 19:10:30, Epoch : 1, Step : 1942, Training Loss : 0.12373, Training Acc : 0.956, Run Time : 0.51
INFO:root:2019-05-10 19:10:31, Epoch : 1, Step : 1943, Training Loss : 0.10297, Training Acc : 0.972, Run Time : 0.48
INFO:root:2019-05-10 19:10:48, Epoch : 1, Step : 1944, Training Loss : 0.19975, Training Acc : 0.933, Run Time : 16.73
INFO:root:2019-05-10 19:10:48, Epoch : 1, Step : 1945, Training Loss : 0.11475, Training Acc : 0.961, Run Time : 0.22
INFO:root:2019-05-10 19:10:48, Epoch : 1, Step : 1946, Training Loss : 0.12701, Training Acc : 0.956, Run Time : 0.50
INFO:root:2019-05-10 19:10:52, Epoch : 1, Step : 1947, Training Loss : 0.13700, Training Acc : 0.922, Run Time : 3.36
INFO:root:2019-05-10 19:10:53, Epoch : 1, Step : 1948, Training Loss : 0.15687, Training Acc : 0.939, Run Time : 0.82
INFO:root:2019-05-10 19:10:53, Epoch : 1, Step : 1949, Training Loss : 0.17837, Training Acc : 0.917, Run Time : 0.93
INFO:root:2019-05-10 19:10:54, Epoch : 1, Step : 1950, Training Loss : 0.09758, Training Acc : 0.983, Run Time : 0.45
INFO:root:2019-05-10 19:11:12, Epoch : 1, Step : 1951, Training Loss : 0.15422, Training Acc : 0.917, Run Time : 18.09
INFO:root:2019-05-10 19:11:12, Epoch : 1, Step : 1952, Training Loss : 0.12070, Training Acc : 0.978, Run Time : 0.33
INFO:root:2019-05-10 19:11:13, Epoch : 1, Step : 1953, Training Loss : 0.11982, Training Acc : 0.961, Run Time : 0.32
INFO:root:2019-05-10 19:11:13, Epoch : 1, Step : 1954, Training Loss : 0.10281, Training Acc : 0.989, Run Time : 0.51
INFO:root:2019-05-10 19:11:14, Epoch : 1, Step : 1955, Training Loss : 0.14134, Training Acc : 0.950, Run Time : 0.50
INFO:root:2019-05-10 19:11:29, Epoch : 1, Step : 1956, Training Loss : 0.13149, Training Acc : 0.950, Run Time : 15.52
INFO:root:2019-05-10 19:11:30, Epoch : 1, Step : 1957, Training Loss : 0.11706, Training Acc : 0.967, Run Time : 0.31
INFO:root:2019-05-10 19:11:30, Epoch : 1, Step : 1958, Training Loss : 0.17803, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-10 19:11:30, Epoch : 1, Step : 1959, Training Loss : 0.16062, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-10 19:11:31, Epoch : 1, Step : 1960, Training Loss : 0.13515, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-10 19:11:48, Epoch : 1, Step : 1961, Training Loss : 0.14104, Training Acc : 0.944, Run Time : 17.22
INFO:root:2019-05-10 19:11:48, Epoch : 1, Step : 1962, Training Loss : 0.10807, Training Acc : 0.978, Run Time : 0.27
INFO:root:2019-05-10 19:11:49, Epoch : 1, Step : 1963, Training Loss : 0.16307, Training Acc : 0.928, Run Time : 0.49
INFO:root:2019-05-10 19:11:49, Epoch : 1, Step : 1964, Training Loss : 0.13063, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-10 19:11:53, Epoch : 1, Step : 1965, Training Loss : 0.11791, Training Acc : 0.961, Run Time : 3.68
INFO:root:2019-05-10 19:11:54, Epoch : 1, Step : 1966, Training Loss : 0.22460, Training Acc : 0.922, Run Time : 1.03
INFO:root:2019-05-10 19:11:55, Epoch : 1, Step : 1967, Training Loss : 0.17312, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 19:12:13, Epoch : 1, Step : 1968, Training Loss : 0.16083, Training Acc : 0.933, Run Time : 18.73
INFO:root:2019-05-10 19:12:14, Epoch : 1, Step : 1969, Training Loss : 0.12933, Training Acc : 0.950, Run Time : 0.67
INFO:root:2019-05-10 19:12:14, Epoch : 1, Step : 1970, Training Loss : 0.14931, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-10 19:12:15, Epoch : 1, Step : 1971, Training Loss : 0.11682, Training Acc : 0.944, Run Time : 0.51
INFO:root:2019-05-10 19:12:15, Epoch : 1, Step : 1972, Training Loss : 0.22403, Training Acc : 0.917, Run Time : 0.50
INFO:root:2019-05-10 19:12:34, Epoch : 1, Step : 1973, Training Loss : 0.14018, Training Acc : 0.939, Run Time : 18.18
INFO:root:2019-05-10 19:12:34, Epoch : 1, Step : 1974, Training Loss : 0.13432, Training Acc : 0.944, Run Time : 0.32
INFO:root:2019-05-10 19:12:34, Epoch : 1, Step : 1975, Training Loss : 0.11314, Training Acc : 0.961, Run Time : 0.46
INFO:root:2019-05-10 19:12:35, Epoch : 1, Step : 1976, Training Loss : 0.14806, Training Acc : 0.933, Run Time : 0.51
INFO:root:2019-05-10 19:12:47, Epoch : 1, Step : 1977, Training Loss : 0.12268, Training Acc : 0.961, Run Time : 11.96
INFO:root:2019-05-10 19:12:47, Epoch : 1, Step : 1978, Training Loss : 0.11655, Training Acc : 0.950, Run Time : 0.64
INFO:root:2019-05-10 19:12:48, Epoch : 1, Step : 1979, Training Loss : 0.16896, Training Acc : 0.917, Run Time : 0.24
INFO:root:2019-05-10 19:12:48, Epoch : 1, Step : 1980, Training Loss : 0.14445, Training Acc : 0.944, Run Time : 0.39
INFO:root:2019-05-10 19:12:48, Epoch : 1, Step : 1981, Training Loss : 0.14578, Training Acc : 0.928, Run Time : 0.40
INFO:root:2019-05-10 19:13:08, Epoch : 1, Step : 1982, Training Loss : 0.12327, Training Acc : 0.944, Run Time : 20.03
INFO:root:2019-05-10 19:13:22, Epoch : 1, Step : 1983, Training Loss : 0.08558, Training Acc : 0.983, Run Time : 13.33
INFO:root:2019-05-10 19:13:27, Epoch : 1, Step : 1984, Training Loss : 0.09450, Training Acc : 0.978, Run Time : 5.02
INFO:root:2019-05-10 19:13:27, Epoch : 1, Step : 1985, Training Loss : 0.08400, Training Acc : 0.978, Run Time : 0.30
INFO:root:2019-05-10 19:13:28, Epoch : 1, Step : 1986, Training Loss : 0.05898, Training Acc : 0.994, Run Time : 0.47
INFO:root:2019-05-10 19:13:28, Epoch : 1, Step : 1987, Training Loss : 0.09539, Training Acc : 0.972, Run Time : 0.49
INFO:root:2019-05-10 19:13:30, Epoch : 1, Step : 1988, Training Loss : 0.12321, Training Acc : 0.961, Run Time : 1.90
INFO:root:2019-05-10 19:13:33, Epoch : 1, Step : 1989, Training Loss : 0.06694, Training Acc : 0.989, Run Time : 2.85
INFO:root:2019-05-10 19:13:33, Epoch : 1, Step : 1990, Training Loss : 0.06435, Training Acc : 0.978, Run Time : 0.41
INFO:root:2019-05-10 19:13:50, Epoch : 1, Step : 1991, Training Loss : 0.07067, Training Acc : 0.978, Run Time : 16.58
INFO:root:2019-05-10 19:13:50, Epoch : 1, Step : 1992, Training Loss : 0.07111, Training Acc : 0.983, Run Time : 0.34
INFO:root:2019-05-10 19:13:51, Epoch : 1, Step : 1993, Training Loss : 0.07624, Training Acc : 0.983, Run Time : 0.45
INFO:root:2019-05-10 19:13:51, Epoch : 1, Step : 1994, Training Loss : 0.07218, Training Acc : 0.967, Run Time : 0.54
INFO:root:2019-05-10 19:13:52, Epoch : 1, Step : 1995, Training Loss : 0.10014, Training Acc : 0.956, Run Time : 0.44
INFO:root:2019-05-10 19:14:09, Epoch : 1, Step : 1996, Training Loss : 0.05451, Training Acc : 0.978, Run Time : 17.28
INFO:root:2019-05-10 19:14:09, Epoch : 1, Step : 1997, Training Loss : 0.09982, Training Acc : 0.961, Run Time : 0.31
INFO:root:2019-05-10 19:14:10, Epoch : 1, Step : 1998, Training Loss : 0.08122, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-10 19:14:10, Epoch : 1, Step : 1999, Training Loss : 0.06529, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-10 19:14:11, Epoch : 1, Step : 2000, Training Loss : 0.10877, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 19:14:27, Epoch : 1, Step : 2001, Training Loss : 1.03902, Training Acc : 0.672, Run Time : 16.41
INFO:root:2019-05-10 19:14:27, Epoch : 1, Step : 2002, Training Loss : 1.35825, Training Acc : 0.611, Run Time : 0.34
INFO:root:2019-05-10 19:14:28, Epoch : 1, Step : 2003, Training Loss : 1.38087, Training Acc : 0.617, Run Time : 0.34
INFO:root:2019-05-10 19:14:28, Epoch : 1, Step : 2004, Training Loss : 1.40290, Training Acc : 0.611, Run Time : 0.47
INFO:root:2019-05-10 19:14:29, Epoch : 1, Step : 2005, Training Loss : 0.97622, Training Acc : 0.667, Run Time : 0.38
INFO:root:2019-05-10 19:14:48, Epoch : 1, Step : 2006, Training Loss : 0.93211, Training Acc : 0.683, Run Time : 19.05
INFO:root:2019-05-10 19:14:48, Epoch : 1, Step : 2007, Training Loss : 0.71363, Training Acc : 0.706, Run Time : 0.25
INFO:root:2019-05-10 19:14:48, Epoch : 1, Step : 2008, Training Loss : 0.51172, Training Acc : 0.783, Run Time : 0.45
INFO:root:2019-05-10 19:14:49, Epoch : 1, Step : 2009, Training Loss : 0.52632, Training Acc : 0.783, Run Time : 0.50
INFO:root:2019-05-10 19:14:49, Epoch : 1, Step : 2010, Training Loss : 0.32872, Training Acc : 0.839, Run Time : 0.49
INFO:root:2019-05-10 19:15:06, Epoch : 1, Step : 2011, Training Loss : 0.26104, Training Acc : 0.867, Run Time : 17.16
INFO:root:2019-05-10 19:15:07, Epoch : 1, Step : 2012, Training Loss : 0.24559, Training Acc : 0.917, Run Time : 0.27
INFO:root:2019-05-10 19:15:07, Epoch : 1, Step : 2013, Training Loss : 0.12494, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-10 19:15:08, Epoch : 1, Step : 2014, Training Loss : 0.16216, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-10 19:15:22, Epoch : 1, Step : 2015, Training Loss : 0.28826, Training Acc : 0.856, Run Time : 14.79
INFO:root:2019-05-10 19:15:23, Epoch : 1, Step : 2016, Training Loss : 0.15107, Training Acc : 0.956, Run Time : 0.97
INFO:root:2019-05-10 19:15:24, Epoch : 1, Step : 2017, Training Loss : 0.18042, Training Acc : 0.939, Run Time : 0.60
INFO:root:2019-05-10 19:15:25, Epoch : 1, Step : 2018, Training Loss : 0.29786, Training Acc : 0.917, Run Time : 0.51
INFO:root:2019-05-10 19:15:39, Epoch : 1, Step : 2019, Training Loss : 0.18430, Training Acc : 0.956, Run Time : 14.10
INFO:root:2019-05-10 19:15:39, Epoch : 1, Step : 2020, Training Loss : 0.46872, Training Acc : 0.839, Run Time : 0.43
INFO:root:2019-05-10 19:15:40, Epoch : 1, Step : 2021, Training Loss : 0.70332, Training Acc : 0.761, Run Time : 0.50
INFO:root:2019-05-10 19:15:42, Epoch : 1, Step : 2022, Training Loss : 0.83811, Training Acc : 0.700, Run Time : 2.01
INFO:root:2019-05-10 19:15:42, Epoch : 1, Step : 2023, Training Loss : 0.58500, Training Acc : 0.778, Run Time : 0.59
INFO:root:2019-05-10 19:16:00, Epoch : 1, Step : 2024, Training Loss : 0.46356, Training Acc : 0.806, Run Time : 18.06
INFO:root:2019-05-10 19:16:01, Epoch : 1, Step : 2025, Training Loss : 0.65237, Training Acc : 0.694, Run Time : 0.54
INFO:root:2019-05-10 19:16:01, Epoch : 1, Step : 2026, Training Loss : 0.40602, Training Acc : 0.806, Run Time : 0.41
INFO:root:2019-05-10 19:16:02, Epoch : 1, Step : 2027, Training Loss : 0.34922, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-10 19:16:02, Epoch : 1, Step : 2028, Training Loss : 0.39191, Training Acc : 0.833, Run Time : 0.50
INFO:root:2019-05-10 19:16:19, Epoch : 1, Step : 2029, Training Loss : 0.30895, Training Acc : 0.883, Run Time : 16.78
INFO:root:2019-05-10 19:16:19, Epoch : 1, Step : 2030, Training Loss : 0.43169, Training Acc : 0.822, Run Time : 0.22
INFO:root:2019-05-10 19:16:19, Epoch : 1, Step : 2031, Training Loss : 0.26962, Training Acc : 0.906, Run Time : 0.37
INFO:root:2019-05-10 19:16:20, Epoch : 1, Step : 2032, Training Loss : 0.22139, Training Acc : 0.911, Run Time : 0.39
INFO:root:2019-05-10 19:16:20, Epoch : 1, Step : 2033, Training Loss : 0.21210, Training Acc : 0.928, Run Time : 0.50
INFO:root:2019-05-10 19:16:34, Epoch : 1, Step : 2034, Training Loss : 0.33576, Training Acc : 0.850, Run Time : 13.84
INFO:root:2019-05-10 19:16:34, Epoch : 1, Step : 2035, Training Loss : 0.31625, Training Acc : 0.872, Run Time : 0.26
INFO:root:2019-05-10 19:16:35, Epoch : 1, Step : 2036, Training Loss : 0.24011, Training Acc : 0.917, Run Time : 0.49
INFO:root:2019-05-10 19:16:35, Epoch : 1, Step : 2037, Training Loss : 0.23941, Training Acc : 0.906, Run Time : 0.49
INFO:root:2019-05-10 19:16:48, Epoch : 1, Step : 2038, Training Loss : 0.40190, Training Acc : 0.822, Run Time : 12.63
INFO:root:2019-05-10 19:16:48, Epoch : 1, Step : 2039, Training Loss : 0.54270, Training Acc : 0.783, Run Time : 0.38
INFO:root:2019-05-10 19:16:49, Epoch : 1, Step : 2040, Training Loss : 0.22740, Training Acc : 0.900, Run Time : 0.36
INFO:root:2019-05-10 19:16:49, Epoch : 1, Step : 2041, Training Loss : 0.34866, Training Acc : 0.856, Run Time : 0.66
INFO:root:2019-05-10 19:16:51, Epoch : 1, Step : 2042, Training Loss : 0.18150, Training Acc : 0.922, Run Time : 1.05
INFO:root:2019-05-10 19:17:06, Epoch : 1, Step : 2043, Training Loss : 0.29657, Training Acc : 0.883, Run Time : 15.09
INFO:root:2019-05-10 19:17:06, Epoch : 1, Step : 2044, Training Loss : 0.35863, Training Acc : 0.844, Run Time : 0.77
INFO:root:2019-05-10 19:17:17, Epoch : 1, Step : 2045, Training Loss : 0.30271, Training Acc : 0.872, Run Time : 10.49
INFO:root:2019-05-10 19:17:18, Epoch : 1, Step : 2046, Training Loss : 0.45973, Training Acc : 0.833, Run Time : 1.02
INFO:root:2019-05-10 19:17:18, Epoch : 1, Step : 2047, Training Loss : 0.39629, Training Acc : 0.822, Run Time : 0.48
INFO:root:2019-05-10 19:17:19, Epoch : 1, Step : 2048, Training Loss : 0.25184, Training Acc : 0.911, Run Time : 0.50
INFO:root:2019-05-10 19:17:19, Epoch : 1, Step : 2049, Training Loss : 0.48212, Training Acc : 0.817, Run Time : 0.47
INFO:root:2019-05-10 19:17:35, Epoch : 1, Step : 2050, Training Loss : 0.65539, Training Acc : 0.750, Run Time : 15.81
INFO:root:2019-05-10 19:17:37, Epoch : 1, Step : 2051, Training Loss : 0.30746, Training Acc : 0.889, Run Time : 1.37
INFO:root:2019-05-10 19:17:37, Epoch : 1, Step : 2052, Training Loss : 0.43051, Training Acc : 0.833, Run Time : 0.47
INFO:root:2019-05-10 19:17:50, Epoch : 1, Step : 2053, Training Loss : 0.23359, Training Acc : 0.894, Run Time : 12.53
INFO:root:2019-05-10 19:17:50, Epoch : 1, Step : 2054, Training Loss : 0.42914, Training Acc : 0.867, Run Time : 0.60
INFO:root:2019-05-10 19:17:50, Epoch : 1, Step : 2055, Training Loss : 0.41430, Training Acc : 0.867, Run Time : 0.34
INFO:root:2019-05-10 19:18:01, Epoch : 1, Step : 2056, Training Loss : 0.33285, Training Acc : 0.900, Run Time : 10.24
INFO:root:2019-05-10 19:18:02, Epoch : 1, Step : 2057, Training Loss : 0.35963, Training Acc : 0.844, Run Time : 1.58
INFO:root:2019-05-10 19:18:13, Epoch : 1, Step : 2058, Training Loss : 0.47758, Training Acc : 0.828, Run Time : 10.59
INFO:root:2019-05-10 19:18:14, Epoch : 1, Step : 2059, Training Loss : 0.28698, Training Acc : 0.906, Run Time : 0.72
INFO:root:2019-05-10 19:18:14, Epoch : 1, Step : 2060, Training Loss : 0.26536, Training Acc : 0.922, Run Time : 0.33
INFO:root:2019-05-10 19:18:14, Epoch : 1, Step : 2061, Training Loss : 0.22331, Training Acc : 0.917, Run Time : 0.48
INFO:root:2019-05-10 19:18:15, Epoch : 1, Step : 2062, Training Loss : 0.26777, Training Acc : 0.906, Run Time : 0.49
INFO:root:2019-05-10 19:18:33, Epoch : 1, Step : 2063, Training Loss : 0.43100, Training Acc : 0.839, Run Time : 17.93
INFO:root:2019-05-10 19:18:33, Epoch : 1, Step : 2064, Training Loss : 0.27239, Training Acc : 0.894, Run Time : 0.33
INFO:root:2019-05-10 19:18:34, Epoch : 1, Step : 2065, Training Loss : 0.33558, Training Acc : 0.883, Run Time : 0.44
INFO:root:2019-05-10 19:18:34, Epoch : 1, Step : 2066, Training Loss : 0.29290, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-10 19:18:35, Epoch : 1, Step : 2067, Training Loss : 0.53418, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-10 19:18:50, Epoch : 1, Step : 2068, Training Loss : 0.26369, Training Acc : 0.928, Run Time : 15.76
INFO:root:2019-05-10 19:18:51, Epoch : 1, Step : 2069, Training Loss : 0.67417, Training Acc : 0.817, Run Time : 0.33
INFO:root:2019-05-10 19:18:51, Epoch : 1, Step : 2070, Training Loss : 0.24136, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 19:18:59, Epoch : 1, Step : 2071, Training Loss : 0.44940, Training Acc : 0.889, Run Time : 7.91
INFO:root:2019-05-10 19:19:00, Epoch : 1, Step : 2072, Training Loss : 0.21414, Training Acc : 0.906, Run Time : 0.57
INFO:root:2019-05-10 19:19:00, Epoch : 1, Step : 2073, Training Loss : 0.32788, Training Acc : 0.883, Run Time : 0.50
INFO:root:2019-05-10 19:19:01, Epoch : 1, Step : 2074, Training Loss : 0.26574, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-10 19:19:01, Epoch : 1, Step : 2075, Training Loss : 0.37281, Training Acc : 0.900, Run Time : 0.52
INFO:root:2019-05-10 19:19:17, Epoch : 1, Step : 2076, Training Loss : 0.66225, Training Acc : 0.700, Run Time : 15.97
INFO:root:2019-05-10 19:19:17, Epoch : 1, Step : 2077, Training Loss : 1.08353, Training Acc : 0.583, Run Time : 0.24
INFO:root:2019-05-10 19:19:18, Epoch : 1, Step : 2078, Training Loss : 0.74088, Training Acc : 0.711, Run Time : 0.42
INFO:root:2019-05-10 19:19:18, Epoch : 1, Step : 2079, Training Loss : 0.74470, Training Acc : 0.722, Run Time : 0.48
INFO:root:2019-05-10 19:19:19, Epoch : 1, Step : 2080, Training Loss : 0.52859, Training Acc : 0.767, Run Time : 0.50
INFO:root:2019-05-10 19:19:33, Epoch : 1, Step : 2081, Training Loss : 0.55282, Training Acc : 0.728, Run Time : 14.55
INFO:root:2019-05-10 19:19:34, Epoch : 1, Step : 2082, Training Loss : 0.56992, Training Acc : 0.811, Run Time : 0.39
INFO:root:2019-05-10 19:19:34, Epoch : 1, Step : 2083, Training Loss : 0.42401, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-10 19:19:48, Epoch : 1, Step : 2084, Training Loss : 0.50228, Training Acc : 0.794, Run Time : 13.65
INFO:root:2019-05-10 19:19:48, Epoch : 1, Step : 2085, Training Loss : 0.32154, Training Acc : 0.889, Run Time : 0.53
INFO:root:2019-05-10 19:19:49, Epoch : 1, Step : 2086, Training Loss : 0.45901, Training Acc : 0.811, Run Time : 0.45
INFO:root:2019-05-10 19:19:49, Epoch : 1, Step : 2087, Training Loss : 0.37999, Training Acc : 0.828, Run Time : 0.39
INFO:root:2019-05-10 19:19:50, Epoch : 1, Step : 2088, Training Loss : 0.49499, Training Acc : 0.794, Run Time : 0.51
INFO:root:2019-05-10 19:20:06, Epoch : 1, Step : 2089, Training Loss : 0.33135, Training Acc : 0.822, Run Time : 16.29
INFO:root:2019-05-10 19:20:06, Epoch : 1, Step : 2090, Training Loss : 0.39612, Training Acc : 0.822, Run Time : 0.27
INFO:root:2019-05-10 19:20:07, Epoch : 1, Step : 2091, Training Loss : 0.45496, Training Acc : 0.794, Run Time : 0.42
INFO:root:2019-05-10 19:20:07, Epoch : 1, Step : 2092, Training Loss : 0.39352, Training Acc : 0.817, Run Time : 0.45
INFO:root:2019-05-10 19:20:08, Epoch : 1, Step : 2093, Training Loss : 0.55601, Training Acc : 0.783, Run Time : 0.49
INFO:root:2019-05-10 19:20:25, Epoch : 1, Step : 2094, Training Loss : 0.35370, Training Acc : 0.811, Run Time : 17.54
INFO:root:2019-05-10 19:20:26, Epoch : 1, Step : 2095, Training Loss : 0.48447, Training Acc : 0.744, Run Time : 0.58
INFO:root:2019-05-10 19:20:40, Epoch : 1, Step : 2096, Training Loss : 0.37518, Training Acc : 0.833, Run Time : 13.95
INFO:root:2019-05-10 19:20:40, Epoch : 1, Step : 2097, Training Loss : 0.23763, Training Acc : 0.911, Run Time : 0.43
INFO:root:2019-05-10 19:20:41, Epoch : 1, Step : 2098, Training Loss : 0.41767, Training Acc : 0.828, Run Time : 0.49
INFO:root:2019-05-10 19:20:51, Epoch : 1, Step : 2099, Training Loss : 0.33231, Training Acc : 0.850, Run Time : 10.83
INFO:root:2019-05-10 19:20:52, Epoch : 1, Step : 2100, Training Loss : 0.30928, Training Acc : 0.856, Run Time : 0.74
INFO:root:2019-05-10 19:21:01, Epoch : 1, Step : 2101, Training Loss : 0.43403, Training Acc : 0.783, Run Time : 8.75
INFO:root:2019-05-10 19:21:01, Epoch : 1, Step : 2102, Training Loss : 0.35499, Training Acc : 0.867, Run Time : 0.52
INFO:root:2019-05-10 19:21:02, Epoch : 1, Step : 2103, Training Loss : 0.34127, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-10 19:21:02, Epoch : 1, Step : 2104, Training Loss : 0.37755, Training Acc : 0.828, Run Time : 0.52
INFO:root:2019-05-10 19:21:04, Epoch : 1, Step : 2105, Training Loss : 0.30336, Training Acc : 0.861, Run Time : 1.89
INFO:root:2019-05-10 19:21:17, Epoch : 1, Step : 2106, Training Loss : 0.33812, Training Acc : 0.833, Run Time : 12.96
INFO:root:2019-05-10 19:21:18, Epoch : 1, Step : 2107, Training Loss : 0.36610, Training Acc : 0.844, Run Time : 0.42
INFO:root:2019-05-10 19:21:18, Epoch : 1, Step : 2108, Training Loss : 0.34850, Training Acc : 0.844, Run Time : 0.46
INFO:root:2019-05-10 19:21:19, Epoch : 1, Step : 2109, Training Loss : 0.36684, Training Acc : 0.806, Run Time : 0.49
INFO:root:2019-05-10 19:21:19, Epoch : 1, Step : 2110, Training Loss : 0.46646, Training Acc : 0.789, Run Time : 0.51
INFO:root:2019-05-10 19:21:34, Epoch : 1, Step : 2111, Training Loss : 0.55814, Training Acc : 0.767, Run Time : 14.88
INFO:root:2019-05-10 19:21:35, Epoch : 1, Step : 2112, Training Loss : 0.32495, Training Acc : 0.839, Run Time : 0.55
INFO:root:2019-05-10 19:21:35, Epoch : 1, Step : 2113, Training Loss : 0.23471, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 19:21:51, Epoch : 1, Step : 2114, Training Loss : 0.28794, Training Acc : 0.878, Run Time : 15.98
INFO:root:2019-05-10 19:21:52, Epoch : 1, Step : 2115, Training Loss : 0.47279, Training Acc : 0.767, Run Time : 0.54
INFO:root:2019-05-10 19:21:52, Epoch : 1, Step : 2116, Training Loss : 0.26317, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 19:21:53, Epoch : 1, Step : 2117, Training Loss : 0.38510, Training Acc : 0.856, Run Time : 0.49
INFO:root:2019-05-10 19:21:53, Epoch : 1, Step : 2118, Training Loss : 0.33407, Training Acc : 0.822, Run Time : 0.48
INFO:root:2019-05-10 19:22:08, Epoch : 1, Step : 2119, Training Loss : 0.34055, Training Acc : 0.828, Run Time : 15.32
INFO:root:2019-05-10 19:22:09, Epoch : 1, Step : 2120, Training Loss : 0.41508, Training Acc : 0.844, Run Time : 0.32
INFO:root:2019-05-10 19:22:09, Epoch : 1, Step : 2121, Training Loss : 0.41971, Training Acc : 0.817, Run Time : 0.47
INFO:root:2019-05-10 19:22:10, Epoch : 1, Step : 2122, Training Loss : 0.36303, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 19:22:10, Epoch : 1, Step : 2123, Training Loss : 0.52858, Training Acc : 0.744, Run Time : 0.51
INFO:root:2019-05-10 19:22:31, Epoch : 1, Step : 2124, Training Loss : 0.60588, Training Acc : 0.761, Run Time : 21.23
INFO:root:2019-05-10 19:22:32, Epoch : 1, Step : 2125, Training Loss : 0.32231, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-10 19:22:32, Epoch : 1, Step : 2126, Training Loss : 0.36117, Training Acc : 0.850, Run Time : 0.63
INFO:root:2019-05-10 19:22:33, Epoch : 1, Step : 2127, Training Loss : 0.46733, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-10 19:22:33, Epoch : 1, Step : 2128, Training Loss : 0.31785, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 19:22:49, Epoch : 1, Step : 2129, Training Loss : 0.52914, Training Acc : 0.733, Run Time : 15.37
INFO:root:2019-05-10 19:22:49, Epoch : 1, Step : 2130, Training Loss : 0.23292, Training Acc : 0.933, Run Time : 0.26
INFO:root:2019-05-10 19:22:49, Epoch : 1, Step : 2131, Training Loss : 0.32765, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-10 19:22:50, Epoch : 1, Step : 2132, Training Loss : 0.16502, Training Acc : 0.989, Run Time : 0.47
INFO:root:2019-05-10 19:23:00, Epoch : 1, Step : 2133, Training Loss : 0.29173, Training Acc : 0.894, Run Time : 9.87
INFO:root:2019-05-10 19:23:01, Epoch : 1, Step : 2134, Training Loss : 0.24402, Training Acc : 0.922, Run Time : 0.78
INFO:root:2019-05-10 19:23:01, Epoch : 1, Step : 2135, Training Loss : 0.25303, Training Acc : 0.917, Run Time : 0.49
INFO:root:2019-05-10 19:23:01, Epoch : 1, Step : 2136, Training Loss : 0.22516, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-10 19:23:02, Epoch : 1, Step : 2137, Training Loss : 0.31586, Training Acc : 0.850, Run Time : 0.51
INFO:root:2019-05-10 19:23:06, Epoch : 1, Step : 2138, Training Loss : 0.25534, Training Acc : 0.917, Run Time : 3.70
INFO:root:2019-05-10 19:23:18, Epoch : 1, Step : 2139, Training Loss : 0.23906, Training Acc : 0.928, Run Time : 12.14
INFO:root:2019-05-10 19:23:18, Epoch : 1, Step : 2140, Training Loss : 0.28422, Training Acc : 0.872, Run Time : 0.36
INFO:root:2019-05-10 19:23:19, Epoch : 1, Step : 2141, Training Loss : 0.22518, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 19:23:19, Epoch : 1, Step : 2142, Training Loss : 0.39588, Training Acc : 0.833, Run Time : 0.47
INFO:root:2019-05-10 19:23:20, Epoch : 1, Step : 2143, Training Loss : 0.28680, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-10 19:23:35, Epoch : 1, Step : 2144, Training Loss : 0.26438, Training Acc : 0.861, Run Time : 15.54
INFO:root:2019-05-10 19:23:36, Epoch : 1, Step : 2145, Training Loss : 0.21324, Training Acc : 0.928, Run Time : 0.57
INFO:root:2019-05-10 19:23:36, Epoch : 1, Step : 2146, Training Loss : 0.12481, Training Acc : 0.983, Run Time : 0.71
INFO:root:2019-05-10 19:23:37, Epoch : 1, Step : 2147, Training Loss : 0.28757, Training Acc : 0.900, Run Time : 0.63
INFO:root:2019-05-10 19:23:47, Epoch : 1, Step : 2148, Training Loss : 0.14577, Training Acc : 0.961, Run Time : 9.47
INFO:root:2019-05-10 19:23:47, Epoch : 1, Step : 2149, Training Loss : 0.17993, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-10 19:23:47, Epoch : 1, Step : 2150, Training Loss : 0.12833, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 19:23:48, Epoch : 1, Step : 2151, Training Loss : 0.23580, Training Acc : 0.906, Run Time : 0.58
INFO:root:2019-05-10 19:23:48, Epoch : 1, Step : 2152, Training Loss : 0.27161, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 19:24:06, Epoch : 1, Step : 2153, Training Loss : 0.15504, Training Acc : 0.944, Run Time : 17.26
INFO:root:2019-05-10 19:24:07, Epoch : 1, Step : 2154, Training Loss : 0.16385, Training Acc : 0.944, Run Time : 0.85
INFO:root:2019-05-10 19:24:07, Epoch : 1, Step : 2155, Training Loss : 0.23669, Training Acc : 0.889, Run Time : 0.56
INFO:root:2019-05-10 19:24:17, Epoch : 1, Step : 2156, Training Loss : 0.16847, Training Acc : 0.944, Run Time : 10.31
INFO:root:2019-05-10 19:24:18, Epoch : 1, Step : 2157, Training Loss : 0.25885, Training Acc : 0.883, Run Time : 1.03
INFO:root:2019-05-10 19:24:19, Epoch : 1, Step : 2158, Training Loss : 0.20508, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-10 19:24:19, Epoch : 1, Step : 2159, Training Loss : 0.19874, Training Acc : 0.894, Run Time : 0.42
INFO:root:2019-05-10 19:24:20, Epoch : 1, Step : 2160, Training Loss : 0.19912, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 19:24:33, Epoch : 1, Step : 2161, Training Loss : 0.31864, Training Acc : 0.833, Run Time : 13.63
INFO:root:2019-05-10 19:24:34, Epoch : 1, Step : 2162, Training Loss : 0.23051, Training Acc : 0.894, Run Time : 0.33
INFO:root:2019-05-10 19:24:34, Epoch : 1, Step : 2163, Training Loss : 0.11394, Training Acc : 0.967, Run Time : 0.47
INFO:root:2019-05-10 19:24:35, Epoch : 1, Step : 2164, Training Loss : 0.18401, Training Acc : 0.933, Run Time : 0.63
INFO:root:2019-05-10 19:24:45, Epoch : 1, Step : 2165, Training Loss : 0.35991, Training Acc : 0.861, Run Time : 10.38
INFO:root:2019-05-10 19:24:47, Epoch : 1, Step : 2166, Training Loss : 0.15262, Training Acc : 0.961, Run Time : 2.24
INFO:root:2019-05-10 19:24:48, Epoch : 1, Step : 2167, Training Loss : 0.44569, Training Acc : 0.861, Run Time : 0.56
INFO:root:2019-05-10 19:24:49, Epoch : 1, Step : 2168, Training Loss : 0.10759, Training Acc : 0.972, Run Time : 0.49
INFO:root:2019-05-10 19:24:49, Epoch : 1, Step : 2169, Training Loss : 0.08757, Training Acc : 0.983, Run Time : 0.47
INFO:root:2019-05-10 19:24:50, Epoch : 1, Step : 2170, Training Loss : 0.07020, Training Acc : 0.972, Run Time : 1.10
INFO:root:2019-05-10 19:25:05, Epoch : 1, Step : 2171, Training Loss : 0.31836, Training Acc : 0.889, Run Time : 15.12
INFO:root:2019-05-10 19:25:06, Epoch : 1, Step : 2172, Training Loss : 0.20599, Training Acc : 0.900, Run Time : 0.39
INFO:root:2019-05-10 19:25:06, Epoch : 1, Step : 2173, Training Loss : 0.22689, Training Acc : 0.894, Run Time : 0.75
INFO:root:2019-05-10 19:25:07, Epoch : 1, Step : 2174, Training Loss : 0.13151, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-10 19:25:07, Epoch : 1, Step : 2175, Training Loss : 0.13575, Training Acc : 0.944, Run Time : 0.50
INFO:root:2019-05-10 19:25:14, Epoch : 1, Step : 2176, Training Loss : 0.21392, Training Acc : 0.922, Run Time : 6.35
INFO:root:2019-05-10 19:25:14, Epoch : 1, Step : 2177, Training Loss : 0.11283, Training Acc : 0.978, Run Time : 0.45
INFO:root:2019-05-10 19:25:30, Epoch : 1, Step : 2178, Training Loss : 0.07857, Training Acc : 0.989, Run Time : 15.62
INFO:root:2019-05-10 19:25:30, Epoch : 1, Step : 2179, Training Loss : 0.14072, Training Acc : 0.956, Run Time : 0.54
INFO:root:2019-05-10 19:25:31, Epoch : 1, Step : 2180, Training Loss : 0.19990, Training Acc : 0.928, Run Time : 0.33
INFO:root:2019-05-10 19:25:31, Epoch : 1, Step : 2181, Training Loss : 0.32320, Training Acc : 0.844, Run Time : 0.47
INFO:root:2019-05-10 19:25:32, Epoch : 1, Step : 2182, Training Loss : 0.29890, Training Acc : 0.839, Run Time : 0.51
INFO:root:2019-05-10 19:25:48, Epoch : 1, Step : 2183, Training Loss : 0.09818, Training Acc : 0.983, Run Time : 16.12
INFO:root:2019-05-10 19:25:48, Epoch : 1, Step : 2184, Training Loss : 0.14349, Training Acc : 0.933, Run Time : 0.21
INFO:root:2019-05-10 19:25:48, Epoch : 1, Step : 2185, Training Loss : 0.16703, Training Acc : 0.917, Run Time : 0.24
INFO:root:2019-05-10 19:25:49, Epoch : 1, Step : 2186, Training Loss : 0.22074, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-10 19:25:49, Epoch : 1, Step : 2187, Training Loss : 0.05290, Training Acc : 0.994, Run Time : 0.48
INFO:root:2019-05-10 19:25:54, Epoch : 1, Step : 2188, Training Loss : 0.15605, Training Acc : 0.939, Run Time : 4.78
INFO:root:2019-05-10 19:25:54, Epoch : 1, Step : 2189, Training Loss : 0.14073, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-10 19:26:10, Epoch : 1, Step : 2190, Training Loss : 0.08046, Training Acc : 0.989, Run Time : 15.38
INFO:root:2019-05-10 19:26:10, Epoch : 1, Step : 2191, Training Loss : 0.05896, Training Acc : 1.000, Run Time : 0.26
INFO:root:2019-05-10 19:26:10, Epoch : 1, Step : 2192, Training Loss : 0.14543, Training Acc : 0.944, Run Time : 0.44
INFO:root:2019-05-10 19:26:11, Epoch : 1, Step : 2193, Training Loss : 0.03571, Training Acc : 1.000, Run Time : 0.46
INFO:root:2019-05-10 19:26:23, Epoch : 1, Step : 2194, Training Loss : 0.04854, Training Acc : 0.989, Run Time : 11.73
INFO:root:2019-05-10 19:26:23, Epoch : 1, Step : 2195, Training Loss : 0.15063, Training Acc : 0.922, Run Time : 0.66
INFO:root:2019-05-10 19:26:24, Epoch : 1, Step : 2196, Training Loss : 0.05902, Training Acc : 1.000, Run Time : 0.46
INFO:root:2019-05-10 19:26:25, Epoch : 1, Step : 2197, Training Loss : 0.11786, Training Acc : 0.961, Run Time : 1.17
INFO:root:2019-05-10 19:26:35, Epoch : 1, Step : 2198, Training Loss : 0.15505, Training Acc : 0.939, Run Time : 9.97
INFO:root:2019-05-10 19:26:35, Epoch : 1, Step : 2199, Training Loss : 0.16110, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-10 19:26:36, Epoch : 1, Step : 2200, Training Loss : 0.38128, Training Acc : 0.844, Run Time : 0.27
INFO:root:2019-05-10 19:26:49, Epoch : 1, Step : 2201, Training Loss : 1.39396, Training Acc : 0.544, Run Time : 13.04
INFO:root:2019-05-10 19:26:49, Epoch : 1, Step : 2202, Training Loss : 1.28251, Training Acc : 0.528, Run Time : 0.24
INFO:root:2019-05-10 19:26:49, Epoch : 1, Step : 2203, Training Loss : 0.95737, Training Acc : 0.628, Run Time : 0.39
INFO:root:2019-05-10 19:26:50, Epoch : 1, Step : 2204, Training Loss : 0.91236, Training Acc : 0.633, Run Time : 0.42
INFO:root:2019-05-10 19:26:50, Epoch : 1, Step : 2205, Training Loss : 0.83759, Training Acc : 0.717, Run Time : 0.48
INFO:root:2019-05-10 19:27:07, Epoch : 1, Step : 2206, Training Loss : 0.69865, Training Acc : 0.661, Run Time : 17.11
INFO:root:2019-05-10 19:27:08, Epoch : 1, Step : 2207, Training Loss : 0.71734, Training Acc : 0.689, Run Time : 0.23
INFO:root:2019-05-10 19:27:08, Epoch : 1, Step : 2208, Training Loss : 0.67874, Training Acc : 0.744, Run Time : 0.50
INFO:root:2019-05-10 19:27:08, Epoch : 1, Step : 2209, Training Loss : 0.49169, Training Acc : 0.783, Run Time : 0.44
INFO:root:2019-05-10 19:27:09, Epoch : 1, Step : 2210, Training Loss : 0.54119, Training Acc : 0.756, Run Time : 0.48
INFO:root:2019-05-10 19:27:25, Epoch : 1, Step : 2211, Training Loss : 0.39881, Training Acc : 0.811, Run Time : 16.35
INFO:root:2019-05-10 19:27:26, Epoch : 1, Step : 2212, Training Loss : 0.54834, Training Acc : 0.794, Run Time : 0.30
INFO:root:2019-05-10 19:27:37, Epoch : 1, Step : 2213, Training Loss : 0.45404, Training Acc : 0.783, Run Time : 11.57
INFO:root:2019-05-10 19:27:37, Epoch : 1, Step : 2214, Training Loss : 0.58866, Training Acc : 0.778, Run Time : 0.24
INFO:root:2019-05-10 19:27:38, Epoch : 1, Step : 2215, Training Loss : 0.64622, Training Acc : 0.750, Run Time : 0.62
INFO:root:2019-05-10 19:27:39, Epoch : 1, Step : 2216, Training Loss : 0.49571, Training Acc : 0.778, Run Time : 0.48
INFO:root:2019-05-10 19:27:40, Epoch : 1, Step : 2217, Training Loss : 0.49371, Training Acc : 0.761, Run Time : 1.45
INFO:root:2019-05-10 19:27:55, Epoch : 1, Step : 2218, Training Loss : 0.61186, Training Acc : 0.756, Run Time : 15.34
INFO:root:2019-05-10 19:27:56, Epoch : 1, Step : 2219, Training Loss : 0.55079, Training Acc : 0.761, Run Time : 0.61
INFO:root:2019-05-10 19:27:57, Epoch : 1, Step : 2220, Training Loss : 0.54213, Training Acc : 0.733, Run Time : 0.59
INFO:root:2019-05-10 19:27:57, Epoch : 1, Step : 2221, Training Loss : 0.41265, Training Acc : 0.806, Run Time : 0.50
INFO:root:2019-05-10 19:27:57, Epoch : 1, Step : 2222, Training Loss : 0.49356, Training Acc : 0.794, Run Time : 0.45
INFO:root:2019-05-10 19:28:14, Epoch : 1, Step : 2223, Training Loss : 0.37880, Training Acc : 0.778, Run Time : 16.13
INFO:root:2019-05-10 19:28:14, Epoch : 1, Step : 2224, Training Loss : 0.38829, Training Acc : 0.811, Run Time : 0.58
INFO:root:2019-05-10 19:28:15, Epoch : 1, Step : 2225, Training Loss : 0.30968, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-10 19:28:15, Epoch : 1, Step : 2226, Training Loss : 0.34633, Training Acc : 0.861, Run Time : 0.56
INFO:root:2019-05-10 19:28:16, Epoch : 1, Step : 2227, Training Loss : 0.32519, Training Acc : 0.817, Run Time : 0.50
INFO:root:2019-05-10 19:28:32, Epoch : 1, Step : 2228, Training Loss : 0.38708, Training Acc : 0.789, Run Time : 16.34
INFO:root:2019-05-10 19:28:33, Epoch : 1, Step : 2229, Training Loss : 0.28881, Training Acc : 0.856, Run Time : 0.59
INFO:root:2019-05-10 19:28:33, Epoch : 1, Step : 2230, Training Loss : 0.24301, Training Acc : 0.894, Run Time : 0.56
INFO:root:2019-05-10 19:28:34, Epoch : 1, Step : 2231, Training Loss : 0.44086, Training Acc : 0.806, Run Time : 1.17
INFO:root:2019-05-10 19:28:43, Epoch : 1, Step : 2232, Training Loss : 0.45830, Training Acc : 0.761, Run Time : 9.12
INFO:root:2019-05-10 19:28:44, Epoch : 1, Step : 2233, Training Loss : 0.45034, Training Acc : 0.778, Run Time : 0.62
INFO:root:2019-05-10 19:28:45, Epoch : 1, Step : 2234, Training Loss : 0.42539, Training Acc : 0.817, Run Time : 0.45
INFO:root:2019-05-10 19:28:45, Epoch : 1, Step : 2235, Training Loss : 0.56031, Training Acc : 0.711, Run Time : 0.55
INFO:root:2019-05-10 19:28:57, Epoch : 1, Step : 2236, Training Loss : 0.41198, Training Acc : 0.811, Run Time : 12.15
INFO:root:2019-05-10 19:28:58, Epoch : 1, Step : 2237, Training Loss : 0.30783, Training Acc : 0.861, Run Time : 0.52
INFO:root:2019-05-10 19:28:58, Epoch : 1, Step : 2238, Training Loss : 0.26411, Training Acc : 0.878, Run Time : 0.21
INFO:root:2019-05-10 19:28:58, Epoch : 1, Step : 2239, Training Loss : 0.86904, Training Acc : 0.572, Run Time : 0.49
INFO:root:2019-05-10 19:28:59, Epoch : 1, Step : 2240, Training Loss : 0.91064, Training Acc : 0.594, Run Time : 0.48
INFO:root:2019-05-10 19:29:14, Epoch : 1, Step : 2241, Training Loss : 0.46855, Training Acc : 0.794, Run Time : 14.89
INFO:root:2019-05-10 19:29:14, Epoch : 1, Step : 2242, Training Loss : 0.37184, Training Acc : 0.822, Run Time : 0.61
INFO:root:2019-05-10 19:29:15, Epoch : 1, Step : 2243, Training Loss : 0.32876, Training Acc : 0.839, Run Time : 0.43
INFO:root:2019-05-10 19:29:15, Epoch : 1, Step : 2244, Training Loss : 0.33652, Training Acc : 0.856, Run Time : 0.31
INFO:root:2019-05-10 19:29:18, Epoch : 1, Step : 2245, Training Loss : 0.34758, Training Acc : 0.856, Run Time : 2.38
INFO:root:2019-05-10 19:29:32, Epoch : 1, Step : 2246, Training Loss : 0.41529, Training Acc : 0.789, Run Time : 14.22
INFO:root:2019-05-10 19:29:32, Epoch : 1, Step : 2247, Training Loss : 0.44131, Training Acc : 0.789, Run Time : 0.33
INFO:root:2019-05-10 19:29:33, Epoch : 1, Step : 2248, Training Loss : 0.48148, Training Acc : 0.844, Run Time : 0.51
INFO:root:2019-05-10 19:29:33, Epoch : 1, Step : 2249, Training Loss : 0.37945, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-10 19:29:34, Epoch : 1, Step : 2250, Training Loss : 0.39384, Training Acc : 0.828, Run Time : 0.48
INFO:root:2019-05-10 19:29:49, Epoch : 1, Step : 2251, Training Loss : 0.39066, Training Acc : 0.767, Run Time : 15.24
INFO:root:2019-05-10 19:29:50, Epoch : 1, Step : 2252, Training Loss : 0.35376, Training Acc : 0.839, Run Time : 0.91
INFO:root:2019-05-10 19:29:50, Epoch : 1, Step : 2253, Training Loss : 0.26509, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 19:29:51, Epoch : 1, Step : 2254, Training Loss : 0.35711, Training Acc : 0.817, Run Time : 0.49
INFO:root:2019-05-10 19:29:51, Epoch : 1, Step : 2255, Training Loss : 0.41072, Training Acc : 0.794, Run Time : 0.50
INFO:root:2019-05-10 19:29:55, Epoch : 1, Step : 2256, Training Loss : 0.48232, Training Acc : 0.711, Run Time : 4.18
INFO:root:2019-05-10 19:30:04, Epoch : 1, Step : 2257, Training Loss : 0.34935, Training Acc : 0.894, Run Time : 8.83
INFO:root:2019-05-10 19:30:07, Epoch : 1, Step : 2258, Training Loss : 0.39303, Training Acc : 0.817, Run Time : 3.17
INFO:root:2019-05-10 19:30:08, Epoch : 1, Step : 2259, Training Loss : 0.37807, Training Acc : 0.867, Run Time : 0.38
INFO:root:2019-05-10 19:30:08, Epoch : 1, Step : 2260, Training Loss : 0.31154, Training Acc : 0.889, Run Time : 0.49
INFO:root:2019-05-10 19:30:09, Epoch : 1, Step : 2261, Training Loss : 0.40036, Training Acc : 0.811, Run Time : 0.48
INFO:root:2019-05-10 19:30:09, Epoch : 1, Step : 2262, Training Loss : 0.48871, Training Acc : 0.678, Run Time : 0.56
INFO:root:2019-05-10 19:30:23, Epoch : 1, Step : 2263, Training Loss : 0.33694, Training Acc : 0.867, Run Time : 14.17
INFO:root:2019-05-10 19:30:24, Epoch : 1, Step : 2264, Training Loss : 0.30754, Training Acc : 0.872, Run Time : 0.43
INFO:root:2019-05-10 19:30:24, Epoch : 1, Step : 2265, Training Loss : 0.37951, Training Acc : 0.833, Run Time : 0.47
INFO:root:2019-05-10 19:30:25, Epoch : 1, Step : 2266, Training Loss : 0.44355, Training Acc : 0.811, Run Time : 0.76
INFO:root:2019-05-10 19:30:36, Epoch : 1, Step : 2267, Training Loss : 0.33468, Training Acc : 0.872, Run Time : 10.92
INFO:root:2019-05-10 19:30:37, Epoch : 1, Step : 2268, Training Loss : 0.38162, Training Acc : 0.833, Run Time : 0.61
INFO:root:2019-05-10 19:30:37, Epoch : 1, Step : 2269, Training Loss : 0.37716, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-10 19:30:38, Epoch : 1, Step : 2270, Training Loss : 0.32356, Training Acc : 0.867, Run Time : 0.50
INFO:root:2019-05-10 19:30:38, Epoch : 1, Step : 2271, Training Loss : 0.34882, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 19:30:52, Epoch : 1, Step : 2272, Training Loss : 0.30636, Training Acc : 0.867, Run Time : 13.81
INFO:root:2019-05-10 19:30:52, Epoch : 1, Step : 2273, Training Loss : 0.40073, Training Acc : 0.817, Run Time : 0.33
INFO:root:2019-05-10 19:30:53, Epoch : 1, Step : 2274, Training Loss : 0.33207, Training Acc : 0.867, Run Time : 0.50
INFO:root:2019-05-10 19:30:53, Epoch : 1, Step : 2275, Training Loss : 0.33841, Training Acc : 0.856, Run Time : 0.48
INFO:root:2019-05-10 19:30:54, Epoch : 1, Step : 2276, Training Loss : 0.32242, Training Acc : 0.850, Run Time : 0.49
INFO:root:2019-05-10 19:31:09, Epoch : 1, Step : 2277, Training Loss : 0.34388, Training Acc : 0.850, Run Time : 15.72
INFO:root:2019-05-10 19:31:10, Epoch : 1, Step : 2278, Training Loss : 0.30167, Training Acc : 0.867, Run Time : 0.25
INFO:root:2019-05-10 19:31:10, Epoch : 1, Step : 2279, Training Loss : 0.29633, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-10 19:31:11, Epoch : 1, Step : 2280, Training Loss : 0.25789, Training Acc : 0.917, Run Time : 0.50
INFO:root:2019-05-10 19:31:11, Epoch : 1, Step : 2281, Training Loss : 0.24198, Training Acc : 0.917, Run Time : 0.49
INFO:root:2019-05-10 19:31:27, Epoch : 1, Step : 2282, Training Loss : 0.34986, Training Acc : 0.828, Run Time : 15.37
INFO:root:2019-05-10 19:31:27, Epoch : 1, Step : 2283, Training Loss : 0.31043, Training Acc : 0.844, Run Time : 0.53
INFO:root:2019-05-10 19:31:28, Epoch : 1, Step : 2284, Training Loss : 0.26093, Training Acc : 0.906, Run Time : 0.54
INFO:root:2019-05-10 19:31:29, Epoch : 1, Step : 2285, Training Loss : 0.24786, Training Acc : 0.906, Run Time : 0.92
INFO:root:2019-05-10 19:31:30, Epoch : 1, Step : 2286, Training Loss : 0.25810, Training Acc : 0.917, Run Time : 1.72
INFO:root:2019-05-10 19:31:42, Epoch : 1, Step : 2287, Training Loss : 0.23468, Training Acc : 0.872, Run Time : 11.90
INFO:root:2019-05-10 19:31:43, Epoch : 1, Step : 2288, Training Loss : 0.27495, Training Acc : 0.878, Run Time : 0.71
INFO:root:2019-05-10 19:31:56, Epoch : 1, Step : 2289, Training Loss : 0.27892, Training Acc : 0.872, Run Time : 13.04
INFO:root:2019-05-10 19:31:56, Epoch : 1, Step : 2290, Training Loss : 0.26790, Training Acc : 0.900, Run Time : 0.55
INFO:root:2019-05-10 19:31:57, Epoch : 1, Step : 2291, Training Loss : 0.26430, Training Acc : 0.867, Run Time : 0.83
INFO:root:2019-05-10 19:31:58, Epoch : 1, Step : 2292, Training Loss : 0.23830, Training Acc : 0.889, Run Time : 0.52
INFO:root:2019-05-10 19:32:08, Epoch : 1, Step : 2293, Training Loss : 0.28035, Training Acc : 0.872, Run Time : 9.90
INFO:root:2019-05-10 19:32:09, Epoch : 1, Step : 2294, Training Loss : 0.36397, Training Acc : 0.828, Run Time : 0.91
INFO:root:2019-05-10 19:32:09, Epoch : 1, Step : 2295, Training Loss : 0.46406, Training Acc : 0.772, Run Time : 0.49
INFO:root:2019-05-10 19:32:10, Epoch : 1, Step : 2296, Training Loss : 0.40767, Training Acc : 0.800, Run Time : 0.49
INFO:root:2019-05-10 19:32:10, Epoch : 1, Step : 2297, Training Loss : 0.29395, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 19:32:13, Epoch : 1, Step : 2298, Training Loss : 0.37281, Training Acc : 0.839, Run Time : 3.29
INFO:root:2019-05-10 19:32:14, Epoch : 1, Step : 2299, Training Loss : 0.23662, Training Acc : 0.883, Run Time : 1.06
INFO:root:2019-05-10 19:32:30, Epoch : 1, Step : 2300, Training Loss : 0.39088, Training Acc : 0.778, Run Time : 15.20
INFO:root:2019-05-10 19:32:30, Epoch : 1, Step : 2301, Training Loss : 0.66209, Training Acc : 0.722, Run Time : 0.69
INFO:root:2019-05-10 19:32:31, Epoch : 1, Step : 2302, Training Loss : 0.45922, Training Acc : 0.822, Run Time : 0.49
INFO:root:2019-05-10 19:32:31, Epoch : 1, Step : 2303, Training Loss : 0.41895, Training Acc : 0.806, Run Time : 0.55
INFO:root:2019-05-10 19:32:33, Epoch : 1, Step : 2304, Training Loss : 0.51789, Training Acc : 0.794, Run Time : 1.38
INFO:root:2019-05-10 19:32:47, Epoch : 1, Step : 2305, Training Loss : 0.38222, Training Acc : 0.806, Run Time : 14.17
INFO:root:2019-05-10 19:32:47, Epoch : 1, Step : 2306, Training Loss : 0.28049, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-10 19:32:48, Epoch : 1, Step : 2307, Training Loss : 0.28913, Training Acc : 0.883, Run Time : 0.61
INFO:root:2019-05-10 19:32:59, Epoch : 1, Step : 2308, Training Loss : 0.33281, Training Acc : 0.839, Run Time : 10.62
INFO:root:2019-05-10 19:33:02, Epoch : 1, Step : 2309, Training Loss : 0.32334, Training Acc : 0.844, Run Time : 3.10
INFO:root:2019-05-10 19:33:02, Epoch : 1, Step : 2310, Training Loss : 0.29327, Training Acc : 0.872, Run Time : 0.30
INFO:root:2019-05-10 19:33:02, Epoch : 1, Step : 2311, Training Loss : 0.39076, Training Acc : 0.822, Run Time : 0.30
INFO:root:2019-05-10 19:33:03, Epoch : 1, Step : 2312, Training Loss : 0.34432, Training Acc : 0.856, Run Time : 0.51
INFO:root:2019-05-10 19:33:03, Epoch : 1, Step : 2313, Training Loss : 0.31146, Training Acc : 0.872, Run Time : 0.49
INFO:root:2019-05-10 19:33:19, Epoch : 1, Step : 2314, Training Loss : 0.34420, Training Acc : 0.839, Run Time : 15.85
INFO:root:2019-05-10 19:33:19, Epoch : 1, Step : 2315, Training Loss : 0.21900, Training Acc : 0.917, Run Time : 0.25
INFO:root:2019-05-10 19:33:20, Epoch : 1, Step : 2316, Training Loss : 0.27492, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-10 19:33:20, Epoch : 1, Step : 2317, Training Loss : 0.25784, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-10 19:33:21, Epoch : 1, Step : 2318, Training Loss : 0.61716, Training Acc : 0.722, Run Time : 0.48
INFO:root:2019-05-10 19:33:36, Epoch : 1, Step : 2319, Training Loss : 0.74967, Training Acc : 0.644, Run Time : 15.21
INFO:root:2019-05-10 19:33:36, Epoch : 1, Step : 2320, Training Loss : 0.49616, Training Acc : 0.761, Run Time : 0.24
INFO:root:2019-05-10 19:33:36, Epoch : 1, Step : 2321, Training Loss : 0.40869, Training Acc : 0.833, Run Time : 0.26
INFO:root:2019-05-10 19:33:37, Epoch : 1, Step : 2322, Training Loss : 0.55741, Training Acc : 0.733, Run Time : 0.47
INFO:root:2019-05-10 19:33:37, Epoch : 1, Step : 2323, Training Loss : 0.37742, Training Acc : 0.811, Run Time : 0.45
INFO:root:2019-05-10 19:33:43, Epoch : 1, Step : 2324, Training Loss : 0.34410, Training Acc : 0.844, Run Time : 5.94
INFO:root:2019-05-10 19:33:44, Epoch : 1, Step : 2325, Training Loss : 0.30899, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-10 19:34:00, Epoch : 1, Step : 2326, Training Loss : 0.48680, Training Acc : 0.744, Run Time : 15.74
INFO:root:2019-05-10 19:34:00, Epoch : 1, Step : 2327, Training Loss : 0.28383, Training Acc : 0.872, Run Time : 0.33
INFO:root:2019-05-10 19:34:00, Epoch : 1, Step : 2328, Training Loss : 0.33392, Training Acc : 0.822, Run Time : 0.57
INFO:root:2019-05-10 19:34:01, Epoch : 1, Step : 2329, Training Loss : 0.36132, Training Acc : 0.839, Run Time : 0.73
INFO:root:2019-05-10 19:34:02, Epoch : 1, Step : 2330, Training Loss : 0.28835, Training Acc : 0.872, Run Time : 1.07
INFO:root:2019-05-10 19:34:14, Epoch : 1, Step : 2331, Training Loss : 0.24737, Training Acc : 0.906, Run Time : 12.19
INFO:root:2019-05-10 19:34:15, Epoch : 1, Step : 2332, Training Loss : 0.32737, Training Acc : 0.839, Run Time : 0.33
INFO:root:2019-05-10 19:34:25, Epoch : 1, Step : 2333, Training Loss : 0.18605, Training Acc : 0.933, Run Time : 10.30
INFO:root:2019-05-10 19:34:25, Epoch : 1, Step : 2334, Training Loss : 0.22829, Training Acc : 0.917, Run Time : 0.32
INFO:root:2019-05-10 19:34:33, Epoch : 1, Step : 2335, Training Loss : 0.27319, Training Acc : 0.850, Run Time : 7.45
INFO:root:2019-05-10 19:34:33, Epoch : 1, Step : 2336, Training Loss : 0.23881, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-10 19:34:34, Epoch : 1, Step : 2337, Training Loss : 0.26308, Training Acc : 0.894, Run Time : 0.51
INFO:root:2019-05-10 19:34:44, Epoch : 1, Step : 2338, Training Loss : 0.18132, Training Acc : 0.939, Run Time : 9.87
INFO:root:2019-05-10 19:34:44, Epoch : 1, Step : 2339, Training Loss : 0.14736, Training Acc : 0.944, Run Time : 0.53
INFO:root:2019-05-10 19:34:45, Epoch : 1, Step : 2340, Training Loss : 0.23991, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-10 19:34:45, Epoch : 1, Step : 2341, Training Loss : 0.24633, Training Acc : 0.900, Run Time : 0.48
INFO:root:2019-05-10 19:34:46, Epoch : 1, Step : 2342, Training Loss : 0.23280, Training Acc : 0.906, Run Time : 0.48
INFO:root:2019-05-10 19:34:59, Epoch : 1, Step : 2343, Training Loss : 0.20878, Training Acc : 0.906, Run Time : 13.90
INFO:root:2019-05-10 19:35:00, Epoch : 1, Step : 2344, Training Loss : 0.36755, Training Acc : 0.817, Run Time : 0.29
INFO:root:2019-05-10 19:35:00, Epoch : 1, Step : 2345, Training Loss : 0.50763, Training Acc : 0.767, Run Time : 0.51
INFO:root:2019-05-10 19:35:01, Epoch : 1, Step : 2346, Training Loss : 0.55169, Training Acc : 0.756, Run Time : 0.51
INFO:root:2019-05-10 19:35:11, Epoch : 1, Step : 2347, Training Loss : 0.59365, Training Acc : 0.750, Run Time : 10.59
INFO:root:2019-05-10 19:35:12, Epoch : 1, Step : 2348, Training Loss : 0.57476, Training Acc : 0.722, Run Time : 0.58
INFO:root:2019-05-10 19:35:13, Epoch : 1, Step : 2349, Training Loss : 0.37549, Training Acc : 0.817, Run Time : 0.77
INFO:root:2019-05-10 19:35:13, Epoch : 1, Step : 2350, Training Loss : 0.31149, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 19:35:14, Epoch : 1, Step : 2351, Training Loss : 0.37222, Training Acc : 0.828, Run Time : 0.38
INFO:root:2019-05-10 19:35:28, Epoch : 1, Step : 2352, Training Loss : 0.28509, Training Acc : 0.900, Run Time : 14.81
INFO:root:2019-05-10 19:35:29, Epoch : 1, Step : 2353, Training Loss : 0.50169, Training Acc : 0.756, Run Time : 0.22
INFO:root:2019-05-10 19:35:29, Epoch : 1, Step : 2354, Training Loss : 0.37733, Training Acc : 0.833, Run Time : 0.46
INFO:root:2019-05-10 19:35:30, Epoch : 1, Step : 2355, Training Loss : 0.34534, Training Acc : 0.828, Run Time : 0.51
INFO:root:2019-05-10 19:35:30, Epoch : 1, Step : 2356, Training Loss : 0.29245, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-10 19:35:43, Epoch : 1, Step : 2357, Training Loss : 0.39886, Training Acc : 0.822, Run Time : 12.63
INFO:root:2019-05-10 19:35:43, Epoch : 1, Step : 2358, Training Loss : 0.50785, Training Acc : 0.744, Run Time : 0.55
INFO:root:2019-05-10 19:35:44, Epoch : 1, Step : 2359, Training Loss : 0.56564, Training Acc : 0.717, Run Time : 0.46
INFO:root:2019-05-10 19:35:44, Epoch : 1, Step : 2360, Training Loss : 0.39587, Training Acc : 0.811, Run Time : 0.47
INFO:root:2019-05-10 19:35:45, Epoch : 1, Step : 2361, Training Loss : 0.51052, Training Acc : 0.772, Run Time : 0.60
INFO:root:2019-05-10 19:36:00, Epoch : 1, Step : 2362, Training Loss : 0.76965, Training Acc : 0.639, Run Time : 15.48
INFO:root:2019-05-10 19:36:01, Epoch : 1, Step : 2363, Training Loss : 0.46125, Training Acc : 0.750, Run Time : 0.33
INFO:root:2019-05-10 19:36:01, Epoch : 1, Step : 2364, Training Loss : 0.32407, Training Acc : 0.883, Run Time : 0.44
INFO:root:2019-05-10 19:36:12, Epoch : 1, Step : 2365, Training Loss : 0.46772, Training Acc : 0.744, Run Time : 11.33
INFO:root:2019-05-10 19:36:13, Epoch : 1, Step : 2366, Training Loss : 0.37544, Training Acc : 0.828, Run Time : 0.78
INFO:root:2019-05-10 19:36:14, Epoch : 1, Step : 2367, Training Loss : 0.25638, Training Acc : 0.939, Run Time : 0.51
INFO:root:2019-05-10 19:36:14, Epoch : 1, Step : 2368, Training Loss : 0.36790, Training Acc : 0.844, Run Time : 0.60
INFO:root:2019-05-10 19:36:15, Epoch : 1, Step : 2369, Training Loss : 0.33363, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-10 19:36:29, Epoch : 1, Step : 2370, Training Loss : 0.28074, Training Acc : 0.889, Run Time : 14.57
INFO:root:2019-05-10 19:36:30, Epoch : 1, Step : 2371, Training Loss : 0.22912, Training Acc : 0.933, Run Time : 0.37
INFO:root:2019-05-10 19:36:30, Epoch : 1, Step : 2372, Training Loss : 0.37743, Training Acc : 0.850, Run Time : 0.49
INFO:root:2019-05-10 19:36:31, Epoch : 1, Step : 2373, Training Loss : 0.28987, Training Acc : 0.889, Run Time : 1.34
INFO:root:2019-05-10 19:36:34, Epoch : 1, Step : 2374, Training Loss : 0.36596, Training Acc : 0.833, Run Time : 2.29
INFO:root:2019-05-10 19:36:34, Epoch : 1, Step : 2375, Training Loss : 0.33321, Training Acc : 0.839, Run Time : 0.51
INFO:root:2019-05-10 19:36:36, Epoch : 1, Step : 2376, Training Loss : 0.32541, Training Acc : 0.872, Run Time : 2.13
INFO:root:2019-05-10 19:36:53, Epoch : 1, Step : 2377, Training Loss : 0.28842, Training Acc : 0.922, Run Time : 16.92
INFO:root:2019-05-10 19:36:54, Epoch : 1, Step : 2378, Training Loss : 0.40425, Training Acc : 0.867, Run Time : 0.38
INFO:root:2019-05-10 19:36:54, Epoch : 1, Step : 2379, Training Loss : 0.35718, Training Acc : 0.828, Run Time : 0.38
INFO:root:2019-05-10 19:36:54, Epoch : 1, Step : 2380, Training Loss : 0.30908, Training Acc : 0.872, Run Time : 0.42
INFO:root:2019-05-10 19:36:55, Epoch : 1, Step : 2381, Training Loss : 0.26660, Training Acc : 0.878, Run Time : 0.50
INFO:root:2019-05-10 19:37:11, Epoch : 1, Step : 2382, Training Loss : 0.23550, Training Acc : 0.894, Run Time : 15.55
INFO:root:2019-05-10 19:37:11, Epoch : 1, Step : 2383, Training Loss : 0.30931, Training Acc : 0.861, Run Time : 0.31
INFO:root:2019-05-10 19:37:11, Epoch : 1, Step : 2384, Training Loss : 0.34112, Training Acc : 0.822, Run Time : 0.56
INFO:root:2019-05-10 19:37:12, Epoch : 1, Step : 2385, Training Loss : 0.28770, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-10 19:37:12, Epoch : 1, Step : 2386, Training Loss : 0.41541, Training Acc : 0.800, Run Time : 0.35
INFO:root:2019-05-10 19:37:27, Epoch : 1, Step : 2387, Training Loss : 0.43736, Training Acc : 0.800, Run Time : 15.25
INFO:root:2019-05-10 19:37:28, Epoch : 1, Step : 2388, Training Loss : 0.40837, Training Acc : 0.789, Run Time : 0.26
INFO:root:2019-05-10 19:37:28, Epoch : 1, Step : 2389, Training Loss : 0.41618, Training Acc : 0.778, Run Time : 0.43
INFO:root:2019-05-10 19:37:29, Epoch : 1, Step : 2390, Training Loss : 0.34833, Training Acc : 0.844, Run Time : 0.48
INFO:root:2019-05-10 19:37:29, Epoch : 1, Step : 2391, Training Loss : 0.32947, Training Acc : 0.828, Run Time : 0.42
INFO:root:2019-05-10 19:37:44, Epoch : 1, Step : 2392, Training Loss : 0.35303, Training Acc : 0.794, Run Time : 14.79
INFO:root:2019-05-10 19:37:44, Epoch : 1, Step : 2393, Training Loss : 0.37277, Training Acc : 0.817, Run Time : 0.33
INFO:root:2019-05-10 19:37:45, Epoch : 1, Step : 2394, Training Loss : 0.35634, Training Acc : 0.833, Run Time : 0.46
INFO:root:2019-05-10 19:37:45, Epoch : 1, Step : 2395, Training Loss : 0.35226, Training Acc : 0.789, Run Time : 0.57
INFO:root:2019-05-10 19:37:47, Epoch : 1, Step : 2396, Training Loss : 0.29628, Training Acc : 0.839, Run Time : 1.87
INFO:root:2019-05-10 19:38:00, Epoch : 1, Step : 2397, Training Loss : 0.32087, Training Acc : 0.844, Run Time : 13.01
INFO:root:2019-05-10 19:38:00, Epoch : 1, Step : 2398, Training Loss : 0.27302, Training Acc : 0.872, Run Time : 0.32
INFO:root:2019-05-10 19:38:01, Epoch : 1, Step : 2399, Training Loss : 0.25895, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-10 19:38:01, Epoch : 1, Step : 2400, Training Loss : 0.23688, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-10 19:38:02, Epoch : 1, Step : 2401, Training Loss : 0.24945, Training Acc : 0.856, Run Time : 0.92
INFO:root:2019-05-10 19:38:17, Epoch : 1, Step : 2402, Training Loss : 0.25987, Training Acc : 0.872, Run Time : 15.06
INFO:root:2019-05-10 19:38:17, Epoch : 1, Step : 2403, Training Loss : 0.25696, Training Acc : 0.900, Run Time : 0.23
INFO:root:2019-05-10 19:38:18, Epoch : 1, Step : 2404, Training Loss : 0.30254, Training Acc : 0.822, Run Time : 0.46
INFO:root:2019-05-10 19:38:18, Epoch : 1, Step : 2405, Training Loss : 0.40023, Training Acc : 0.833, Run Time : 0.50
INFO:root:2019-05-10 19:38:31, Epoch : 1, Step : 2406, Training Loss : 0.36580, Training Acc : 0.839, Run Time : 12.42
INFO:root:2019-05-10 19:38:31, Epoch : 1, Step : 2407, Training Loss : 0.49116, Training Acc : 0.789, Run Time : 0.58
INFO:root:2019-05-10 19:38:32, Epoch : 1, Step : 2408, Training Loss : 0.43904, Training Acc : 0.811, Run Time : 0.44
INFO:root:2019-05-10 19:38:33, Epoch : 1, Step : 2409, Training Loss : 0.42147, Training Acc : 0.806, Run Time : 1.59
INFO:root:2019-05-10 19:38:34, Epoch : 1, Step : 2410, Training Loss : 0.35142, Training Acc : 0.794, Run Time : 1.05
INFO:root:2019-05-10 19:38:48, Epoch : 1, Step : 2411, Training Loss : 0.57620, Training Acc : 0.733, Run Time : 13.61
INFO:root:2019-05-10 19:38:48, Epoch : 1, Step : 2412, Training Loss : 0.36350, Training Acc : 0.850, Run Time : 0.24
INFO:root:2019-05-10 19:38:48, Epoch : 1, Step : 2413, Training Loss : 0.37153, Training Acc : 0.811, Run Time : 0.22
INFO:root:2019-05-10 19:38:49, Epoch : 1, Step : 2414, Training Loss : 0.34251, Training Acc : 0.878, Run Time : 0.46
INFO:root:2019-05-10 19:38:49, Epoch : 1, Step : 2415, Training Loss : 0.47455, Training Acc : 0.772, Run Time : 0.49
INFO:root:2019-05-10 19:38:54, Epoch : 1, Step : 2416, Training Loss : 0.26088, Training Acc : 0.911, Run Time : 4.36
INFO:root:2019-05-10 19:38:54, Epoch : 1, Step : 2417, Training Loss : 0.35520, Training Acc : 0.867, Run Time : 0.52
INFO:root:2019-05-10 19:39:10, Epoch : 1, Step : 2418, Training Loss : 0.26138, Training Acc : 0.878, Run Time : 15.45
INFO:root:2019-05-10 19:39:10, Epoch : 1, Step : 2419, Training Loss : 0.37926, Training Acc : 0.844, Run Time : 0.38
INFO:root:2019-05-10 19:39:11, Epoch : 1, Step : 2420, Training Loss : 0.24520, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-10 19:39:11, Epoch : 1, Step : 2421, Training Loss : 0.33083, Training Acc : 0.856, Run Time : 0.48
INFO:root:2019-05-10 19:39:12, Epoch : 1, Step : 2422, Training Loss : 0.34049, Training Acc : 0.867, Run Time : 0.71
INFO:root:2019-05-10 19:39:27, Epoch : 1, Step : 2423, Training Loss : 0.28440, Training Acc : 0.856, Run Time : 15.59
INFO:root:2019-05-10 19:39:28, Epoch : 1, Step : 2424, Training Loss : 0.33626, Training Acc : 0.878, Run Time : 0.23
INFO:root:2019-05-10 19:39:28, Epoch : 1, Step : 2425, Training Loss : 0.35339, Training Acc : 0.850, Run Time : 0.21
INFO:root:2019-05-10 19:39:28, Epoch : 1, Step : 2426, Training Loss : 0.22325, Training Acc : 0.911, Run Time : 0.28
INFO:root:2019-05-10 19:39:29, Epoch : 1, Step : 2427, Training Loss : 0.15231, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-10 19:39:48, Epoch : 1, Step : 2428, Training Loss : 0.37230, Training Acc : 0.844, Run Time : 18.98
INFO:root:2019-05-10 19:39:48, Epoch : 1, Step : 2429, Training Loss : 0.23137, Training Acc : 0.906, Run Time : 0.57
INFO:root:2019-05-10 19:39:49, Epoch : 1, Step : 2430, Training Loss : 0.16487, Training Acc : 0.944, Run Time : 0.51
INFO:root:2019-05-10 19:39:57, Epoch : 1, Step : 2431, Training Loss : 0.32817, Training Acc : 0.894, Run Time : 8.33
INFO:root:2019-05-10 19:39:59, Epoch : 1, Step : 2432, Training Loss : 0.19155, Training Acc : 0.933, Run Time : 2.20
INFO:root:2019-05-10 19:40:00, Epoch : 1, Step : 2433, Training Loss : 0.26384, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 19:40:00, Epoch : 1, Step : 2434, Training Loss : 0.22044, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 19:40:01, Epoch : 1, Step : 2435, Training Loss : 0.21209, Training Acc : 0.933, Run Time : 0.50
INFO:root:2019-05-10 19:40:03, Epoch : 1, Step : 2436, Training Loss : 0.20769, Training Acc : 0.900, Run Time : 1.94
INFO:root:2019-05-10 19:40:04, Epoch : 1, Step : 2437, Training Loss : 0.22733, Training Acc : 0.911, Run Time : 1.72
INFO:root:2019-05-10 19:40:19, Epoch : 1, Step : 2438, Training Loss : 0.33783, Training Acc : 0.844, Run Time : 14.62
INFO:root:2019-05-10 19:40:19, Epoch : 1, Step : 2439, Training Loss : 0.16561, Training Acc : 0.933, Run Time : 0.22
INFO:root:2019-05-10 19:40:19, Epoch : 1, Step : 2440, Training Loss : 0.31542, Training Acc : 0.839, Run Time : 0.34
INFO:root:2019-05-10 19:40:20, Epoch : 1, Step : 2441, Training Loss : 0.28778, Training Acc : 0.878, Run Time : 0.49
INFO:root:2019-05-10 19:40:20, Epoch : 1, Step : 2442, Training Loss : 0.31788, Training Acc : 0.878, Run Time : 0.49
INFO:root:2019-05-10 19:40:37, Epoch : 1, Step : 2443, Training Loss : 0.24454, Training Acc : 0.889, Run Time : 16.85
INFO:root:2019-05-10 19:40:38, Epoch : 1, Step : 2444, Training Loss : 0.34367, Training Acc : 0.844, Run Time : 0.24
INFO:root:2019-05-10 19:40:38, Epoch : 1, Step : 2445, Training Loss : 0.29668, Training Acc : 0.878, Run Time : 0.49
INFO:root:2019-05-10 19:40:41, Epoch : 1, Step : 2446, Training Loss : 0.25926, Training Acc : 0.872, Run Time : 2.48
INFO:root:2019-05-10 19:40:48, Epoch : 1, Step : 2447, Training Loss : 0.23372, Training Acc : 0.917, Run Time : 7.97
INFO:root:2019-05-10 19:40:49, Epoch : 1, Step : 2448, Training Loss : 0.51135, Training Acc : 0.794, Run Time : 0.25
INFO:root:2019-05-10 19:40:49, Epoch : 1, Step : 2449, Training Loss : 0.47599, Training Acc : 0.794, Run Time : 0.49
INFO:root:2019-05-10 19:40:50, Epoch : 1, Step : 2450, Training Loss : 0.25229, Training Acc : 0.894, Run Time : 0.50
INFO:root:2019-05-10 19:40:50, Epoch : 1, Step : 2451, Training Loss : 0.27698, Training Acc : 0.872, Run Time : 0.45
INFO:root:2019-05-10 19:41:04, Epoch : 1, Step : 2452, Training Loss : 0.20229, Training Acc : 0.922, Run Time : 13.85
INFO:root:2019-05-10 19:41:05, Epoch : 1, Step : 2453, Training Loss : 0.24030, Training Acc : 0.878, Run Time : 0.80
INFO:root:2019-05-10 19:41:05, Epoch : 1, Step : 2454, Training Loss : 0.24794, Training Acc : 0.917, Run Time : 0.35
INFO:root:2019-05-10 19:41:06, Epoch : 1, Step : 2455, Training Loss : 0.24066, Training Acc : 0.911, Run Time : 0.49
INFO:root:2019-05-10 19:41:19, Epoch : 1, Step : 2456, Training Loss : 0.33177, Training Acc : 0.883, Run Time : 12.97
INFO:root:2019-05-10 19:41:19, Epoch : 1, Step : 2457, Training Loss : 0.27141, Training Acc : 0.883, Run Time : 0.23
INFO:root:2019-05-10 19:41:19, Epoch : 1, Step : 2458, Training Loss : 0.23483, Training Acc : 0.878, Run Time : 0.33
INFO:root:2019-05-10 19:41:20, Epoch : 1, Step : 2459, Training Loss : 0.27244, Training Acc : 0.878, Run Time : 0.45
INFO:root:2019-05-10 19:41:20, Epoch : 1, Step : 2460, Training Loss : 0.22928, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-10 19:41:37, Epoch : 1, Step : 2461, Training Loss : 0.61431, Training Acc : 0.694, Run Time : 16.57
INFO:root:2019-05-10 19:41:37, Epoch : 1, Step : 2462, Training Loss : 1.71201, Training Acc : 0.506, Run Time : 0.26
INFO:root:2019-05-10 19:41:37, Epoch : 1, Step : 2463, Training Loss : 1.37525, Training Acc : 0.533, Run Time : 0.56
INFO:root:2019-05-10 19:41:38, Epoch : 1, Step : 2464, Training Loss : 0.71347, Training Acc : 0.633, Run Time : 0.51
INFO:root:2019-05-10 19:41:38, Epoch : 1, Step : 2465, Training Loss : 0.65627, Training Acc : 0.767, Run Time : 0.49
INFO:root:2019-05-10 19:41:56, Epoch : 1, Step : 2466, Training Loss : 0.44783, Training Acc : 0.867, Run Time : 17.42
INFO:root:2019-05-10 19:41:57, Epoch : 1, Step : 2467, Training Loss : 0.36373, Training Acc : 0.889, Run Time : 0.96
INFO:root:2019-05-10 19:41:57, Epoch : 1, Step : 2468, Training Loss : 0.28926, Training Acc : 0.867, Run Time : 0.62
INFO:root:2019-05-10 19:41:58, Epoch : 1, Step : 2469, Training Loss : 0.33978, Training Acc : 0.822, Run Time : 0.49
INFO:root:2019-05-10 19:41:58, Epoch : 1, Step : 2470, Training Loss : 0.20543, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-10 19:42:10, Epoch : 1, Step : 2471, Training Loss : 0.23868, Training Acc : 0.922, Run Time : 12.00
INFO:root:2019-05-10 19:42:12, Epoch : 1, Step : 2472, Training Loss : 0.19950, Training Acc : 0.928, Run Time : 1.12
INFO:root:2019-05-10 19:42:12, Epoch : 1, Step : 2473, Training Loss : 0.43945, Training Acc : 0.839, Run Time : 0.59
INFO:root:2019-05-10 19:42:13, Epoch : 1, Step : 2474, Training Loss : 0.24222, Training Acc : 0.922, Run Time : 0.58
INFO:root:2019-05-10 19:42:13, Epoch : 1, Step : 2475, Training Loss : 0.35981, Training Acc : 0.878, Run Time : 0.51
INFO:root:2019-05-10 19:42:29, Epoch : 1, Step : 2476, Training Loss : 0.30510, Training Acc : 0.906, Run Time : 15.31
INFO:root:2019-05-10 19:42:29, Epoch : 1, Step : 2477, Training Loss : 0.39317, Training Acc : 0.833, Run Time : 0.29
INFO:root:2019-05-10 19:42:29, Epoch : 1, Step : 2478, Training Loss : 0.26826, Training Acc : 0.878, Run Time : 0.43
INFO:root:2019-05-10 19:42:30, Epoch : 1, Step : 2479, Training Loss : 0.24951, Training Acc : 0.900, Run Time : 0.49
INFO:root:2019-05-10 19:42:30, Epoch : 1, Step : 2480, Training Loss : 0.37002, Training Acc : 0.828, Run Time : 0.47
INFO:root:2019-05-10 19:42:44, Epoch : 1, Step : 2481, Training Loss : 0.23914, Training Acc : 0.917, Run Time : 13.35
INFO:root:2019-05-10 19:42:44, Epoch : 1, Step : 2482, Training Loss : 0.27747, Training Acc : 0.883, Run Time : 0.66
INFO:root:2019-05-10 19:42:45, Epoch : 1, Step : 2483, Training Loss : 0.24759, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-10 19:42:45, Epoch : 1, Step : 2484, Training Loss : 0.20125, Training Acc : 0.928, Run Time : 0.69
INFO:root:2019-05-10 19:42:47, Epoch : 1, Step : 2485, Training Loss : 0.34646, Training Acc : 0.856, Run Time : 1.61
INFO:root:2019-05-10 19:43:01, Epoch : 1, Step : 2486, Training Loss : 0.31034, Training Acc : 0.844, Run Time : 14.34
INFO:root:2019-05-10 19:43:02, Epoch : 1, Step : 2487, Training Loss : 1.08622, Training Acc : 0.589, Run Time : 0.32
INFO:root:2019-05-10 19:43:03, Epoch : 1, Step : 2488, Training Loss : 0.59820, Training Acc : 0.733, Run Time : 0.88
INFO:root:2019-05-10 19:43:13, Epoch : 1, Step : 2489, Training Loss : 0.66200, Training Acc : 0.700, Run Time : 10.51
INFO:root:2019-05-10 19:43:14, Epoch : 1, Step : 2490, Training Loss : 0.42720, Training Acc : 0.761, Run Time : 0.49
INFO:root:2019-05-10 19:43:14, Epoch : 1, Step : 2491, Training Loss : 0.27503, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 19:43:14, Epoch : 1, Step : 2492, Training Loss : 0.36963, Training Acc : 0.822, Run Time : 0.45
INFO:root:2019-05-10 19:43:15, Epoch : 1, Step : 2493, Training Loss : 0.31640, Training Acc : 0.883, Run Time : 0.68
INFO:root:2019-05-10 19:43:29, Epoch : 1, Step : 2494, Training Loss : 0.36657, Training Acc : 0.817, Run Time : 14.17
INFO:root:2019-05-10 19:43:30, Epoch : 1, Step : 2495, Training Loss : 0.38447, Training Acc : 0.806, Run Time : 0.26
INFO:root:2019-05-10 19:43:30, Epoch : 1, Step : 2496, Training Loss : 0.55000, Training Acc : 0.789, Run Time : 0.41
INFO:root:2019-05-10 19:43:41, Epoch : 1, Step : 2497, Training Loss : 0.31953, Training Acc : 0.889, Run Time : 10.63
INFO:root:2019-05-10 19:43:42, Epoch : 1, Step : 2498, Training Loss : 0.34372, Training Acc : 0.833, Run Time : 0.92
INFO:root:2019-05-10 19:43:42, Epoch : 1, Step : 2499, Training Loss : 0.27038, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-10 19:43:42, Epoch : 1, Step : 2500, Training Loss : 0.27033, Training Acc : 0.889, Run Time : 0.49
INFO:root:2019-05-10 19:43:43, Epoch : 1, Step : 2501, Training Loss : 0.25776, Training Acc : 0.861, Run Time : 0.93
INFO:root:2019-05-10 19:43:59, Epoch : 1, Step : 2502, Training Loss : 0.32368, Training Acc : 0.828, Run Time : 15.49
INFO:root:2019-05-10 19:43:59, Epoch : 1, Step : 2503, Training Loss : 0.24646, Training Acc : 0.900, Run Time : 0.23
INFO:root:2019-05-10 19:44:00, Epoch : 1, Step : 2504, Training Loss : 0.22220, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 19:44:01, Epoch : 1, Step : 2505, Training Loss : 0.20429, Training Acc : 0.911, Run Time : 1.47
INFO:root:2019-05-10 19:44:12, Epoch : 1, Step : 2506, Training Loss : 0.18875, Training Acc : 0.944, Run Time : 11.32
INFO:root:2019-05-10 19:44:13, Epoch : 1, Step : 2507, Training Loss : 0.21827, Training Acc : 0.922, Run Time : 0.73
INFO:root:2019-05-10 19:44:14, Epoch : 1, Step : 2508, Training Loss : 0.32190, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 19:44:14, Epoch : 1, Step : 2509, Training Loss : 0.32507, Training Acc : 0.861, Run Time : 0.50
INFO:root:2019-05-10 19:44:27, Epoch : 1, Step : 2510, Training Loss : 0.44420, Training Acc : 0.750, Run Time : 13.08
INFO:root:2019-05-10 19:44:28, Epoch : 1, Step : 2511, Training Loss : 0.31362, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 19:44:28, Epoch : 1, Step : 2512, Training Loss : 0.23044, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-10 19:44:29, Epoch : 1, Step : 2513, Training Loss : 0.33650, Training Acc : 0.839, Run Time : 0.50
INFO:root:2019-05-10 19:44:29, Epoch : 1, Step : 2514, Training Loss : 0.12780, Training Acc : 0.972, Run Time : 0.49
INFO:root:2019-05-10 19:44:44, Epoch : 1, Step : 2515, Training Loss : 0.32251, Training Acc : 0.883, Run Time : 15.22
INFO:root:2019-05-10 19:44:45, Epoch : 1, Step : 2516, Training Loss : 0.20488, Training Acc : 0.933, Run Time : 0.32
INFO:root:2019-05-10 19:44:45, Epoch : 1, Step : 2517, Training Loss : 0.26360, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-10 19:44:46, Epoch : 1, Step : 2518, Training Loss : 0.23392, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-10 19:44:56, Epoch : 1, Step : 2519, Training Loss : 0.15176, Training Acc : 0.967, Run Time : 10.71
INFO:root:2019-05-10 19:44:57, Epoch : 1, Step : 2520, Training Loss : 0.27657, Training Acc : 0.844, Run Time : 0.49
INFO:root:2019-05-10 19:44:57, Epoch : 1, Step : 2521, Training Loss : 0.25729, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-10 19:44:58, Epoch : 1, Step : 2522, Training Loss : 0.17844, Training Acc : 0.939, Run Time : 0.49
INFO:root:2019-05-10 19:44:58, Epoch : 1, Step : 2523, Training Loss : 0.18196, Training Acc : 0.944, Run Time : 0.51
INFO:root:2019-05-10 19:45:13, Epoch : 1, Step : 2524, Training Loss : 0.20252, Training Acc : 0.922, Run Time : 15.15
INFO:root:2019-05-10 19:45:14, Epoch : 1, Step : 2525, Training Loss : 0.20021, Training Acc : 0.933, Run Time : 0.28
INFO:root:2019-05-10 19:45:14, Epoch : 1, Step : 2526, Training Loss : 0.19528, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 19:45:15, Epoch : 1, Step : 2527, Training Loss : 0.27025, Training Acc : 0.878, Run Time : 0.49
INFO:root:2019-05-10 19:45:15, Epoch : 1, Step : 2528, Training Loss : 0.18165, Training Acc : 0.933, Run Time : 0.50
INFO:root:2019-05-10 19:45:30, Epoch : 1, Step : 2529, Training Loss : 0.26779, Training Acc : 0.878, Run Time : 14.95
INFO:root:2019-05-10 19:45:30, Epoch : 1, Step : 2530, Training Loss : 0.16409, Training Acc : 0.944, Run Time : 0.33
INFO:root:2019-05-10 19:45:31, Epoch : 1, Step : 2531, Training Loss : 0.18194, Training Acc : 0.928, Run Time : 0.49
INFO:root:2019-05-10 19:45:31, Epoch : 1, Step : 2532, Training Loss : 0.20234, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 19:45:32, Epoch : 1, Step : 2533, Training Loss : 0.11572, Training Acc : 0.972, Run Time : 0.48
INFO:root:2019-05-10 19:45:48, Epoch : 1, Step : 2534, Training Loss : 0.17222, Training Acc : 0.906, Run Time : 16.19
INFO:root:2019-05-10 19:45:48, Epoch : 1, Step : 2535, Training Loss : 0.12044, Training Acc : 0.967, Run Time : 0.25
INFO:root:2019-05-10 19:45:49, Epoch : 1, Step : 2536, Training Loss : 0.16991, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-10 19:45:50, Epoch : 1, Step : 2537, Training Loss : 0.14246, Training Acc : 0.939, Run Time : 1.20
INFO:root:2019-05-10 19:46:02, Epoch : 1, Step : 2538, Training Loss : 0.14401, Training Acc : 0.944, Run Time : 11.88
INFO:root:2019-05-10 19:46:02, Epoch : 1, Step : 2539, Training Loss : 0.13181, Training Acc : 0.961, Run Time : 0.62
INFO:root:2019-05-10 19:46:03, Epoch : 1, Step : 2540, Training Loss : 0.18089, Training Acc : 0.939, Run Time : 0.47
INFO:root:2019-05-10 19:46:03, Epoch : 1, Step : 2541, Training Loss : 0.16105, Training Acc : 0.922, Run Time : 0.50
INFO:root:2019-05-10 19:46:04, Epoch : 1, Step : 2542, Training Loss : 0.15892, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-10 19:46:26, Epoch : 1, Step : 2543, Training Loss : 0.27474, Training Acc : 0.850, Run Time : 21.84
INFO:root:2019-05-10 19:46:26, Epoch : 1, Step : 2544, Training Loss : 0.16925, Training Acc : 0.950, Run Time : 0.62
INFO:root:2019-05-10 19:46:27, Epoch : 1, Step : 2545, Training Loss : 0.20567, Training Acc : 0.900, Run Time : 0.45
INFO:root:2019-05-10 19:46:27, Epoch : 1, Step : 2546, Training Loss : 0.23238, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 19:46:28, Epoch : 1, Step : 2547, Training Loss : 0.19504, Training Acc : 0.917, Run Time : 0.49
INFO:root:2019-05-10 19:46:43, Epoch : 1, Step : 2548, Training Loss : 0.28482, Training Acc : 0.856, Run Time : 15.07
INFO:root:2019-05-10 19:46:43, Epoch : 1, Step : 2549, Training Loss : 0.22215, Training Acc : 0.894, Run Time : 0.50
INFO:root:2019-05-10 19:46:44, Epoch : 1, Step : 2550, Training Loss : 0.16968, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 19:46:44, Epoch : 1, Step : 2551, Training Loss : 0.13159, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-10 19:46:56, Epoch : 1, Step : 2552, Training Loss : 0.15801, Training Acc : 0.928, Run Time : 11.42
INFO:root:2019-05-10 19:46:56, Epoch : 1, Step : 2553, Training Loss : 0.26672, Training Acc : 0.911, Run Time : 0.42
INFO:root:2019-05-10 19:46:56, Epoch : 1, Step : 2554, Training Loss : 0.17112, Training Acc : 0.933, Run Time : 0.37
INFO:root:2019-05-10 19:46:57, Epoch : 1, Step : 2555, Training Loss : 0.29153, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 19:47:09, Epoch : 1, Step : 2556, Training Loss : 0.37861, Training Acc : 0.872, Run Time : 12.29
INFO:root:2019-05-10 19:47:10, Epoch : 1, Step : 2557, Training Loss : 0.19848, Training Acc : 0.917, Run Time : 0.49
INFO:root:2019-05-10 19:47:10, Epoch : 1, Step : 2558, Training Loss : 0.24152, Training Acc : 0.889, Run Time : 0.59
INFO:root:2019-05-10 19:47:11, Epoch : 1, Step : 2559, Training Loss : 0.21657, Training Acc : 0.894, Run Time : 0.59
INFO:root:2019-05-10 19:47:11, Epoch : 1, Step : 2560, Training Loss : 0.25574, Training Acc : 0.872, Run Time : 0.43
INFO:root:2019-05-10 19:47:27, Epoch : 1, Step : 2561, Training Loss : 0.19870, Training Acc : 0.939, Run Time : 15.89
INFO:root:2019-05-10 19:47:28, Epoch : 1, Step : 2562, Training Loss : 0.20728, Training Acc : 0.928, Run Time : 0.88
INFO:root:2019-05-10 19:47:29, Epoch : 1, Step : 2563, Training Loss : 0.29550, Training Acc : 0.883, Run Time : 0.50
INFO:root:2019-05-10 19:47:29, Epoch : 1, Step : 2564, Training Loss : 0.17763, Training Acc : 0.928, Run Time : 0.84
INFO:root:2019-05-10 19:47:37, Epoch : 1, Step : 2565, Training Loss : 0.23413, Training Acc : 0.883, Run Time : 7.50
INFO:root:2019-05-10 19:47:38, Epoch : 1, Step : 2566, Training Loss : 0.19828, Training Acc : 0.906, Run Time : 0.60
INFO:root:2019-05-10 19:47:38, Epoch : 1, Step : 2567, Training Loss : 0.17066, Training Acc : 0.950, Run Time : 0.44
INFO:root:2019-05-10 19:47:39, Epoch : 1, Step : 2568, Training Loss : 0.21904, Training Acc : 0.894, Run Time : 1.52
INFO:root:2019-05-10 19:47:40, Epoch : 1, Step : 2569, Training Loss : 0.17472, Training Acc : 0.933, Run Time : 0.66
INFO:root:2019-05-10 19:47:54, Epoch : 1, Step : 2570, Training Loss : 0.22720, Training Acc : 0.917, Run Time : 13.41
INFO:root:2019-05-10 19:47:54, Epoch : 1, Step : 2571, Training Loss : 0.22646, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-10 19:47:55, Epoch : 1, Step : 2572, Training Loss : 0.33015, Training Acc : 0.850, Run Time : 0.65
INFO:root:2019-05-10 19:47:55, Epoch : 1, Step : 2573, Training Loss : 0.26218, Training Acc : 0.878, Run Time : 0.39
INFO:root:2019-05-10 19:47:56, Epoch : 1, Step : 2574, Training Loss : 0.29891, Training Acc : 0.861, Run Time : 0.51
INFO:root:2019-05-10 19:48:10, Epoch : 1, Step : 2575, Training Loss : 0.27535, Training Acc : 0.883, Run Time : 14.87
INFO:root:2019-05-10 19:48:11, Epoch : 1, Step : 2576, Training Loss : 0.32229, Training Acc : 0.878, Run Time : 0.33
INFO:root:2019-05-10 19:48:11, Epoch : 1, Step : 2577, Training Loss : 0.41743, Training Acc : 0.789, Run Time : 0.46
INFO:root:2019-05-10 19:48:12, Epoch : 1, Step : 2578, Training Loss : 0.29233, Training Acc : 0.867, Run Time : 0.48
INFO:root:2019-05-10 19:48:23, Epoch : 1, Step : 2579, Training Loss : 0.34024, Training Acc : 0.806, Run Time : 11.75
INFO:root:2019-05-10 19:48:24, Epoch : 1, Step : 2580, Training Loss : 0.15604, Training Acc : 0.928, Run Time : 0.77
INFO:root:2019-05-10 19:48:25, Epoch : 1, Step : 2581, Training Loss : 0.18128, Training Acc : 0.933, Run Time : 0.49
INFO:root:2019-05-10 19:48:25, Epoch : 1, Step : 2582, Training Loss : 0.20740, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-10 19:48:26, Epoch : 1, Step : 2583, Training Loss : 0.12736, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-10 19:48:41, Epoch : 1, Step : 2584, Training Loss : 0.32330, Training Acc : 0.878, Run Time : 15.42
INFO:root:2019-05-10 19:48:41, Epoch : 1, Step : 2585, Training Loss : 0.24593, Training Acc : 0.878, Run Time : 0.30
INFO:root:2019-05-10 19:48:42, Epoch : 1, Step : 2586, Training Loss : 0.35811, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-10 19:48:42, Epoch : 1, Step : 2587, Training Loss : 0.32420, Training Acc : 0.861, Run Time : 0.50
INFO:root:2019-05-10 19:48:43, Epoch : 1, Step : 2588, Training Loss : 0.40930, Training Acc : 0.806, Run Time : 0.48
INFO:root:2019-05-10 19:49:02, Epoch : 1, Step : 2589, Training Loss : 0.47543, Training Acc : 0.772, Run Time : 18.88
INFO:root:2019-05-10 19:49:02, Epoch : 1, Step : 2590, Training Loss : 0.34844, Training Acc : 0.806, Run Time : 0.32
INFO:root:2019-05-10 19:49:02, Epoch : 1, Step : 2591, Training Loss : 0.31520, Training Acc : 0.839, Run Time : 0.48
INFO:root:2019-05-10 19:49:03, Epoch : 1, Step : 2592, Training Loss : 0.20623, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-10 19:49:03, Epoch : 1, Step : 2593, Training Loss : 0.20399, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 19:49:19, Epoch : 1, Step : 2594, Training Loss : 0.14307, Training Acc : 0.950, Run Time : 15.67
INFO:root:2019-05-10 19:49:19, Epoch : 1, Step : 2595, Training Loss : 0.16070, Training Acc : 0.928, Run Time : 0.34
INFO:root:2019-05-10 19:49:20, Epoch : 1, Step : 2596, Training Loss : 0.23813, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-10 19:49:31, Epoch : 1, Step : 2597, Training Loss : 0.21180, Training Acc : 0.872, Run Time : 11.52
INFO:root:2019-05-10 19:49:32, Epoch : 1, Step : 2598, Training Loss : 0.22326, Training Acc : 0.911, Run Time : 0.50
INFO:root:2019-05-10 19:49:32, Epoch : 1, Step : 2599, Training Loss : 0.26756, Training Acc : 0.900, Run Time : 0.44
INFO:root:2019-05-10 19:49:33, Epoch : 1, Step : 2600, Training Loss : 0.31123, Training Acc : 0.850, Run Time : 0.51
INFO:root:2019-05-10 19:49:46, Epoch : 1, Step : 2601, Training Loss : 0.79825, Training Acc : 0.744, Run Time : 13.50
INFO:root:2019-05-10 19:49:47, Epoch : 1, Step : 2602, Training Loss : 0.70153, Training Acc : 0.744, Run Time : 0.42
INFO:root:2019-05-10 19:49:47, Epoch : 1, Step : 2603, Training Loss : 0.46387, Training Acc : 0.689, Run Time : 0.28
INFO:root:2019-05-10 19:49:48, Epoch : 1, Step : 2604, Training Loss : 0.62993, Training Acc : 0.800, Run Time : 0.45
INFO:root:2019-05-10 19:49:48, Epoch : 1, Step : 2605, Training Loss : 0.52957, Training Acc : 0.767, Run Time : 0.49
INFO:root:2019-05-10 19:50:04, Epoch : 1, Step : 2606, Training Loss : 0.41175, Training Acc : 0.756, Run Time : 16.07
INFO:root:2019-05-10 19:50:04, Epoch : 1, Step : 2607, Training Loss : 0.40277, Training Acc : 0.794, Run Time : 0.27
INFO:root:2019-05-10 19:50:05, Epoch : 1, Step : 2608, Training Loss : 0.38156, Training Acc : 0.800, Run Time : 0.26
INFO:root:2019-05-10 19:50:05, Epoch : 1, Step : 2609, Training Loss : 0.30107, Training Acc : 0.856, Run Time : 0.52
INFO:root:2019-05-10 19:50:06, Epoch : 1, Step : 2610, Training Loss : 0.24252, Training Acc : 0.911, Run Time : 0.52
INFO:root:2019-05-10 19:50:21, Epoch : 1, Step : 2611, Training Loss : 0.17013, Training Acc : 0.956, Run Time : 15.64
INFO:root:2019-05-10 19:50:22, Epoch : 1, Step : 2612, Training Loss : 0.48749, Training Acc : 0.822, Run Time : 0.32
INFO:root:2019-05-10 19:50:22, Epoch : 1, Step : 2613, Training Loss : 0.19208, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-10 19:50:23, Epoch : 1, Step : 2614, Training Loss : 0.08038, Training Acc : 0.978, Run Time : 0.59
INFO:root:2019-05-10 19:50:24, Epoch : 1, Step : 2615, Training Loss : 0.32566, Training Acc : 0.850, Run Time : 0.98
INFO:root:2019-05-10 19:50:37, Epoch : 1, Step : 2616, Training Loss : 0.15041, Training Acc : 0.928, Run Time : 13.78
INFO:root:2019-05-10 19:50:38, Epoch : 1, Step : 2617, Training Loss : 0.10953, Training Acc : 0.950, Run Time : 0.22
INFO:root:2019-05-10 19:50:38, Epoch : 1, Step : 2618, Training Loss : 0.25824, Training Acc : 0.906, Run Time : 0.49
INFO:root:2019-05-10 19:50:39, Epoch : 1, Step : 2619, Training Loss : 0.16514, Training Acc : 0.956, Run Time : 0.51
INFO:root:2019-05-10 19:50:39, Epoch : 1, Step : 2620, Training Loss : 0.20578, Training Acc : 0.933, Run Time : 0.49
INFO:root:2019-05-10 19:50:52, Epoch : 1, Step : 2621, Training Loss : 0.20913, Training Acc : 0.928, Run Time : 12.83
INFO:root:2019-05-10 19:50:53, Epoch : 1, Step : 2622, Training Loss : 0.25555, Training Acc : 0.878, Run Time : 1.25
INFO:root:2019-05-10 19:50:54, Epoch : 1, Step : 2623, Training Loss : 0.30898, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-10 19:50:54, Epoch : 1, Step : 2624, Training Loss : 0.29306, Training Acc : 0.878, Run Time : 0.49
INFO:root:2019-05-10 19:50:55, Epoch : 1, Step : 2625, Training Loss : 0.39432, Training Acc : 0.878, Run Time : 0.70
INFO:root:2019-05-10 19:51:09, Epoch : 1, Step : 2626, Training Loss : 0.30662, Training Acc : 0.878, Run Time : 13.68
INFO:root:2019-05-10 19:51:09, Epoch : 1, Step : 2627, Training Loss : 0.54078, Training Acc : 0.783, Run Time : 0.25
INFO:root:2019-05-10 19:51:09, Epoch : 1, Step : 2628, Training Loss : 1.25080, Training Acc : 0.578, Run Time : 0.45
INFO:root:2019-05-10 19:51:10, Epoch : 1, Step : 2629, Training Loss : 0.50717, Training Acc : 0.778, Run Time : 0.46
INFO:root:2019-05-10 19:51:10, Epoch : 1, Step : 2630, Training Loss : 0.41814, Training Acc : 0.817, Run Time : 0.45
INFO:root:2019-05-10 19:51:15, Epoch : 1, Step : 2631, Training Loss : 0.30346, Training Acc : 0.900, Run Time : 4.47
INFO:root:2019-05-10 19:51:27, Epoch : 1, Step : 2632, Training Loss : 0.58912, Training Acc : 0.761, Run Time : 12.86
INFO:root:2019-05-10 19:51:28, Epoch : 1, Step : 2633, Training Loss : 0.86532, Training Acc : 0.672, Run Time : 0.47
INFO:root:2019-05-10 19:51:28, Epoch : 1, Step : 2634, Training Loss : 0.51062, Training Acc : 0.772, Run Time : 0.36
INFO:root:2019-05-10 19:51:29, Epoch : 1, Step : 2635, Training Loss : 0.68195, Training Acc : 0.667, Run Time : 0.52
INFO:root:2019-05-10 19:51:29, Epoch : 1, Step : 2636, Training Loss : 0.70920, Training Acc : 0.667, Run Time : 0.50
INFO:root:2019-05-10 19:51:34, Epoch : 1, Step : 2637, Training Loss : 0.52977, Training Acc : 0.761, Run Time : 4.22
INFO:root:2019-05-10 19:51:34, Epoch : 1, Step : 2638, Training Loss : 0.58316, Training Acc : 0.711, Run Time : 0.48
INFO:root:2019-05-10 19:51:50, Epoch : 1, Step : 2639, Training Loss : 0.49727, Training Acc : 0.750, Run Time : 16.05
INFO:root:2019-05-10 19:51:50, Epoch : 1, Step : 2640, Training Loss : 0.49664, Training Acc : 0.789, Run Time : 0.26
INFO:root:2019-05-10 19:51:51, Epoch : 1, Step : 2641, Training Loss : 0.29947, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-10 19:51:51, Epoch : 1, Step : 2642, Training Loss : 0.18017, Training Acc : 0.978, Run Time : 0.48
INFO:root:2019-05-10 19:51:52, Epoch : 1, Step : 2643, Training Loss : 0.22676, Training Acc : 0.911, Run Time : 0.49
INFO:root:2019-05-10 19:52:11, Epoch : 1, Step : 2644, Training Loss : 0.54999, Training Acc : 0.828, Run Time : 19.14
INFO:root:2019-05-10 19:52:11, Epoch : 1, Step : 2645, Training Loss : 0.30775, Training Acc : 0.889, Run Time : 0.23
INFO:root:2019-05-10 19:52:12, Epoch : 1, Step : 2646, Training Loss : 0.24593, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-10 19:52:12, Epoch : 1, Step : 2647, Training Loss : 0.33497, Training Acc : 0.878, Run Time : 0.61
INFO:root:2019-05-10 19:52:24, Epoch : 1, Step : 2648, Training Loss : 0.24636, Training Acc : 0.906, Run Time : 11.45
INFO:root:2019-05-10 19:52:24, Epoch : 1, Step : 2649, Training Loss : 0.52642, Training Acc : 0.778, Run Time : 0.63
INFO:root:2019-05-10 19:52:25, Epoch : 1, Step : 2650, Training Loss : 0.31129, Training Acc : 0.833, Run Time : 0.43
INFO:root:2019-05-10 19:52:37, Epoch : 1, Step : 2651, Training Loss : 0.27405, Training Acc : 0.883, Run Time : 11.88
INFO:root:2019-05-10 19:52:37, Epoch : 1, Step : 2652, Training Loss : 0.21312, Training Acc : 0.939, Run Time : 0.68
INFO:root:2019-05-10 19:52:38, Epoch : 1, Step : 2653, Training Loss : 0.43386, Training Acc : 0.794, Run Time : 0.58
INFO:root:2019-05-10 19:52:38, Epoch : 1, Step : 2654, Training Loss : 0.33337, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-10 19:52:40, Epoch : 1, Step : 2655, Training Loss : 0.35341, Training Acc : 0.817, Run Time : 1.63
INFO:root:2019-05-10 19:52:43, Epoch : 1, Step : 2656, Training Loss : 0.15949, Training Acc : 0.961, Run Time : 2.59
INFO:root:2019-05-10 19:52:43, Epoch : 1, Step : 2657, Training Loss : 0.19876, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-10 19:52:59, Epoch : 1, Step : 2658, Training Loss : 0.18115, Training Acc : 0.961, Run Time : 16.14
INFO:root:2019-05-10 19:52:59, Epoch : 1, Step : 2659, Training Loss : 0.11780, Training Acc : 0.994, Run Time : 0.23
INFO:root:2019-05-10 19:53:00, Epoch : 1, Step : 2660, Training Loss : 0.18064, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-10 19:53:00, Epoch : 1, Step : 2661, Training Loss : 0.10163, Training Acc : 1.000, Run Time : 0.48
INFO:root:2019-05-10 19:53:01, Epoch : 1, Step : 2662, Training Loss : 0.19976, Training Acc : 0.944, Run Time : 0.50
INFO:root:2019-05-10 19:53:17, Epoch : 1, Step : 2663, Training Loss : 0.13906, Training Acc : 0.967, Run Time : 15.90
INFO:root:2019-05-10 19:53:17, Epoch : 1, Step : 2664, Training Loss : 0.20249, Training Acc : 0.922, Run Time : 0.73
INFO:root:2019-05-10 19:53:18, Epoch : 1, Step : 2665, Training Loss : 0.20670, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-10 19:53:18, Epoch : 1, Step : 2666, Training Loss : 0.32753, Training Acc : 0.861, Run Time : 0.46
INFO:root:2019-05-10 19:53:20, Epoch : 1, Step : 2667, Training Loss : 0.22369, Training Acc : 0.917, Run Time : 1.45
INFO:root:2019-05-10 19:53:23, Epoch : 1, Step : 2668, Training Loss : 0.14207, Training Acc : 0.961, Run Time : 3.08
INFO:root:2019-05-10 19:53:24, Epoch : 1, Step : 2669, Training Loss : 0.23763, Training Acc : 0.894, Run Time : 0.70
INFO:root:2019-05-10 19:53:39, Epoch : 1, Step : 2670, Training Loss : 0.31143, Training Acc : 0.883, Run Time : 15.85
INFO:root:2019-05-10 19:53:40, Epoch : 1, Step : 2671, Training Loss : 0.07114, Training Acc : 0.994, Run Time : 0.32
INFO:root:2019-05-10 19:53:40, Epoch : 1, Step : 2672, Training Loss : 0.23767, Training Acc : 0.939, Run Time : 0.51
INFO:root:2019-05-10 19:53:41, Epoch : 1, Step : 2673, Training Loss : 0.27761, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 19:53:41, Epoch : 1, Step : 2674, Training Loss : 0.18148, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 19:53:57, Epoch : 1, Step : 2675, Training Loss : 0.13141, Training Acc : 0.972, Run Time : 15.54
INFO:root:2019-05-10 19:53:57, Epoch : 1, Step : 2676, Training Loss : 0.30737, Training Acc : 0.872, Run Time : 0.24
INFO:root:2019-05-10 19:53:57, Epoch : 1, Step : 2677, Training Loss : 0.19734, Training Acc : 0.922, Run Time : 0.34
INFO:root:2019-05-10 19:53:58, Epoch : 1, Step : 2678, Training Loss : 0.13793, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-10 19:53:59, Epoch : 1, Step : 2679, Training Loss : 0.35855, Training Acc : 0.856, Run Time : 1.34
INFO:root:2019-05-10 19:54:14, Epoch : 1, Step : 2680, Training Loss : 0.21243, Training Acc : 0.911, Run Time : 14.75
INFO:root:2019-05-10 19:54:15, Epoch : 1, Step : 2681, Training Loss : 0.53912, Training Acc : 0.800, Run Time : 0.98
INFO:root:2019-05-10 19:54:15, Epoch : 1, Step : 2682, Training Loss : 0.40441, Training Acc : 0.844, Run Time : 0.54
INFO:root:2019-05-10 19:54:17, Epoch : 1, Step : 2683, Training Loss : 0.32567, Training Acc : 0.872, Run Time : 1.46
INFO:root:2019-05-10 19:54:26, Epoch : 1, Step : 2684, Training Loss : 0.45315, Training Acc : 0.828, Run Time : 9.32
INFO:root:2019-05-10 19:54:26, Epoch : 1, Step : 2685, Training Loss : 0.10388, Training Acc : 0.983, Run Time : 0.23
INFO:root:2019-05-10 19:54:27, Epoch : 1, Step : 2686, Training Loss : 0.11712, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-10 19:54:27, Epoch : 1, Step : 2687, Training Loss : 0.08570, Training Acc : 0.978, Run Time : 0.48
INFO:root:2019-05-10 19:54:28, Epoch : 1, Step : 2688, Training Loss : 0.10582, Training Acc : 0.983, Run Time : 0.44
INFO:root:2019-05-10 19:54:43, Epoch : 1, Step : 2689, Training Loss : 0.14794, Training Acc : 0.933, Run Time : 15.38
INFO:root:2019-05-10 19:54:44, Epoch : 1, Step : 2690, Training Loss : 0.11182, Training Acc : 0.967, Run Time : 0.60
INFO:root:2019-05-10 19:54:45, Epoch : 1, Step : 2691, Training Loss : 0.26049, Training Acc : 0.906, Run Time : 1.14
INFO:root:2019-05-10 19:54:54, Epoch : 1, Step : 2692, Training Loss : 0.11544, Training Acc : 0.944, Run Time : 9.12
INFO:root:2019-05-10 19:54:55, Epoch : 1, Step : 2693, Training Loss : 0.12422, Training Acc : 0.967, Run Time : 0.58
INFO:root:2019-05-10 19:54:55, Epoch : 1, Step : 2694, Training Loss : 0.06389, Training Acc : 0.983, Run Time : 0.46
INFO:root:2019-05-10 19:54:56, Epoch : 1, Step : 2695, Training Loss : 0.14629, Training Acc : 0.972, Run Time : 0.43
INFO:root:2019-05-10 19:54:57, Epoch : 1, Step : 2696, Training Loss : 0.07697, Training Acc : 0.994, Run Time : 1.92
INFO:root:2019-05-10 19:55:11, Epoch : 1, Step : 2697, Training Loss : 0.10050, Training Acc : 0.978, Run Time : 13.76
INFO:root:2019-05-10 19:55:11, Epoch : 1, Step : 2698, Training Loss : 0.13743, Training Acc : 0.961, Run Time : 0.29
INFO:root:2019-05-10 19:55:12, Epoch : 1, Step : 2699, Training Loss : 0.10590, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-10 19:55:12, Epoch : 1, Step : 2700, Training Loss : 0.06603, Training Acc : 0.983, Run Time : 0.49
INFO:root:2019-05-10 19:55:14, Epoch : 1, Step : 2701, Training Loss : 0.08457, Training Acc : 0.983, Run Time : 1.70
INFO:root:2019-05-10 19:55:28, Epoch : 1, Step : 2702, Training Loss : 0.05696, Training Acc : 1.000, Run Time : 13.95
INFO:root:2019-05-10 19:55:29, Epoch : 1, Step : 2703, Training Loss : 0.03548, Training Acc : 1.000, Run Time : 0.81
INFO:root:2019-05-10 19:55:29, Epoch : 1, Step : 2704, Training Loss : 0.05551, Training Acc : 1.000, Run Time : 0.59
INFO:root:2019-05-10 19:55:31, Epoch : 1, Step : 2705, Training Loss : 0.16138, Training Acc : 0.961, Run Time : 1.13
INFO:root:2019-05-10 19:55:40, Epoch : 1, Step : 2706, Training Loss : 0.07812, Training Acc : 0.972, Run Time : 9.82
INFO:root:2019-05-10 19:55:41, Epoch : 1, Step : 2707, Training Loss : 0.05514, Training Acc : 0.989, Run Time : 0.42
INFO:root:2019-05-10 19:55:41, Epoch : 1, Step : 2708, Training Loss : 0.08231, Training Acc : 0.978, Run Time : 0.46
INFO:root:2019-05-10 19:55:42, Epoch : 1, Step : 2709, Training Loss : 0.10392, Training Acc : 0.967, Run Time : 0.78
INFO:root:2019-05-10 19:55:53, Epoch : 1, Step : 2710, Training Loss : 0.10298, Training Acc : 0.956, Run Time : 10.73
INFO:root:2019-05-10 19:55:53, Epoch : 1, Step : 2711, Training Loss : 0.03067, Training Acc : 1.000, Run Time : 0.62
INFO:root:2019-05-10 19:55:54, Epoch : 1, Step : 2712, Training Loss : 0.03429, Training Acc : 0.994, Run Time : 0.46
INFO:root:2019-05-10 19:55:54, Epoch : 1, Step : 2713, Training Loss : 0.03385, Training Acc : 1.000, Run Time : 0.53
INFO:root:2019-05-10 19:55:55, Epoch : 1, Step : 2714, Training Loss : 0.04457, Training Acc : 1.000, Run Time : 0.47
INFO:root:2019-05-10 19:56:10, Epoch : 1, Step : 2715, Training Loss : 0.04483, Training Acc : 0.989, Run Time : 15.05
INFO:root:2019-05-10 19:56:10, Epoch : 1, Step : 2716, Training Loss : 0.03317, Training Acc : 0.994, Run Time : 0.33
INFO:root:2019-05-10 19:56:11, Epoch : 1, Step : 2717, Training Loss : 0.08527, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-10 19:56:11, Epoch : 1, Step : 2718, Training Loss : 0.08216, Training Acc : 0.972, Run Time : 0.37
INFO:root:2019-05-10 19:56:12, Epoch : 1, Step : 2719, Training Loss : 0.03078, Training Acc : 1.000, Run Time : 0.48
INFO:root:2019-05-10 19:56:27, Epoch : 1, Step : 2720, Training Loss : 0.09446, Training Acc : 0.961, Run Time : 15.83
INFO:root:2019-05-10 19:56:28, Epoch : 1, Step : 2721, Training Loss : 0.05057, Training Acc : 0.983, Run Time : 0.23
INFO:root:2019-05-10 19:56:28, Epoch : 1, Step : 2722, Training Loss : 0.09798, Training Acc : 0.972, Run Time : 0.26
INFO:root:2019-05-10 19:56:28, Epoch : 1, Step : 2723, Training Loss : 0.11308, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-10 19:56:29, Epoch : 1, Step : 2724, Training Loss : 0.03382, Training Acc : 0.994, Run Time : 0.47
INFO:root:2019-05-10 19:56:34, Epoch : 1, Step : 2725, Training Loss : 0.02603, Training Acc : 1.000, Run Time : 5.45
INFO:root:2019-05-10 19:56:35, Epoch : 1, Step : 2726, Training Loss : 0.16926, Training Acc : 0.944, Run Time : 0.90
INFO:root:2019-05-10 19:56:50, Epoch : 1, Step : 2727, Training Loss : 0.04105, Training Acc : 1.000, Run Time : 15.26
INFO:root:2019-05-10 19:56:51, Epoch : 1, Step : 2728, Training Loss : 0.13394, Training Acc : 0.950, Run Time : 0.87
INFO:root:2019-05-10 19:56:52, Epoch : 1, Step : 2729, Training Loss : 0.03263, Training Acc : 0.994, Run Time : 0.63
INFO:root:2019-05-10 19:56:52, Epoch : 1, Step : 2730, Training Loss : 0.04716, Training Acc : 0.989, Run Time : 0.48
INFO:root:2019-05-10 19:56:53, Epoch : 1, Step : 2731, Training Loss : 0.03317, Training Acc : 0.994, Run Time : 0.57
INFO:root:2019-05-10 19:57:04, Epoch : 1, Step : 2732, Training Loss : 0.03022, Training Acc : 1.000, Run Time : 11.10
INFO:root:2019-05-10 19:57:04, Epoch : 1, Step : 2733, Training Loss : 0.03666, Training Acc : 0.994, Run Time : 0.26
INFO:root:2019-05-10 19:57:05, Epoch : 1, Step : 2734, Training Loss : 0.05416, Training Acc : 0.989, Run Time : 0.48
INFO:root:2019-05-10 19:57:05, Epoch : 1, Step : 2735, Training Loss : 0.05063, Training Acc : 0.989, Run Time : 0.47
INFO:root:2019-05-10 19:57:06, Epoch : 1, Step : 2736, Training Loss : 0.04688, Training Acc : 0.989, Run Time : 0.49
INFO:root:2019-05-10 19:57:22, Epoch : 1, Step : 2737, Training Loss : 0.05298, Training Acc : 0.989, Run Time : 15.78
INFO:root:2019-05-10 19:57:22, Epoch : 1, Step : 2738, Training Loss : 0.09942, Training Acc : 0.956, Run Time : 0.31
INFO:root:2019-05-10 19:57:22, Epoch : 1, Step : 2739, Training Loss : 0.20565, Training Acc : 0.894, Run Time : 0.28
INFO:root:2019-05-10 19:57:23, Epoch : 1, Step : 2740, Training Loss : 0.85733, Training Acc : 0.728, Run Time : 0.39
INFO:root:2019-05-10 19:57:23, Epoch : 1, Step : 2741, Training Loss : 0.38056, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-10 19:57:39, Epoch : 1, Step : 2742, Training Loss : 0.32502, Training Acc : 0.883, Run Time : 15.69
INFO:root:2019-05-10 19:57:39, Epoch : 1, Step : 2743, Training Loss : 0.17118, Training Acc : 0.922, Run Time : 0.23
INFO:root:2019-05-10 19:57:39, Epoch : 1, Step : 2744, Training Loss : 0.28372, Training Acc : 0.889, Run Time : 0.35
INFO:root:2019-05-10 19:57:40, Epoch : 1, Step : 2745, Training Loss : 0.78863, Training Acc : 0.789, Run Time : 0.45
INFO:root:2019-05-10 19:57:40, Epoch : 1, Step : 2746, Training Loss : 0.21817, Training Acc : 0.911, Run Time : 0.75
INFO:root:2019-05-10 19:58:00, Epoch : 1, Step : 2747, Training Loss : 0.90600, Training Acc : 0.678, Run Time : 19.60
INFO:root:2019-05-10 19:58:00, Epoch : 1, Step : 2748, Training Loss : 0.16533, Training Acc : 0.950, Run Time : 0.21
INFO:root:2019-05-10 19:58:01, Epoch : 1, Step : 2749, Training Loss : 0.32110, Training Acc : 0.889, Run Time : 0.32
INFO:root:2019-05-10 19:58:01, Epoch : 1, Step : 2750, Training Loss : 0.22451, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-10 19:58:02, Epoch : 1, Step : 2751, Training Loss : 0.45262, Training Acc : 0.850, Run Time : 0.50
INFO:root:2019-05-10 19:58:20, Epoch : 1, Step : 2752, Training Loss : 0.41585, Training Acc : 0.828, Run Time : 18.63
INFO:root:2019-05-10 19:58:20, Epoch : 1, Step : 2753, Training Loss : 0.61619, Training Acc : 0.756, Run Time : 0.25
INFO:root:2019-05-10 19:58:21, Epoch : 1, Step : 2754, Training Loss : 0.45974, Training Acc : 0.800, Run Time : 0.52
INFO:root:2019-05-10 19:58:21, Epoch : 1, Step : 2755, Training Loss : 0.29093, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-10 19:58:22, Epoch : 1, Step : 2756, Training Loss : 0.16310, Training Acc : 0.928, Run Time : 0.50
INFO:root:2019-05-10 19:58:43, Epoch : 1, Step : 2757, Training Loss : 0.26577, Training Acc : 0.906, Run Time : 20.76
INFO:root:2019-05-10 19:58:43, Epoch : 1, Step : 2758, Training Loss : 0.26531, Training Acc : 0.889, Run Time : 0.65
INFO:root:2019-05-10 19:58:44, Epoch : 1, Step : 2759, Training Loss : 0.30716, Training Acc : 0.906, Run Time : 0.45
INFO:root:2019-05-10 19:58:44, Epoch : 1, Step : 2760, Training Loss : 0.36832, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-10 19:58:45, Epoch : 1, Step : 2761, Training Loss : 0.22907, Training Acc : 0.922, Run Time : 0.56
INFO:root:2019-05-10 19:59:02, Epoch : 1, Step : 2762, Training Loss : 0.31202, Training Acc : 0.889, Run Time : 17.39
INFO:root:2019-05-10 19:59:03, Epoch : 1, Step : 2763, Training Loss : 0.16329, Training Acc : 0.944, Run Time : 0.75
INFO:root:2019-05-10 19:59:04, Epoch : 1, Step : 2764, Training Loss : 0.24360, Training Acc : 0.900, Run Time : 0.58
INFO:root:2019-05-10 19:59:04, Epoch : 1, Step : 2765, Training Loss : 0.28224, Training Acc : 0.911, Run Time : 0.33
INFO:root:2019-05-10 19:59:04, Epoch : 1, Step : 2766, Training Loss : 0.24270, Training Acc : 0.872, Run Time : 0.43
INFO:root:2019-05-10 19:59:23, Epoch : 1, Step : 2767, Training Loss : 0.53864, Training Acc : 0.767, Run Time : 18.70
INFO:root:2019-05-10 19:59:23, Epoch : 1, Step : 2768, Training Loss : 0.20209, Training Acc : 0.917, Run Time : 0.36
INFO:root:2019-05-10 19:59:24, Epoch : 1, Step : 2769, Training Loss : 0.19419, Training Acc : 0.961, Run Time : 0.49
INFO:root:2019-05-10 19:59:24, Epoch : 1, Step : 2770, Training Loss : 0.20936, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 19:59:25, Epoch : 1, Step : 2771, Training Loss : 0.23370, Training Acc : 0.906, Run Time : 0.51
INFO:root:2019-05-10 19:59:46, Epoch : 1, Step : 2772, Training Loss : 0.22528, Training Acc : 0.883, Run Time : 20.76
INFO:root:2019-05-10 19:59:46, Epoch : 1, Step : 2773, Training Loss : 0.12390, Training Acc : 0.978, Run Time : 0.56
INFO:root:2019-05-10 19:59:47, Epoch : 1, Step : 2774, Training Loss : 0.11761, Training Acc : 0.961, Run Time : 0.46
INFO:root:2019-05-10 19:59:47, Epoch : 1, Step : 2775, Training Loss : 0.16306, Training Acc : 0.939, Run Time : 0.50
INFO:root:2019-05-10 19:59:48, Epoch : 1, Step : 2776, Training Loss : 0.21893, Training Acc : 0.900, Run Time : 0.70
INFO:root:2019-05-10 20:00:01, Epoch : 1, Step : 2777, Training Loss : 0.23138, Training Acc : 0.911, Run Time : 13.71
INFO:root:2019-05-10 20:00:02, Epoch : 1, Step : 2778, Training Loss : 0.39982, Training Acc : 0.828, Run Time : 0.81
INFO:root:2019-05-10 20:00:03, Epoch : 1, Step : 2779, Training Loss : 0.22882, Training Acc : 0.911, Run Time : 0.49
INFO:root:2019-05-10 20:00:03, Epoch : 1, Step : 2780, Training Loss : 0.20497, Training Acc : 0.933, Run Time : 0.31
INFO:root:2019-05-10 20:00:04, Epoch : 1, Step : 2781, Training Loss : 0.17488, Training Acc : 0.928, Run Time : 1.36
INFO:root:2019-05-10 20:00:19, Epoch : 1, Step : 2782, Training Loss : 0.28126, Training Acc : 0.844, Run Time : 14.98
INFO:root:2019-05-10 20:00:20, Epoch : 1, Step : 2783, Training Loss : 0.12477, Training Acc : 0.956, Run Time : 0.22
INFO:root:2019-05-10 20:00:20, Epoch : 1, Step : 2784, Training Loss : 0.63387, Training Acc : 0.756, Run Time : 0.55
INFO:root:2019-05-10 20:00:21, Epoch : 1, Step : 2785, Training Loss : 0.71915, Training Acc : 0.700, Run Time : 0.49
INFO:root:2019-05-10 20:00:21, Epoch : 1, Step : 2786, Training Loss : 0.59453, Training Acc : 0.711, Run Time : 0.50
INFO:root:2019-05-10 20:00:35, Epoch : 1, Step : 2787, Training Loss : 0.43912, Training Acc : 0.833, Run Time : 13.94
INFO:root:2019-05-10 20:00:36, Epoch : 1, Step : 2788, Training Loss : 0.33310, Training Acc : 0.872, Run Time : 0.74
INFO:root:2019-05-10 20:00:37, Epoch : 1, Step : 2789, Training Loss : 0.22800, Training Acc : 0.889, Run Time : 0.70
INFO:root:2019-05-10 20:00:37, Epoch : 1, Step : 2790, Training Loss : 0.24067, Training Acc : 0.922, Run Time : 0.51
INFO:root:2019-05-10 20:00:38, Epoch : 1, Step : 2791, Training Loss : 0.17241, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 20:00:51, Epoch : 1, Step : 2792, Training Loss : 0.36762, Training Acc : 0.828, Run Time : 13.33
INFO:root:2019-05-10 20:00:51, Epoch : 1, Step : 2793, Training Loss : 0.21256, Training Acc : 0.933, Run Time : 0.55
INFO:root:2019-05-10 20:00:52, Epoch : 1, Step : 2794, Training Loss : 0.43987, Training Acc : 0.794, Run Time : 0.43
INFO:root:2019-05-10 20:00:52, Epoch : 1, Step : 2795, Training Loss : 0.60768, Training Acc : 0.828, Run Time : 0.48
INFO:root:2019-05-10 20:00:53, Epoch : 1, Step : 2796, Training Loss : 0.34285, Training Acc : 0.822, Run Time : 0.49
INFO:root:2019-05-10 20:01:08, Epoch : 1, Step : 2797, Training Loss : 0.74606, Training Acc : 0.717, Run Time : 15.18
INFO:root:2019-05-10 20:01:16, Epoch : 1, Step : 2798, Training Loss : 0.40747, Training Acc : 0.778, Run Time : 7.52
INFO:root:2019-05-10 20:01:19, Epoch : 1, Step : 2799, Training Loss : 0.40209, Training Acc : 0.811, Run Time : 3.41
INFO:root:2019-05-10 20:01:19, Epoch : 1, Step : 2800, Training Loss : 0.39604, Training Acc : 0.822, Run Time : 0.37
INFO:root:2019-05-10 20:01:20, Epoch : 1, Step : 2801, Training Loss : 0.38468, Training Acc : 0.828, Run Time : 0.91
INFO:root:2019-05-10 20:01:21, Epoch : 1, Step : 2802, Training Loss : 0.33816, Training Acc : 0.844, Run Time : 0.41
INFO:root:2019-05-10 20:01:21, Epoch : 1, Step : 2803, Training Loss : 0.36421, Training Acc : 0.900, Run Time : 0.50
INFO:root:2019-05-10 20:01:33, Epoch : 1, Step : 2804, Training Loss : 0.36905, Training Acc : 0.822, Run Time : 11.39
INFO:root:2019-05-10 20:01:35, Epoch : 1, Step : 2805, Training Loss : 0.19624, Training Acc : 0.917, Run Time : 2.14
INFO:root:2019-05-10 20:01:35, Epoch : 1, Step : 2806, Training Loss : 0.25880, Training Acc : 0.911, Run Time : 0.44
INFO:root:2019-05-10 20:01:36, Epoch : 1, Step : 2807, Training Loss : 0.23703, Training Acc : 0.889, Run Time : 0.58
INFO:root:2019-05-10 20:01:47, Epoch : 1, Step : 2808, Training Loss : 0.24814, Training Acc : 0.928, Run Time : 11.44
INFO:root:2019-05-10 20:01:48, Epoch : 1, Step : 2809, Training Loss : 0.31537, Training Acc : 0.883, Run Time : 0.52
INFO:root:2019-05-10 20:01:48, Epoch : 1, Step : 2810, Training Loss : 0.30267, Training Acc : 0.900, Run Time : 0.44
INFO:root:2019-05-10 20:01:49, Epoch : 1, Step : 2811, Training Loss : 0.32163, Training Acc : 0.861, Run Time : 0.48
INFO:root:2019-05-10 20:01:49, Epoch : 1, Step : 2812, Training Loss : 0.23762, Training Acc : 0.894, Run Time : 0.32
INFO:root:2019-05-10 20:01:54, Epoch : 1, Step : 2813, Training Loss : 0.29603, Training Acc : 0.878, Run Time : 5.05
INFO:root:2019-05-10 20:01:54, Epoch : 1, Step : 2814, Training Loss : 0.19750, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 20:02:10, Epoch : 1, Step : 2815, Training Loss : 0.25536, Training Acc : 0.900, Run Time : 15.14
INFO:root:2019-05-10 20:02:10, Epoch : 1, Step : 2816, Training Loss : 0.21727, Training Acc : 0.917, Run Time : 0.28
INFO:root:2019-05-10 20:02:10, Epoch : 1, Step : 2817, Training Loss : 0.26703, Training Acc : 0.900, Run Time : 0.61
INFO:root:2019-05-10 20:02:11, Epoch : 1, Step : 2818, Training Loss : 0.29249, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-10 20:02:11, Epoch : 1, Step : 2819, Training Loss : 0.19845, Training Acc : 0.878, Run Time : 0.51
INFO:root:2019-05-10 20:02:27, Epoch : 1, Step : 2820, Training Loss : 0.22294, Training Acc : 0.894, Run Time : 15.34
INFO:root:2019-05-10 20:02:28, Epoch : 1, Step : 2821, Training Loss : 0.17644, Training Acc : 0.939, Run Time : 0.83
INFO:root:2019-05-10 20:02:28, Epoch : 1, Step : 2822, Training Loss : 0.31495, Training Acc : 0.839, Run Time : 0.45
INFO:root:2019-05-10 20:02:28, Epoch : 1, Step : 2823, Training Loss : 0.17354, Training Acc : 0.906, Run Time : 0.48
INFO:root:2019-05-10 20:02:29, Epoch : 1, Step : 2824, Training Loss : 0.16293, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-10 20:02:34, Epoch : 1, Step : 2825, Training Loss : 0.31109, Training Acc : 0.883, Run Time : 5.38
INFO:root:2019-05-10 20:02:35, Epoch : 1, Step : 2826, Training Loss : 0.18043, Training Acc : 0.939, Run Time : 0.50
INFO:root:2019-05-10 20:02:50, Epoch : 1, Step : 2827, Training Loss : 0.22184, Training Acc : 0.878, Run Time : 15.62
INFO:root:2019-05-10 20:02:51, Epoch : 1, Step : 2828, Training Loss : 0.10258, Training Acc : 0.972, Run Time : 0.29
INFO:root:2019-05-10 20:02:51, Epoch : 1, Step : 2829, Training Loss : 0.15170, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-10 20:02:52, Epoch : 1, Step : 2830, Training Loss : 0.18168, Training Acc : 0.939, Run Time : 0.41
INFO:root:2019-05-10 20:02:52, Epoch : 1, Step : 2831, Training Loss : 0.19350, Training Acc : 0.922, Run Time : 0.51
INFO:root:2019-05-10 20:03:09, Epoch : 1, Step : 2832, Training Loss : 0.19675, Training Acc : 0.906, Run Time : 16.44
INFO:root:2019-05-10 20:03:09, Epoch : 1, Step : 2833, Training Loss : 0.19262, Training Acc : 0.911, Run Time : 0.60
INFO:root:2019-05-10 20:03:10, Epoch : 1, Step : 2834, Training Loss : 0.15604, Training Acc : 0.944, Run Time : 0.49
INFO:root:2019-05-10 20:03:10, Epoch : 1, Step : 2835, Training Loss : 0.10916, Training Acc : 0.972, Run Time : 0.50
INFO:root:2019-05-10 20:03:12, Epoch : 1, Step : 2836, Training Loss : 0.14847, Training Acc : 0.939, Run Time : 1.51
INFO:root:2019-05-10 20:03:15, Epoch : 1, Step : 2837, Training Loss : 0.24057, Training Acc : 0.883, Run Time : 3.29
INFO:root:2019-05-10 20:03:26, Epoch : 1, Step : 2838, Training Loss : 0.10578, Training Acc : 0.967, Run Time : 10.69
INFO:root:2019-05-10 20:03:26, Epoch : 1, Step : 2839, Training Loss : 0.30410, Training Acc : 0.867, Run Time : 0.49
INFO:root:2019-05-10 20:03:33, Epoch : 1, Step : 2840, Training Loss : 0.34964, Training Acc : 0.850, Run Time : 7.18
INFO:root:2019-05-10 20:03:35, Epoch : 1, Step : 2841, Training Loss : 0.14361, Training Acc : 0.939, Run Time : 1.20
INFO:root:2019-05-10 20:03:35, Epoch : 1, Step : 2842, Training Loss : 0.16384, Training Acc : 0.933, Run Time : 0.47
INFO:root:2019-05-10 20:03:36, Epoch : 1, Step : 2843, Training Loss : 0.11408, Training Acc : 0.967, Run Time : 0.49
INFO:root:2019-05-10 20:03:48, Epoch : 1, Step : 2844, Training Loss : 0.14466, Training Acc : 0.939, Run Time : 12.65
INFO:root:2019-05-10 20:03:48, Epoch : 1, Step : 2845, Training Loss : 0.10748, Training Acc : 0.961, Run Time : 0.22
INFO:root:2019-05-10 20:03:49, Epoch : 1, Step : 2846, Training Loss : 0.16947, Training Acc : 0.933, Run Time : 0.31
INFO:root:2019-05-10 20:03:49, Epoch : 1, Step : 2847, Training Loss : 0.20610, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 20:03:50, Epoch : 1, Step : 2848, Training Loss : 0.16133, Training Acc : 0.928, Run Time : 0.90
INFO:root:2019-05-10 20:04:06, Epoch : 1, Step : 2849, Training Loss : 0.28338, Training Acc : 0.850, Run Time : 15.83
INFO:root:2019-05-10 20:04:07, Epoch : 1, Step : 2850, Training Loss : 0.28231, Training Acc : 0.867, Run Time : 0.80
INFO:root:2019-05-10 20:04:07, Epoch : 1, Step : 2851, Training Loss : 0.09551, Training Acc : 0.978, Run Time : 0.59
INFO:root:2019-05-10 20:04:08, Epoch : 1, Step : 2852, Training Loss : 0.17276, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-10 20:04:08, Epoch : 1, Step : 2853, Training Loss : 0.17385, Training Acc : 0.933, Run Time : 0.50
INFO:root:2019-05-10 20:04:23, Epoch : 1, Step : 2854, Training Loss : 0.18700, Training Acc : 0.911, Run Time : 14.63
INFO:root:2019-05-10 20:04:23, Epoch : 1, Step : 2855, Training Loss : 0.17476, Training Acc : 0.939, Run Time : 0.23
INFO:root:2019-05-10 20:04:24, Epoch : 1, Step : 2856, Training Loss : 0.26176, Training Acc : 0.872, Run Time : 0.49
INFO:root:2019-05-10 20:04:24, Epoch : 1, Step : 2857, Training Loss : 0.37929, Training Acc : 0.872, Run Time : 0.53
INFO:root:2019-05-10 20:04:25, Epoch : 1, Step : 2858, Training Loss : 0.50342, Training Acc : 0.789, Run Time : 0.49
INFO:root:2019-05-10 20:04:42, Epoch : 1, Step : 2859, Training Loss : 0.16679, Training Acc : 0.939, Run Time : 17.79
INFO:root:2019-05-10 20:04:43, Epoch : 1, Step : 2860, Training Loss : 0.25919, Training Acc : 0.883, Run Time : 0.60
INFO:root:2019-05-10 20:04:43, Epoch : 1, Step : 2861, Training Loss : 0.11867, Training Acc : 0.950, Run Time : 0.32
INFO:root:2019-05-10 20:04:44, Epoch : 1, Step : 2862, Training Loss : 0.17003, Training Acc : 0.950, Run Time : 0.44
INFO:root:2019-05-10 20:04:45, Epoch : 1, Step : 2863, Training Loss : 0.09619, Training Acc : 0.978, Run Time : 1.10
INFO:root:2019-05-10 20:05:01, Epoch : 1, Step : 2864, Training Loss : 0.11733, Training Acc : 0.972, Run Time : 15.67
INFO:root:2019-05-10 20:05:01, Epoch : 1, Step : 2865, Training Loss : 0.11578, Training Acc : 0.944, Run Time : 0.35
INFO:root:2019-05-10 20:05:01, Epoch : 1, Step : 2866, Training Loss : 0.16590, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-10 20:05:02, Epoch : 1, Step : 2867, Training Loss : 0.28474, Training Acc : 0.883, Run Time : 0.44
INFO:root:2019-05-10 20:05:14, Epoch : 1, Step : 2868, Training Loss : 0.16354, Training Acc : 0.944, Run Time : 11.91
INFO:root:2019-05-10 20:05:14, Epoch : 1, Step : 2869, Training Loss : 0.07200, Training Acc : 0.978, Run Time : 0.59
INFO:root:2019-05-10 20:05:15, Epoch : 1, Step : 2870, Training Loss : 0.19841, Training Acc : 0.933, Run Time : 0.47
INFO:root:2019-05-10 20:05:15, Epoch : 1, Step : 2871, Training Loss : 0.13253, Training Acc : 0.961, Run Time : 0.50
INFO:root:2019-05-10 20:05:16, Epoch : 1, Step : 2872, Training Loss : 0.20291, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 20:05:32, Epoch : 1, Step : 2873, Training Loss : 0.49420, Training Acc : 0.800, Run Time : 15.81
INFO:root:2019-05-10 20:05:32, Epoch : 1, Step : 2874, Training Loss : 0.36392, Training Acc : 0.822, Run Time : 0.32
INFO:root:2019-05-10 20:05:32, Epoch : 1, Step : 2875, Training Loss : 0.41634, Training Acc : 0.844, Run Time : 0.51
INFO:root:2019-05-10 20:05:33, Epoch : 1, Step : 2876, Training Loss : 0.13387, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 20:05:33, Epoch : 1, Step : 2877, Training Loss : 0.19018, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 20:05:49, Epoch : 1, Step : 2878, Training Loss : 0.14799, Training Acc : 0.961, Run Time : 15.87
INFO:root:2019-05-10 20:05:49, Epoch : 1, Step : 2879, Training Loss : 0.12680, Training Acc : 0.961, Run Time : 0.26
INFO:root:2019-05-10 20:05:50, Epoch : 1, Step : 2880, Training Loss : 0.25480, Training Acc : 0.878, Run Time : 0.46
INFO:root:2019-05-10 20:05:50, Epoch : 1, Step : 2881, Training Loss : 0.40160, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-10 20:05:51, Epoch : 1, Step : 2882, Training Loss : 0.45051, Training Acc : 0.794, Run Time : 0.50
INFO:root:2019-05-10 20:06:06, Epoch : 1, Step : 2883, Training Loss : 0.36096, Training Acc : 0.856, Run Time : 14.75
INFO:root:2019-05-10 20:06:06, Epoch : 1, Step : 2884, Training Loss : 0.42014, Training Acc : 0.822, Run Time : 0.53
INFO:root:2019-05-10 20:06:07, Epoch : 1, Step : 2885, Training Loss : 0.27427, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-10 20:06:07, Epoch : 1, Step : 2886, Training Loss : 0.17150, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 20:06:08, Epoch : 1, Step : 2887, Training Loss : 0.13972, Training Acc : 0.961, Run Time : 0.49
INFO:root:2019-05-10 20:06:12, Epoch : 1, Step : 2888, Training Loss : 0.15318, Training Acc : 0.939, Run Time : 4.48
INFO:root:2019-05-10 20:06:13, Epoch : 1, Step : 2889, Training Loss : 0.33025, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 20:06:30, Epoch : 1, Step : 2890, Training Loss : 0.27487, Training Acc : 0.883, Run Time : 16.98
INFO:root:2019-05-10 20:06:30, Epoch : 1, Step : 2891, Training Loss : 0.18944, Training Acc : 0.911, Run Time : 0.31
INFO:root:2019-05-10 20:06:30, Epoch : 1, Step : 2892, Training Loss : 0.20691, Training Acc : 0.928, Run Time : 0.24
INFO:root:2019-05-10 20:06:31, Epoch : 1, Step : 2893, Training Loss : 0.16806, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-10 20:06:31, Epoch : 1, Step : 2894, Training Loss : 0.13372, Training Acc : 0.956, Run Time : 0.48
INFO:root:2019-05-10 20:06:48, Epoch : 1, Step : 2895, Training Loss : 0.17395, Training Acc : 0.922, Run Time : 17.17
INFO:root:2019-05-10 20:06:48, Epoch : 1, Step : 2896, Training Loss : 0.17441, Training Acc : 0.928, Run Time : 0.26
INFO:root:2019-05-10 20:06:49, Epoch : 1, Step : 2897, Training Loss : 0.27641, Training Acc : 0.878, Run Time : 0.42
INFO:root:2019-05-10 20:06:49, Epoch : 1, Step : 2898, Training Loss : 0.15903, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-10 20:06:50, Epoch : 1, Step : 2899, Training Loss : 0.13261, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-10 20:06:56, Epoch : 1, Step : 2900, Training Loss : 0.34670, Training Acc : 0.850, Run Time : 5.97
INFO:root:2019-05-10 20:07:09, Epoch : 1, Step : 2901, Training Loss : 0.23814, Training Acc : 0.889, Run Time : 12.97
INFO:root:2019-05-10 20:07:09, Epoch : 1, Step : 2902, Training Loss : 0.16506, Training Acc : 0.933, Run Time : 0.26
INFO:root:2019-05-10 20:07:09, Epoch : 1, Step : 2903, Training Loss : 0.22806, Training Acc : 0.889, Run Time : 0.22
INFO:root:2019-05-10 20:07:10, Epoch : 1, Step : 2904, Training Loss : 0.35742, Training Acc : 0.822, Run Time : 0.49
INFO:root:2019-05-10 20:07:10, Epoch : 1, Step : 2905, Training Loss : 0.29014, Training Acc : 0.850, Run Time : 0.69
INFO:root:2019-05-10 20:07:25, Epoch : 1, Step : 2906, Training Loss : 0.19969, Training Acc : 0.917, Run Time : 14.71
INFO:root:2019-05-10 20:07:26, Epoch : 1, Step : 2907, Training Loss : 0.15526, Training Acc : 0.956, Run Time : 0.33
INFO:root:2019-05-10 20:07:26, Epoch : 1, Step : 2908, Training Loss : 0.28991, Training Acc : 0.867, Run Time : 0.64
INFO:root:2019-05-10 20:07:28, Epoch : 1, Step : 2909, Training Loss : 0.26357, Training Acc : 0.878, Run Time : 1.46
INFO:root:2019-05-10 20:07:38, Epoch : 1, Step : 2910, Training Loss : 0.24565, Training Acc : 0.906, Run Time : 10.51
INFO:root:2019-05-10 20:07:39, Epoch : 1, Step : 2911, Training Loss : 0.11973, Training Acc : 0.978, Run Time : 0.89
INFO:root:2019-05-10 20:07:40, Epoch : 1, Step : 2912, Training Loss : 0.14972, Training Acc : 0.961, Run Time : 0.51
INFO:root:2019-05-10 20:07:40, Epoch : 1, Step : 2913, Training Loss : 0.17572, Training Acc : 0.944, Run Time : 0.50
INFO:root:2019-05-10 20:07:41, Epoch : 1, Step : 2914, Training Loss : 0.16925, Training Acc : 0.933, Run Time : 0.49
INFO:root:2019-05-10 20:07:55, Epoch : 1, Step : 2915, Training Loss : 0.21434, Training Acc : 0.928, Run Time : 14.77
INFO:root:2019-05-10 20:07:57, Epoch : 1, Step : 2916, Training Loss : 0.17554, Training Acc : 0.917, Run Time : 1.24
INFO:root:2019-05-10 20:07:57, Epoch : 1, Step : 2917, Training Loss : 0.18453, Training Acc : 0.911, Run Time : 0.44
INFO:root:2019-05-10 20:08:07, Epoch : 1, Step : 2918, Training Loss : 0.13414, Training Acc : 0.950, Run Time : 10.35
INFO:root:2019-05-10 20:08:08, Epoch : 1, Step : 2919, Training Loss : 0.09653, Training Acc : 0.983, Run Time : 0.43
INFO:root:2019-05-10 20:08:08, Epoch : 1, Step : 2920, Training Loss : 0.12099, Training Acc : 0.967, Run Time : 0.47
INFO:root:2019-05-10 20:08:09, Epoch : 1, Step : 2921, Training Loss : 0.30989, Training Acc : 0.861, Run Time : 0.48
INFO:root:2019-05-10 20:08:21, Epoch : 1, Step : 2922, Training Loss : 0.24349, Training Acc : 0.878, Run Time : 12.31
INFO:root:2019-05-10 20:08:21, Epoch : 1, Step : 2923, Training Loss : 0.14756, Training Acc : 0.933, Run Time : 0.30
INFO:root:2019-05-10 20:08:22, Epoch : 1, Step : 2924, Training Loss : 0.25108, Training Acc : 0.911, Run Time : 0.42
INFO:root:2019-05-10 20:08:22, Epoch : 1, Step : 2925, Training Loss : 0.34467, Training Acc : 0.850, Run Time : 0.49
INFO:root:2019-05-10 20:08:23, Epoch : 1, Step : 2926, Training Loss : 0.18122, Training Acc : 0.922, Run Time : 1.09
INFO:root:2019-05-10 20:08:38, Epoch : 1, Step : 2927, Training Loss : 0.22185, Training Acc : 0.900, Run Time : 14.52
INFO:root:2019-05-10 20:08:38, Epoch : 1, Step : 2928, Training Loss : 0.33639, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-10 20:08:39, Epoch : 1, Step : 2929, Training Loss : 0.31120, Training Acc : 0.856, Run Time : 0.62
INFO:root:2019-05-10 20:08:39, Epoch : 1, Step : 2930, Training Loss : 0.35883, Training Acc : 0.844, Run Time : 0.49
INFO:root:2019-05-10 20:08:52, Epoch : 1, Step : 2931, Training Loss : 0.37158, Training Acc : 0.861, Run Time : 12.79
INFO:root:2019-05-10 20:08:53, Epoch : 1, Step : 2932, Training Loss : 0.32517, Training Acc : 0.878, Run Time : 0.69
INFO:root:2019-05-10 20:08:53, Epoch : 1, Step : 2933, Training Loss : 0.27488, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-10 20:08:54, Epoch : 1, Step : 2934, Training Loss : 0.33371, Training Acc : 0.833, Run Time : 0.42
INFO:root:2019-05-10 20:08:54, Epoch : 1, Step : 2935, Training Loss : 0.24610, Training Acc : 0.872, Run Time : 0.64
INFO:root:2019-05-10 20:09:09, Epoch : 1, Step : 2936, Training Loss : 0.21732, Training Acc : 0.933, Run Time : 14.82
INFO:root:2019-05-10 20:09:10, Epoch : 1, Step : 2937, Training Loss : 0.25742, Training Acc : 0.878, Run Time : 0.29
INFO:root:2019-05-10 20:09:10, Epoch : 1, Step : 2938, Training Loss : 0.21942, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-10 20:09:11, Epoch : 1, Step : 2939, Training Loss : 0.17822, Training Acc : 0.922, Run Time : 0.58
INFO:root:2019-05-10 20:09:22, Epoch : 1, Step : 2940, Training Loss : 0.19431, Training Acc : 0.917, Run Time : 11.69
INFO:root:2019-05-10 20:09:23, Epoch : 1, Step : 2941, Training Loss : 0.23680, Training Acc : 0.917, Run Time : 0.78
INFO:root:2019-05-10 20:09:23, Epoch : 1, Step : 2942, Training Loss : 0.12557, Training Acc : 0.950, Run Time : 0.40
INFO:root:2019-05-10 20:09:24, Epoch : 1, Step : 2943, Training Loss : 0.13817, Training Acc : 0.961, Run Time : 0.49
INFO:root:2019-05-10 20:09:24, Epoch : 1, Step : 2944, Training Loss : 0.08686, Training Acc : 0.983, Run Time : 0.47
INFO:root:2019-05-10 20:09:40, Epoch : 1, Step : 2945, Training Loss : 0.19761, Training Acc : 0.922, Run Time : 15.56
INFO:root:2019-05-10 20:09:40, Epoch : 1, Step : 2946, Training Loss : 0.16744, Training Acc : 0.928, Run Time : 0.33
INFO:root:2019-05-10 20:09:41, Epoch : 1, Step : 2947, Training Loss : 0.25208, Training Acc : 0.906, Run Time : 0.48
INFO:root:2019-05-10 20:09:41, Epoch : 1, Step : 2948, Training Loss : 0.15639, Training Acc : 0.933, Run Time : 0.39
INFO:root:2019-05-10 20:09:42, Epoch : 1, Step : 2949, Training Loss : 0.10013, Training Acc : 0.956, Run Time : 0.62
INFO:root:2019-05-10 20:09:59, Epoch : 1, Step : 2950, Training Loss : 0.06643, Training Acc : 0.983, Run Time : 17.03
INFO:root:2019-05-10 20:09:59, Epoch : 1, Step : 2951, Training Loss : 0.05866, Training Acc : 0.994, Run Time : 0.24
INFO:root:2019-05-10 20:09:59, Epoch : 1, Step : 2952, Training Loss : 0.08783, Training Acc : 0.972, Run Time : 0.48
INFO:root:2019-05-10 20:10:00, Epoch : 1, Step : 2953, Training Loss : 0.08262, Training Acc : 0.972, Run Time : 0.48
INFO:root:2019-05-10 20:10:01, Epoch : 1, Step : 2954, Training Loss : 0.06440, Training Acc : 0.989, Run Time : 0.53
INFO:root:2019-05-10 20:10:17, Epoch : 1, Step : 2955, Training Loss : 0.06576, Training Acc : 0.983, Run Time : 16.35
INFO:root:2019-05-10 20:10:17, Epoch : 1, Step : 2956, Training Loss : 0.18255, Training Acc : 0.939, Run Time : 0.24
INFO:root:2019-05-10 20:10:18, Epoch : 1, Step : 2957, Training Loss : 0.87031, Training Acc : 0.661, Run Time : 0.47
INFO:root:2019-05-10 20:10:18, Epoch : 1, Step : 2958, Training Loss : 0.63278, Training Acc : 0.767, Run Time : 0.48
INFO:root:2019-05-10 20:10:20, Epoch : 1, Step : 2959, Training Loss : 0.53427, Training Acc : 0.761, Run Time : 1.70
INFO:root:2019-05-10 20:10:35, Epoch : 1, Step : 2960, Training Loss : 0.32189, Training Acc : 0.861, Run Time : 15.75
INFO:root:2019-05-10 20:10:37, Epoch : 1, Step : 2961, Training Loss : 0.17743, Training Acc : 0.906, Run Time : 1.25
INFO:root:2019-05-10 20:10:47, Epoch : 1, Step : 2962, Training Loss : 0.22085, Training Acc : 0.911, Run Time : 10.59
INFO:root:2019-05-10 20:10:48, Epoch : 1, Step : 2963, Training Loss : 0.21240, Training Acc : 0.894, Run Time : 0.59
INFO:root:2019-05-10 20:10:48, Epoch : 1, Step : 2964, Training Loss : 0.21820, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 20:10:49, Epoch : 1, Step : 2965, Training Loss : 0.13712, Training Acc : 0.956, Run Time : 0.49
INFO:root:2019-05-10 20:10:49, Epoch : 1, Step : 2966, Training Loss : 0.16693, Training Acc : 0.939, Run Time : 0.49
INFO:root:2019-05-10 20:10:55, Epoch : 1, Step : 2967, Training Loss : 0.15064, Training Acc : 0.961, Run Time : 5.23
INFO:root:2019-05-10 20:11:04, Epoch : 1, Step : 2968, Training Loss : 0.15642, Training Acc : 0.956, Run Time : 9.01
INFO:root:2019-05-10 20:11:06, Epoch : 1, Step : 2969, Training Loss : 0.16304, Training Acc : 0.933, Run Time : 1.96
INFO:root:2019-05-10 20:11:07, Epoch : 1, Step : 2970, Training Loss : 0.19592, Training Acc : 0.939, Run Time : 0.98
INFO:root:2019-05-10 20:11:07, Epoch : 1, Step : 2971, Training Loss : 0.36726, Training Acc : 0.883, Run Time : 0.87
INFO:root:2019-05-10 20:11:08, Epoch : 1, Step : 2972, Training Loss : 0.30252, Training Acc : 0.856, Run Time : 0.49
INFO:root:2019-05-10 20:11:08, Epoch : 1, Step : 2973, Training Loss : 0.33125, Training Acc : 0.833, Run Time : 0.53
INFO:root:2019-05-10 20:11:22, Epoch : 1, Step : 2974, Training Loss : 0.36755, Training Acc : 0.856, Run Time : 13.58
INFO:root:2019-05-10 20:11:23, Epoch : 1, Step : 2975, Training Loss : 0.38222, Training Acc : 0.833, Run Time : 0.60
INFO:root:2019-05-10 20:11:23, Epoch : 1, Step : 2976, Training Loss : 0.33203, Training Acc : 0.844, Run Time : 0.46
INFO:root:2019-05-10 20:11:24, Epoch : 1, Step : 2977, Training Loss : 0.31131, Training Acc : 0.878, Run Time : 0.50
INFO:root:2019-05-10 20:11:25, Epoch : 1, Step : 2978, Training Loss : 0.44438, Training Acc : 0.828, Run Time : 1.89
INFO:root:2019-05-10 20:11:39, Epoch : 1, Step : 2979, Training Loss : 0.37598, Training Acc : 0.833, Run Time : 13.90
INFO:root:2019-05-10 20:11:40, Epoch : 1, Step : 2980, Training Loss : 0.45949, Training Acc : 0.806, Run Time : 0.32
INFO:root:2019-05-10 20:11:40, Epoch : 1, Step : 2981, Training Loss : 0.64958, Training Acc : 0.739, Run Time : 0.45
INFO:root:2019-05-10 20:11:41, Epoch : 1, Step : 2982, Training Loss : 0.30884, Training Acc : 0.878, Run Time : 1.05
INFO:root:2019-05-10 20:11:53, Epoch : 1, Step : 2983, Training Loss : 0.55327, Training Acc : 0.778, Run Time : 11.80
INFO:root:2019-05-10 20:11:54, Epoch : 1, Step : 2984, Training Loss : 0.35460, Training Acc : 0.867, Run Time : 0.62
INFO:root:2019-05-10 20:11:54, Epoch : 1, Step : 2985, Training Loss : 0.43968, Training Acc : 0.817, Run Time : 0.56
INFO:root:2019-05-10 20:11:55, Epoch : 1, Step : 2986, Training Loss : 0.34537, Training Acc : 0.828, Run Time : 0.49
INFO:root:2019-05-10 20:11:55, Epoch : 1, Step : 2987, Training Loss : 0.26348, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-10 20:12:12, Epoch : 1, Step : 2988, Training Loss : 0.38972, Training Acc : 0.833, Run Time : 16.53
INFO:root:2019-05-10 20:12:12, Epoch : 1, Step : 2989, Training Loss : 0.19683, Training Acc : 0.933, Run Time : 0.34
INFO:root:2019-05-10 20:12:12, Epoch : 1, Step : 2990, Training Loss : 0.20393, Training Acc : 0.911, Run Time : 0.26
INFO:root:2019-05-10 20:12:23, Epoch : 1, Step : 2991, Training Loss : 0.19316, Training Acc : 0.911, Run Time : 10.45
INFO:root:2019-05-10 20:12:23, Epoch : 1, Step : 2992, Training Loss : 0.26561, Training Acc : 0.872, Run Time : 0.68
INFO:root:2019-05-10 20:12:24, Epoch : 1, Step : 2993, Training Loss : 0.23076, Training Acc : 0.911, Run Time : 0.50
INFO:root:2019-05-10 20:12:24, Epoch : 1, Step : 2994, Training Loss : 0.32212, Training Acc : 0.872, Run Time : 0.53
INFO:root:2019-05-10 20:12:25, Epoch : 1, Step : 2995, Training Loss : 0.26890, Training Acc : 0.878, Run Time : 0.49
INFO:root:2019-05-10 20:12:40, Epoch : 1, Step : 2996, Training Loss : 0.27851, Training Acc : 0.878, Run Time : 14.92
INFO:root:2019-05-10 20:12:40, Epoch : 1, Step : 2997, Training Loss : 0.20700, Training Acc : 0.872, Run Time : 0.29
INFO:root:2019-05-10 20:12:41, Epoch : 1, Step : 2998, Training Loss : 0.16782, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 20:12:41, Epoch : 1, Step : 2999, Training Loss : 0.22621, Training Acc : 0.906, Run Time : 0.45
INFO:root:2019-05-10 20:12:42, Epoch : 1, Step : 3000, Training Loss : 0.13804, Training Acc : 0.939, Run Time : 0.64
INFO:root:2019-05-10 20:12:57, Epoch : 1, Step : 3001, Training Loss : 0.59446, Training Acc : 0.750, Run Time : 15.23
INFO:root:2019-05-10 20:12:57, Epoch : 1, Step : 3002, Training Loss : 0.76793, Training Acc : 0.717, Run Time : 0.24
INFO:root:2019-05-10 20:12:58, Epoch : 1, Step : 3003, Training Loss : 0.44842, Training Acc : 0.739, Run Time : 0.47
INFO:root:2019-05-10 20:12:58, Epoch : 1, Step : 3004, Training Loss : 0.51725, Training Acc : 0.722, Run Time : 0.47
INFO:root:2019-05-10 20:12:59, Epoch : 1, Step : 3005, Training Loss : 0.44215, Training Acc : 0.778, Run Time : 0.48
INFO:root:2019-05-10 20:13:04, Epoch : 1, Step : 3006, Training Loss : 0.35224, Training Acc : 0.872, Run Time : 5.49
INFO:root:2019-05-10 20:13:05, Epoch : 1, Step : 3007, Training Loss : 0.33380, Training Acc : 0.850, Run Time : 0.51
INFO:root:2019-05-10 20:13:18, Epoch : 1, Step : 3008, Training Loss : 0.17126, Training Acc : 0.944, Run Time : 12.98
INFO:root:2019-05-10 20:13:18, Epoch : 1, Step : 3009, Training Loss : 0.28062, Training Acc : 0.878, Run Time : 0.21
INFO:root:2019-05-10 20:13:18, Epoch : 1, Step : 3010, Training Loss : 0.31348, Training Acc : 0.878, Run Time : 0.39
INFO:root:2019-05-10 20:13:19, Epoch : 1, Step : 3011, Training Loss : 0.33557, Training Acc : 0.856, Run Time : 0.48
INFO:root:2019-05-10 20:13:19, Epoch : 1, Step : 3012, Training Loss : 0.51320, Training Acc : 0.844, Run Time : 0.47
INFO:root:2019-05-10 20:13:34, Epoch : 1, Step : 3013, Training Loss : 0.15139, Training Acc : 0.956, Run Time : 15.08
INFO:root:2019-05-10 20:13:34, Epoch : 1, Step : 3014, Training Loss : 0.30248, Training Acc : 0.844, Run Time : 0.28
INFO:root:2019-05-10 20:13:35, Epoch : 1, Step : 3015, Training Loss : 0.30853, Training Acc : 0.861, Run Time : 0.65
INFO:root:2019-05-10 20:13:36, Epoch : 1, Step : 3016, Training Loss : 0.26205, Training Acc : 0.894, Run Time : 0.50
INFO:root:2019-05-10 20:13:48, Epoch : 1, Step : 3017, Training Loss : 0.32296, Training Acc : 0.850, Run Time : 12.34
INFO:root:2019-05-10 20:13:48, Epoch : 1, Step : 3018, Training Loss : 0.49406, Training Acc : 0.800, Run Time : 0.42
INFO:root:2019-05-10 20:13:49, Epoch : 1, Step : 3019, Training Loss : 0.50881, Training Acc : 0.756, Run Time : 0.44
INFO:root:2019-05-10 20:13:49, Epoch : 1, Step : 3020, Training Loss : 0.58893, Training Acc : 0.750, Run Time : 0.48
INFO:root:2019-05-10 20:13:50, Epoch : 1, Step : 3021, Training Loss : 0.31838, Training Acc : 0.861, Run Time : 0.53
INFO:root:2019-05-10 20:14:04, Epoch : 1, Step : 3022, Training Loss : 0.42494, Training Acc : 0.794, Run Time : 14.63
INFO:root:2019-05-10 20:14:05, Epoch : 1, Step : 3023, Training Loss : 0.41036, Training Acc : 0.856, Run Time : 0.31
INFO:root:2019-05-10 20:14:05, Epoch : 1, Step : 3024, Training Loss : 0.24886, Training Acc : 0.889, Run Time : 0.35
INFO:root:2019-05-10 20:14:06, Epoch : 1, Step : 3025, Training Loss : 0.14412, Training Acc : 0.956, Run Time : 0.73
INFO:root:2019-05-10 20:14:18, Epoch : 1, Step : 3026, Training Loss : 0.18556, Training Acc : 0.939, Run Time : 11.74
INFO:root:2019-05-10 20:14:18, Epoch : 1, Step : 3027, Training Loss : 0.21556, Training Acc : 0.906, Run Time : 0.22
INFO:root:2019-05-10 20:14:18, Epoch : 1, Step : 3028, Training Loss : 0.20159, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-10 20:14:26, Epoch : 1, Step : 3029, Training Loss : 0.46058, Training Acc : 0.811, Run Time : 7.30
INFO:root:2019-05-10 20:14:27, Epoch : 1, Step : 3030, Training Loss : 0.36172, Training Acc : 0.828, Run Time : 1.00
INFO:root:2019-05-10 20:14:27, Epoch : 1, Step : 3031, Training Loss : 0.24723, Training Acc : 0.922, Run Time : 0.45
INFO:root:2019-05-10 20:14:28, Epoch : 1, Step : 3032, Training Loss : 0.17744, Training Acc : 0.911, Run Time : 0.50
INFO:root:2019-05-10 20:14:28, Epoch : 1, Step : 3033, Training Loss : 0.33505, Training Acc : 0.856, Run Time : 0.50
INFO:root:2019-05-10 20:14:40, Epoch : 1, Step : 3034, Training Loss : 0.34014, Training Acc : 0.817, Run Time : 11.99
INFO:root:2019-05-10 20:14:41, Epoch : 1, Step : 3035, Training Loss : 0.18148, Training Acc : 0.933, Run Time : 1.01
INFO:root:2019-05-10 20:14:42, Epoch : 1, Step : 3036, Training Loss : 0.17182, Training Acc : 0.928, Run Time : 0.51
INFO:root:2019-05-10 20:14:42, Epoch : 1, Step : 3037, Training Loss : 0.32936, Training Acc : 0.844, Run Time : 0.42
INFO:root:2019-05-10 20:14:53, Epoch : 1, Step : 3038, Training Loss : 0.28567, Training Acc : 0.878, Run Time : 11.28
INFO:root:2019-05-10 20:14:54, Epoch : 1, Step : 3039, Training Loss : 0.40034, Training Acc : 0.878, Run Time : 0.54
INFO:root:2019-05-10 20:14:54, Epoch : 1, Step : 3040, Training Loss : 0.30896, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 20:15:05, Epoch : 1, Step : 3041, Training Loss : 0.26896, Training Acc : 0.900, Run Time : 10.85
INFO:root:2019-05-10 20:15:06, Epoch : 1, Step : 3042, Training Loss : 0.17589, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 20:15:07, Epoch : 1, Step : 3043, Training Loss : 0.22675, Training Acc : 0.917, Run Time : 1.63
INFO:root:2019-05-10 20:15:18, Epoch : 1, Step : 3044, Training Loss : 0.17484, Training Acc : 0.933, Run Time : 10.86
INFO:root:2019-05-10 20:15:18, Epoch : 1, Step : 3045, Training Loss : 0.25916, Training Acc : 0.872, Run Time : 0.26
INFO:root:2019-05-10 20:15:19, Epoch : 1, Step : 3046, Training Loss : 0.23364, Training Acc : 0.933, Run Time : 0.43
INFO:root:2019-05-10 20:15:19, Epoch : 1, Step : 3047, Training Loss : 0.15886, Training Acc : 0.939, Run Time : 0.50
INFO:root:2019-05-10 20:15:20, Epoch : 1, Step : 3048, Training Loss : 0.22647, Training Acc : 0.906, Run Time : 0.51
INFO:root:2019-05-10 20:15:25, Epoch : 1, Step : 3049, Training Loss : 0.17929, Training Acc : 0.933, Run Time : 5.15
INFO:root:2019-05-10 20:15:25, Epoch : 1, Step : 3050, Training Loss : 0.08615, Training Acc : 0.983, Run Time : 0.49
INFO:root:2019-05-10 20:15:40, Epoch : 1, Step : 3051, Training Loss : 0.17568, Training Acc : 0.928, Run Time : 14.49
INFO:root:2019-05-10 20:15:40, Epoch : 1, Step : 3052, Training Loss : 0.10270, Training Acc : 0.967, Run Time : 0.31
INFO:root:2019-05-10 20:15:41, Epoch : 1, Step : 3053, Training Loss : 0.06560, Training Acc : 0.994, Run Time : 0.45
INFO:root:2019-05-10 20:15:41, Epoch : 1, Step : 3054, Training Loss : 0.09657, Training Acc : 0.972, Run Time : 0.46
INFO:root:2019-05-10 20:15:42, Epoch : 1, Step : 3055, Training Loss : 0.10684, Training Acc : 0.967, Run Time : 0.48
INFO:root:2019-05-10 20:15:57, Epoch : 1, Step : 3056, Training Loss : 0.09160, Training Acc : 0.967, Run Time : 15.70
INFO:root:2019-05-10 20:15:58, Epoch : 1, Step : 3057, Training Loss : 0.07051, Training Acc : 0.994, Run Time : 0.21
INFO:root:2019-05-10 20:15:58, Epoch : 1, Step : 3058, Training Loss : 0.06268, Training Acc : 0.989, Run Time : 0.39
INFO:root:2019-05-10 20:15:58, Epoch : 1, Step : 3059, Training Loss : 0.07175, Training Acc : 0.983, Run Time : 0.48
INFO:root:2019-05-10 20:15:59, Epoch : 1, Step : 3060, Training Loss : 0.16207, Training Acc : 0.983, Run Time : 0.50
INFO:root:2019-05-10 20:16:13, Epoch : 1, Step : 3061, Training Loss : 0.20195, Training Acc : 0.961, Run Time : 14.29
INFO:root:2019-05-10 20:16:13, Epoch : 1, Step : 3062, Training Loss : 0.22653, Training Acc : 0.922, Run Time : 0.29
INFO:root:2019-05-10 20:16:14, Epoch : 1, Step : 3063, Training Loss : 0.15616, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-10 20:16:14, Epoch : 1, Step : 3064, Training Loss : 0.09397, Training Acc : 0.978, Run Time : 0.47
INFO:root:2019-05-10 20:16:16, Epoch : 1, Step : 3065, Training Loss : 0.24109, Training Acc : 0.883, Run Time : 1.25
INFO:root:2019-05-10 20:16:29, Epoch : 1, Step : 3066, Training Loss : 0.15935, Training Acc : 0.950, Run Time : 13.21
INFO:root:2019-05-10 20:16:29, Epoch : 1, Step : 3067, Training Loss : 0.07501, Training Acc : 0.978, Run Time : 0.30
INFO:root:2019-05-10 20:16:30, Epoch : 1, Step : 3068, Training Loss : 0.53175, Training Acc : 0.817, Run Time : 0.49
INFO:root:2019-05-10 20:16:31, Epoch : 1, Step : 3069, Training Loss : 0.26453, Training Acc : 0.889, Run Time : 1.26
INFO:root:2019-05-10 20:16:32, Epoch : 1, Step : 3070, Training Loss : 0.19767, Training Acc : 0.939, Run Time : 0.91
INFO:root:2019-05-10 20:16:34, Epoch : 1, Step : 3071, Training Loss : 0.13110, Training Acc : 0.939, Run Time : 2.36
INFO:root:2019-05-10 20:16:35, Epoch : 1, Step : 3072, Training Loss : 0.16433, Training Acc : 0.939, Run Time : 0.74
INFO:root:2019-05-10 20:16:50, Epoch : 1, Step : 3073, Training Loss : 0.06885, Training Acc : 0.978, Run Time : 15.57
INFO:root:2019-05-10 20:16:51, Epoch : 1, Step : 3074, Training Loss : 0.14214, Training Acc : 0.967, Run Time : 0.28
INFO:root:2019-05-10 20:16:51, Epoch : 1, Step : 3075, Training Loss : 0.09974, Training Acc : 0.978, Run Time : 0.46
INFO:root:2019-05-10 20:16:52, Epoch : 1, Step : 3076, Training Loss : 0.12043, Training Acc : 0.967, Run Time : 0.48
INFO:root:2019-05-10 20:16:52, Epoch : 1, Step : 3077, Training Loss : 0.22318, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 20:17:08, Epoch : 1, Step : 3078, Training Loss : 0.22668, Training Acc : 0.883, Run Time : 15.82
INFO:root:2019-05-10 20:17:08, Epoch : 1, Step : 3079, Training Loss : 0.20396, Training Acc : 0.911, Run Time : 0.25
INFO:root:2019-05-10 20:17:09, Epoch : 1, Step : 3080, Training Loss : 0.11829, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-10 20:17:09, Epoch : 1, Step : 3081, Training Loss : 0.13734, Training Acc : 0.956, Run Time : 0.48
INFO:root:2019-05-10 20:17:10, Epoch : 1, Step : 3082, Training Loss : 0.15750, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-10 20:17:15, Epoch : 1, Step : 3083, Training Loss : 0.37528, Training Acc : 0.828, Run Time : 5.18
INFO:root:2019-05-10 20:17:15, Epoch : 1, Step : 3084, Training Loss : 0.49572, Training Acc : 0.789, Run Time : 0.44
INFO:root:2019-05-10 20:17:31, Epoch : 1, Step : 3085, Training Loss : 0.20259, Training Acc : 0.917, Run Time : 15.91
INFO:root:2019-05-10 20:17:31, Epoch : 1, Step : 3086, Training Loss : 0.17728, Training Acc : 0.928, Run Time : 0.29
INFO:root:2019-05-10 20:17:32, Epoch : 1, Step : 3087, Training Loss : 0.09411, Training Acc : 0.983, Run Time : 0.47
INFO:root:2019-05-10 20:17:32, Epoch : 1, Step : 3088, Training Loss : 0.07664, Training Acc : 0.983, Run Time : 0.47
INFO:root:2019-05-10 20:17:33, Epoch : 1, Step : 3089, Training Loss : 0.13083, Training Acc : 0.972, Run Time : 0.47
INFO:root:2019-05-10 20:17:48, Epoch : 1, Step : 3090, Training Loss : 0.19197, Training Acc : 0.944, Run Time : 15.48
INFO:root:2019-05-10 20:17:49, Epoch : 1, Step : 3091, Training Loss : 0.11250, Training Acc : 0.950, Run Time : 0.60
INFO:root:2019-05-10 20:17:49, Epoch : 1, Step : 3092, Training Loss : 0.21324, Training Acc : 0.933, Run Time : 0.45
INFO:root:2019-05-10 20:17:50, Epoch : 1, Step : 3093, Training Loss : 0.16123, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 20:17:50, Epoch : 1, Step : 3094, Training Loss : 0.18648, Training Acc : 0.933, Run Time : 0.50
INFO:root:2019-05-10 20:17:54, Epoch : 1, Step : 3095, Training Loss : 0.23972, Training Acc : 0.894, Run Time : 3.61
INFO:root:2019-05-10 20:18:07, Epoch : 1, Step : 3096, Training Loss : 0.39257, Training Acc : 0.861, Run Time : 13.20
INFO:root:2019-05-10 20:18:08, Epoch : 1, Step : 3097, Training Loss : 0.10924, Training Acc : 0.972, Run Time : 0.54
INFO:root:2019-05-10 20:18:08, Epoch : 1, Step : 3098, Training Loss : 0.16831, Training Acc : 0.933, Run Time : 0.45
INFO:root:2019-05-10 20:18:09, Epoch : 1, Step : 3099, Training Loss : 0.13881, Training Acc : 0.944, Run Time : 0.53
INFO:root:2019-05-10 20:18:09, Epoch : 1, Step : 3100, Training Loss : 0.09392, Training Acc : 0.978, Run Time : 0.50
INFO:root:2019-05-10 20:18:26, Epoch : 1, Step : 3101, Training Loss : 0.13323, Training Acc : 0.961, Run Time : 17.25
INFO:root:2019-05-10 20:18:27, Epoch : 1, Step : 3102, Training Loss : 0.12043, Training Acc : 0.944, Run Time : 0.27
INFO:root:2019-05-10 20:18:27, Epoch : 1, Step : 3103, Training Loss : 0.08274, Training Acc : 0.972, Run Time : 0.46
INFO:root:2019-05-10 20:18:29, Epoch : 1, Step : 3104, Training Loss : 0.15577, Training Acc : 0.961, Run Time : 1.49
INFO:root:2019-05-10 20:18:39, Epoch : 1, Step : 3105, Training Loss : 0.13459, Training Acc : 0.950, Run Time : 10.06
INFO:root:2019-05-10 20:18:41, Epoch : 1, Step : 3106, Training Loss : 0.15664, Training Acc : 0.928, Run Time : 2.03
INFO:root:2019-05-10 20:18:41, Epoch : 1, Step : 3107, Training Loss : 0.11437, Training Acc : 0.972, Run Time : 0.24
INFO:root:2019-05-10 20:18:41, Epoch : 1, Step : 3108, Training Loss : 0.14117, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-10 20:18:42, Epoch : 1, Step : 3109, Training Loss : 0.12062, Training Acc : 0.967, Run Time : 0.45
INFO:root:2019-05-10 20:18:43, Epoch : 1, Step : 3110, Training Loss : 0.18224, Training Acc : 0.922, Run Time : 1.25
INFO:root:2019-05-10 20:18:59, Epoch : 1, Step : 3111, Training Loss : 0.07728, Training Acc : 0.989, Run Time : 15.59
INFO:root:2019-05-10 20:18:59, Epoch : 1, Step : 3112, Training Loss : 0.15680, Training Acc : 0.950, Run Time : 0.22
INFO:root:2019-05-10 20:18:59, Epoch : 1, Step : 3113, Training Loss : 0.10751, Training Acc : 0.978, Run Time : 0.42
INFO:root:2019-05-10 20:19:00, Epoch : 1, Step : 3114, Training Loss : 0.10560, Training Acc : 0.961, Run Time : 0.51
INFO:root:2019-05-10 20:19:11, Epoch : 1, Step : 3115, Training Loss : 0.11397, Training Acc : 0.956, Run Time : 11.37
INFO:root:2019-05-10 20:19:12, Epoch : 1, Step : 3116, Training Loss : 0.09967, Training Acc : 0.967, Run Time : 0.54
INFO:root:2019-05-10 20:19:12, Epoch : 1, Step : 3117, Training Loss : 0.12517, Training Acc : 0.967, Run Time : 0.48
INFO:root:2019-05-10 20:19:13, Epoch : 1, Step : 3118, Training Loss : 0.07929, Training Acc : 0.994, Run Time : 0.46
INFO:root:2019-05-10 20:19:14, Epoch : 1, Step : 3119, Training Loss : 0.16872, Training Acc : 0.928, Run Time : 1.53
INFO:root:2019-05-10 20:19:29, Epoch : 1, Step : 3120, Training Loss : 0.15608, Training Acc : 0.944, Run Time : 14.80
INFO:root:2019-05-10 20:19:29, Epoch : 1, Step : 3121, Training Loss : 0.10093, Training Acc : 0.972, Run Time : 0.24
INFO:root:2019-05-10 20:19:30, Epoch : 1, Step : 3122, Training Loss : 0.16174, Training Acc : 0.956, Run Time : 0.58
INFO:root:2019-05-10 20:19:30, Epoch : 1, Step : 3123, Training Loss : 0.06196, Training Acc : 0.989, Run Time : 0.47
INFO:root:2019-05-10 20:19:41, Epoch : 1, Step : 3124, Training Loss : 0.09938, Training Acc : 0.972, Run Time : 10.35
INFO:root:2019-05-10 20:19:41, Epoch : 1, Step : 3125, Training Loss : 0.08422, Training Acc : 0.972, Run Time : 0.69
INFO:root:2019-05-10 20:19:42, Epoch : 1, Step : 3126, Training Loss : 0.15495, Training Acc : 0.939, Run Time : 0.39
INFO:root:2019-05-10 20:19:42, Epoch : 1, Step : 3127, Training Loss : 0.05578, Training Acc : 0.994, Run Time : 0.54
INFO:root:2019-05-10 20:19:43, Epoch : 1, Step : 3128, Training Loss : 0.08740, Training Acc : 0.972, Run Time : 0.45
INFO:root:2019-05-10 20:19:57, Epoch : 1, Step : 3129, Training Loss : 0.12319, Training Acc : 0.967, Run Time : 14.11
INFO:root:2019-05-10 20:19:57, Epoch : 1, Step : 3130, Training Loss : 0.19991, Training Acc : 0.922, Run Time : 0.21
INFO:root:2019-05-10 20:19:58, Epoch : 1, Step : 3131, Training Loss : 0.32776, Training Acc : 0.894, Run Time : 0.87
INFO:root:2019-05-10 20:20:08, Epoch : 1, Step : 3132, Training Loss : 0.20328, Training Acc : 0.933, Run Time : 10.05
INFO:root:2019-05-10 20:20:09, Epoch : 1, Step : 3133, Training Loss : 0.04416, Training Acc : 1.000, Run Time : 0.69
INFO:root:2019-05-10 20:20:09, Epoch : 1, Step : 3134, Training Loss : 0.14443, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-10 20:20:20, Epoch : 1, Step : 3135, Training Loss : 0.38056, Training Acc : 0.828, Run Time : 11.26
INFO:root:2019-05-10 20:20:22, Epoch : 1, Step : 3136, Training Loss : 0.20678, Training Acc : 0.917, Run Time : 1.72
INFO:root:2019-05-10 20:20:23, Epoch : 1, Step : 3137, Training Loss : 0.09417, Training Acc : 0.978, Run Time : 0.47
INFO:root:2019-05-10 20:20:23, Epoch : 1, Step : 3138, Training Loss : 0.36941, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 20:20:24, Epoch : 1, Step : 3139, Training Loss : 0.08928, Training Acc : 0.967, Run Time : 0.47
INFO:root:2019-05-10 20:20:25, Epoch : 1, Step : 3140, Training Loss : 0.19227, Training Acc : 0.939, Run Time : 1.22
INFO:root:2019-05-10 20:20:39, Epoch : 1, Step : 3141, Training Loss : 0.08561, Training Acc : 0.972, Run Time : 14.66
INFO:root:2019-05-10 20:20:40, Epoch : 1, Step : 3142, Training Loss : 0.15027, Training Acc : 0.950, Run Time : 0.30
INFO:root:2019-05-10 20:20:40, Epoch : 1, Step : 3143, Training Loss : 0.11201, Training Acc : 0.956, Run Time : 0.62
INFO:root:2019-05-10 20:20:41, Epoch : 1, Step : 3144, Training Loss : 0.17620, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-10 20:20:41, Epoch : 1, Step : 3145, Training Loss : 0.05723, Training Acc : 0.983, Run Time : 0.49
INFO:root:2019-05-10 20:20:58, Epoch : 1, Step : 3146, Training Loss : 0.18388, Training Acc : 0.950, Run Time : 17.05
INFO:root:2019-05-10 20:20:59, Epoch : 1, Step : 3147, Training Loss : 0.07095, Training Acc : 0.978, Run Time : 0.49
INFO:root:2019-05-10 20:20:59, Epoch : 1, Step : 3148, Training Loss : 0.07374, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-10 20:21:00, Epoch : 1, Step : 3149, Training Loss : 0.15754, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 20:21:00, Epoch : 1, Step : 3150, Training Loss : 0.10672, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-10 20:21:19, Epoch : 1, Step : 3151, Training Loss : 0.08339, Training Acc : 0.972, Run Time : 18.76
INFO:root:2019-05-10 20:21:20, Epoch : 1, Step : 3152, Training Loss : 0.06317, Training Acc : 0.972, Run Time : 0.51
INFO:root:2019-05-10 20:21:20, Epoch : 1, Step : 3153, Training Loss : 0.04226, Training Acc : 0.994, Run Time : 0.46
INFO:root:2019-05-10 20:21:20, Epoch : 1, Step : 3154, Training Loss : 0.07759, Training Acc : 0.983, Run Time : 0.49
INFO:root:2019-05-10 20:21:21, Epoch : 1, Step : 3155, Training Loss : 0.03574, Training Acc : 0.989, Run Time : 0.52
INFO:root:2019-05-10 20:21:26, Epoch : 1, Step : 3156, Training Loss : 0.03373, Training Acc : 0.989, Run Time : 4.71
INFO:root:2019-05-10 20:21:35, Epoch : 1, Step : 3157, Training Loss : 0.06041, Training Acc : 0.983, Run Time : 9.07
INFO:root:2019-05-10 20:21:36, Epoch : 1, Step : 3158, Training Loss : 0.03352, Training Acc : 0.994, Run Time : 1.07
INFO:root:2019-05-10 20:21:45, Epoch : 1, Step : 3159, Training Loss : 0.13144, Training Acc : 0.933, Run Time : 9.28
INFO:root:2019-05-10 20:21:46, Epoch : 1, Step : 3160, Training Loss : 0.08826, Training Acc : 0.967, Run Time : 0.39
INFO:root:2019-05-10 20:21:46, Epoch : 1, Step : 3161, Training Loss : 0.04781, Training Acc : 0.983, Run Time : 0.43
INFO:root:2019-05-10 20:21:58, Epoch : 1, Step : 3162, Training Loss : 0.06519, Training Acc : 0.983, Run Time : 11.80
INFO:root:2019-05-10 20:21:58, Epoch : 1, Step : 3163, Training Loss : 0.09147, Training Acc : 0.967, Run Time : 0.23
INFO:root:2019-05-10 20:21:58, Epoch : 1, Step : 3164, Training Loss : 0.08726, Training Acc : 0.967, Run Time : 0.45
INFO:root:2019-05-10 20:21:59, Epoch : 1, Step : 3165, Training Loss : 0.07288, Training Acc : 0.967, Run Time : 0.49
INFO:root:2019-05-10 20:21:59, Epoch : 1, Step : 3166, Training Loss : 0.05397, Training Acc : 0.989, Run Time : 0.47
INFO:root:2019-05-10 20:22:13, Epoch : 1, Step : 3167, Training Loss : 0.04604, Training Acc : 0.978, Run Time : 13.92
INFO:root:2019-05-10 20:22:14, Epoch : 1, Step : 3168, Training Loss : 0.01766, Training Acc : 0.994, Run Time : 0.53
INFO:root:2019-05-10 20:22:14, Epoch : 1, Step : 3169, Training Loss : 0.10102, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-10 20:22:15, Epoch : 1, Step : 3170, Training Loss : 0.02236, Training Acc : 1.000, Run Time : 0.47
INFO:root:2019-05-10 20:22:15, Epoch : 1, Step : 3171, Training Loss : 0.05248, Training Acc : 0.983, Run Time : 0.52
INFO:root:2019-05-10 20:22:33, Epoch : 1, Step : 3172, Training Loss : 0.01775, Training Acc : 1.000, Run Time : 17.74
INFO:root:2019-05-10 20:22:34, Epoch : 1, Step : 3173, Training Loss : 0.02631, Training Acc : 1.000, Run Time : 0.89
INFO:root:2019-05-10 20:22:34, Epoch : 1, Step : 3174, Training Loss : 0.07340, Training Acc : 0.978, Run Time : 0.45
INFO:root:2019-05-10 20:22:35, Epoch : 1, Step : 3175, Training Loss : 0.02604, Training Acc : 1.000, Run Time : 0.45
INFO:root:2019-05-10 20:22:35, Epoch : 1, Step : 3176, Training Loss : 0.06590, Training Acc : 0.983, Run Time : 0.59
INFO:root:2019-05-10 20:22:52, Epoch : 1, Step : 3177, Training Loss : 0.09893, Training Acc : 0.967, Run Time : 17.00
INFO:root:2019-05-10 20:22:53, Epoch : 1, Step : 3178, Training Loss : 0.08164, Training Acc : 0.972, Run Time : 0.32
INFO:root:2019-05-10 20:22:53, Epoch : 1, Step : 3179, Training Loss : 0.05007, Training Acc : 0.978, Run Time : 0.42
INFO:root:2019-05-10 20:22:54, Epoch : 1, Step : 3180, Training Loss : 0.10467, Training Acc : 0.972, Run Time : 0.72
INFO:root:2019-05-10 20:22:54, Epoch : 1, Step : 3181, Training Loss : 0.14817, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-10 20:23:11, Epoch : 1, Step : 3182, Training Loss : 0.55767, Training Acc : 0.772, Run Time : 16.38
INFO:root:2019-05-10 20:23:11, Epoch : 1, Step : 3183, Training Loss : 0.25761, Training Acc : 0.906, Run Time : 0.30
INFO:root:2019-05-10 20:23:11, Epoch : 1, Step : 3184, Training Loss : 0.28661, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-10 20:23:23, Epoch : 1, Step : 3185, Training Loss : 0.08890, Training Acc : 0.972, Run Time : 11.44
INFO:root:2019-05-10 20:23:23, Epoch : 1, Step : 3186, Training Loss : 0.09434, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-10 20:23:24, Epoch : 1, Step : 3187, Training Loss : 0.04212, Training Acc : 0.989, Run Time : 0.76
INFO:root:2019-05-10 20:23:35, Epoch : 1, Step : 3188, Training Loss : 0.17578, Training Acc : 0.922, Run Time : 10.55
INFO:root:2019-05-10 20:23:36, Epoch : 1, Step : 3189, Training Loss : 0.14821, Training Acc : 0.967, Run Time : 0.85
INFO:root:2019-05-10 20:23:37, Epoch : 1, Step : 3190, Training Loss : 0.12910, Training Acc : 0.944, Run Time : 1.26
INFO:root:2019-05-10 20:23:47, Epoch : 1, Step : 3191, Training Loss : 0.09902, Training Acc : 0.967, Run Time : 10.25
INFO:root:2019-05-10 20:23:47, Epoch : 1, Step : 3192, Training Loss : 0.19519, Training Acc : 0.939, Run Time : 0.42
INFO:root:2019-05-10 20:23:48, Epoch : 1, Step : 3193, Training Loss : 0.12019, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-10 20:23:48, Epoch : 1, Step : 3194, Training Loss : 0.26309, Training Acc : 0.900, Run Time : 0.51
INFO:root:2019-05-10 20:23:49, Epoch : 1, Step : 3195, Training Loss : 0.37499, Training Acc : 0.883, Run Time : 0.50
INFO:root:2019-05-10 20:24:02, Epoch : 1, Step : 3196, Training Loss : 0.26704, Training Acc : 0.922, Run Time : 13.45
INFO:root:2019-05-10 20:24:03, Epoch : 1, Step : 3197, Training Loss : 0.27340, Training Acc : 0.922, Run Time : 0.32
INFO:root:2019-05-10 20:24:03, Epoch : 1, Step : 3198, Training Loss : 0.17087, Training Acc : 0.956, Run Time : 0.63
INFO:root:2019-05-10 20:24:04, Epoch : 1, Step : 3199, Training Loss : 0.27911, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 20:24:04, Epoch : 1, Step : 3200, Training Loss : 0.46820, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-10 20:24:19, Epoch : 1, Step : 3201, Training Loss : 1.25712, Training Acc : 0.661, Run Time : 14.32
INFO:root:2019-05-10 20:24:19, Epoch : 1, Step : 3202, Training Loss : 0.99726, Training Acc : 0.656, Run Time : 0.25
INFO:root:2019-05-10 20:24:19, Epoch : 1, Step : 3203, Training Loss : 0.90168, Training Acc : 0.689, Run Time : 0.31
INFO:root:2019-05-10 20:24:20, Epoch : 1, Step : 3204, Training Loss : 0.80240, Training Acc : 0.689, Run Time : 0.49
INFO:root:2019-05-10 20:24:20, Epoch : 1, Step : 3205, Training Loss : 0.64016, Training Acc : 0.739, Run Time : 0.49
INFO:root:2019-05-10 20:24:25, Epoch : 1, Step : 3206, Training Loss : 0.48669, Training Acc : 0.783, Run Time : 4.49
INFO:root:2019-05-10 20:24:25, Epoch : 1, Step : 3207, Training Loss : 0.42985, Training Acc : 0.800, Run Time : 0.49
INFO:root:2019-05-10 20:24:40, Epoch : 1, Step : 3208, Training Loss : 0.25526, Training Acc : 0.878, Run Time : 15.06
INFO:root:2019-05-10 20:24:40, Epoch : 1, Step : 3209, Training Loss : 0.34193, Training Acc : 0.828, Run Time : 0.26
INFO:root:2019-05-10 20:24:41, Epoch : 1, Step : 3210, Training Loss : 0.23393, Training Acc : 0.867, Run Time : 0.42
INFO:root:2019-05-10 20:24:41, Epoch : 1, Step : 3211, Training Loss : 0.20206, Training Acc : 0.928, Run Time : 0.37
INFO:root:2019-05-10 20:24:42, Epoch : 1, Step : 3212, Training Loss : 0.15885, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 20:24:56, Epoch : 1, Step : 3213, Training Loss : 0.18943, Training Acc : 0.939, Run Time : 14.15
INFO:root:2019-05-10 20:24:56, Epoch : 1, Step : 3214, Training Loss : 0.17213, Training Acc : 0.939, Run Time : 0.31
INFO:root:2019-05-10 20:24:57, Epoch : 1, Step : 3215, Training Loss : 0.23797, Training Acc : 0.922, Run Time : 0.52
INFO:root:2019-05-10 20:24:57, Epoch : 1, Step : 3216, Training Loss : 0.18512, Training Acc : 0.922, Run Time : 0.50
INFO:root:2019-05-10 20:24:59, Epoch : 1, Step : 3217, Training Loss : 0.20573, Training Acc : 0.933, Run Time : 2.28
INFO:root:2019-05-10 20:25:02, Epoch : 1, Step : 3218, Training Loss : 0.17505, Training Acc : 0.933, Run Time : 2.42
INFO:root:2019-05-10 20:25:02, Epoch : 1, Step : 3219, Training Loss : 0.25727, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 20:25:16, Epoch : 1, Step : 3220, Training Loss : 0.20950, Training Acc : 0.917, Run Time : 13.26
INFO:root:2019-05-10 20:25:16, Epoch : 1, Step : 3221, Training Loss : 0.21738, Training Acc : 0.917, Run Time : 0.24
INFO:root:2019-05-10 20:25:16, Epoch : 1, Step : 3222, Training Loss : 0.20089, Training Acc : 0.917, Run Time : 0.56
INFO:root:2019-05-10 20:25:17, Epoch : 1, Step : 3223, Training Loss : 0.20246, Training Acc : 0.922, Run Time : 0.51
INFO:root:2019-05-10 20:25:17, Epoch : 1, Step : 3224, Training Loss : 0.18413, Training Acc : 0.928, Run Time : 0.49
INFO:root:2019-05-10 20:25:34, Epoch : 1, Step : 3225, Training Loss : 0.22145, Training Acc : 0.911, Run Time : 16.37
INFO:root:2019-05-10 20:25:34, Epoch : 1, Step : 3226, Training Loss : 0.19125, Training Acc : 0.928, Run Time : 0.35
INFO:root:2019-05-10 20:25:35, Epoch : 1, Step : 3227, Training Loss : 0.24324, Training Acc : 0.917, Run Time : 0.60
INFO:root:2019-05-10 20:25:46, Epoch : 1, Step : 3228, Training Loss : 0.16952, Training Acc : 0.922, Run Time : 11.06
INFO:root:2019-05-10 20:25:47, Epoch : 1, Step : 3229, Training Loss : 0.22349, Training Acc : 0.928, Run Time : 1.61
INFO:root:2019-05-10 20:25:59, Epoch : 1, Step : 3230, Training Loss : 0.34041, Training Acc : 0.906, Run Time : 11.65
INFO:root:2019-05-10 20:25:59, Epoch : 1, Step : 3231, Training Loss : 0.18923, Training Acc : 0.944, Run Time : 0.22
INFO:root:2019-05-10 20:26:01, Epoch : 1, Step : 3232, Training Loss : 0.19623, Training Acc : 0.933, Run Time : 1.31
INFO:root:2019-05-10 20:26:01, Epoch : 1, Step : 3233, Training Loss : 0.15559, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-10 20:26:01, Epoch : 1, Step : 3234, Training Loss : 0.13532, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-10 20:26:16, Epoch : 1, Step : 3235, Training Loss : 0.16095, Training Acc : 0.906, Run Time : 14.92
INFO:root:2019-05-10 20:26:17, Epoch : 1, Step : 3236, Training Loss : 0.10637, Training Acc : 0.944, Run Time : 0.58
INFO:root:2019-05-10 20:26:18, Epoch : 1, Step : 3237, Training Loss : 0.14906, Training Acc : 0.928, Run Time : 0.65
INFO:root:2019-05-10 20:26:18, Epoch : 1, Step : 3238, Training Loss : 0.18411, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-10 20:26:20, Epoch : 1, Step : 3239, Training Loss : 0.10867, Training Acc : 0.933, Run Time : 1.67
INFO:root:2019-05-10 20:26:24, Epoch : 1, Step : 3240, Training Loss : 0.15752, Training Acc : 0.944, Run Time : 4.48
INFO:root:2019-05-10 20:26:25, Epoch : 1, Step : 3241, Training Loss : 0.11869, Training Acc : 0.944, Run Time : 0.51
INFO:root:2019-05-10 20:26:40, Epoch : 1, Step : 3242, Training Loss : 0.16975, Training Acc : 0.933, Run Time : 15.64
INFO:root:2019-05-10 20:26:41, Epoch : 1, Step : 3243, Training Loss : 0.20119, Training Acc : 0.906, Run Time : 0.30
INFO:root:2019-05-10 20:26:41, Epoch : 1, Step : 3244, Training Loss : 0.12218, Training Acc : 0.928, Run Time : 0.26
INFO:root:2019-05-10 20:26:41, Epoch : 1, Step : 3245, Training Loss : 0.13182, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 20:26:42, Epoch : 1, Step : 3246, Training Loss : 0.20877, Training Acc : 0.950, Run Time : 0.50
INFO:root:2019-05-10 20:26:58, Epoch : 1, Step : 3247, Training Loss : 0.14321, Training Acc : 0.939, Run Time : 15.75
INFO:root:2019-05-10 20:26:58, Epoch : 1, Step : 3248, Training Loss : 0.16135, Training Acc : 0.928, Run Time : 0.88
INFO:root:2019-05-10 20:27:09, Epoch : 1, Step : 3249, Training Loss : 0.16271, Training Acc : 0.922, Run Time : 10.04
INFO:root:2019-05-10 20:27:10, Epoch : 1, Step : 3250, Training Loss : 0.15685, Training Acc : 0.922, Run Time : 1.12
INFO:root:2019-05-10 20:27:21, Epoch : 1, Step : 3251, Training Loss : 0.17826, Training Acc : 0.933, Run Time : 11.49
INFO:root:2019-05-10 20:27:22, Epoch : 1, Step : 3252, Training Loss : 0.20258, Training Acc : 0.922, Run Time : 1.24
INFO:root:2019-05-10 20:27:23, Epoch : 1, Step : 3253, Training Loss : 0.12252, Training Acc : 0.922, Run Time : 0.45
INFO:root:2019-05-10 20:27:24, Epoch : 1, Step : 3254, Training Loss : 0.21761, Training Acc : 0.911, Run Time : 1.12
INFO:root:2019-05-10 20:27:34, Epoch : 1, Step : 3255, Training Loss : 0.19962, Training Acc : 0.922, Run Time : 10.28
INFO:root:2019-05-10 20:27:35, Epoch : 1, Step : 3256, Training Loss : 0.20640, Training Acc : 0.900, Run Time : 0.64
INFO:root:2019-05-10 20:27:35, Epoch : 1, Step : 3257, Training Loss : 0.18593, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 20:27:36, Epoch : 1, Step : 3258, Training Loss : 0.20812, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 20:27:46, Epoch : 1, Step : 3259, Training Loss : 0.17999, Training Acc : 0.928, Run Time : 10.12
INFO:root:2019-05-10 20:27:47, Epoch : 1, Step : 3260, Training Loss : 0.15602, Training Acc : 0.939, Run Time : 1.27
INFO:root:2019-05-10 20:27:59, Epoch : 1, Step : 3261, Training Loss : 0.18865, Training Acc : 0.928, Run Time : 11.48
INFO:root:2019-05-10 20:28:00, Epoch : 1, Step : 3262, Training Loss : 0.18905, Training Acc : 0.928, Run Time : 1.10
INFO:root:2019-05-10 20:28:00, Epoch : 1, Step : 3263, Training Loss : 0.19684, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-10 20:28:01, Epoch : 1, Step : 3264, Training Loss : 0.20305, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-10 20:28:02, Epoch : 1, Step : 3265, Training Loss : 0.25686, Training Acc : 0.872, Run Time : 1.73
INFO:root:2019-05-10 20:28:16, Epoch : 1, Step : 3266, Training Loss : 0.20154, Training Acc : 0.911, Run Time : 13.94
INFO:root:2019-05-10 20:28:17, Epoch : 1, Step : 3267, Training Loss : 0.23629, Training Acc : 0.883, Run Time : 0.67
INFO:root:2019-05-10 20:28:17, Epoch : 1, Step : 3268, Training Loss : 0.19198, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-10 20:28:27, Epoch : 1, Step : 3269, Training Loss : 0.18348, Training Acc : 0.928, Run Time : 9.93
INFO:root:2019-05-10 20:28:28, Epoch : 1, Step : 3270, Training Loss : 0.21312, Training Acc : 0.889, Run Time : 0.93
INFO:root:2019-05-10 20:28:29, Epoch : 1, Step : 3271, Training Loss : 0.13986, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 20:28:32, Epoch : 1, Step : 3272, Training Loss : 0.15575, Training Acc : 0.911, Run Time : 2.78
INFO:root:2019-05-10 20:28:38, Epoch : 1, Step : 3273, Training Loss : 0.14684, Training Acc : 0.928, Run Time : 6.65
INFO:root:2019-05-10 20:28:42, Epoch : 1, Step : 3274, Training Loss : 0.15238, Training Acc : 0.917, Run Time : 4.12
INFO:root:2019-05-10 20:28:43, Epoch : 1, Step : 3275, Training Loss : 0.13635, Training Acc : 0.939, Run Time : 0.56
INFO:root:2019-05-10 20:28:43, Epoch : 1, Step : 3276, Training Loss : 0.14536, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-10 20:28:44, Epoch : 1, Step : 3277, Training Loss : 0.19417, Training Acc : 0.878, Run Time : 0.59
INFO:root:2019-05-10 20:28:55, Epoch : 1, Step : 3278, Training Loss : 0.19700, Training Acc : 0.889, Run Time : 10.94
INFO:root:2019-05-10 20:28:56, Epoch : 1, Step : 3279, Training Loss : 0.19070, Training Acc : 0.894, Run Time : 0.71
INFO:root:2019-05-10 20:28:57, Epoch : 1, Step : 3280, Training Loss : 0.17500, Training Acc : 0.911, Run Time : 1.16
INFO:root:2019-05-10 20:29:05, Epoch : 1, Step : 3281, Training Loss : 0.15923, Training Acc : 0.917, Run Time : 8.69
INFO:root:2019-05-10 20:29:06, Epoch : 1, Step : 3282, Training Loss : 0.16302, Training Acc : 0.939, Run Time : 0.34
INFO:root:2019-05-10 20:29:07, Epoch : 1, Step : 3283, Training Loss : 0.16952, Training Acc : 0.917, Run Time : 1.68
INFO:root:2019-05-10 20:29:08, Epoch : 1, Step : 3284, Training Loss : 0.16062, Training Acc : 0.911, Run Time : 0.59
INFO:root:2019-05-10 20:29:09, Epoch : 1, Step : 3285, Training Loss : 0.13268, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-10 20:29:24, Epoch : 1, Step : 3286, Training Loss : 0.15053, Training Acc : 0.917, Run Time : 15.23
INFO:root:2019-05-10 20:29:24, Epoch : 1, Step : 3287, Training Loss : 0.12440, Training Acc : 0.950, Run Time : 0.41
INFO:root:2019-05-10 20:29:25, Epoch : 1, Step : 3288, Training Loss : 0.13382, Training Acc : 0.939, Run Time : 0.57
INFO:root:2019-05-10 20:29:26, Epoch : 1, Step : 3289, Training Loss : 0.11549, Training Acc : 0.967, Run Time : 1.12
INFO:root:2019-05-10 20:29:37, Epoch : 1, Step : 3290, Training Loss : 0.15271, Training Acc : 0.933, Run Time : 11.37
INFO:root:2019-05-10 20:29:37, Epoch : 1, Step : 3291, Training Loss : 0.14967, Training Acc : 0.944, Run Time : 0.22
INFO:root:2019-05-10 20:29:38, Epoch : 1, Step : 3292, Training Loss : 0.14555, Training Acc : 0.917, Run Time : 0.48
INFO:root:2019-05-10 20:29:38, Epoch : 1, Step : 3293, Training Loss : 0.11041, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 20:29:49, Epoch : 1, Step : 3294, Training Loss : 0.15321, Training Acc : 0.911, Run Time : 10.87
INFO:root:2019-05-10 20:29:50, Epoch : 1, Step : 3295, Training Loss : 0.12543, Training Acc : 0.950, Run Time : 0.80
INFO:root:2019-05-10 20:29:51, Epoch : 1, Step : 3296, Training Loss : 0.13210, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 20:29:51, Epoch : 1, Step : 3297, Training Loss : 0.16502, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-10 20:29:51, Epoch : 1, Step : 3298, Training Loss : 0.12484, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 20:30:05, Epoch : 1, Step : 3299, Training Loss : 0.12045, Training Acc : 0.939, Run Time : 13.69
INFO:root:2019-05-10 20:30:06, Epoch : 1, Step : 3300, Training Loss : 0.11896, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-10 20:30:16, Epoch : 1, Step : 3301, Training Loss : 0.09637, Training Acc : 0.972, Run Time : 10.73
INFO:root:2019-05-10 20:30:17, Epoch : 1, Step : 3302, Training Loss : 0.13243, Training Acc : 0.950, Run Time : 0.30
INFO:root:2019-05-10 20:30:17, Epoch : 1, Step : 3303, Training Loss : 0.11142, Training Acc : 0.950, Run Time : 0.41
INFO:root:2019-05-10 20:30:18, Epoch : 1, Step : 3304, Training Loss : 0.12298, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 20:30:20, Epoch : 1, Step : 3305, Training Loss : 0.13646, Training Acc : 0.939, Run Time : 2.26
INFO:root:2019-05-10 20:30:32, Epoch : 1, Step : 3306, Training Loss : 0.08893, Training Acc : 0.972, Run Time : 12.52
INFO:root:2019-05-10 20:30:33, Epoch : 1, Step : 3307, Training Loss : 0.12968, Training Acc : 0.967, Run Time : 0.72
INFO:root:2019-05-10 20:30:34, Epoch : 1, Step : 3308, Training Loss : 0.13036, Training Acc : 0.972, Run Time : 0.49
INFO:root:2019-05-10 20:30:34, Epoch : 1, Step : 3309, Training Loss : 0.11567, Training Acc : 0.967, Run Time : 0.49
INFO:root:2019-05-10 20:30:35, Epoch : 1, Step : 3310, Training Loss : 0.12299, Training Acc : 0.961, Run Time : 0.75
INFO:root:2019-05-10 20:30:53, Epoch : 1, Step : 3311, Training Loss : 0.14364, Training Acc : 0.944, Run Time : 18.31
INFO:root:2019-05-10 20:30:53, Epoch : 1, Step : 3312, Training Loss : 0.11994, Training Acc : 0.972, Run Time : 0.38
INFO:root:2019-05-10 20:30:54, Epoch : 1, Step : 3313, Training Loss : 0.14162, Training Acc : 0.944, Run Time : 0.43
INFO:root:2019-05-10 20:30:55, Epoch : 1, Step : 3314, Training Loss : 0.10033, Training Acc : 0.983, Run Time : 0.63
INFO:root:2019-05-10 20:30:55, Epoch : 1, Step : 3315, Training Loss : 0.09847, Training Acc : 0.972, Run Time : 0.49
INFO:root:2019-05-10 20:31:11, Epoch : 1, Step : 3316, Training Loss : 0.13147, Training Acc : 0.950, Run Time : 16.32
INFO:root:2019-05-10 20:31:12, Epoch : 1, Step : 3317, Training Loss : 0.10492, Training Acc : 0.967, Run Time : 0.60
INFO:root:2019-05-10 20:31:12, Epoch : 1, Step : 3318, Training Loss : 0.11268, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-10 20:31:13, Epoch : 1, Step : 3319, Training Loss : 0.10520, Training Acc : 0.978, Run Time : 0.48
INFO:root:2019-05-10 20:31:13, Epoch : 1, Step : 3320, Training Loss : 0.27451, Training Acc : 0.844, Run Time : 0.48
INFO:root:2019-05-10 20:31:30, Epoch : 1, Step : 3321, Training Loss : 0.19171, Training Acc : 0.906, Run Time : 16.80
INFO:root:2019-05-10 20:31:30, Epoch : 1, Step : 3322, Training Loss : 0.10176, Training Acc : 0.967, Run Time : 0.23
INFO:root:2019-05-10 20:31:31, Epoch : 1, Step : 3323, Training Loss : 0.15742, Training Acc : 0.961, Run Time : 0.25
INFO:root:2019-05-10 20:31:31, Epoch : 1, Step : 3324, Training Loss : 0.10136, Training Acc : 0.972, Run Time : 0.48
INFO:root:2019-05-10 20:31:32, Epoch : 1, Step : 3325, Training Loss : 0.09336, Training Acc : 0.972, Run Time : 0.50
INFO:root:2019-05-10 20:31:49, Epoch : 1, Step : 3326, Training Loss : 0.14718, Training Acc : 0.961, Run Time : 17.31
INFO:root:2019-05-10 20:31:49, Epoch : 1, Step : 3327, Training Loss : 0.08646, Training Acc : 0.961, Run Time : 0.22
INFO:root:2019-05-10 20:31:50, Epoch : 1, Step : 3328, Training Loss : 0.11035, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-10 20:31:50, Epoch : 1, Step : 3329, Training Loss : 0.10512, Training Acc : 0.961, Run Time : 0.49
INFO:root:2019-05-10 20:32:01, Epoch : 1, Step : 3330, Training Loss : 0.14857, Training Acc : 0.917, Run Time : 10.73
INFO:root:2019-05-10 20:32:02, Epoch : 1, Step : 3331, Training Loss : 0.09288, Training Acc : 0.972, Run Time : 1.04
INFO:root:2019-05-10 20:32:02, Epoch : 1, Step : 3332, Training Loss : 0.09089, Training Acc : 0.972, Run Time : 0.44
INFO:root:2019-05-10 20:32:03, Epoch : 1, Step : 3333, Training Loss : 0.12118, Training Acc : 0.967, Run Time : 0.53
INFO:root:2019-05-10 20:32:14, Epoch : 1, Step : 3334, Training Loss : 0.12922, Training Acc : 0.950, Run Time : 10.96
INFO:root:2019-05-10 20:32:14, Epoch : 1, Step : 3335, Training Loss : 0.11380, Training Acc : 0.967, Run Time : 0.54
INFO:root:2019-05-10 20:32:15, Epoch : 1, Step : 3336, Training Loss : 0.10756, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-10 20:32:15, Epoch : 1, Step : 3337, Training Loss : 0.09166, Training Acc : 0.972, Run Time : 0.50
INFO:root:2019-05-10 20:32:16, Epoch : 1, Step : 3338, Training Loss : 0.10242, Training Acc : 0.956, Run Time : 0.46
INFO:root:2019-05-10 20:32:32, Epoch : 1, Step : 3339, Training Loss : 0.11769, Training Acc : 0.961, Run Time : 16.17
INFO:root:2019-05-10 20:32:32, Epoch : 1, Step : 3340, Training Loss : 0.09217, Training Acc : 0.978, Run Time : 0.31
INFO:root:2019-05-10 20:32:33, Epoch : 1, Step : 3341, Training Loss : 0.11476, Training Acc : 0.944, Run Time : 0.49
INFO:root:2019-05-10 20:32:34, Epoch : 1, Step : 3342, Training Loss : 0.11203, Training Acc : 0.950, Run Time : 1.07
INFO:root:2019-05-10 20:32:44, Epoch : 1, Step : 3343, Training Loss : 0.11747, Training Acc : 0.961, Run Time : 10.67
INFO:root:2019-05-10 20:32:45, Epoch : 1, Step : 3344, Training Loss : 0.14247, Training Acc : 0.944, Run Time : 0.81
INFO:root:2019-05-10 20:32:46, Epoch : 1, Step : 3345, Training Loss : 0.15291, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-10 20:32:56, Epoch : 1, Step : 3346, Training Loss : 0.15496, Training Acc : 0.939, Run Time : 10.36
INFO:root:2019-05-10 20:32:57, Epoch : 1, Step : 3347, Training Loss : 0.11685, Training Acc : 0.972, Run Time : 0.45
INFO:root:2019-05-10 20:32:57, Epoch : 1, Step : 3348, Training Loss : 0.12966, Training Acc : 0.928, Run Time : 0.43
INFO:root:2019-05-10 20:32:57, Epoch : 1, Step : 3349, Training Loss : 0.14067, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 20:32:58, Epoch : 1, Step : 3350, Training Loss : 0.13716, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 20:33:13, Epoch : 1, Step : 3351, Training Loss : 0.11026, Training Acc : 0.972, Run Time : 15.15
INFO:root:2019-05-10 20:33:14, Epoch : 1, Step : 3352, Training Loss : 0.13958, Training Acc : 0.939, Run Time : 0.55
INFO:root:2019-05-10 20:33:14, Epoch : 1, Step : 3353, Training Loss : 0.13394, Training Acc : 0.944, Run Time : 0.49
INFO:root:2019-05-10 20:33:15, Epoch : 1, Step : 3354, Training Loss : 0.11348, Training Acc : 0.978, Run Time : 0.49
INFO:root:2019-05-10 20:33:15, Epoch : 1, Step : 3355, Training Loss : 0.12801, Training Acc : 0.956, Run Time : 0.64
INFO:root:2019-05-10 20:33:32, Epoch : 1, Step : 3356, Training Loss : 0.14992, Training Acc : 0.928, Run Time : 16.88
INFO:root:2019-05-10 20:33:33, Epoch : 1, Step : 3357, Training Loss : 0.15131, Training Acc : 0.944, Run Time : 0.76
INFO:root:2019-05-10 20:33:34, Epoch : 1, Step : 3358, Training Loss : 0.12854, Training Acc : 0.950, Run Time : 0.79
INFO:root:2019-05-10 20:33:34, Epoch : 1, Step : 3359, Training Loss : 0.14782, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-10 20:33:35, Epoch : 1, Step : 3360, Training Loss : 0.16032, Training Acc : 0.911, Run Time : 0.49
INFO:root:2019-05-10 20:33:48, Epoch : 1, Step : 3361, Training Loss : 0.13430, Training Acc : 0.939, Run Time : 13.62
INFO:root:2019-05-10 20:33:49, Epoch : 1, Step : 3362, Training Loss : 0.10045, Training Acc : 0.967, Run Time : 0.23
INFO:root:2019-05-10 20:33:49, Epoch : 1, Step : 3363, Training Loss : 0.12615, Training Acc : 0.933, Run Time : 0.43
INFO:root:2019-05-10 20:33:50, Epoch : 1, Step : 3364, Training Loss : 0.11661, Training Acc : 0.950, Run Time : 1.53
INFO:root:2019-05-10 20:33:51, Epoch : 1, Step : 3365, Training Loss : 0.14577, Training Acc : 0.917, Run Time : 0.50
INFO:root:2019-05-10 20:34:06, Epoch : 1, Step : 3366, Training Loss : 0.10692, Training Acc : 0.967, Run Time : 15.31
INFO:root:2019-05-10 20:34:07, Epoch : 1, Step : 3367, Training Loss : 0.10677, Training Acc : 0.978, Run Time : 0.41
INFO:root:2019-05-10 20:34:07, Epoch : 1, Step : 3368, Training Loss : 0.15947, Training Acc : 0.933, Run Time : 0.34
INFO:root:2019-05-10 20:34:07, Epoch : 1, Step : 3369, Training Loss : 0.13288, Training Acc : 0.944, Run Time : 0.41
INFO:root:2019-05-10 20:34:08, Epoch : 1, Step : 3370, Training Loss : 0.17015, Training Acc : 0.928, Run Time : 0.51
INFO:root:2019-05-10 20:34:20, Epoch : 1, Step : 3371, Training Loss : 0.10667, Training Acc : 0.961, Run Time : 11.53
INFO:root:2019-05-10 20:34:22, Epoch : 1, Step : 3372, Training Loss : 0.13632, Training Acc : 0.956, Run Time : 2.67
INFO:root:2019-05-10 20:34:24, Epoch : 1, Step : 3373, Training Loss : 0.16598, Training Acc : 0.906, Run Time : 1.75
INFO:root:2019-05-10 20:34:24, Epoch : 1, Step : 3374, Training Loss : 0.17080, Training Acc : 0.933, Run Time : 0.45
INFO:root:2019-05-10 20:34:25, Epoch : 1, Step : 3375, Training Loss : 0.10788, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-10 20:34:25, Epoch : 1, Step : 3376, Training Loss : 0.14876, Training Acc : 0.950, Run Time : 0.61
INFO:root:2019-05-10 20:34:41, Epoch : 1, Step : 3377, Training Loss : 0.14813, Training Acc : 0.933, Run Time : 15.88
INFO:root:2019-05-10 20:34:42, Epoch : 1, Step : 3378, Training Loss : 0.12641, Training Acc : 0.950, Run Time : 0.26
INFO:root:2019-05-10 20:34:42, Epoch : 1, Step : 3379, Training Loss : 0.14422, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-10 20:34:43, Epoch : 1, Step : 3380, Training Loss : 0.14336, Training Acc : 0.956, Run Time : 0.55
INFO:root:2019-05-10 20:34:43, Epoch : 1, Step : 3381, Training Loss : 0.10167, Training Acc : 0.967, Run Time : 0.64
INFO:root:2019-05-10 20:35:00, Epoch : 1, Step : 3382, Training Loss : 0.16755, Training Acc : 0.933, Run Time : 16.76
INFO:root:2019-05-10 20:35:00, Epoch : 1, Step : 3383, Training Loss : 0.10594, Training Acc : 0.961, Run Time : 0.22
INFO:root:2019-05-10 20:35:01, Epoch : 1, Step : 3384, Training Loss : 0.10309, Training Acc : 0.961, Run Time : 0.61
INFO:root:2019-05-10 20:35:01, Epoch : 1, Step : 3385, Training Loss : 0.14300, Training Acc : 0.933, Run Time : 0.47
INFO:root:2019-05-10 20:35:02, Epoch : 1, Step : 3386, Training Loss : 0.15924, Training Acc : 0.917, Run Time : 0.59
INFO:root:2019-05-10 20:35:17, Epoch : 1, Step : 3387, Training Loss : 0.16582, Training Acc : 0.917, Run Time : 15.31
INFO:root:2019-05-10 20:35:17, Epoch : 1, Step : 3388, Training Loss : 0.14670, Training Acc : 0.939, Run Time : 0.22
INFO:root:2019-05-10 20:35:18, Epoch : 1, Step : 3389, Training Loss : 0.17360, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-10 20:35:18, Epoch : 1, Step : 3390, Training Loss : 0.14145, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-10 20:35:30, Epoch : 1, Step : 3391, Training Loss : 0.14750, Training Acc : 0.950, Run Time : 11.39
INFO:root:2019-05-10 20:35:32, Epoch : 1, Step : 3392, Training Loss : 0.19708, Training Acc : 0.911, Run Time : 2.70
INFO:root:2019-05-10 20:35:33, Epoch : 1, Step : 3393, Training Loss : 0.23170, Training Acc : 0.900, Run Time : 0.50
INFO:root:2019-05-10 20:35:33, Epoch : 1, Step : 3394, Training Loss : 0.16143, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-10 20:35:34, Epoch : 1, Step : 3395, Training Loss : 0.16245, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 20:35:34, Epoch : 1, Step : 3396, Training Loss : 0.13116, Training Acc : 0.928, Run Time : 0.49
INFO:root:2019-05-10 20:35:50, Epoch : 1, Step : 3397, Training Loss : 0.13089, Training Acc : 0.933, Run Time : 15.19
INFO:root:2019-05-10 20:35:50, Epoch : 1, Step : 3398, Training Loss : 0.09160, Training Acc : 0.961, Run Time : 0.23
INFO:root:2019-05-10 20:35:50, Epoch : 1, Step : 3399, Training Loss : 0.09702, Training Acc : 0.967, Run Time : 0.40
INFO:root:2019-05-10 20:35:51, Epoch : 1, Step : 3400, Training Loss : 0.12116, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-10 20:36:04, Epoch : 1, Step : 3401, Training Loss : 0.48013, Training Acc : 0.833, Run Time : 13.02
INFO:root:2019-05-10 20:36:04, Epoch : 1, Step : 3402, Training Loss : 0.53360, Training Acc : 0.772, Run Time : 0.35
INFO:root:2019-05-10 20:36:05, Epoch : 1, Step : 3403, Training Loss : 0.33612, Training Acc : 0.844, Run Time : 0.47
INFO:root:2019-05-10 20:36:05, Epoch : 1, Step : 3404, Training Loss : 0.46632, Training Acc : 0.806, Run Time : 0.52
INFO:root:2019-05-10 20:36:16, Epoch : 1, Step : 3405, Training Loss : 0.45813, Training Acc : 0.817, Run Time : 11.04
INFO:root:2019-05-10 20:36:17, Epoch : 1, Step : 3406, Training Loss : 0.28603, Training Acc : 0.850, Run Time : 0.59
INFO:root:2019-05-10 20:36:17, Epoch : 1, Step : 3407, Training Loss : 0.28021, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-10 20:36:18, Epoch : 1, Step : 3408, Training Loss : 0.27929, Training Acc : 0.856, Run Time : 0.49
INFO:root:2019-05-10 20:36:18, Epoch : 1, Step : 3409, Training Loss : 0.43792, Training Acc : 0.850, Run Time : 0.64
INFO:root:2019-05-10 20:36:23, Epoch : 1, Step : 3410, Training Loss : 0.33701, Training Acc : 0.878, Run Time : 4.51
INFO:root:2019-05-10 20:36:23, Epoch : 1, Step : 3411, Training Loss : 1.00542, Training Acc : 0.700, Run Time : 0.51
INFO:root:2019-05-10 20:36:40, Epoch : 1, Step : 3412, Training Loss : 0.92460, Training Acc : 0.700, Run Time : 16.50
INFO:root:2019-05-10 20:36:40, Epoch : 1, Step : 3413, Training Loss : 0.55727, Training Acc : 0.839, Run Time : 0.22
INFO:root:2019-05-10 20:36:41, Epoch : 1, Step : 3414, Training Loss : 0.34358, Training Acc : 0.844, Run Time : 0.50
INFO:root:2019-05-10 20:36:41, Epoch : 1, Step : 3415, Training Loss : 0.52376, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-10 20:36:44, Epoch : 1, Step : 3416, Training Loss : 0.38203, Training Acc : 0.872, Run Time : 2.85
INFO:root:2019-05-10 20:36:46, Epoch : 1, Step : 3417, Training Loss : 0.15986, Training Acc : 0.922, Run Time : 1.95
INFO:root:2019-05-10 20:36:55, Epoch : 1, Step : 3418, Training Loss : 0.17424, Training Acc : 0.933, Run Time : 9.26
INFO:root:2019-05-10 20:36:56, Epoch : 1, Step : 3419, Training Loss : 0.15692, Training Acc : 0.944, Run Time : 0.68
INFO:root:2019-05-10 20:36:56, Epoch : 1, Step : 3420, Training Loss : 0.17030, Training Acc : 0.894, Run Time : 0.56
INFO:root:2019-05-10 20:37:00, Epoch : 1, Step : 3421, Training Loss : 0.13582, Training Acc : 0.933, Run Time : 3.72
INFO:root:2019-05-10 20:37:00, Epoch : 1, Step : 3422, Training Loss : 0.10793, Training Acc : 0.967, Run Time : 0.43
INFO:root:2019-05-10 20:37:02, Epoch : 1, Step : 3423, Training Loss : 0.29296, Training Acc : 0.883, Run Time : 1.27
INFO:root:2019-05-10 20:37:02, Epoch : 1, Step : 3424, Training Loss : 0.10665, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-10 20:37:18, Epoch : 1, Step : 3425, Training Loss : 0.15534, Training Acc : 0.939, Run Time : 15.92
INFO:root:2019-05-10 20:37:18, Epoch : 1, Step : 3426, Training Loss : 0.18422, Training Acc : 0.917, Run Time : 0.22
INFO:root:2019-05-10 20:37:19, Epoch : 1, Step : 3427, Training Loss : 0.13818, Training Acc : 0.956, Run Time : 0.24
INFO:root:2019-05-10 20:37:19, Epoch : 1, Step : 3428, Training Loss : 0.29210, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-10 20:37:19, Epoch : 1, Step : 3429, Training Loss : 0.18773, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-10 20:37:35, Epoch : 1, Step : 3430, Training Loss : 0.28213, Training Acc : 0.894, Run Time : 15.37
INFO:root:2019-05-10 20:37:35, Epoch : 1, Step : 3431, Training Loss : 0.23235, Training Acc : 0.911, Run Time : 0.54
INFO:root:2019-05-10 20:37:36, Epoch : 1, Step : 3432, Training Loss : 0.17580, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-10 20:37:47, Epoch : 1, Step : 3433, Training Loss : 0.12447, Training Acc : 0.961, Run Time : 10.69
INFO:root:2019-05-10 20:37:48, Epoch : 1, Step : 3434, Training Loss : 0.36042, Training Acc : 0.861, Run Time : 1.44
INFO:root:2019-05-10 20:37:55, Epoch : 1, Step : 3435, Training Loss : 0.24286, Training Acc : 0.917, Run Time : 6.73
INFO:root:2019-05-10 20:37:55, Epoch : 1, Step : 3436, Training Loss : 0.07898, Training Acc : 0.972, Run Time : 0.27
INFO:root:2019-05-10 20:37:56, Epoch : 1, Step : 3437, Training Loss : 0.13987, Training Acc : 0.961, Run Time : 0.56
INFO:root:2019-05-10 20:37:57, Epoch : 1, Step : 3438, Training Loss : 0.23974, Training Acc : 0.894, Run Time : 1.61
INFO:root:2019-05-10 20:38:08, Epoch : 1, Step : 3439, Training Loss : 0.20969, Training Acc : 0.928, Run Time : 11.20
INFO:root:2019-05-10 20:38:09, Epoch : 1, Step : 3440, Training Loss : 0.17294, Training Acc : 0.928, Run Time : 0.22
INFO:root:2019-05-10 20:38:09, Epoch : 1, Step : 3441, Training Loss : 0.32933, Training Acc : 0.856, Run Time : 0.23
INFO:root:2019-05-10 20:38:09, Epoch : 1, Step : 3442, Training Loss : 0.49611, Training Acc : 0.817, Run Time : 0.48
INFO:root:2019-05-10 20:38:10, Epoch : 1, Step : 3443, Training Loss : 0.81378, Training Acc : 0.678, Run Time : 0.48
INFO:root:2019-05-10 20:38:26, Epoch : 1, Step : 3444, Training Loss : 0.27858, Training Acc : 0.883, Run Time : 16.23
INFO:root:2019-05-10 20:38:26, Epoch : 1, Step : 3445, Training Loss : 0.31807, Training Acc : 0.867, Run Time : 0.51
INFO:root:2019-05-10 20:38:27, Epoch : 1, Step : 3446, Training Loss : 0.24979, Training Acc : 0.917, Run Time : 0.40
INFO:root:2019-05-10 20:38:27, Epoch : 1, Step : 3447, Training Loss : 0.20592, Training Acc : 0.906, Run Time : 0.49
INFO:root:2019-05-10 20:38:39, Epoch : 1, Step : 3448, Training Loss : 0.19071, Training Acc : 0.939, Run Time : 11.26
INFO:root:2019-05-10 20:38:39, Epoch : 1, Step : 3449, Training Loss : 0.32652, Training Acc : 0.856, Run Time : 0.77
INFO:root:2019-05-10 20:38:40, Epoch : 1, Step : 3450, Training Loss : 0.74988, Training Acc : 0.733, Run Time : 0.49
INFO:root:2019-05-10 20:38:40, Epoch : 1, Step : 3451, Training Loss : 0.50087, Training Acc : 0.794, Run Time : 0.50
INFO:root:2019-05-10 20:38:41, Epoch : 1, Step : 3452, Training Loss : 0.39557, Training Acc : 0.828, Run Time : 0.50
INFO:root:2019-05-10 20:38:57, Epoch : 1, Step : 3453, Training Loss : 0.16793, Training Acc : 0.950, Run Time : 15.63
INFO:root:2019-05-10 20:38:57, Epoch : 1, Step : 3454, Training Loss : 0.28133, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 20:38:57, Epoch : 1, Step : 3455, Training Loss : 0.24768, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-10 20:39:08, Epoch : 1, Step : 3456, Training Loss : 0.25347, Training Acc : 0.906, Run Time : 10.92
INFO:root:2019-05-10 20:39:09, Epoch : 1, Step : 3457, Training Loss : 0.45350, Training Acc : 0.856, Run Time : 0.56
INFO:root:2019-05-10 20:39:09, Epoch : 1, Step : 3458, Training Loss : 0.57017, Training Acc : 0.739, Run Time : 0.43
INFO:root:2019-05-10 20:39:12, Epoch : 1, Step : 3459, Training Loss : 0.24723, Training Acc : 0.917, Run Time : 2.13
INFO:root:2019-05-10 20:39:12, Epoch : 1, Step : 3460, Training Loss : 0.21005, Training Acc : 0.933, Run Time : 0.75
INFO:root:2019-05-10 20:39:15, Epoch : 1, Step : 3461, Training Loss : 0.15720, Training Acc : 0.950, Run Time : 3.06
INFO:root:2019-05-10 20:39:16, Epoch : 1, Step : 3462, Training Loss : 0.21738, Training Acc : 0.906, Run Time : 0.52
INFO:root:2019-05-10 20:39:32, Epoch : 1, Step : 3463, Training Loss : 0.22322, Training Acc : 0.894, Run Time : 15.68
INFO:root:2019-05-10 20:39:32, Epoch : 1, Step : 3464, Training Loss : 0.11874, Training Acc : 0.956, Run Time : 0.33
INFO:root:2019-05-10 20:39:32, Epoch : 1, Step : 3465, Training Loss : 0.20404, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-10 20:39:33, Epoch : 1, Step : 3466, Training Loss : 0.10003, Training Acc : 0.983, Run Time : 0.50
INFO:root:2019-05-10 20:39:45, Epoch : 1, Step : 3467, Training Loss : 0.22075, Training Acc : 0.917, Run Time : 12.28
INFO:root:2019-05-10 20:39:46, Epoch : 1, Step : 3468, Training Loss : 0.41524, Training Acc : 0.783, Run Time : 0.71
INFO:root:2019-05-10 20:39:47, Epoch : 1, Step : 3469, Training Loss : 0.14673, Training Acc : 0.961, Run Time : 1.32
INFO:root:2019-05-10 20:39:59, Epoch : 1, Step : 3470, Training Loss : 0.20107, Training Acc : 0.933, Run Time : 11.78
INFO:root:2019-05-10 20:39:59, Epoch : 1, Step : 3471, Training Loss : 0.15717, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-10 20:40:00, Epoch : 1, Step : 3472, Training Loss : 0.16750, Training Acc : 0.956, Run Time : 0.48
INFO:root:2019-05-10 20:40:00, Epoch : 1, Step : 3473, Training Loss : 0.10487, Training Acc : 0.978, Run Time : 0.49
INFO:root:2019-05-10 20:40:01, Epoch : 1, Step : 3474, Training Loss : 0.06978, Training Acc : 0.994, Run Time : 0.52
INFO:root:2019-05-10 20:40:18, Epoch : 1, Step : 3475, Training Loss : 0.16150, Training Acc : 0.917, Run Time : 17.03
INFO:root:2019-05-10 20:40:18, Epoch : 1, Step : 3476, Training Loss : 0.15691, Training Acc : 0.950, Run Time : 0.26
INFO:root:2019-05-10 20:40:18, Epoch : 1, Step : 3477, Training Loss : 0.14644, Training Acc : 0.933, Run Time : 0.28
INFO:root:2019-05-10 20:40:19, Epoch : 1, Step : 3478, Training Loss : 0.20591, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-10 20:40:19, Epoch : 1, Step : 3479, Training Loss : 0.25073, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-10 20:40:36, Epoch : 1, Step : 3480, Training Loss : 0.12560, Training Acc : 0.950, Run Time : 16.93
INFO:root:2019-05-10 20:40:36, Epoch : 1, Step : 3481, Training Loss : 0.17388, Training Acc : 0.917, Run Time : 0.25
INFO:root:2019-05-10 20:40:37, Epoch : 1, Step : 3482, Training Loss : 0.11998, Training Acc : 0.961, Run Time : 0.24
INFO:root:2019-05-10 20:40:37, Epoch : 1, Step : 3483, Training Loss : 0.43284, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-10 20:40:38, Epoch : 1, Step : 3484, Training Loss : 0.14746, Training Acc : 0.933, Run Time : 0.49
INFO:root:2019-05-10 20:40:54, Epoch : 1, Step : 3485, Training Loss : 0.31147, Training Acc : 0.906, Run Time : 16.48
INFO:root:2019-05-10 20:40:55, Epoch : 1, Step : 3486, Training Loss : 0.17058, Training Acc : 0.917, Run Time : 0.68
INFO:root:2019-05-10 20:40:55, Epoch : 1, Step : 3487, Training Loss : 0.14816, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-10 20:40:56, Epoch : 1, Step : 3488, Training Loss : 0.17918, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-10 20:41:08, Epoch : 1, Step : 3489, Training Loss : 0.10948, Training Acc : 0.978, Run Time : 12.28
INFO:root:2019-05-10 20:41:08, Epoch : 1, Step : 3490, Training Loss : 0.08553, Training Acc : 0.989, Run Time : 0.45
INFO:root:2019-05-10 20:41:09, Epoch : 1, Step : 3491, Training Loss : 0.11954, Training Acc : 0.967, Run Time : 0.23
INFO:root:2019-05-10 20:41:10, Epoch : 1, Step : 3492, Training Loss : 0.09655, Training Acc : 0.978, Run Time : 0.99
INFO:root:2019-05-10 20:41:22, Epoch : 1, Step : 3493, Training Loss : 0.09289, Training Acc : 0.972, Run Time : 11.87
INFO:root:2019-05-10 20:41:24, Epoch : 1, Step : 3494, Training Loss : 0.07958, Training Acc : 0.989, Run Time : 2.39
INFO:root:2019-05-10 20:41:33, Epoch : 1, Step : 3495, Training Loss : 0.08706, Training Acc : 0.967, Run Time : 8.73
INFO:root:2019-05-10 20:41:33, Epoch : 1, Step : 3496, Training Loss : 0.09605, Training Acc : 0.972, Run Time : 0.70
INFO:root:2019-05-10 20:41:34, Epoch : 1, Step : 3497, Training Loss : 0.04966, Training Acc : 0.989, Run Time : 0.41
INFO:root:2019-05-10 20:41:34, Epoch : 1, Step : 3498, Training Loss : 0.16503, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-10 20:41:38, Epoch : 1, Step : 3499, Training Loss : 0.09117, Training Acc : 0.956, Run Time : 3.33
INFO:root:2019-05-10 20:41:48, Epoch : 1, Step : 3500, Training Loss : 0.18430, Training Acc : 0.917, Run Time : 10.79
INFO:root:2019-05-10 20:41:49, Epoch : 1, Step : 3501, Training Loss : 0.25015, Training Acc : 0.894, Run Time : 0.58
INFO:root:2019-05-10 20:41:49, Epoch : 1, Step : 3502, Training Loss : 0.21792, Training Acc : 0.922, Run Time : 0.40
INFO:root:2019-05-10 20:41:50, Epoch : 1, Step : 3503, Training Loss : 0.15883, Training Acc : 0.939, Run Time : 0.53
INFO:root:2019-05-10 20:41:50, Epoch : 1, Step : 3504, Training Loss : 0.23419, Training Acc : 0.872, Run Time : 0.50
INFO:root:2019-05-10 20:42:06, Epoch : 1, Step : 3505, Training Loss : 0.35076, Training Acc : 0.861, Run Time : 16.10
INFO:root:2019-05-10 20:42:07, Epoch : 1, Step : 3506, Training Loss : 0.23190, Training Acc : 0.928, Run Time : 0.26
INFO:root:2019-05-10 20:42:07, Epoch : 1, Step : 3507, Training Loss : 0.29930, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-10 20:42:08, Epoch : 1, Step : 3508, Training Loss : 0.06547, Training Acc : 0.978, Run Time : 0.47
INFO:root:2019-05-10 20:42:08, Epoch : 1, Step : 3509, Training Loss : 0.21000, Training Acc : 0.922, Run Time : 0.52
INFO:root:2019-05-10 20:42:24, Epoch : 1, Step : 3510, Training Loss : 0.13915, Training Acc : 0.928, Run Time : 15.63
INFO:root:2019-05-10 20:42:24, Epoch : 1, Step : 3511, Training Loss : 0.09015, Training Acc : 0.961, Run Time : 0.61
INFO:root:2019-05-10 20:42:25, Epoch : 1, Step : 3512, Training Loss : 0.07165, Training Acc : 0.983, Run Time : 0.60
INFO:root:2019-05-10 20:42:25, Epoch : 1, Step : 3513, Training Loss : 0.10813, Training Acc : 0.956, Run Time : 0.49
INFO:root:2019-05-10 20:42:37, Epoch : 1, Step : 3514, Training Loss : 0.14207, Training Acc : 0.933, Run Time : 11.87
INFO:root:2019-05-10 20:42:38, Epoch : 1, Step : 3515, Training Loss : 0.14271, Training Acc : 0.944, Run Time : 0.41
INFO:root:2019-05-10 20:42:38, Epoch : 1, Step : 3516, Training Loss : 0.20120, Training Acc : 0.911, Run Time : 0.25
INFO:root:2019-05-10 20:42:38, Epoch : 1, Step : 3517, Training Loss : 0.21644, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-10 20:42:39, Epoch : 1, Step : 3518, Training Loss : 0.14185, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-10 20:42:54, Epoch : 1, Step : 3519, Training Loss : 0.19213, Training Acc : 0.906, Run Time : 15.42
INFO:root:2019-05-10 20:42:55, Epoch : 1, Step : 3520, Training Loss : 0.23407, Training Acc : 0.906, Run Time : 0.23
INFO:root:2019-05-10 20:42:55, Epoch : 1, Step : 3521, Training Loss : 0.23072, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-10 20:42:55, Epoch : 1, Step : 3522, Training Loss : 0.17422, Training Acc : 0.933, Run Time : 0.47
INFO:root:2019-05-10 20:42:57, Epoch : 1, Step : 3523, Training Loss : 0.13572, Training Acc : 0.950, Run Time : 2.01
INFO:root:2019-05-10 20:43:12, Epoch : 1, Step : 3524, Training Loss : 0.05512, Training Acc : 0.989, Run Time : 14.30
INFO:root:2019-05-10 20:43:12, Epoch : 1, Step : 3525, Training Loss : 0.09448, Training Acc : 0.956, Run Time : 0.33
INFO:root:2019-05-10 20:43:13, Epoch : 1, Step : 3526, Training Loss : 0.06153, Training Acc : 0.989, Run Time : 0.46
INFO:root:2019-05-10 20:43:14, Epoch : 1, Step : 3527, Training Loss : 0.11884, Training Acc : 0.950, Run Time : 1.31
INFO:root:2019-05-10 20:43:15, Epoch : 1, Step : 3528, Training Loss : 0.04731, Training Acc : 0.989, Run Time : 1.38
INFO:root:2019-05-10 20:43:27, Epoch : 1, Step : 3529, Training Loss : 0.09909, Training Acc : 0.967, Run Time : 12.20
INFO:root:2019-05-10 20:43:28, Epoch : 1, Step : 3530, Training Loss : 0.06287, Training Acc : 0.972, Run Time : 0.24
INFO:root:2019-05-10 20:43:28, Epoch : 1, Step : 3531, Training Loss : 0.07832, Training Acc : 0.972, Run Time : 0.46
INFO:root:2019-05-10 20:43:29, Epoch : 1, Step : 3532, Training Loss : 0.09136, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-10 20:43:29, Epoch : 1, Step : 3533, Training Loss : 0.06366, Training Acc : 0.983, Run Time : 0.50
INFO:root:2019-05-10 20:43:35, Epoch : 1, Step : 3534, Training Loss : 0.15531, Training Acc : 0.944, Run Time : 5.40
INFO:root:2019-05-10 20:43:47, Epoch : 1, Step : 3535, Training Loss : 0.10682, Training Acc : 0.967, Run Time : 12.38
INFO:root:2019-05-10 20:43:47, Epoch : 1, Step : 3536, Training Loss : 0.10394, Training Acc : 0.961, Run Time : 0.51
INFO:root:2019-05-10 20:43:48, Epoch : 1, Step : 3537, Training Loss : 0.04528, Training Acc : 0.978, Run Time : 0.22
INFO:root:2019-05-10 20:43:48, Epoch : 1, Step : 3538, Training Loss : 0.04886, Training Acc : 0.983, Run Time : 0.39
INFO:root:2019-05-10 20:43:48, Epoch : 1, Step : 3539, Training Loss : 0.07567, Training Acc : 0.972, Run Time : 0.48
INFO:root:2019-05-10 20:44:06, Epoch : 1, Step : 3540, Training Loss : 0.11651, Training Acc : 0.956, Run Time : 17.83
INFO:root:2019-05-10 20:44:07, Epoch : 1, Step : 3541, Training Loss : 0.07325, Training Acc : 0.972, Run Time : 0.28
INFO:root:2019-05-10 20:44:07, Epoch : 1, Step : 3542, Training Loss : 0.30102, Training Acc : 0.872, Run Time : 0.22
INFO:root:2019-05-10 20:44:07, Epoch : 1, Step : 3543, Training Loss : 0.12748, Training Acc : 0.956, Run Time : 0.25
INFO:root:2019-05-10 20:44:13, Epoch : 1, Step : 3544, Training Loss : 0.08662, Training Acc : 0.972, Run Time : 5.93
INFO:root:2019-05-10 20:44:16, Epoch : 1, Step : 3545, Training Loss : 0.10157, Training Acc : 0.972, Run Time : 2.60
INFO:root:2019-05-10 20:44:17, Epoch : 1, Step : 3546, Training Loss : 0.04985, Training Acc : 0.983, Run Time : 1.32
INFO:root:2019-05-10 20:44:27, Epoch : 1, Step : 3547, Training Loss : 0.17580, Training Acc : 0.944, Run Time : 10.28
INFO:root:2019-05-10 20:44:28, Epoch : 1, Step : 3548, Training Loss : 0.12480, Training Acc : 0.950, Run Time : 0.44
INFO:root:2019-05-10 20:44:28, Epoch : 1, Step : 3549, Training Loss : 0.07537, Training Acc : 0.961, Run Time : 0.22
INFO:root:2019-05-10 20:44:28, Epoch : 1, Step : 3550, Training Loss : 0.15140, Training Acc : 0.928, Run Time : 0.43
INFO:root:2019-05-10 20:44:29, Epoch : 1, Step : 3551, Training Loss : 0.12522, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-10 20:44:48, Epoch : 1, Step : 3552, Training Loss : 0.08388, Training Acc : 0.983, Run Time : 18.75
INFO:root:2019-05-10 20:44:48, Epoch : 1, Step : 3553, Training Loss : 0.16566, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-10 20:44:49, Epoch : 1, Step : 3554, Training Loss : 0.10843, Training Acc : 0.967, Run Time : 0.77
INFO:root:2019-05-10 20:44:49, Epoch : 1, Step : 3555, Training Loss : 0.15904, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-10 20:44:50, Epoch : 1, Step : 3556, Training Loss : 0.19631, Training Acc : 0.939, Run Time : 0.50
INFO:root:2019-05-10 20:44:54, Epoch : 1, Step : 3557, Training Loss : 0.09151, Training Acc : 0.972, Run Time : 4.57
INFO:root:2019-05-10 20:44:55, Epoch : 1, Step : 3558, Training Loss : 0.10966, Training Acc : 0.956, Run Time : 0.46
INFO:root:2019-05-10 20:45:11, Epoch : 1, Step : 3559, Training Loss : 0.10367, Training Acc : 0.956, Run Time : 16.39
INFO:root:2019-05-10 20:45:11, Epoch : 1, Step : 3560, Training Loss : 0.17577, Training Acc : 0.922, Run Time : 0.31
INFO:root:2019-05-10 20:45:12, Epoch : 1, Step : 3561, Training Loss : 0.15998, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-10 20:45:12, Epoch : 1, Step : 3562, Training Loss : 0.15547, Training Acc : 0.928, Run Time : 0.44
INFO:root:2019-05-10 20:45:13, Epoch : 1, Step : 3563, Training Loss : 0.30054, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-10 20:45:33, Epoch : 1, Step : 3564, Training Loss : 0.13008, Training Acc : 0.928, Run Time : 19.90
INFO:root:2019-05-10 20:45:33, Epoch : 1, Step : 3565, Training Loss : 0.14250, Training Acc : 0.950, Run Time : 0.67
INFO:root:2019-05-10 20:45:34, Epoch : 1, Step : 3566, Training Loss : 0.15145, Training Acc : 0.944, Run Time : 0.22
INFO:root:2019-05-10 20:45:34, Epoch : 1, Step : 3567, Training Loss : 0.12928, Training Acc : 0.950, Run Time : 0.67
INFO:root:2019-05-10 20:45:46, Epoch : 1, Step : 3568, Training Loss : 0.18221, Training Acc : 0.922, Run Time : 12.04
INFO:root:2019-05-10 20:45:47, Epoch : 1, Step : 3569, Training Loss : 0.29243, Training Acc : 0.883, Run Time : 0.52
INFO:root:2019-05-10 20:45:47, Epoch : 1, Step : 3570, Training Loss : 0.18355, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 20:45:48, Epoch : 1, Step : 3571, Training Loss : 0.08341, Training Acc : 0.967, Run Time : 0.48
INFO:root:2019-05-10 20:45:48, Epoch : 1, Step : 3572, Training Loss : 0.14353, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-10 20:46:03, Epoch : 1, Step : 3573, Training Loss : 0.09972, Training Acc : 0.950, Run Time : 14.92
INFO:root:2019-05-10 20:46:04, Epoch : 1, Step : 3574, Training Loss : 0.09800, Training Acc : 0.961, Run Time : 0.53
INFO:root:2019-05-10 20:46:04, Epoch : 1, Step : 3575, Training Loss : 0.13856, Training Acc : 0.939, Run Time : 0.56
INFO:root:2019-05-10 20:46:05, Epoch : 1, Step : 3576, Training Loss : 0.19320, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-10 20:46:05, Epoch : 1, Step : 3577, Training Loss : 0.11202, Training Acc : 0.967, Run Time : 0.51
INFO:root:2019-05-10 20:46:22, Epoch : 1, Step : 3578, Training Loss : 0.17463, Training Acc : 0.944, Run Time : 17.11
INFO:root:2019-05-10 20:46:23, Epoch : 1, Step : 3579, Training Loss : 0.17140, Training Acc : 0.922, Run Time : 0.97
INFO:root:2019-05-10 20:46:24, Epoch : 1, Step : 3580, Training Loss : 0.11844, Training Acc : 0.956, Run Time : 0.46
INFO:root:2019-05-10 20:46:24, Epoch : 1, Step : 3581, Training Loss : 0.13106, Training Acc : 0.956, Run Time : 0.49
INFO:root:2019-05-10 20:46:39, Epoch : 1, Step : 3582, Training Loss : 0.21006, Training Acc : 0.906, Run Time : 14.30
INFO:root:2019-05-10 20:46:40, Epoch : 1, Step : 3583, Training Loss : 0.25841, Training Acc : 0.911, Run Time : 1.67
INFO:root:2019-05-10 20:46:41, Epoch : 1, Step : 3584, Training Loss : 0.14970, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-10 20:46:41, Epoch : 1, Step : 3585, Training Loss : 0.22434, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 20:46:42, Epoch : 1, Step : 3586, Training Loss : 0.05254, Training Acc : 0.994, Run Time : 0.57
INFO:root:2019-05-10 20:46:52, Epoch : 1, Step : 3587, Training Loss : 0.30924, Training Acc : 0.894, Run Time : 10.28
INFO:root:2019-05-10 20:46:54, Epoch : 1, Step : 3588, Training Loss : 0.20501, Training Acc : 0.939, Run Time : 1.38
INFO:root:2019-05-10 20:47:04, Epoch : 1, Step : 3589, Training Loss : 0.12023, Training Acc : 0.956, Run Time : 10.68
INFO:root:2019-05-10 20:47:05, Epoch : 1, Step : 3590, Training Loss : 0.17005, Training Acc : 0.933, Run Time : 0.67
INFO:root:2019-05-10 20:47:06, Epoch : 1, Step : 3591, Training Loss : 0.12234, Training Acc : 0.950, Run Time : 0.67
INFO:root:2019-05-10 20:47:06, Epoch : 1, Step : 3592, Training Loss : 0.08823, Training Acc : 0.967, Run Time : 0.50
INFO:root:2019-05-10 20:47:11, Epoch : 1, Step : 3593, Training Loss : 0.16205, Training Acc : 0.933, Run Time : 4.89
INFO:root:2019-05-10 20:47:11, Epoch : 1, Step : 3594, Training Loss : 0.09945, Training Acc : 0.972, Run Time : 0.30
INFO:root:2019-05-10 20:47:12, Epoch : 1, Step : 3595, Training Loss : 0.12084, Training Acc : 0.967, Run Time : 0.51
INFO:root:2019-05-10 20:47:16, Epoch : 1, Step : 3596, Training Loss : 0.30313, Training Acc : 0.856, Run Time : 4.16
INFO:root:2019-05-10 20:47:28, Epoch : 1, Step : 3597, Training Loss : 0.22646, Training Acc : 0.906, Run Time : 12.43
INFO:root:2019-05-10 20:47:29, Epoch : 1, Step : 3598, Training Loss : 0.20670, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-10 20:47:29, Epoch : 1, Step : 3599, Training Loss : 0.32195, Training Acc : 0.872, Run Time : 0.21
INFO:root:2019-05-10 20:47:29, Epoch : 1, Step : 3600, Training Loss : 0.38256, Training Acc : 0.839, Run Time : 0.52
INFO:root:2019-05-10 20:47:33, Epoch : 1, Step : 3601, Training Loss : 0.63476, Training Acc : 0.789, Run Time : 3.09
INFO:root:2019-05-10 20:47:35, Epoch : 1, Step : 3602, Training Loss : 0.93101, Training Acc : 0.694, Run Time : 2.42
INFO:root:2019-05-10 20:47:46, Epoch : 1, Step : 3603, Training Loss : 0.68796, Training Acc : 0.706, Run Time : 10.88
INFO:root:2019-05-10 20:47:47, Epoch : 1, Step : 3604, Training Loss : 1.34099, Training Acc : 0.561, Run Time : 0.98
INFO:root:2019-05-10 20:47:47, Epoch : 1, Step : 3605, Training Loss : 0.67989, Training Acc : 0.706, Run Time : 0.22
INFO:root:2019-05-10 20:47:48, Epoch : 1, Step : 3606, Training Loss : 0.93801, Training Acc : 0.583, Run Time : 0.46
INFO:root:2019-05-10 20:47:48, Epoch : 1, Step : 3607, Training Loss : 0.77376, Training Acc : 0.617, Run Time : 0.46
INFO:root:2019-05-10 20:47:55, Epoch : 1, Step : 3608, Training Loss : 0.73765, Training Acc : 0.656, Run Time : 6.79
INFO:root:2019-05-10 20:47:55, Epoch : 1, Step : 3609, Training Loss : 0.58153, Training Acc : 0.689, Run Time : 0.41
INFO:root:2019-05-10 20:48:11, Epoch : 1, Step : 3610, Training Loss : 0.74806, Training Acc : 0.672, Run Time : 15.34
INFO:root:2019-05-10 20:48:11, Epoch : 1, Step : 3611, Training Loss : 0.57977, Training Acc : 0.728, Run Time : 0.28
INFO:root:2019-05-10 20:48:11, Epoch : 1, Step : 3612, Training Loss : 0.28242, Training Acc : 0.878, Run Time : 0.45
INFO:root:2019-05-10 20:48:12, Epoch : 1, Step : 3613, Training Loss : 0.42674, Training Acc : 0.789, Run Time : 0.47
INFO:root:2019-05-10 20:48:13, Epoch : 1, Step : 3614, Training Loss : 0.48129, Training Acc : 0.783, Run Time : 1.25
INFO:root:2019-05-10 20:48:28, Epoch : 1, Step : 3615, Training Loss : 0.49288, Training Acc : 0.722, Run Time : 14.89
INFO:root:2019-05-10 20:48:28, Epoch : 1, Step : 3616, Training Loss : 0.51349, Training Acc : 0.717, Run Time : 0.43
INFO:root:2019-05-10 20:48:29, Epoch : 1, Step : 3617, Training Loss : 0.60768, Training Acc : 0.683, Run Time : 0.21
INFO:root:2019-05-10 20:48:29, Epoch : 1, Step : 3618, Training Loss : 0.49290, Training Acc : 0.728, Run Time : 0.45
INFO:root:2019-05-10 20:48:29, Epoch : 1, Step : 3619, Training Loss : 0.55483, Training Acc : 0.661, Run Time : 0.44
INFO:root:2019-05-10 20:48:34, Epoch : 1, Step : 3620, Training Loss : 0.37083, Training Acc : 0.794, Run Time : 4.44
INFO:root:2019-05-10 20:48:34, Epoch : 1, Step : 3621, Training Loss : 0.57221, Training Acc : 0.711, Run Time : 0.48
INFO:root:2019-05-10 20:48:50, Epoch : 1, Step : 3622, Training Loss : 0.50709, Training Acc : 0.761, Run Time : 16.01
INFO:root:2019-05-10 20:48:51, Epoch : 1, Step : 3623, Training Loss : 0.51644, Training Acc : 0.672, Run Time : 0.32
INFO:root:2019-05-10 20:48:51, Epoch : 1, Step : 3624, Training Loss : 0.49320, Training Acc : 0.744, Run Time : 0.43
INFO:root:2019-05-10 20:48:51, Epoch : 1, Step : 3625, Training Loss : 0.48705, Training Acc : 0.750, Run Time : 0.27
INFO:root:2019-05-10 20:48:52, Epoch : 1, Step : 3626, Training Loss : 0.44873, Training Acc : 0.783, Run Time : 0.46
INFO:root:2019-05-10 20:49:07, Epoch : 1, Step : 3627, Training Loss : 0.40824, Training Acc : 0.806, Run Time : 15.59
INFO:root:2019-05-10 20:49:08, Epoch : 1, Step : 3628, Training Loss : 0.40353, Training Acc : 0.822, Run Time : 0.22
INFO:root:2019-05-10 20:49:08, Epoch : 1, Step : 3629, Training Loss : 0.35505, Training Acc : 0.861, Run Time : 0.22
INFO:root:2019-05-10 20:49:08, Epoch : 1, Step : 3630, Training Loss : 0.36585, Training Acc : 0.856, Run Time : 0.31
INFO:root:2019-05-10 20:49:09, Epoch : 1, Step : 3631, Training Loss : 0.36815, Training Acc : 0.856, Run Time : 1.03
INFO:root:2019-05-10 20:49:14, Epoch : 1, Step : 3632, Training Loss : 0.31803, Training Acc : 0.906, Run Time : 4.57
INFO:root:2019-05-10 20:49:14, Epoch : 1, Step : 3633, Training Loss : 0.41356, Training Acc : 0.806, Run Time : 0.39
INFO:root:2019-05-10 20:49:30, Epoch : 1, Step : 3634, Training Loss : 0.39100, Training Acc : 0.828, Run Time : 15.54
INFO:root:2019-05-10 20:49:30, Epoch : 1, Step : 3635, Training Loss : 0.43089, Training Acc : 0.811, Run Time : 0.29
INFO:root:2019-05-10 20:49:30, Epoch : 1, Step : 3636, Training Loss : 0.35786, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 20:49:31, Epoch : 1, Step : 3637, Training Loss : 0.30913, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 20:49:31, Epoch : 1, Step : 3638, Training Loss : 0.41439, Training Acc : 0.811, Run Time : 0.48
INFO:root:2019-05-10 20:49:40, Epoch : 1, Step : 3639, Training Loss : 0.41749, Training Acc : 0.783, Run Time : 8.79
INFO:root:2019-05-10 20:49:47, Epoch : 1, Step : 3640, Training Loss : 0.65874, Training Acc : 0.661, Run Time : 6.91
INFO:root:2019-05-10 20:49:48, Epoch : 1, Step : 3641, Training Loss : 0.27890, Training Acc : 0.906, Run Time : 0.63
INFO:root:2019-05-10 20:49:48, Epoch : 1, Step : 3642, Training Loss : 0.42971, Training Acc : 0.811, Run Time : 0.43
INFO:root:2019-05-10 20:49:49, Epoch : 1, Step : 3643, Training Loss : 0.46464, Training Acc : 0.744, Run Time : 0.46
INFO:root:2019-05-10 20:50:01, Epoch : 1, Step : 3644, Training Loss : 0.43799, Training Acc : 0.800, Run Time : 12.66
INFO:root:2019-05-10 20:50:02, Epoch : 1, Step : 3645, Training Loss : 0.30791, Training Acc : 0.878, Run Time : 0.44
INFO:root:2019-05-10 20:50:02, Epoch : 1, Step : 3646, Training Loss : 0.32421, Training Acc : 0.856, Run Time : 0.44
INFO:root:2019-05-10 20:50:14, Epoch : 1, Step : 3647, Training Loss : 0.33657, Training Acc : 0.894, Run Time : 11.41
INFO:root:2019-05-10 20:50:14, Epoch : 1, Step : 3648, Training Loss : 0.24943, Training Acc : 0.878, Run Time : 0.52
INFO:root:2019-05-10 20:50:15, Epoch : 1, Step : 3649, Training Loss : 0.35850, Training Acc : 0.839, Run Time : 0.61
INFO:root:2019-05-10 20:50:15, Epoch : 1, Step : 3650, Training Loss : 0.34367, Training Acc : 0.839, Run Time : 0.50
INFO:root:2019-05-10 20:50:27, Epoch : 1, Step : 3651, Training Loss : 0.26051, Training Acc : 0.944, Run Time : 11.71
INFO:root:2019-05-10 20:50:27, Epoch : 1, Step : 3652, Training Loss : 0.33702, Training Acc : 0.850, Run Time : 0.40
INFO:root:2019-05-10 20:50:28, Epoch : 1, Step : 3653, Training Loss : 0.49605, Training Acc : 0.739, Run Time : 0.21
INFO:root:2019-05-10 20:50:28, Epoch : 1, Step : 3654, Training Loss : 0.44646, Training Acc : 0.778, Run Time : 0.22
INFO:root:2019-05-10 20:50:28, Epoch : 1, Step : 3655, Training Loss : 0.37945, Training Acc : 0.822, Run Time : 0.44
INFO:root:2019-05-10 20:50:46, Epoch : 1, Step : 3656, Training Loss : 0.38058, Training Acc : 0.850, Run Time : 17.69
INFO:root:2019-05-10 20:50:46, Epoch : 1, Step : 3657, Training Loss : 0.35903, Training Acc : 0.844, Run Time : 0.54
INFO:root:2019-05-10 20:50:47, Epoch : 1, Step : 3658, Training Loss : 0.31048, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 20:50:47, Epoch : 1, Step : 3659, Training Loss : 0.35756, Training Acc : 0.844, Run Time : 0.50
INFO:root:2019-05-10 20:50:48, Epoch : 1, Step : 3660, Training Loss : 0.22387, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-10 20:51:02, Epoch : 1, Step : 3661, Training Loss : 0.35338, Training Acc : 0.878, Run Time : 14.01
INFO:root:2019-05-10 20:51:02, Epoch : 1, Step : 3662, Training Loss : 0.47142, Training Acc : 0.767, Run Time : 0.36
INFO:root:2019-05-10 20:51:03, Epoch : 1, Step : 3663, Training Loss : 0.33579, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-10 20:51:03, Epoch : 1, Step : 3664, Training Loss : 0.38083, Training Acc : 0.828, Run Time : 0.48
INFO:root:2019-05-10 20:51:16, Epoch : 1, Step : 3665, Training Loss : 0.31143, Training Acc : 0.856, Run Time : 12.61
INFO:root:2019-05-10 20:51:17, Epoch : 1, Step : 3666, Training Loss : 0.44664, Training Acc : 0.789, Run Time : 0.93
INFO:root:2019-05-10 20:51:17, Epoch : 1, Step : 3667, Training Loss : 0.30424, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-10 20:51:18, Epoch : 1, Step : 3668, Training Loss : 0.23333, Training Acc : 0.917, Run Time : 0.49
INFO:root:2019-05-10 20:51:19, Epoch : 1, Step : 3669, Training Loss : 0.54868, Training Acc : 0.717, Run Time : 0.92
INFO:root:2019-05-10 20:51:25, Epoch : 1, Step : 3670, Training Loss : 0.36795, Training Acc : 0.789, Run Time : 6.28
INFO:root:2019-05-10 20:51:25, Epoch : 1, Step : 3671, Training Loss : 0.46730, Training Acc : 0.739, Run Time : 0.45
INFO:root:2019-05-10 20:51:41, Epoch : 1, Step : 3672, Training Loss : 0.37721, Training Acc : 0.856, Run Time : 16.00
INFO:root:2019-05-10 20:51:42, Epoch : 1, Step : 3673, Training Loss : 0.36968, Training Acc : 0.861, Run Time : 0.34
INFO:root:2019-05-10 20:51:42, Epoch : 1, Step : 3674, Training Loss : 0.36933, Training Acc : 0.850, Run Time : 0.29
INFO:root:2019-05-10 20:51:42, Epoch : 1, Step : 3675, Training Loss : 0.27621, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-10 20:51:43, Epoch : 1, Step : 3676, Training Loss : 0.41601, Training Acc : 0.806, Run Time : 0.48
INFO:root:2019-05-10 20:52:00, Epoch : 1, Step : 3677, Training Loss : 0.28069, Training Acc : 0.906, Run Time : 17.11
INFO:root:2019-05-10 20:52:00, Epoch : 1, Step : 3678, Training Loss : 0.33275, Training Acc : 0.828, Run Time : 0.28
INFO:root:2019-05-10 20:52:01, Epoch : 1, Step : 3679, Training Loss : 0.30091, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-10 20:52:01, Epoch : 1, Step : 3680, Training Loss : 0.37530, Training Acc : 0.872, Run Time : 0.41
INFO:root:2019-05-10 20:52:01, Epoch : 1, Step : 3681, Training Loss : 0.40875, Training Acc : 0.822, Run Time : 0.23
INFO:root:2019-05-10 20:52:20, Epoch : 1, Step : 3682, Training Loss : 0.31759, Training Acc : 0.856, Run Time : 18.24
INFO:root:2019-05-10 20:52:20, Epoch : 1, Step : 3683, Training Loss : 0.24703, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-10 20:52:20, Epoch : 1, Step : 3684, Training Loss : 0.24429, Training Acc : 0.911, Run Time : 0.30
INFO:root:2019-05-10 20:52:21, Epoch : 1, Step : 3685, Training Loss : 0.20440, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 20:52:21, Epoch : 1, Step : 3686, Training Loss : 0.50713, Training Acc : 0.722, Run Time : 0.48
INFO:root:2019-05-10 20:52:38, Epoch : 1, Step : 3687, Training Loss : 0.44818, Training Acc : 0.822, Run Time : 16.52
INFO:root:2019-05-10 20:52:38, Epoch : 1, Step : 3688, Training Loss : 0.35158, Training Acc : 0.828, Run Time : 0.23
INFO:root:2019-05-10 20:52:38, Epoch : 1, Step : 3689, Training Loss : 0.28625, Training Acc : 0.883, Run Time : 0.27
INFO:root:2019-05-10 20:52:39, Epoch : 1, Step : 3690, Training Loss : 0.32320, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-10 20:52:39, Epoch : 1, Step : 3691, Training Loss : 0.45357, Training Acc : 0.794, Run Time : 0.70
INFO:root:2019-05-10 20:52:55, Epoch : 1, Step : 3692, Training Loss : 0.35639, Training Acc : 0.817, Run Time : 15.69
INFO:root:2019-05-10 20:52:56, Epoch : 1, Step : 3693, Training Loss : 0.57273, Training Acc : 0.761, Run Time : 0.59
INFO:root:2019-05-10 20:52:56, Epoch : 1, Step : 3694, Training Loss : 0.41254, Training Acc : 0.811, Run Time : 0.72
INFO:root:2019-05-10 20:52:57, Epoch : 1, Step : 3695, Training Loss : 0.41527, Training Acc : 0.811, Run Time : 0.65
INFO:root:2019-05-10 20:52:58, Epoch : 1, Step : 3696, Training Loss : 0.46694, Training Acc : 0.767, Run Time : 1.18
INFO:root:2019-05-10 20:53:14, Epoch : 1, Step : 3697, Training Loss : 0.26791, Training Acc : 0.867, Run Time : 15.63
INFO:root:2019-05-10 20:53:15, Epoch : 1, Step : 3698, Training Loss : 0.67851, Training Acc : 0.644, Run Time : 0.59
INFO:root:2019-05-10 20:53:15, Epoch : 1, Step : 3699, Training Loss : 0.35039, Training Acc : 0.833, Run Time : 0.45
INFO:root:2019-05-10 20:53:15, Epoch : 1, Step : 3700, Training Loss : 0.62482, Training Acc : 0.672, Run Time : 0.47
INFO:root:2019-05-10 20:53:30, Epoch : 1, Step : 3701, Training Loss : 0.38193, Training Acc : 0.811, Run Time : 14.39
INFO:root:2019-05-10 20:53:30, Epoch : 1, Step : 3702, Training Loss : 0.54147, Training Acc : 0.761, Run Time : 0.64
INFO:root:2019-05-10 20:53:31, Epoch : 1, Step : 3703, Training Loss : 0.37574, Training Acc : 0.828, Run Time : 0.22
INFO:root:2019-05-10 20:53:31, Epoch : 1, Step : 3704, Training Loss : 0.56015, Training Acc : 0.744, Run Time : 0.50
INFO:root:2019-05-10 20:53:32, Epoch : 1, Step : 3705, Training Loss : 0.43057, Training Acc : 0.778, Run Time : 0.46
INFO:root:2019-05-10 20:53:48, Epoch : 1, Step : 3706, Training Loss : 0.64482, Training Acc : 0.656, Run Time : 16.31
INFO:root:2019-05-10 20:53:48, Epoch : 1, Step : 3707, Training Loss : 0.49714, Training Acc : 0.800, Run Time : 0.24
INFO:root:2019-05-10 20:53:49, Epoch : 1, Step : 3708, Training Loss : 0.48298, Training Acc : 0.739, Run Time : 0.41
INFO:root:2019-05-10 20:53:49, Epoch : 1, Step : 3709, Training Loss : 0.41436, Training Acc : 0.767, Run Time : 0.30
INFO:root:2019-05-10 20:53:49, Epoch : 1, Step : 3710, Training Loss : 0.62632, Training Acc : 0.633, Run Time : 0.53
INFO:root:2019-05-10 20:54:06, Epoch : 1, Step : 3711, Training Loss : 0.42775, Training Acc : 0.750, Run Time : 16.46
INFO:root:2019-05-10 20:54:07, Epoch : 1, Step : 3712, Training Loss : 0.45046, Training Acc : 0.739, Run Time : 0.90
INFO:root:2019-05-10 20:54:07, Epoch : 1, Step : 3713, Training Loss : 0.34836, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-10 20:54:19, Epoch : 1, Step : 3714, Training Loss : 0.35814, Training Acc : 0.856, Run Time : 11.36
INFO:root:2019-05-10 20:54:19, Epoch : 1, Step : 3715, Training Loss : 0.26597, Training Acc : 0.900, Run Time : 0.60
INFO:root:2019-05-10 20:54:19, Epoch : 1, Step : 3716, Training Loss : 0.41250, Training Acc : 0.800, Run Time : 0.27
INFO:root:2019-05-10 20:54:20, Epoch : 1, Step : 3717, Training Loss : 0.39108, Training Acc : 0.800, Run Time : 0.48
INFO:root:2019-05-10 20:54:20, Epoch : 1, Step : 3718, Training Loss : 0.33751, Training Acc : 0.878, Run Time : 0.51
INFO:root:2019-05-10 20:54:37, Epoch : 1, Step : 3719, Training Loss : 0.46033, Training Acc : 0.739, Run Time : 16.52
INFO:root:2019-05-10 20:54:38, Epoch : 1, Step : 3720, Training Loss : 0.48534, Training Acc : 0.789, Run Time : 0.79
INFO:root:2019-05-10 20:54:38, Epoch : 1, Step : 3721, Training Loss : 0.23993, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-10 20:54:39, Epoch : 1, Step : 3722, Training Loss : 0.22224, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-10 20:54:50, Epoch : 1, Step : 3723, Training Loss : 0.21670, Training Acc : 0.939, Run Time : 11.04
INFO:root:2019-05-10 20:54:50, Epoch : 1, Step : 3724, Training Loss : 0.38023, Training Acc : 0.811, Run Time : 0.65
INFO:root:2019-05-10 20:54:51, Epoch : 1, Step : 3725, Training Loss : 0.22332, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-10 20:54:51, Epoch : 1, Step : 3726, Training Loss : 0.20563, Training Acc : 0.933, Run Time : 0.57
INFO:root:2019-05-10 20:54:52, Epoch : 1, Step : 3727, Training Loss : 0.24997, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 20:55:09, Epoch : 1, Step : 3728, Training Loss : 0.28213, Training Acc : 0.878, Run Time : 16.75
INFO:root:2019-05-10 20:55:09, Epoch : 1, Step : 3729, Training Loss : 0.14801, Training Acc : 0.978, Run Time : 0.23
INFO:root:2019-05-10 20:55:09, Epoch : 1, Step : 3730, Training Loss : 0.24633, Training Acc : 0.906, Run Time : 0.45
INFO:root:2019-05-10 20:55:10, Epoch : 1, Step : 3731, Training Loss : 0.16126, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-10 20:55:10, Epoch : 1, Step : 3732, Training Loss : 0.32544, Training Acc : 0.878, Run Time : 0.49
INFO:root:2019-05-10 20:55:25, Epoch : 1, Step : 3733, Training Loss : 0.32970, Training Acc : 0.872, Run Time : 14.79
INFO:root:2019-05-10 20:55:25, Epoch : 1, Step : 3734, Training Loss : 0.23895, Training Acc : 0.894, Run Time : 0.35
INFO:root:2019-05-10 20:55:26, Epoch : 1, Step : 3735, Training Loss : 0.19458, Training Acc : 0.933, Run Time : 0.28
INFO:root:2019-05-10 20:55:33, Epoch : 1, Step : 3736, Training Loss : 0.34433, Training Acc : 0.839, Run Time : 7.68
INFO:root:2019-05-10 20:55:34, Epoch : 1, Step : 3737, Training Loss : 0.61247, Training Acc : 0.733, Run Time : 0.86
INFO:root:2019-05-10 20:55:35, Epoch : 1, Step : 3738, Training Loss : 0.27746, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-10 20:55:35, Epoch : 1, Step : 3739, Training Loss : 0.36536, Training Acc : 0.828, Run Time : 0.51
INFO:root:2019-05-10 20:55:36, Epoch : 1, Step : 3740, Training Loss : 0.31453, Training Acc : 0.839, Run Time : 0.49
INFO:root:2019-05-10 20:55:51, Epoch : 1, Step : 3741, Training Loss : 0.34127, Training Acc : 0.867, Run Time : 15.46
INFO:root:2019-05-10 20:55:51, Epoch : 1, Step : 3742, Training Loss : 0.37425, Training Acc : 0.833, Run Time : 0.28
INFO:root:2019-05-10 20:55:52, Epoch : 1, Step : 3743, Training Loss : 0.19625, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-10 20:55:52, Epoch : 1, Step : 3744, Training Loss : 0.24883, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-10 20:56:04, Epoch : 1, Step : 3745, Training Loss : 0.28947, Training Acc : 0.872, Run Time : 11.46
INFO:root:2019-05-10 20:56:05, Epoch : 1, Step : 3746, Training Loss : 0.28400, Training Acc : 0.889, Run Time : 0.96
INFO:root:2019-05-10 20:56:05, Epoch : 1, Step : 3747, Training Loss : 0.32838, Training Acc : 0.856, Run Time : 0.44
INFO:root:2019-05-10 20:56:06, Epoch : 1, Step : 3748, Training Loss : 0.37562, Training Acc : 0.828, Run Time : 0.33
INFO:root:2019-05-10 20:56:06, Epoch : 1, Step : 3749, Training Loss : 0.23730, Training Acc : 0.956, Run Time : 0.46
INFO:root:2019-05-10 20:56:23, Epoch : 1, Step : 3750, Training Loss : 0.40677, Training Acc : 0.817, Run Time : 16.70
INFO:root:2019-05-10 20:56:23, Epoch : 1, Step : 3751, Training Loss : 0.35608, Training Acc : 0.872, Run Time : 0.51
INFO:root:2019-05-10 20:56:24, Epoch : 1, Step : 3752, Training Loss : 0.43752, Training Acc : 0.794, Run Time : 0.42
INFO:root:2019-05-10 20:56:32, Epoch : 1, Step : 3753, Training Loss : 0.25424, Training Acc : 0.928, Run Time : 8.18
INFO:root:2019-05-10 20:56:35, Epoch : 1, Step : 3754, Training Loss : 0.29195, Training Acc : 0.872, Run Time : 3.31
INFO:root:2019-05-10 20:56:35, Epoch : 1, Step : 3755, Training Loss : 0.30189, Training Acc : 0.911, Run Time : 0.33
INFO:root:2019-05-10 20:56:36, Epoch : 1, Step : 3756, Training Loss : 0.32673, Training Acc : 0.883, Run Time : 0.29
INFO:root:2019-05-10 20:56:38, Epoch : 1, Step : 3757, Training Loss : 0.36181, Training Acc : 0.861, Run Time : 1.80
INFO:root:2019-05-10 20:56:50, Epoch : 1, Step : 3758, Training Loss : 0.26792, Training Acc : 0.889, Run Time : 12.12
INFO:root:2019-05-10 20:56:50, Epoch : 1, Step : 3759, Training Loss : 0.33557, Training Acc : 0.856, Run Time : 0.22
INFO:root:2019-05-10 20:56:50, Epoch : 1, Step : 3760, Training Loss : 0.38098, Training Acc : 0.817, Run Time : 0.27
INFO:root:2019-05-10 20:56:51, Epoch : 1, Step : 3761, Training Loss : 0.37056, Training Acc : 0.850, Run Time : 0.48
INFO:root:2019-05-10 20:56:51, Epoch : 1, Step : 3762, Training Loss : 0.30616, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-10 20:57:09, Epoch : 1, Step : 3763, Training Loss : 0.37696, Training Acc : 0.811, Run Time : 17.71
INFO:root:2019-05-10 20:57:09, Epoch : 1, Step : 3764, Training Loss : 0.27428, Training Acc : 0.894, Run Time : 0.25
INFO:root:2019-05-10 20:57:09, Epoch : 1, Step : 3765, Training Loss : 0.38085, Training Acc : 0.822, Run Time : 0.25
INFO:root:2019-05-10 20:57:10, Epoch : 1, Step : 3766, Training Loss : 0.47854, Training Acc : 0.761, Run Time : 0.47
INFO:root:2019-05-10 20:57:20, Epoch : 1, Step : 3767, Training Loss : 0.41035, Training Acc : 0.756, Run Time : 9.75
INFO:root:2019-05-10 20:57:20, Epoch : 1, Step : 3768, Training Loss : 0.41574, Training Acc : 0.800, Run Time : 0.40
INFO:root:2019-05-10 20:57:21, Epoch : 1, Step : 3769, Training Loss : 0.30781, Training Acc : 0.850, Run Time : 0.70
INFO:root:2019-05-10 20:57:21, Epoch : 1, Step : 3770, Training Loss : 0.44079, Training Acc : 0.761, Run Time : 0.47
INFO:root:2019-05-10 20:57:22, Epoch : 1, Step : 3771, Training Loss : 0.39666, Training Acc : 0.811, Run Time : 0.46
INFO:root:2019-05-10 20:57:37, Epoch : 1, Step : 3772, Training Loss : 0.44849, Training Acc : 0.772, Run Time : 14.96
INFO:root:2019-05-10 20:57:37, Epoch : 1, Step : 3773, Training Loss : 0.49388, Training Acc : 0.728, Run Time : 0.48
INFO:root:2019-05-10 20:57:37, Epoch : 1, Step : 3774, Training Loss : 0.37293, Training Acc : 0.822, Run Time : 0.26
INFO:root:2019-05-10 20:57:38, Epoch : 1, Step : 3775, Training Loss : 0.32006, Training Acc : 0.828, Run Time : 0.46
INFO:root:2019-05-10 20:57:38, Epoch : 1, Step : 3776, Training Loss : 0.48019, Training Acc : 0.739, Run Time : 0.44
INFO:root:2019-05-10 20:58:01, Epoch : 1, Step : 3777, Training Loss : 0.25826, Training Acc : 0.894, Run Time : 22.47
INFO:root:2019-05-10 20:58:01, Epoch : 1, Step : 3778, Training Loss : 0.34231, Training Acc : 0.828, Run Time : 0.24
INFO:root:2019-05-10 20:58:01, Epoch : 1, Step : 3779, Training Loss : 0.31866, Training Acc : 0.861, Run Time : 0.22
INFO:root:2019-05-10 20:58:01, Epoch : 1, Step : 3780, Training Loss : 0.30279, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-10 20:58:17, Epoch : 1, Step : 3781, Training Loss : 0.34979, Training Acc : 0.811, Run Time : 15.68
INFO:root:2019-05-10 20:58:18, Epoch : 1, Step : 3782, Training Loss : 0.32675, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-10 20:58:18, Epoch : 1, Step : 3783, Training Loss : 0.31370, Training Acc : 0.856, Run Time : 0.29
INFO:root:2019-05-10 20:58:19, Epoch : 1, Step : 3784, Training Loss : 0.32895, Training Acc : 0.861, Run Time : 1.56
INFO:root:2019-05-10 20:58:33, Epoch : 1, Step : 3785, Training Loss : 0.31194, Training Acc : 0.828, Run Time : 13.12
INFO:root:2019-05-10 20:58:34, Epoch : 1, Step : 3786, Training Loss : 0.32331, Training Acc : 0.833, Run Time : 0.92
INFO:root:2019-05-10 20:58:34, Epoch : 1, Step : 3787, Training Loss : 0.31724, Training Acc : 0.844, Run Time : 0.36
INFO:root:2019-05-10 20:58:34, Epoch : 1, Step : 3788, Training Loss : 0.34869, Training Acc : 0.806, Run Time : 0.30
INFO:root:2019-05-10 20:58:45, Epoch : 1, Step : 3789, Training Loss : 0.36006, Training Acc : 0.778, Run Time : 10.71
INFO:root:2019-05-10 20:58:46, Epoch : 1, Step : 3790, Training Loss : 0.36020, Training Acc : 0.833, Run Time : 1.00
INFO:root:2019-05-10 20:58:47, Epoch : 1, Step : 3791, Training Loss : 0.28760, Training Acc : 0.844, Run Time : 0.63
INFO:root:2019-05-10 20:58:47, Epoch : 1, Step : 3792, Training Loss : 0.42602, Training Acc : 0.767, Run Time : 0.47
INFO:root:2019-05-10 20:58:47, Epoch : 1, Step : 3793, Training Loss : 0.29786, Training Acc : 0.861, Run Time : 0.46
INFO:root:2019-05-10 20:59:00, Epoch : 1, Step : 3794, Training Loss : 0.39324, Training Acc : 0.789, Run Time : 12.56
INFO:root:2019-05-10 20:59:01, Epoch : 1, Step : 3795, Training Loss : 0.37289, Training Acc : 0.794, Run Time : 0.74
INFO:root:2019-05-10 20:59:01, Epoch : 1, Step : 3796, Training Loss : 0.33125, Training Acc : 0.844, Run Time : 0.38
INFO:root:2019-05-10 20:59:02, Epoch : 1, Step : 3797, Training Loss : 0.39392, Training Acc : 0.783, Run Time : 0.48
INFO:root:2019-05-10 20:59:02, Epoch : 1, Step : 3798, Training Loss : 0.28831, Training Acc : 0.867, Run Time : 0.52
INFO:root:2019-05-10 20:59:14, Epoch : 1, Step : 3799, Training Loss : 0.34735, Training Acc : 0.811, Run Time : 11.75
INFO:root:2019-05-10 20:59:18, Epoch : 1, Step : 3800, Training Loss : 0.31579, Training Acc : 0.828, Run Time : 4.10
INFO:root:2019-05-10 20:59:19, Epoch : 1, Step : 3801, Training Loss : 0.82813, Training Acc : 0.722, Run Time : 1.03
INFO:root:2019-05-10 20:59:19, Epoch : 1, Step : 3802, Training Loss : 0.83533, Training Acc : 0.678, Run Time : 0.47
INFO:root:2019-05-10 20:59:20, Epoch : 1, Step : 3803, Training Loss : 0.67830, Training Acc : 0.722, Run Time : 0.49
INFO:root:2019-05-10 20:59:20, Epoch : 1, Step : 3804, Training Loss : 0.68670, Training Acc : 0.778, Run Time : 0.47
INFO:root:2019-05-10 20:59:39, Epoch : 1, Step : 3805, Training Loss : 0.46052, Training Acc : 0.739, Run Time : 18.22
INFO:root:2019-05-10 20:59:39, Epoch : 1, Step : 3806, Training Loss : 0.50945, Training Acc : 0.756, Run Time : 0.78
INFO:root:2019-05-10 20:59:40, Epoch : 1, Step : 3807, Training Loss : 0.48330, Training Acc : 0.783, Run Time : 0.44
INFO:root:2019-05-10 20:59:40, Epoch : 1, Step : 3808, Training Loss : 0.30600, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-10 20:59:41, Epoch : 1, Step : 3809, Training Loss : 0.26802, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 20:59:58, Epoch : 1, Step : 3810, Training Loss : 0.25362, Training Acc : 0.900, Run Time : 16.71
INFO:root:2019-05-10 20:59:58, Epoch : 1, Step : 3811, Training Loss : 0.30529, Training Acc : 0.883, Run Time : 0.22
INFO:root:2019-05-10 20:59:58, Epoch : 1, Step : 3812, Training Loss : 0.40081, Training Acc : 0.828, Run Time : 0.25
INFO:root:2019-05-10 20:59:58, Epoch : 1, Step : 3813, Training Loss : 0.30127, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-10 21:00:00, Epoch : 1, Step : 3814, Training Loss : 0.41200, Training Acc : 0.822, Run Time : 1.42
INFO:root:2019-05-10 21:00:15, Epoch : 1, Step : 3815, Training Loss : 0.24051, Training Acc : 0.911, Run Time : 15.54
INFO:root:2019-05-10 21:00:17, Epoch : 1, Step : 3816, Training Loss : 0.37668, Training Acc : 0.822, Run Time : 1.16
INFO:root:2019-05-10 21:00:17, Epoch : 1, Step : 3817, Training Loss : 0.25666, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-10 21:00:17, Epoch : 1, Step : 3818, Training Loss : 0.49393, Training Acc : 0.789, Run Time : 0.44
INFO:root:2019-05-10 21:00:18, Epoch : 1, Step : 3819, Training Loss : 0.29999, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 21:00:34, Epoch : 1, Step : 3820, Training Loss : 0.33681, Training Acc : 0.883, Run Time : 15.90
INFO:root:2019-05-10 21:00:34, Epoch : 1, Step : 3821, Training Loss : 0.42778, Training Acc : 0.822, Run Time : 0.32
INFO:root:2019-05-10 21:00:35, Epoch : 1, Step : 3822, Training Loss : 0.45061, Training Acc : 0.783, Run Time : 0.47
INFO:root:2019-05-10 21:00:44, Epoch : 1, Step : 3823, Training Loss : 0.55188, Training Acc : 0.767, Run Time : 9.80
INFO:root:2019-05-10 21:00:48, Epoch : 1, Step : 3824, Training Loss : 0.29090, Training Acc : 0.883, Run Time : 3.37
INFO:root:2019-05-10 21:00:48, Epoch : 1, Step : 3825, Training Loss : 0.36203, Training Acc : 0.817, Run Time : 0.50
INFO:root:2019-05-10 21:00:49, Epoch : 1, Step : 3826, Training Loss : 0.40944, Training Acc : 0.817, Run Time : 0.49
INFO:root:2019-05-10 21:00:49, Epoch : 1, Step : 3827, Training Loss : 0.37904, Training Acc : 0.811, Run Time : 0.48
INFO:root:2019-05-10 21:00:51, Epoch : 1, Step : 3828, Training Loss : 0.28774, Training Acc : 0.872, Run Time : 1.88
INFO:root:2019-05-10 21:01:01, Epoch : 1, Step : 3829, Training Loss : 0.24848, Training Acc : 0.894, Run Time : 9.63
INFO:root:2019-05-10 21:01:02, Epoch : 1, Step : 3830, Training Loss : 0.32030, Training Acc : 0.817, Run Time : 1.14
INFO:root:2019-05-10 21:01:02, Epoch : 1, Step : 3831, Training Loss : 0.35173, Training Acc : 0.844, Run Time : 0.50
INFO:root:2019-05-10 21:01:03, Epoch : 1, Step : 3832, Training Loss : 0.28323, Training Acc : 0.872, Run Time : 0.49
INFO:root:2019-05-10 21:01:03, Epoch : 1, Step : 3833, Training Loss : 0.33516, Training Acc : 0.861, Run Time : 0.47
INFO:root:2019-05-10 21:01:20, Epoch : 1, Step : 3834, Training Loss : 0.40941, Training Acc : 0.817, Run Time : 17.08
INFO:root:2019-05-10 21:01:21, Epoch : 1, Step : 3835, Training Loss : 0.24986, Training Acc : 0.917, Run Time : 0.31
INFO:root:2019-05-10 21:01:21, Epoch : 1, Step : 3836, Training Loss : 0.40131, Training Acc : 0.861, Run Time : 0.45
INFO:root:2019-05-10 21:01:23, Epoch : 1, Step : 3837, Training Loss : 0.37984, Training Acc : 0.800, Run Time : 1.54
INFO:root:2019-05-10 21:01:24, Epoch : 1, Step : 3838, Training Loss : 0.28809, Training Acc : 0.906, Run Time : 0.76
INFO:root:2019-05-10 21:01:39, Epoch : 1, Step : 3839, Training Loss : 0.41056, Training Acc : 0.783, Run Time : 15.83
INFO:root:2019-05-10 21:01:40, Epoch : 1, Step : 3840, Training Loss : 0.38222, Training Acc : 0.794, Run Time : 0.62
INFO:root:2019-05-10 21:01:40, Epoch : 1, Step : 3841, Training Loss : 0.36286, Training Acc : 0.844, Run Time : 0.23
INFO:root:2019-05-10 21:01:41, Epoch : 1, Step : 3842, Training Loss : 0.49617, Training Acc : 0.806, Run Time : 0.49
INFO:root:2019-05-10 21:01:42, Epoch : 1, Step : 3843, Training Loss : 0.64533, Training Acc : 0.767, Run Time : 1.00
INFO:root:2019-05-10 21:01:57, Epoch : 1, Step : 3844, Training Loss : 0.58919, Training Acc : 0.728, Run Time : 15.65
INFO:root:2019-05-10 21:01:58, Epoch : 1, Step : 3845, Training Loss : 0.40300, Training Acc : 0.822, Run Time : 0.22
INFO:root:2019-05-10 21:01:58, Epoch : 1, Step : 3846, Training Loss : 0.38191, Training Acc : 0.828, Run Time : 0.26
INFO:root:2019-05-10 21:01:58, Epoch : 1, Step : 3847, Training Loss : 0.43550, Training Acc : 0.806, Run Time : 0.46
INFO:root:2019-05-10 21:01:59, Epoch : 1, Step : 3848, Training Loss : 0.48439, Training Acc : 0.767, Run Time : 0.43
INFO:root:2019-05-10 21:02:14, Epoch : 1, Step : 3849, Training Loss : 0.39156, Training Acc : 0.794, Run Time : 15.59
INFO:root:2019-05-10 21:02:15, Epoch : 1, Step : 3850, Training Loss : 0.33120, Training Acc : 0.844, Run Time : 0.45
INFO:root:2019-05-10 21:02:15, Epoch : 1, Step : 3851, Training Loss : 0.36445, Training Acc : 0.844, Run Time : 0.61
INFO:root:2019-05-10 21:02:16, Epoch : 1, Step : 3852, Training Loss : 0.35887, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-10 21:02:34, Epoch : 1, Step : 3853, Training Loss : 0.27389, Training Acc : 0.883, Run Time : 17.96
INFO:root:2019-05-10 21:02:34, Epoch : 1, Step : 3854, Training Loss : 0.54892, Training Acc : 0.767, Run Time : 0.59
INFO:root:2019-05-10 21:02:35, Epoch : 1, Step : 3855, Training Loss : 0.25567, Training Acc : 0.917, Run Time : 0.22
INFO:root:2019-05-10 21:02:35, Epoch : 1, Step : 3856, Training Loss : 0.33909, Training Acc : 0.861, Run Time : 0.26
INFO:root:2019-05-10 21:02:36, Epoch : 1, Step : 3857, Training Loss : 0.33069, Training Acc : 0.878, Run Time : 0.67
INFO:root:2019-05-10 21:02:55, Epoch : 1, Step : 3858, Training Loss : 0.50976, Training Acc : 0.794, Run Time : 19.04
INFO:root:2019-05-10 21:02:55, Epoch : 1, Step : 3859, Training Loss : 0.54048, Training Acc : 0.722, Run Time : 0.42
INFO:root:2019-05-10 21:02:56, Epoch : 1, Step : 3860, Training Loss : 0.41166, Training Acc : 0.828, Run Time : 1.01
INFO:root:2019-05-10 21:03:08, Epoch : 1, Step : 3861, Training Loss : 0.63437, Training Acc : 0.672, Run Time : 12.48
INFO:root:2019-05-10 21:03:09, Epoch : 1, Step : 3862, Training Loss : 0.48497, Training Acc : 0.761, Run Time : 0.45
INFO:root:2019-05-10 21:03:09, Epoch : 1, Step : 3863, Training Loss : 0.33996, Training Acc : 0.822, Run Time : 0.32
INFO:root:2019-05-10 21:03:10, Epoch : 1, Step : 3864, Training Loss : 0.50306, Training Acc : 0.744, Run Time : 0.45
INFO:root:2019-05-10 21:03:20, Epoch : 1, Step : 3865, Training Loss : 0.53860, Training Acc : 0.756, Run Time : 10.52
INFO:root:2019-05-10 21:03:24, Epoch : 1, Step : 3866, Training Loss : 0.27624, Training Acc : 0.872, Run Time : 3.29
INFO:root:2019-05-10 21:03:24, Epoch : 1, Step : 3867, Training Loss : 0.38867, Training Acc : 0.822, Run Time : 0.28
INFO:root:2019-05-10 21:03:24, Epoch : 1, Step : 3868, Training Loss : 0.28474, Training Acc : 0.878, Run Time : 0.44
INFO:root:2019-05-10 21:03:25, Epoch : 1, Step : 3869, Training Loss : 0.41610, Training Acc : 0.756, Run Time : 0.95
INFO:root:2019-05-10 21:03:39, Epoch : 1, Step : 3870, Training Loss : 0.38137, Training Acc : 0.794, Run Time : 13.45
INFO:root:2019-05-10 21:03:39, Epoch : 1, Step : 3871, Training Loss : 0.18877, Training Acc : 0.956, Run Time : 0.22
INFO:root:2019-05-10 21:03:39, Epoch : 1, Step : 3872, Training Loss : 0.19732, Training Acc : 0.933, Run Time : 0.22
INFO:root:2019-05-10 21:03:39, Epoch : 1, Step : 3873, Training Loss : 0.23471, Training Acc : 0.928, Run Time : 0.22
INFO:root:2019-05-10 21:03:50, Epoch : 1, Step : 3874, Training Loss : 0.17571, Training Acc : 0.950, Run Time : 10.98
INFO:root:2019-05-10 21:03:51, Epoch : 1, Step : 3875, Training Loss : 0.20158, Training Acc : 0.939, Run Time : 1.15
INFO:root:2019-05-10 21:03:52, Epoch : 1, Step : 3876, Training Loss : 0.19263, Training Acc : 0.944, Run Time : 0.52
INFO:root:2019-05-10 21:04:02, Epoch : 1, Step : 3877, Training Loss : 0.19758, Training Acc : 0.906, Run Time : 10.32
INFO:root:2019-05-10 21:04:03, Epoch : 1, Step : 3878, Training Loss : 0.16331, Training Acc : 0.967, Run Time : 1.17
INFO:root:2019-05-10 21:04:04, Epoch : 1, Step : 3879, Training Loss : 0.24313, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-10 21:04:04, Epoch : 1, Step : 3880, Training Loss : 0.22231, Training Acc : 0.911, Run Time : 0.49
INFO:root:2019-05-10 21:04:16, Epoch : 1, Step : 3881, Training Loss : 0.34531, Training Acc : 0.828, Run Time : 11.84
INFO:root:2019-05-10 21:04:16, Epoch : 1, Step : 3882, Training Loss : 0.19894, Training Acc : 0.961, Run Time : 0.25
INFO:root:2019-05-10 21:04:17, Epoch : 1, Step : 3883, Training Loss : 0.30379, Training Acc : 0.928, Run Time : 0.28
INFO:root:2019-05-10 21:04:17, Epoch : 1, Step : 3884, Training Loss : 0.28711, Training Acc : 0.878, Run Time : 0.45
INFO:root:2019-05-10 21:04:18, Epoch : 1, Step : 3885, Training Loss : 0.38319, Training Acc : 0.828, Run Time : 0.45
INFO:root:2019-05-10 21:04:24, Epoch : 1, Step : 3886, Training Loss : 0.27737, Training Acc : 0.883, Run Time : 6.75
INFO:root:2019-05-10 21:04:25, Epoch : 1, Step : 3887, Training Loss : 0.25038, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-10 21:04:43, Epoch : 1, Step : 3888, Training Loss : 0.27617, Training Acc : 0.867, Run Time : 18.63
INFO:root:2019-05-10 21:04:44, Epoch : 1, Step : 3889, Training Loss : 0.43557, Training Acc : 0.778, Run Time : 0.35
INFO:root:2019-05-10 21:04:44, Epoch : 1, Step : 3890, Training Loss : 0.27734, Training Acc : 0.922, Run Time : 0.50
INFO:root:2019-05-10 21:04:58, Epoch : 1, Step : 3891, Training Loss : 0.38357, Training Acc : 0.822, Run Time : 13.51
INFO:root:2019-05-10 21:04:58, Epoch : 1, Step : 3892, Training Loss : 0.28076, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-10 21:04:58, Epoch : 1, Step : 3893, Training Loss : 0.29841, Training Acc : 0.839, Run Time : 0.26
INFO:root:2019-05-10 21:04:59, Epoch : 1, Step : 3894, Training Loss : 0.39375, Training Acc : 0.806, Run Time : 0.46
INFO:root:2019-05-10 21:04:59, Epoch : 1, Step : 3895, Training Loss : 0.36187, Training Acc : 0.811, Run Time : 0.52
INFO:root:2019-05-10 21:05:04, Epoch : 1, Step : 3896, Training Loss : 0.31429, Training Acc : 0.839, Run Time : 4.40
INFO:root:2019-05-10 21:05:04, Epoch : 1, Step : 3897, Training Loss : 0.28848, Training Acc : 0.883, Run Time : 0.22
INFO:root:2019-05-10 21:05:21, Epoch : 1, Step : 3898, Training Loss : 0.34925, Training Acc : 0.833, Run Time : 17.18
INFO:root:2019-05-10 21:05:22, Epoch : 1, Step : 3899, Training Loss : 0.23831, Training Acc : 0.900, Run Time : 0.32
INFO:root:2019-05-10 21:05:22, Epoch : 1, Step : 3900, Training Loss : 0.30594, Training Acc : 0.856, Run Time : 0.43
INFO:root:2019-05-10 21:05:36, Epoch : 1, Step : 3901, Training Loss : 0.39173, Training Acc : 0.794, Run Time : 13.56
INFO:root:2019-05-10 21:05:36, Epoch : 1, Step : 3902, Training Loss : 0.39078, Training Acc : 0.800, Run Time : 0.34
INFO:root:2019-05-10 21:05:37, Epoch : 1, Step : 3903, Training Loss : 0.32743, Training Acc : 0.856, Run Time : 0.77
INFO:root:2019-05-10 21:05:37, Epoch : 1, Step : 3904, Training Loss : 0.22950, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 21:05:50, Epoch : 1, Step : 3905, Training Loss : 0.19128, Training Acc : 0.939, Run Time : 12.47
INFO:root:2019-05-10 21:05:50, Epoch : 1, Step : 3906, Training Loss : 0.29131, Training Acc : 0.883, Run Time : 0.53
INFO:root:2019-05-10 21:05:51, Epoch : 1, Step : 3907, Training Loss : 0.34071, Training Acc : 0.844, Run Time : 0.47
INFO:root:2019-05-10 21:05:51, Epoch : 1, Step : 3908, Training Loss : 0.26738, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 21:05:52, Epoch : 1, Step : 3909, Training Loss : 0.32653, Training Acc : 0.844, Run Time : 0.50
INFO:root:2019-05-10 21:06:06, Epoch : 1, Step : 3910, Training Loss : 0.24755, Training Acc : 0.883, Run Time : 14.30
INFO:root:2019-05-10 21:06:07, Epoch : 1, Step : 3911, Training Loss : 0.27225, Training Acc : 0.883, Run Time : 0.91
INFO:root:2019-05-10 21:06:07, Epoch : 1, Step : 3912, Training Loss : 0.21812, Training Acc : 0.922, Run Time : 0.45
INFO:root:2019-05-10 21:06:08, Epoch : 1, Step : 3913, Training Loss : 0.17593, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-10 21:06:08, Epoch : 1, Step : 3914, Training Loss : 0.18931, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-10 21:06:24, Epoch : 1, Step : 3915, Training Loss : 0.24740, Training Acc : 0.917, Run Time : 15.62
INFO:root:2019-05-10 21:06:24, Epoch : 1, Step : 3916, Training Loss : 0.23996, Training Acc : 0.894, Run Time : 0.61
INFO:root:2019-05-10 21:06:25, Epoch : 1, Step : 3917, Training Loss : 0.23631, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-10 21:06:35, Epoch : 1, Step : 3918, Training Loss : 0.19398, Training Acc : 0.928, Run Time : 10.22
INFO:root:2019-05-10 21:06:36, Epoch : 1, Step : 3919, Training Loss : 0.19941, Training Acc : 0.922, Run Time : 0.66
INFO:root:2019-05-10 21:06:38, Epoch : 1, Step : 3920, Training Loss : 0.22627, Training Acc : 0.900, Run Time : 2.00
INFO:root:2019-05-10 21:06:49, Epoch : 1, Step : 3921, Training Loss : 0.16493, Training Acc : 0.933, Run Time : 11.52
INFO:root:2019-05-10 21:06:50, Epoch : 1, Step : 3922, Training Loss : 0.18477, Training Acc : 0.911, Run Time : 0.22
INFO:root:2019-05-10 21:06:50, Epoch : 1, Step : 3923, Training Loss : 0.18322, Training Acc : 0.939, Run Time : 0.27
INFO:root:2019-05-10 21:06:50, Epoch : 1, Step : 3924, Training Loss : 0.15432, Training Acc : 0.939, Run Time : 0.47
INFO:root:2019-05-10 21:06:51, Epoch : 1, Step : 3925, Training Loss : 0.11086, Training Acc : 0.961, Run Time : 0.42
INFO:root:2019-05-10 21:07:06, Epoch : 1, Step : 3926, Training Loss : 0.19202, Training Acc : 0.922, Run Time : 15.48
INFO:root:2019-05-10 21:07:07, Epoch : 1, Step : 3927, Training Loss : 0.23372, Training Acc : 0.911, Run Time : 0.69
INFO:root:2019-05-10 21:07:07, Epoch : 1, Step : 3928, Training Loss : 0.30368, Training Acc : 0.856, Run Time : 0.25
INFO:root:2019-05-10 21:07:08, Epoch : 1, Step : 3929, Training Loss : 0.30604, Training Acc : 0.867, Run Time : 0.45
INFO:root:2019-05-10 21:07:08, Epoch : 1, Step : 3930, Training Loss : 0.34610, Training Acc : 0.839, Run Time : 0.44
INFO:root:2019-05-10 21:07:24, Epoch : 1, Step : 3931, Training Loss : 0.42229, Training Acc : 0.789, Run Time : 16.09
INFO:root:2019-05-10 21:07:24, Epoch : 1, Step : 3932, Training Loss : 0.45497, Training Acc : 0.794, Run Time : 0.40
INFO:root:2019-05-10 21:07:25, Epoch : 1, Step : 3933, Training Loss : 0.43345, Training Acc : 0.800, Run Time : 0.49
INFO:root:2019-05-10 21:07:25, Epoch : 1, Step : 3934, Training Loss : 0.53350, Training Acc : 0.739, Run Time : 0.47
INFO:root:2019-05-10 21:07:26, Epoch : 1, Step : 3935, Training Loss : 0.31160, Training Acc : 0.867, Run Time : 0.33
INFO:root:2019-05-10 21:07:42, Epoch : 1, Step : 3936, Training Loss : 0.26378, Training Acc : 0.900, Run Time : 16.53
INFO:root:2019-05-10 21:07:43, Epoch : 1, Step : 3937, Training Loss : 0.46701, Training Acc : 0.806, Run Time : 0.46
INFO:root:2019-05-10 21:07:43, Epoch : 1, Step : 3938, Training Loss : 0.46195, Training Acc : 0.833, Run Time : 0.64
INFO:root:2019-05-10 21:07:44, Epoch : 1, Step : 3939, Training Loss : 0.32127, Training Acc : 0.883, Run Time : 0.39
INFO:root:2019-05-10 21:07:44, Epoch : 1, Step : 3940, Training Loss : 0.32614, Training Acc : 0.889, Run Time : 0.27
INFO:root:2019-05-10 21:08:01, Epoch : 1, Step : 3941, Training Loss : 0.37328, Training Acc : 0.856, Run Time : 17.08
INFO:root:2019-05-10 21:08:01, Epoch : 1, Step : 3942, Training Loss : 0.35635, Training Acc : 0.861, Run Time : 0.31
INFO:root:2019-05-10 21:08:02, Epoch : 1, Step : 3943, Training Loss : 0.42720, Training Acc : 0.794, Run Time : 0.23
INFO:root:2019-05-10 21:08:02, Epoch : 1, Step : 3944, Training Loss : 0.44668, Training Acc : 0.783, Run Time : 0.47
INFO:root:2019-05-10 21:08:11, Epoch : 1, Step : 3945, Training Loss : 0.26594, Training Acc : 0.906, Run Time : 8.64
INFO:root:2019-05-10 21:08:11, Epoch : 1, Step : 3946, Training Loss : 0.30824, Training Acc : 0.889, Run Time : 0.62
INFO:root:2019-05-10 21:08:12, Epoch : 1, Step : 3947, Training Loss : 0.25150, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-10 21:08:12, Epoch : 1, Step : 3948, Training Loss : 0.26269, Training Acc : 0.939, Run Time : 0.58
INFO:root:2019-05-10 21:08:14, Epoch : 1, Step : 3949, Training Loss : 0.32569, Training Acc : 0.867, Run Time : 1.87
INFO:root:2019-05-10 21:08:29, Epoch : 1, Step : 3950, Training Loss : 0.30605, Training Acc : 0.906, Run Time : 14.37
INFO:root:2019-05-10 21:08:29, Epoch : 1, Step : 3951, Training Loss : 0.69099, Training Acc : 0.656, Run Time : 0.23
INFO:root:2019-05-10 21:08:29, Epoch : 1, Step : 3952, Training Loss : 0.61186, Training Acc : 0.706, Run Time : 0.29
INFO:root:2019-05-10 21:08:30, Epoch : 1, Step : 3953, Training Loss : 0.45143, Training Acc : 0.800, Run Time : 0.49
INFO:root:2019-05-10 21:08:42, Epoch : 1, Step : 3954, Training Loss : 0.19118, Training Acc : 0.917, Run Time : 12.60
INFO:root:2019-05-10 21:08:43, Epoch : 1, Step : 3955, Training Loss : 0.28290, Training Acc : 0.900, Run Time : 0.79
INFO:root:2019-05-10 21:08:44, Epoch : 1, Step : 3956, Training Loss : 0.30119, Training Acc : 0.867, Run Time : 0.44
INFO:root:2019-05-10 21:08:44, Epoch : 1, Step : 3957, Training Loss : 0.20595, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 21:08:45, Epoch : 1, Step : 3958, Training Loss : 0.26102, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 21:09:01, Epoch : 1, Step : 3959, Training Loss : 0.19130, Training Acc : 0.939, Run Time : 16.52
INFO:root:2019-05-10 21:09:01, Epoch : 1, Step : 3960, Training Loss : 0.37156, Training Acc : 0.806, Run Time : 0.32
INFO:root:2019-05-10 21:09:02, Epoch : 1, Step : 3961, Training Loss : 0.32255, Training Acc : 0.833, Run Time : 0.36
INFO:root:2019-05-10 21:09:02, Epoch : 1, Step : 3962, Training Loss : 0.19895, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-10 21:09:03, Epoch : 1, Step : 3963, Training Loss : 0.11841, Training Acc : 0.967, Run Time : 0.48
INFO:root:2019-05-10 21:09:20, Epoch : 1, Step : 3964, Training Loss : 0.27949, Training Acc : 0.911, Run Time : 16.92
INFO:root:2019-05-10 21:09:20, Epoch : 1, Step : 3965, Training Loss : 0.14206, Training Acc : 0.961, Run Time : 0.24
INFO:root:2019-05-10 21:09:20, Epoch : 1, Step : 3966, Training Loss : 0.09867, Training Acc : 0.978, Run Time : 0.49
INFO:root:2019-05-10 21:09:21, Epoch : 1, Step : 3967, Training Loss : 0.17070, Training Acc : 0.967, Run Time : 0.45
INFO:root:2019-05-10 21:09:22, Epoch : 1, Step : 3968, Training Loss : 0.31658, Training Acc : 0.878, Run Time : 1.27
INFO:root:2019-05-10 21:09:37, Epoch : 1, Step : 3969, Training Loss : 0.28030, Training Acc : 0.922, Run Time : 15.46
INFO:root:2019-05-10 21:09:38, Epoch : 1, Step : 3970, Training Loss : 0.23107, Training Acc : 0.911, Run Time : 0.70
INFO:root:2019-05-10 21:09:39, Epoch : 1, Step : 3971, Training Loss : 0.16802, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-10 21:09:40, Epoch : 1, Step : 3972, Training Loss : 0.19792, Training Acc : 0.950, Run Time : 1.48
INFO:root:2019-05-10 21:09:41, Epoch : 1, Step : 3973, Training Loss : 0.30746, Training Acc : 0.894, Run Time : 0.71
INFO:root:2019-05-10 21:09:54, Epoch : 1, Step : 3974, Training Loss : 0.14514, Training Acc : 0.972, Run Time : 13.47
INFO:root:2019-05-10 21:09:55, Epoch : 1, Step : 3975, Training Loss : 0.18118, Training Acc : 0.939, Run Time : 0.65
INFO:root:2019-05-10 21:09:55, Epoch : 1, Step : 3976, Training Loss : 0.10320, Training Acc : 0.972, Run Time : 0.47
INFO:root:2019-05-10 21:09:56, Epoch : 1, Step : 3977, Training Loss : 0.15781, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-10 21:09:58, Epoch : 1, Step : 3978, Training Loss : 0.20419, Training Acc : 0.917, Run Time : 1.77
INFO:root:2019-05-10 21:10:10, Epoch : 1, Step : 3979, Training Loss : 0.19711, Training Acc : 0.922, Run Time : 12.63
INFO:root:2019-05-10 21:10:11, Epoch : 1, Step : 3980, Training Loss : 0.33760, Training Acc : 0.883, Run Time : 0.27
INFO:root:2019-05-10 21:10:11, Epoch : 1, Step : 3981, Training Loss : 0.31936, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-10 21:10:11, Epoch : 1, Step : 3982, Training Loss : 0.30973, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-10 21:10:25, Epoch : 1, Step : 3983, Training Loss : 0.19999, Training Acc : 0.917, Run Time : 13.28
INFO:root:2019-05-10 21:10:25, Epoch : 1, Step : 3984, Training Loss : 0.12590, Training Acc : 0.956, Run Time : 0.57
INFO:root:2019-05-10 21:10:26, Epoch : 1, Step : 3985, Training Loss : 0.16197, Training Acc : 0.961, Run Time : 0.32
INFO:root:2019-05-10 21:10:26, Epoch : 1, Step : 3986, Training Loss : 0.16562, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-10 21:10:37, Epoch : 1, Step : 3987, Training Loss : 0.14041, Training Acc : 0.944, Run Time : 11.09
INFO:root:2019-05-10 21:10:38, Epoch : 1, Step : 3988, Training Loss : 0.15511, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-10 21:10:38, Epoch : 1, Step : 3989, Training Loss : 0.17355, Training Acc : 0.928, Run Time : 0.44
INFO:root:2019-05-10 21:10:40, Epoch : 1, Step : 3990, Training Loss : 0.17162, Training Acc : 0.944, Run Time : 1.61
INFO:root:2019-05-10 21:10:40, Epoch : 1, Step : 3991, Training Loss : 0.22924, Training Acc : 0.917, Run Time : 0.31
INFO:root:2019-05-10 21:10:45, Epoch : 1, Step : 3992, Training Loss : 0.26561, Training Acc : 0.850, Run Time : 4.82
INFO:root:2019-05-10 21:10:45, Epoch : 1, Step : 3993, Training Loss : 0.16684, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-10 21:11:00, Epoch : 1, Step : 3994, Training Loss : 0.14635, Training Acc : 0.950, Run Time : 14.50
INFO:root:2019-05-10 21:11:00, Epoch : 1, Step : 3995, Training Loss : 0.16214, Training Acc : 0.911, Run Time : 0.29
INFO:root:2019-05-10 21:11:01, Epoch : 1, Step : 3996, Training Loss : 0.21374, Training Acc : 0.917, Run Time : 0.58
INFO:root:2019-05-10 21:11:01, Epoch : 1, Step : 3997, Training Loss : 0.11304, Training Acc : 0.961, Run Time : 0.46
INFO:root:2019-05-10 21:11:02, Epoch : 1, Step : 3998, Training Loss : 0.18784, Training Acc : 0.917, Run Time : 1.41
INFO:root:2019-05-10 21:11:16, Epoch : 1, Step : 3999, Training Loss : 0.23238, Training Acc : 0.889, Run Time : 13.39
INFO:root:2019-05-10 21:11:16, Epoch : 1, Step : 4000, Training Loss : 0.24016, Training Acc : 0.889, Run Time : 0.34
INFO:root:2019-05-10 21:11:17, Epoch : 1, Step : 4001, Training Loss : 0.54943, Training Acc : 0.744, Run Time : 1.14
INFO:root:2019-05-10 21:11:18, Epoch : 1, Step : 4002, Training Loss : 0.39286, Training Acc : 0.817, Run Time : 0.46
INFO:root:2019-05-10 21:11:18, Epoch : 1, Step : 4003, Training Loss : 0.36723, Training Acc : 0.828, Run Time : 0.49
INFO:root:2019-05-10 21:11:33, Epoch : 1, Step : 4004, Training Loss : 0.31608, Training Acc : 0.872, Run Time : 14.48
INFO:root:2019-05-10 21:11:33, Epoch : 1, Step : 4005, Training Loss : 0.24692, Training Acc : 0.900, Run Time : 0.64
INFO:root:2019-05-10 21:11:34, Epoch : 1, Step : 4006, Training Loss : 0.26100, Training Acc : 0.883, Run Time : 0.23
INFO:root:2019-05-10 21:11:34, Epoch : 1, Step : 4007, Training Loss : 0.32680, Training Acc : 0.856, Run Time : 0.52
INFO:root:2019-05-10 21:11:35, Epoch : 1, Step : 4008, Training Loss : 0.21924, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-10 21:11:50, Epoch : 1, Step : 4009, Training Loss : 0.24398, Training Acc : 0.900, Run Time : 15.20
INFO:root:2019-05-10 21:11:50, Epoch : 1, Step : 4010, Training Loss : 0.30645, Training Acc : 0.850, Run Time : 0.23
INFO:root:2019-05-10 21:11:50, Epoch : 1, Step : 4011, Training Loss : 0.29564, Training Acc : 0.878, Run Time : 0.22
INFO:root:2019-05-10 21:11:50, Epoch : 1, Step : 4012, Training Loss : 0.21575, Training Acc : 0.900, Run Time : 0.22
INFO:root:2019-05-10 21:11:51, Epoch : 1, Step : 4013, Training Loss : 0.18184, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-10 21:12:05, Epoch : 1, Step : 4014, Training Loss : 0.35290, Training Acc : 0.861, Run Time : 13.74
INFO:root:2019-05-10 21:12:05, Epoch : 1, Step : 4015, Training Loss : 0.39149, Training Acc : 0.833, Run Time : 0.27
INFO:root:2019-05-10 21:12:05, Epoch : 1, Step : 4016, Training Loss : 0.24768, Training Acc : 0.922, Run Time : 0.39
INFO:root:2019-05-10 21:12:06, Epoch : 1, Step : 4017, Training Loss : 0.21673, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-10 21:12:06, Epoch : 1, Step : 4018, Training Loss : 0.22540, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-10 21:12:21, Epoch : 1, Step : 4019, Training Loss : 0.23542, Training Acc : 0.922, Run Time : 15.28
INFO:root:2019-05-10 21:12:22, Epoch : 1, Step : 4020, Training Loss : 0.36034, Training Acc : 0.844, Run Time : 0.22
INFO:root:2019-05-10 21:12:22, Epoch : 1, Step : 4021, Training Loss : 0.25463, Training Acc : 0.906, Run Time : 0.29
INFO:root:2019-05-10 21:12:22, Epoch : 1, Step : 4022, Training Loss : 0.17956, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 21:12:23, Epoch : 1, Step : 4023, Training Loss : 0.40713, Training Acc : 0.844, Run Time : 0.47
INFO:root:2019-05-10 21:12:40, Epoch : 1, Step : 4024, Training Loss : 0.19702, Training Acc : 0.917, Run Time : 16.58
INFO:root:2019-05-10 21:12:40, Epoch : 1, Step : 4025, Training Loss : 0.10058, Training Acc : 0.972, Run Time : 0.33
INFO:root:2019-05-10 21:12:40, Epoch : 1, Step : 4026, Training Loss : 0.35773, Training Acc : 0.867, Run Time : 0.49
INFO:root:2019-05-10 21:12:41, Epoch : 1, Step : 4027, Training Loss : 0.23644, Training Acc : 0.900, Run Time : 0.48
INFO:root:2019-05-10 21:12:42, Epoch : 1, Step : 4028, Training Loss : 0.16787, Training Acc : 0.922, Run Time : 0.88
INFO:root:2019-05-10 21:12:58, Epoch : 1, Step : 4029, Training Loss : 0.16873, Training Acc : 0.933, Run Time : 16.46
INFO:root:2019-05-10 21:12:58, Epoch : 1, Step : 4030, Training Loss : 0.16967, Training Acc : 0.939, Run Time : 0.22
INFO:root:2019-05-10 21:12:59, Epoch : 1, Step : 4031, Training Loss : 0.16538, Training Acc : 0.933, Run Time : 0.26
INFO:root:2019-05-10 21:12:59, Epoch : 1, Step : 4032, Training Loss : 0.21420, Training Acc : 0.922, Run Time : 0.50
INFO:root:2019-05-10 21:13:00, Epoch : 1, Step : 4033, Training Loss : 0.28119, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-10 21:13:14, Epoch : 1, Step : 4034, Training Loss : 0.14031, Training Acc : 0.950, Run Time : 14.49
INFO:root:2019-05-10 21:13:14, Epoch : 1, Step : 4035, Training Loss : 0.17150, Training Acc : 0.928, Run Time : 0.31
INFO:root:2019-05-10 21:13:15, Epoch : 1, Step : 4036, Training Loss : 0.20535, Training Acc : 0.889, Run Time : 0.44
INFO:root:2019-05-10 21:13:15, Epoch : 1, Step : 4037, Training Loss : 0.22003, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 21:13:16, Epoch : 1, Step : 4038, Training Loss : 0.24372, Training Acc : 0.922, Run Time : 0.45
INFO:root:2019-05-10 21:13:31, Epoch : 1, Step : 4039, Training Loss : 0.27663, Training Acc : 0.883, Run Time : 15.59
INFO:root:2019-05-10 21:13:32, Epoch : 1, Step : 4040, Training Loss : 0.34686, Training Acc : 0.850, Run Time : 0.37
INFO:root:2019-05-10 21:13:32, Epoch : 1, Step : 4041, Training Loss : 0.24994, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-10 21:13:33, Epoch : 1, Step : 4042, Training Loss : 0.56945, Training Acc : 0.800, Run Time : 0.46
INFO:root:2019-05-10 21:13:33, Epoch : 1, Step : 4043, Training Loss : 0.51923, Training Acc : 0.806, Run Time : 0.41
INFO:root:2019-05-10 21:13:48, Epoch : 1, Step : 4044, Training Loss : 0.33519, Training Acc : 0.889, Run Time : 14.84
INFO:root:2019-05-10 21:13:48, Epoch : 1, Step : 4045, Training Loss : 0.36257, Training Acc : 0.822, Run Time : 0.22
INFO:root:2019-05-10 21:13:49, Epoch : 1, Step : 4046, Training Loss : 0.26552, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 21:13:49, Epoch : 1, Step : 4047, Training Loss : 0.25815, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-10 21:13:59, Epoch : 1, Step : 4048, Training Loss : 0.33114, Training Acc : 0.872, Run Time : 10.03
INFO:root:2019-05-10 21:14:00, Epoch : 1, Step : 4049, Training Loss : 0.37983, Training Acc : 0.839, Run Time : 0.77
INFO:root:2019-05-10 21:14:00, Epoch : 1, Step : 4050, Training Loss : 0.35717, Training Acc : 0.856, Run Time : 0.68
INFO:root:2019-05-10 21:14:01, Epoch : 1, Step : 4051, Training Loss : 0.19382, Training Acc : 0.922, Run Time : 0.50
INFO:root:2019-05-10 21:14:01, Epoch : 1, Step : 4052, Training Loss : 0.35271, Training Acc : 0.878, Run Time : 0.46
INFO:root:2019-05-10 21:14:06, Epoch : 1, Step : 4053, Training Loss : 0.36214, Training Acc : 0.856, Run Time : 4.79
INFO:root:2019-05-10 21:14:15, Epoch : 1, Step : 4054, Training Loss : 0.37064, Training Acc : 0.856, Run Time : 9.12
INFO:root:2019-05-10 21:14:17, Epoch : 1, Step : 4055, Training Loss : 0.31556, Training Acc : 0.861, Run Time : 1.86
INFO:root:2019-05-10 21:14:18, Epoch : 1, Step : 4056, Training Loss : 0.52180, Training Acc : 0.750, Run Time : 0.47
INFO:root:2019-05-10 21:14:18, Epoch : 1, Step : 4057, Training Loss : 0.51254, Training Acc : 0.800, Run Time : 0.49
INFO:root:2019-05-10 21:14:19, Epoch : 1, Step : 4058, Training Loss : 0.39990, Training Acc : 0.833, Run Time : 1.19
INFO:root:2019-05-10 21:14:20, Epoch : 1, Step : 4059, Training Loss : 0.36009, Training Acc : 0.844, Run Time : 0.78
INFO:root:2019-05-10 21:14:24, Epoch : 1, Step : 4060, Training Loss : 0.34654, Training Acc : 0.856, Run Time : 4.33
INFO:root:2019-05-10 21:14:25, Epoch : 1, Step : 4061, Training Loss : 0.29010, Training Acc : 0.878, Run Time : 0.46
INFO:root:2019-05-10 21:14:40, Epoch : 1, Step : 4062, Training Loss : 0.26530, Training Acc : 0.889, Run Time : 15.06
INFO:root:2019-05-10 21:14:40, Epoch : 1, Step : 4063, Training Loss : 0.40327, Training Acc : 0.817, Run Time : 0.29
INFO:root:2019-05-10 21:14:41, Epoch : 1, Step : 4064, Training Loss : 0.45215, Training Acc : 0.794, Run Time : 0.45
INFO:root:2019-05-10 21:14:41, Epoch : 1, Step : 4065, Training Loss : 0.45853, Training Acc : 0.789, Run Time : 0.45
INFO:root:2019-05-10 21:14:42, Epoch : 1, Step : 4066, Training Loss : 0.36733, Training Acc : 0.789, Run Time : 0.75
INFO:root:2019-05-10 21:14:49, Epoch : 1, Step : 4067, Training Loss : 0.42201, Training Acc : 0.783, Run Time : 6.71
INFO:root:2019-05-10 21:14:54, Epoch : 1, Step : 4068, Training Loss : 0.32926, Training Acc : 0.856, Run Time : 5.46
INFO:root:2019-05-10 21:14:55, Epoch : 1, Step : 4069, Training Loss : 0.30460, Training Acc : 0.867, Run Time : 0.51
INFO:root:2019-05-10 21:14:55, Epoch : 1, Step : 4070, Training Loss : 0.27531, Training Acc : 0.900, Run Time : 0.51
INFO:root:2019-05-10 21:15:09, Epoch : 1, Step : 4071, Training Loss : 0.39236, Training Acc : 0.822, Run Time : 14.22
INFO:root:2019-05-10 21:15:10, Epoch : 1, Step : 4072, Training Loss : 0.32211, Training Acc : 0.878, Run Time : 0.23
INFO:root:2019-05-10 21:15:10, Epoch : 1, Step : 4073, Training Loss : 0.30041, Training Acc : 0.911, Run Time : 0.29
INFO:root:2019-05-10 21:15:10, Epoch : 1, Step : 4074, Training Loss : 0.23134, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 21:15:24, Epoch : 1, Step : 4075, Training Loss : 0.25131, Training Acc : 0.911, Run Time : 13.60
INFO:root:2019-05-10 21:15:24, Epoch : 1, Step : 4076, Training Loss : 0.37568, Training Acc : 0.844, Run Time : 0.56
INFO:root:2019-05-10 21:15:25, Epoch : 1, Step : 4077, Training Loss : 0.24961, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-10 21:15:25, Epoch : 1, Step : 4078, Training Loss : 0.44772, Training Acc : 0.806, Run Time : 0.47
INFO:root:2019-05-10 21:15:26, Epoch : 1, Step : 4079, Training Loss : 0.31413, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 21:15:44, Epoch : 1, Step : 4080, Training Loss : 0.32745, Training Acc : 0.817, Run Time : 18.43
INFO:root:2019-05-10 21:15:45, Epoch : 1, Step : 4081, Training Loss : 0.38611, Training Acc : 0.844, Run Time : 0.26
INFO:root:2019-05-10 21:15:45, Epoch : 1, Step : 4082, Training Loss : 0.29997, Training Acc : 0.878, Run Time : 0.55
INFO:root:2019-05-10 21:15:46, Epoch : 1, Step : 4083, Training Loss : 0.24579, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-10 21:15:46, Epoch : 1, Step : 4084, Training Loss : 0.28709, Training Acc : 0.878, Run Time : 0.59
INFO:root:2019-05-10 21:16:02, Epoch : 1, Step : 4085, Training Loss : 0.35151, Training Acc : 0.850, Run Time : 15.82
INFO:root:2019-05-10 21:16:02, Epoch : 1, Step : 4086, Training Loss : 0.22046, Training Acc : 0.906, Run Time : 0.31
INFO:root:2019-05-10 21:16:03, Epoch : 1, Step : 4087, Training Loss : 0.29617, Training Acc : 0.872, Run Time : 0.43
INFO:root:2019-05-10 21:16:03, Epoch : 1, Step : 4088, Training Loss : 0.14016, Training Acc : 0.967, Run Time : 0.49
INFO:root:2019-05-10 21:16:04, Epoch : 1, Step : 4089, Training Loss : 0.21277, Training Acc : 0.900, Run Time : 0.49
INFO:root:2019-05-10 21:16:20, Epoch : 1, Step : 4090, Training Loss : 0.26250, Training Acc : 0.883, Run Time : 16.03
INFO:root:2019-05-10 21:16:20, Epoch : 1, Step : 4091, Training Loss : 0.26211, Training Acc : 0.872, Run Time : 0.63
INFO:root:2019-05-10 21:16:21, Epoch : 1, Step : 4092, Training Loss : 0.27510, Training Acc : 0.894, Run Time : 0.56
INFO:root:2019-05-10 21:16:21, Epoch : 1, Step : 4093, Training Loss : 0.26393, Training Acc : 0.878, Run Time : 0.32
INFO:root:2019-05-10 21:16:22, Epoch : 1, Step : 4094, Training Loss : 0.27051, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 21:16:37, Epoch : 1, Step : 4095, Training Loss : 0.16840, Training Acc : 0.950, Run Time : 15.31
INFO:root:2019-05-10 21:16:37, Epoch : 1, Step : 4096, Training Loss : 0.27398, Training Acc : 0.906, Run Time : 0.25
INFO:root:2019-05-10 21:16:37, Epoch : 1, Step : 4097, Training Loss : 0.29295, Training Acc : 0.922, Run Time : 0.22
INFO:root:2019-05-10 21:16:38, Epoch : 1, Step : 4098, Training Loss : 0.24845, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 21:16:38, Epoch : 1, Step : 4099, Training Loss : 0.30286, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-10 21:16:54, Epoch : 1, Step : 4100, Training Loss : 0.22957, Training Acc : 0.911, Run Time : 15.98
INFO:root:2019-05-10 21:16:56, Epoch : 1, Step : 4101, Training Loss : 0.32240, Training Acc : 0.878, Run Time : 1.27
INFO:root:2019-05-10 21:16:56, Epoch : 1, Step : 4102, Training Loss : 0.19716, Training Acc : 0.922, Run Time : 0.60
INFO:root:2019-05-10 21:16:59, Epoch : 1, Step : 4103, Training Loss : 0.17846, Training Acc : 0.928, Run Time : 3.26
INFO:root:2019-05-10 21:17:05, Epoch : 1, Step : 4104, Training Loss : 0.22711, Training Acc : 0.922, Run Time : 5.49
INFO:root:2019-05-10 21:17:13, Epoch : 1, Step : 4105, Training Loss : 0.31624, Training Acc : 0.867, Run Time : 7.65
INFO:root:2019-05-10 21:17:15, Epoch : 1, Step : 4106, Training Loss : 0.36511, Training Acc : 0.828, Run Time : 2.07
INFO:root:2019-05-10 21:17:15, Epoch : 1, Step : 4107, Training Loss : 0.26103, Training Acc : 0.900, Run Time : 0.60
INFO:root:2019-05-10 21:17:16, Epoch : 1, Step : 4108, Training Loss : 0.23319, Training Acc : 0.922, Run Time : 0.50
INFO:root:2019-05-10 21:17:16, Epoch : 1, Step : 4109, Training Loss : 0.28001, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-10 21:17:27, Epoch : 1, Step : 4110, Training Loss : 0.24284, Training Acc : 0.867, Run Time : 10.61
INFO:root:2019-05-10 21:17:27, Epoch : 1, Step : 4111, Training Loss : 0.29112, Training Acc : 0.889, Run Time : 0.57
INFO:root:2019-05-10 21:17:28, Epoch : 1, Step : 4112, Training Loss : 0.29656, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 21:17:28, Epoch : 1, Step : 4113, Training Loss : 0.33613, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-10 21:17:29, Epoch : 1, Step : 4114, Training Loss : 0.28932, Training Acc : 0.883, Run Time : 0.51
INFO:root:2019-05-10 21:17:44, Epoch : 1, Step : 4115, Training Loss : 0.20511, Training Acc : 0.911, Run Time : 15.40
INFO:root:2019-05-10 21:17:45, Epoch : 1, Step : 4116, Training Loss : 0.21723, Training Acc : 0.906, Run Time : 0.55
INFO:root:2019-05-10 21:17:45, Epoch : 1, Step : 4117, Training Loss : 0.31461, Training Acc : 0.883, Run Time : 0.55
INFO:root:2019-05-10 21:17:46, Epoch : 1, Step : 4118, Training Loss : 0.26917, Training Acc : 0.894, Run Time : 0.44
INFO:root:2019-05-10 21:17:58, Epoch : 1, Step : 4119, Training Loss : 0.17352, Training Acc : 0.922, Run Time : 12.14
INFO:root:2019-05-10 21:17:58, Epoch : 1, Step : 4120, Training Loss : 0.33813, Training Acc : 0.867, Run Time : 0.23
INFO:root:2019-05-10 21:17:58, Epoch : 1, Step : 4121, Training Loss : 0.24593, Training Acc : 0.889, Run Time : 0.22
INFO:root:2019-05-10 21:17:59, Epoch : 1, Step : 4122, Training Loss : 0.40141, Training Acc : 0.856, Run Time : 0.21
INFO:root:2019-05-10 21:17:59, Epoch : 1, Step : 4123, Training Loss : 0.25294, Training Acc : 0.894, Run Time : 0.20
INFO:root:2019-05-10 21:18:16, Epoch : 1, Step : 4124, Training Loss : 0.30337, Training Acc : 0.861, Run Time : 17.07
INFO:root:2019-05-10 21:18:16, Epoch : 1, Step : 4125, Training Loss : 0.23036, Training Acc : 0.900, Run Time : 0.43
INFO:root:2019-05-10 21:18:17, Epoch : 1, Step : 4126, Training Loss : 0.20145, Training Acc : 0.928, Run Time : 0.67
INFO:root:2019-05-10 21:18:18, Epoch : 1, Step : 4127, Training Loss : 0.16544, Training Acc : 0.939, Run Time : 1.10
INFO:root:2019-05-10 21:18:28, Epoch : 1, Step : 4128, Training Loss : 0.14292, Training Acc : 0.956, Run Time : 9.72
INFO:root:2019-05-10 21:18:28, Epoch : 1, Step : 4129, Training Loss : 0.18673, Training Acc : 0.928, Run Time : 0.27
INFO:root:2019-05-10 21:18:28, Epoch : 1, Step : 4130, Training Loss : 0.23183, Training Acc : 0.906, Run Time : 0.30
INFO:root:2019-05-10 21:18:29, Epoch : 1, Step : 4131, Training Loss : 0.26453, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-10 21:18:29, Epoch : 1, Step : 4132, Training Loss : 0.29263, Training Acc : 0.889, Run Time : 0.52
INFO:root:2019-05-10 21:18:35, Epoch : 1, Step : 4133, Training Loss : 0.39575, Training Acc : 0.833, Run Time : 5.29
INFO:root:2019-05-10 21:18:36, Epoch : 1, Step : 4134, Training Loss : 0.41829, Training Acc : 0.828, Run Time : 1.55
INFO:root:2019-05-10 21:18:50, Epoch : 1, Step : 4135, Training Loss : 0.28393, Training Acc : 0.861, Run Time : 13.83
INFO:root:2019-05-10 21:18:51, Epoch : 1, Step : 4136, Training Loss : 0.42092, Training Acc : 0.817, Run Time : 1.19
INFO:root:2019-05-10 21:18:52, Epoch : 1, Step : 4137, Training Loss : 0.23388, Training Acc : 0.906, Run Time : 0.39
INFO:root:2019-05-10 21:18:52, Epoch : 1, Step : 4138, Training Loss : 0.21868, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 21:18:54, Epoch : 1, Step : 4139, Training Loss : 0.26135, Training Acc : 0.878, Run Time : 1.61
INFO:root:2019-05-10 21:19:07, Epoch : 1, Step : 4140, Training Loss : 0.28220, Training Acc : 0.900, Run Time : 13.35
INFO:root:2019-05-10 21:19:08, Epoch : 1, Step : 4141, Training Loss : 0.30262, Training Acc : 0.889, Run Time : 0.52
INFO:root:2019-05-10 21:19:08, Epoch : 1, Step : 4142, Training Loss : 0.22213, Training Acc : 0.900, Run Time : 0.44
INFO:root:2019-05-10 21:19:08, Epoch : 1, Step : 4143, Training Loss : 0.15668, Training Acc : 0.967, Run Time : 0.48
INFO:root:2019-05-10 21:19:09, Epoch : 1, Step : 4144, Training Loss : 0.19231, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 21:19:24, Epoch : 1, Step : 4145, Training Loss : 0.18697, Training Acc : 0.911, Run Time : 15.13
INFO:root:2019-05-10 21:19:25, Epoch : 1, Step : 4146, Training Loss : 0.15494, Training Acc : 0.944, Run Time : 0.81
INFO:root:2019-05-10 21:19:25, Epoch : 1, Step : 4147, Training Loss : 0.17444, Training Acc : 0.922, Run Time : 0.62
INFO:root:2019-05-10 21:19:26, Epoch : 1, Step : 4148, Training Loss : 0.29535, Training Acc : 0.872, Run Time : 0.59
INFO:root:2019-05-10 21:19:38, Epoch : 1, Step : 4149, Training Loss : 0.45561, Training Acc : 0.811, Run Time : 12.03
INFO:root:2019-05-10 21:19:38, Epoch : 1, Step : 4150, Training Loss : 0.40565, Training Acc : 0.822, Run Time : 0.22
INFO:root:2019-05-10 21:19:39, Epoch : 1, Step : 4151, Training Loss : 0.33451, Training Acc : 0.894, Run Time : 0.22
INFO:root:2019-05-10 21:19:39, Epoch : 1, Step : 4152, Training Loss : 0.37588, Training Acc : 0.856, Run Time : 0.44
INFO:root:2019-05-10 21:19:39, Epoch : 1, Step : 4153, Training Loss : 0.36005, Training Acc : 0.850, Run Time : 0.44
INFO:root:2019-05-10 21:19:58, Epoch : 1, Step : 4154, Training Loss : 0.28186, Training Acc : 0.900, Run Time : 18.81
INFO:root:2019-05-10 21:19:59, Epoch : 1, Step : 4155, Training Loss : 0.23213, Training Acc : 0.917, Run Time : 0.71
INFO:root:2019-05-10 21:19:59, Epoch : 1, Step : 4156, Training Loss : 0.17519, Training Acc : 0.950, Run Time : 0.23
INFO:root:2019-05-10 21:20:00, Epoch : 1, Step : 4157, Training Loss : 0.24048, Training Acc : 0.911, Run Time : 0.39
INFO:root:2019-05-10 21:20:00, Epoch : 1, Step : 4158, Training Loss : 0.22140, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-10 21:20:06, Epoch : 1, Step : 4159, Training Loss : 0.29956, Training Acc : 0.850, Run Time : 5.66
INFO:root:2019-05-10 21:20:06, Epoch : 1, Step : 4160, Training Loss : 0.27927, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-10 21:20:22, Epoch : 1, Step : 4161, Training Loss : 0.29966, Training Acc : 0.861, Run Time : 15.82
INFO:root:2019-05-10 21:20:22, Epoch : 1, Step : 4162, Training Loss : 0.45173, Training Acc : 0.817, Run Time : 0.32
INFO:root:2019-05-10 21:20:23, Epoch : 1, Step : 4163, Training Loss : 0.32702, Training Acc : 0.861, Run Time : 0.36
INFO:root:2019-05-10 21:20:23, Epoch : 1, Step : 4164, Training Loss : 0.28123, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-10 21:20:24, Epoch : 1, Step : 4165, Training Loss : 0.27496, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-10 21:20:39, Epoch : 1, Step : 4166, Training Loss : 0.22000, Training Acc : 0.917, Run Time : 15.47
INFO:root:2019-05-10 21:20:39, Epoch : 1, Step : 4167, Training Loss : 0.39134, Training Acc : 0.850, Run Time : 0.26
INFO:root:2019-05-10 21:20:40, Epoch : 1, Step : 4168, Training Loss : 0.23834, Training Acc : 0.911, Run Time : 0.33
INFO:root:2019-05-10 21:20:40, Epoch : 1, Step : 4169, Training Loss : 0.26583, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-10 21:20:41, Epoch : 1, Step : 4170, Training Loss : 0.37097, Training Acc : 0.833, Run Time : 0.49
INFO:root:2019-05-10 21:20:57, Epoch : 1, Step : 4171, Training Loss : 0.25223, Training Acc : 0.906, Run Time : 16.83
INFO:root:2019-05-10 21:20:58, Epoch : 1, Step : 4172, Training Loss : 0.35364, Training Acc : 0.872, Run Time : 0.23
INFO:root:2019-05-10 21:20:58, Epoch : 1, Step : 4173, Training Loss : 0.20429, Training Acc : 0.917, Run Time : 0.32
INFO:root:2019-05-10 21:20:58, Epoch : 1, Step : 4174, Training Loss : 0.16849, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-10 21:20:59, Epoch : 1, Step : 4175, Training Loss : 0.17844, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-10 21:21:14, Epoch : 1, Step : 4176, Training Loss : 0.26456, Training Acc : 0.878, Run Time : 15.56
INFO:root:2019-05-10 21:21:15, Epoch : 1, Step : 4177, Training Loss : 0.21314, Training Acc : 0.906, Run Time : 0.55
INFO:root:2019-05-10 21:21:15, Epoch : 1, Step : 4178, Training Loss : 0.13393, Training Acc : 0.956, Run Time : 0.43
INFO:root:2019-05-10 21:21:16, Epoch : 1, Step : 4179, Training Loss : 0.23319, Training Acc : 0.900, Run Time : 0.45
INFO:root:2019-05-10 21:21:16, Epoch : 1, Step : 4180, Training Loss : 0.17393, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 21:21:34, Epoch : 1, Step : 4181, Training Loss : 0.25837, Training Acc : 0.900, Run Time : 17.29
INFO:root:2019-05-10 21:21:34, Epoch : 1, Step : 4182, Training Loss : 0.19641, Training Acc : 0.928, Run Time : 0.33
INFO:root:2019-05-10 21:21:34, Epoch : 1, Step : 4183, Training Loss : 0.14968, Training Acc : 0.928, Run Time : 0.51
INFO:root:2019-05-10 21:21:46, Epoch : 1, Step : 4184, Training Loss : 0.14612, Training Acc : 0.939, Run Time : 12.05
INFO:root:2019-05-10 21:21:47, Epoch : 1, Step : 4185, Training Loss : 0.10568, Training Acc : 0.978, Run Time : 0.54
INFO:root:2019-05-10 21:21:47, Epoch : 1, Step : 4186, Training Loss : 0.11890, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-10 21:21:48, Epoch : 1, Step : 4187, Training Loss : 0.11943, Training Acc : 0.956, Run Time : 0.44
INFO:root:2019-05-10 21:21:48, Epoch : 1, Step : 4188, Training Loss : 0.11899, Training Acc : 0.972, Run Time : 0.47
INFO:root:2019-05-10 21:21:55, Epoch : 1, Step : 4189, Training Loss : 0.11783, Training Acc : 0.944, Run Time : 7.00
INFO:root:2019-05-10 21:21:56, Epoch : 1, Step : 4190, Training Loss : 0.18824, Training Acc : 0.944, Run Time : 0.40
INFO:root:2019-05-10 21:22:11, Epoch : 1, Step : 4191, Training Loss : 0.25361, Training Acc : 0.928, Run Time : 15.57
INFO:root:2019-05-10 21:22:12, Epoch : 1, Step : 4192, Training Loss : 0.22994, Training Acc : 0.922, Run Time : 0.32
INFO:root:2019-05-10 21:22:12, Epoch : 1, Step : 4193, Training Loss : 0.21421, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-10 21:22:22, Epoch : 1, Step : 4194, Training Loss : 0.18486, Training Acc : 0.911, Run Time : 10.28
INFO:root:2019-05-10 21:22:23, Epoch : 1, Step : 4195, Training Loss : 0.28593, Training Acc : 0.889, Run Time : 0.78
INFO:root:2019-05-10 21:22:24, Epoch : 1, Step : 4196, Training Loss : 0.13594, Training Acc : 0.961, Run Time : 0.49
INFO:root:2019-05-10 21:22:26, Epoch : 1, Step : 4197, Training Loss : 0.28831, Training Acc : 0.878, Run Time : 1.92
INFO:root:2019-05-10 21:22:34, Epoch : 1, Step : 4198, Training Loss : 0.59195, Training Acc : 0.811, Run Time : 8.50
INFO:root:2019-05-10 21:22:34, Epoch : 1, Step : 4199, Training Loss : 0.48780, Training Acc : 0.756, Run Time : 0.34
INFO:root:2019-05-10 21:22:35, Epoch : 1, Step : 4200, Training Loss : 0.46129, Training Acc : 0.800, Run Time : 0.54
INFO:root:2019-05-10 21:22:44, Epoch : 1, Step : 4201, Training Loss : 0.95974, Training Acc : 0.639, Run Time : 8.90
INFO:root:2019-05-10 21:22:45, Epoch : 1, Step : 4202, Training Loss : 0.60240, Training Acc : 0.761, Run Time : 1.53
INFO:root:2019-05-10 21:22:46, Epoch : 1, Step : 4203, Training Loss : 0.28477, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-10 21:22:46, Epoch : 1, Step : 4204, Training Loss : 0.35197, Training Acc : 0.850, Run Time : 0.39
INFO:root:2019-05-10 21:22:56, Epoch : 1, Step : 4205, Training Loss : 0.43566, Training Acc : 0.844, Run Time : 10.08
INFO:root:2019-05-10 21:22:57, Epoch : 1, Step : 4206, Training Loss : 0.42321, Training Acc : 0.794, Run Time : 0.77
INFO:root:2019-05-10 21:22:57, Epoch : 1, Step : 4207, Training Loss : 0.47477, Training Acc : 0.817, Run Time : 0.37
INFO:root:2019-05-10 21:22:58, Epoch : 1, Step : 4208, Training Loss : 0.50149, Training Acc : 0.828, Run Time : 0.40
INFO:root:2019-05-10 21:22:58, Epoch : 1, Step : 4209, Training Loss : 0.61252, Training Acc : 0.739, Run Time : 0.52
INFO:root:2019-05-10 21:23:02, Epoch : 1, Step : 4210, Training Loss : 0.48277, Training Acc : 0.822, Run Time : 4.06
INFO:root:2019-05-10 21:23:04, Epoch : 1, Step : 4211, Training Loss : 0.40824, Training Acc : 0.828, Run Time : 1.34
INFO:root:2019-05-10 21:23:20, Epoch : 1, Step : 4212, Training Loss : 0.29099, Training Acc : 0.917, Run Time : 16.47
INFO:root:2019-05-10 21:23:21, Epoch : 1, Step : 4213, Training Loss : 0.36974, Training Acc : 0.822, Run Time : 0.24
INFO:root:2019-05-10 21:23:21, Epoch : 1, Step : 4214, Training Loss : 0.27124, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 21:23:21, Epoch : 1, Step : 4215, Training Loss : 0.22747, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 21:23:22, Epoch : 1, Step : 4216, Training Loss : 0.19001, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-10 21:23:39, Epoch : 1, Step : 4217, Training Loss : 0.49588, Training Acc : 0.767, Run Time : 17.01
INFO:root:2019-05-10 21:23:39, Epoch : 1, Step : 4218, Training Loss : 0.29768, Training Acc : 0.883, Run Time : 0.26
INFO:root:2019-05-10 21:23:39, Epoch : 1, Step : 4219, Training Loss : 0.49500, Training Acc : 0.767, Run Time : 0.25
INFO:root:2019-05-10 21:23:40, Epoch : 1, Step : 4220, Training Loss : 0.34008, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-10 21:23:40, Epoch : 1, Step : 4221, Training Loss : 0.52155, Training Acc : 0.783, Run Time : 0.46
INFO:root:2019-05-10 21:23:55, Epoch : 1, Step : 4222, Training Loss : 0.64227, Training Acc : 0.744, Run Time : 14.63
INFO:root:2019-05-10 21:23:56, Epoch : 1, Step : 4223, Training Loss : 0.28980, Training Acc : 0.867, Run Time : 0.84
INFO:root:2019-05-10 21:24:05, Epoch : 1, Step : 4224, Training Loss : 0.45657, Training Acc : 0.806, Run Time : 9.25
INFO:root:2019-05-10 21:24:05, Epoch : 1, Step : 4225, Training Loss : 0.29123, Training Acc : 0.906, Run Time : 0.31
INFO:root:2019-05-10 21:24:06, Epoch : 1, Step : 4226, Training Loss : 0.32514, Training Acc : 0.883, Run Time : 0.27
INFO:root:2019-05-10 21:24:06, Epoch : 1, Step : 4227, Training Loss : 0.41170, Training Acc : 0.778, Run Time : 0.44
INFO:root:2019-05-10 21:24:17, Epoch : 1, Step : 4228, Training Loss : 0.33367, Training Acc : 0.850, Run Time : 10.81
INFO:root:2019-05-10 21:24:18, Epoch : 1, Step : 4229, Training Loss : 0.25293, Training Acc : 0.906, Run Time : 0.68
INFO:root:2019-05-10 21:24:18, Epoch : 1, Step : 4230, Training Loss : 0.36499, Training Acc : 0.806, Run Time : 0.21
INFO:root:2019-05-10 21:24:18, Epoch : 1, Step : 4231, Training Loss : 0.32137, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-10 21:24:30, Epoch : 1, Step : 4232, Training Loss : 0.45708, Training Acc : 0.794, Run Time : 11.90
INFO:root:2019-05-10 21:24:31, Epoch : 1, Step : 4233, Training Loss : 0.31390, Training Acc : 0.878, Run Time : 0.56
INFO:root:2019-05-10 21:24:31, Epoch : 1, Step : 4234, Training Loss : 0.40040, Training Acc : 0.800, Run Time : 0.46
INFO:root:2019-05-10 21:24:32, Epoch : 1, Step : 4235, Training Loss : 0.37873, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-10 21:24:32, Epoch : 1, Step : 4236, Training Loss : 0.26848, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-10 21:24:49, Epoch : 1, Step : 4237, Training Loss : 0.24778, Training Acc : 0.906, Run Time : 17.02
INFO:root:2019-05-10 21:24:50, Epoch : 1, Step : 4238, Training Loss : 0.42470, Training Acc : 0.811, Run Time : 0.46
INFO:root:2019-05-10 21:24:50, Epoch : 1, Step : 4239, Training Loss : 0.28909, Training Acc : 0.878, Run Time : 0.61
INFO:root:2019-05-10 21:24:51, Epoch : 1, Step : 4240, Training Loss : 0.47119, Training Acc : 0.756, Run Time : 0.47
INFO:root:2019-05-10 21:24:51, Epoch : 1, Step : 4241, Training Loss : 0.52536, Training Acc : 0.761, Run Time : 0.47
INFO:root:2019-05-10 21:25:09, Epoch : 1, Step : 4242, Training Loss : 0.33944, Training Acc : 0.856, Run Time : 17.90
INFO:root:2019-05-10 21:25:09, Epoch : 1, Step : 4243, Training Loss : 0.41056, Training Acc : 0.806, Run Time : 0.22
INFO:root:2019-05-10 21:25:09, Epoch : 1, Step : 4244, Training Loss : 0.36401, Training Acc : 0.833, Run Time : 0.22
INFO:root:2019-05-10 21:25:10, Epoch : 1, Step : 4245, Training Loss : 0.43883, Training Acc : 0.822, Run Time : 0.24
INFO:root:2019-05-10 21:25:13, Epoch : 1, Step : 4246, Training Loss : 0.63914, Training Acc : 0.678, Run Time : 3.13
INFO:root:2019-05-10 21:25:27, Epoch : 1, Step : 4247, Training Loss : 0.30354, Training Acc : 0.872, Run Time : 14.14
INFO:root:2019-05-10 21:25:28, Epoch : 1, Step : 4248, Training Loss : 0.40394, Training Acc : 0.822, Run Time : 0.58
INFO:root:2019-05-10 21:25:28, Epoch : 1, Step : 4249, Training Loss : 0.35574, Training Acc : 0.800, Run Time : 0.22
INFO:root:2019-05-10 21:25:28, Epoch : 1, Step : 4250, Training Loss : 0.47016, Training Acc : 0.750, Run Time : 0.40
INFO:root:2019-05-10 21:25:29, Epoch : 1, Step : 4251, Training Loss : 0.61457, Training Acc : 0.761, Run Time : 0.45
INFO:root:2019-05-10 21:25:45, Epoch : 1, Step : 4252, Training Loss : 0.35488, Training Acc : 0.844, Run Time : 16.85
INFO:root:2019-05-10 21:25:46, Epoch : 1, Step : 4253, Training Loss : 0.25114, Training Acc : 0.911, Run Time : 0.32
INFO:root:2019-05-10 21:25:46, Epoch : 1, Step : 4254, Training Loss : 0.38635, Training Acc : 0.828, Run Time : 0.54
INFO:root:2019-05-10 21:25:56, Epoch : 1, Step : 4255, Training Loss : 0.34952, Training Acc : 0.867, Run Time : 9.21
INFO:root:2019-05-10 21:25:56, Epoch : 1, Step : 4256, Training Loss : 0.26102, Training Acc : 0.889, Run Time : 0.70
INFO:root:2019-05-10 21:25:57, Epoch : 1, Step : 4257, Training Loss : 0.27762, Training Acc : 0.889, Run Time : 0.78
INFO:root:2019-05-10 21:25:59, Epoch : 1, Step : 4258, Training Loss : 0.28868, Training Acc : 0.883, Run Time : 2.09
INFO:root:2019-05-10 21:26:00, Epoch : 1, Step : 4259, Training Loss : 0.32736, Training Acc : 0.850, Run Time : 0.64
INFO:root:2019-05-10 21:26:05, Epoch : 1, Step : 4260, Training Loss : 0.32072, Training Acc : 0.839, Run Time : 5.58
INFO:root:2019-05-10 21:26:06, Epoch : 1, Step : 4261, Training Loss : 0.52279, Training Acc : 0.717, Run Time : 0.43
INFO:root:2019-05-10 21:26:21, Epoch : 1, Step : 4262, Training Loss : 0.34609, Training Acc : 0.861, Run Time : 15.56
INFO:root:2019-05-10 21:26:22, Epoch : 1, Step : 4263, Training Loss : 0.34351, Training Acc : 0.861, Run Time : 0.65
INFO:root:2019-05-10 21:26:22, Epoch : 1, Step : 4264, Training Loss : 0.35589, Training Acc : 0.856, Run Time : 0.45
INFO:root:2019-05-10 21:26:23, Epoch : 1, Step : 4265, Training Loss : 0.45216, Training Acc : 0.806, Run Time : 0.48
INFO:root:2019-05-10 21:26:23, Epoch : 1, Step : 4266, Training Loss : 0.31102, Training Acc : 0.889, Run Time : 0.23
INFO:root:2019-05-10 21:26:39, Epoch : 1, Step : 4267, Training Loss : 0.36713, Training Acc : 0.850, Run Time : 15.95
INFO:root:2019-05-10 21:26:39, Epoch : 1, Step : 4268, Training Loss : 0.31032, Training Acc : 0.861, Run Time : 0.22
INFO:root:2019-05-10 21:26:40, Epoch : 1, Step : 4269, Training Loss : 0.39534, Training Acc : 0.806, Run Time : 0.24
INFO:root:2019-05-10 21:26:40, Epoch : 1, Step : 4270, Training Loss : 0.29926, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-10 21:26:40, Epoch : 1, Step : 4271, Training Loss : 0.37912, Training Acc : 0.833, Run Time : 0.40
INFO:root:2019-05-10 21:26:55, Epoch : 1, Step : 4272, Training Loss : 0.29691, Training Acc : 0.839, Run Time : 14.53
INFO:root:2019-05-10 21:26:56, Epoch : 1, Step : 4273, Training Loss : 0.35570, Training Acc : 0.839, Run Time : 0.63
INFO:root:2019-05-10 21:26:56, Epoch : 1, Step : 4274, Training Loss : 0.42979, Training Acc : 0.811, Run Time : 0.67
INFO:root:2019-05-10 21:27:04, Epoch : 1, Step : 4275, Training Loss : 0.36358, Training Acc : 0.833, Run Time : 7.97
INFO:root:2019-05-10 21:27:05, Epoch : 1, Step : 4276, Training Loss : 0.70282, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-10 21:27:05, Epoch : 1, Step : 4277, Training Loss : 0.44820, Training Acc : 0.817, Run Time : 0.26
INFO:root:2019-05-10 21:27:05, Epoch : 1, Step : 4278, Training Loss : 0.27279, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 21:27:06, Epoch : 1, Step : 4279, Training Loss : 0.40518, Training Acc : 0.822, Run Time : 0.39
INFO:root:2019-05-10 21:27:21, Epoch : 1, Step : 4280, Training Loss : 0.33284, Training Acc : 0.850, Run Time : 15.55
INFO:root:2019-05-10 21:27:22, Epoch : 1, Step : 4281, Training Loss : 0.36594, Training Acc : 0.839, Run Time : 0.31
INFO:root:2019-05-10 21:27:22, Epoch : 1, Step : 4282, Training Loss : 0.53980, Training Acc : 0.744, Run Time : 0.42
INFO:root:2019-05-10 21:27:23, Epoch : 1, Step : 4283, Training Loss : 0.36093, Training Acc : 0.844, Run Time : 1.21
INFO:root:2019-05-10 21:27:24, Epoch : 1, Step : 4284, Training Loss : 0.39589, Training Acc : 0.844, Run Time : 0.71
INFO:root:2019-05-10 21:27:37, Epoch : 1, Step : 4285, Training Loss : 0.39839, Training Acc : 0.833, Run Time : 13.35
INFO:root:2019-05-10 21:27:38, Epoch : 1, Step : 4286, Training Loss : 0.41453, Training Acc : 0.811, Run Time : 0.52
INFO:root:2019-05-10 21:27:38, Epoch : 1, Step : 4287, Training Loss : 0.45222, Training Acc : 0.783, Run Time : 0.57
INFO:root:2019-05-10 21:27:52, Epoch : 1, Step : 4288, Training Loss : 0.65066, Training Acc : 0.700, Run Time : 13.16
INFO:root:2019-05-10 21:27:53, Epoch : 1, Step : 4289, Training Loss : 0.38325, Training Acc : 0.828, Run Time : 1.51
INFO:root:2019-05-10 21:27:53, Epoch : 1, Step : 4290, Training Loss : 0.31960, Training Acc : 0.861, Run Time : 0.43
INFO:root:2019-05-10 21:27:54, Epoch : 1, Step : 4291, Training Loss : 0.37100, Training Acc : 0.844, Run Time : 0.48
INFO:root:2019-05-10 21:27:54, Epoch : 1, Step : 4292, Training Loss : 0.37982, Training Acc : 0.811, Run Time : 0.45
INFO:root:2019-05-10 21:28:11, Epoch : 1, Step : 4293, Training Loss : 0.32129, Training Acc : 0.856, Run Time : 16.51
INFO:root:2019-05-10 21:28:11, Epoch : 1, Step : 4294, Training Loss : 0.29050, Training Acc : 0.872, Run Time : 0.33
INFO:root:2019-05-10 21:28:12, Epoch : 1, Step : 4295, Training Loss : 0.38492, Training Acc : 0.839, Run Time : 0.84
INFO:root:2019-05-10 21:28:13, Epoch : 1, Step : 4296, Training Loss : 0.37756, Training Acc : 0.844, Run Time : 0.40
INFO:root:2019-05-10 21:28:13, Epoch : 1, Step : 4297, Training Loss : 0.28316, Training Acc : 0.878, Run Time : 0.50
INFO:root:2019-05-10 21:28:33, Epoch : 1, Step : 4298, Training Loss : 0.29343, Training Acc : 0.867, Run Time : 20.44
INFO:root:2019-05-10 21:28:34, Epoch : 1, Step : 4299, Training Loss : 0.25516, Training Acc : 0.906, Run Time : 0.50
INFO:root:2019-05-10 21:28:34, Epoch : 1, Step : 4300, Training Loss : 0.45068, Training Acc : 0.800, Run Time : 0.41
INFO:root:2019-05-10 21:28:50, Epoch : 1, Step : 4301, Training Loss : 0.54741, Training Acc : 0.733, Run Time : 15.65
INFO:root:2019-05-10 21:28:50, Epoch : 1, Step : 4302, Training Loss : 0.67167, Training Acc : 0.700, Run Time : 0.28
INFO:root:2019-05-10 21:28:51, Epoch : 1, Step : 4303, Training Loss : 1.04479, Training Acc : 0.578, Run Time : 0.22
INFO:root:2019-05-10 21:28:51, Epoch : 1, Step : 4304, Training Loss : 0.94855, Training Acc : 0.628, Run Time : 0.29
INFO:root:2019-05-10 21:28:52, Epoch : 1, Step : 4305, Training Loss : 0.80686, Training Acc : 0.561, Run Time : 1.18
INFO:root:2019-05-10 21:29:10, Epoch : 1, Step : 4306, Training Loss : 0.61047, Training Acc : 0.661, Run Time : 18.06
INFO:root:2019-05-10 21:29:10, Epoch : 1, Step : 4307, Training Loss : 0.43063, Training Acc : 0.772, Run Time : 0.24
INFO:root:2019-05-10 21:29:10, Epoch : 1, Step : 4308, Training Loss : 0.38402, Training Acc : 0.844, Run Time : 0.21
INFO:root:2019-05-10 21:29:11, Epoch : 1, Step : 4309, Training Loss : 0.57600, Training Acc : 0.717, Run Time : 0.23
INFO:root:2019-05-10 21:29:11, Epoch : 1, Step : 4310, Training Loss : 0.54419, Training Acc : 0.717, Run Time : 0.48
INFO:root:2019-05-10 21:29:29, Epoch : 1, Step : 4311, Training Loss : 0.45913, Training Acc : 0.789, Run Time : 17.76
INFO:root:2019-05-10 21:29:29, Epoch : 1, Step : 4312, Training Loss : 0.48976, Training Acc : 0.733, Run Time : 0.40
INFO:root:2019-05-10 21:29:30, Epoch : 1, Step : 4313, Training Loss : 0.40130, Training Acc : 0.817, Run Time : 0.22
INFO:root:2019-05-10 21:29:30, Epoch : 1, Step : 4314, Training Loss : 0.34367, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-10 21:29:30, Epoch : 1, Step : 4315, Training Loss : 0.48509, Training Acc : 0.772, Run Time : 0.46
INFO:root:2019-05-10 21:29:47, Epoch : 1, Step : 4316, Training Loss : 0.51908, Training Acc : 0.756, Run Time : 16.05
INFO:root:2019-05-10 21:29:47, Epoch : 1, Step : 4317, Training Loss : 0.43926, Training Acc : 0.806, Run Time : 0.61
INFO:root:2019-05-10 21:29:48, Epoch : 1, Step : 4318, Training Loss : 0.41733, Training Acc : 0.839, Run Time : 0.40
INFO:root:2019-05-10 21:29:48, Epoch : 1, Step : 4319, Training Loss : 0.47626, Training Acc : 0.794, Run Time : 0.47
INFO:root:2019-05-10 21:29:48, Epoch : 1, Step : 4320, Training Loss : 0.47543, Training Acc : 0.750, Run Time : 0.50
INFO:root:2019-05-10 21:30:03, Epoch : 1, Step : 4321, Training Loss : 0.53964, Training Acc : 0.722, Run Time : 14.49
INFO:root:2019-05-10 21:30:03, Epoch : 1, Step : 4322, Training Loss : 0.52555, Training Acc : 0.728, Run Time : 0.36
INFO:root:2019-05-10 21:30:04, Epoch : 1, Step : 4323, Training Loss : 0.54971, Training Acc : 0.728, Run Time : 0.45
INFO:root:2019-05-10 21:30:15, Epoch : 1, Step : 4324, Training Loss : 0.61831, Training Acc : 0.683, Run Time : 11.58
INFO:root:2019-05-10 21:30:16, Epoch : 1, Step : 4325, Training Loss : 0.47008, Training Acc : 0.767, Run Time : 0.88
INFO:root:2019-05-10 21:30:17, Epoch : 1, Step : 4326, Training Loss : 0.52066, Training Acc : 0.728, Run Time : 0.78
INFO:root:2019-05-10 21:30:17, Epoch : 1, Step : 4327, Training Loss : 0.53971, Training Acc : 0.661, Run Time : 0.44
INFO:root:2019-05-10 21:30:18, Epoch : 1, Step : 4328, Training Loss : 0.45166, Training Acc : 0.789, Run Time : 0.49
INFO:root:2019-05-10 21:30:21, Epoch : 1, Step : 4329, Training Loss : 0.52846, Training Acc : 0.722, Run Time : 2.72
INFO:root:2019-05-10 21:30:37, Epoch : 1, Step : 4330, Training Loss : 0.42617, Training Acc : 0.800, Run Time : 16.43
INFO:root:2019-05-10 21:30:38, Epoch : 1, Step : 4331, Training Loss : 0.45260, Training Acc : 0.778, Run Time : 0.65
INFO:root:2019-05-10 21:30:38, Epoch : 1, Step : 4332, Training Loss : 0.45944, Training Acc : 0.756, Run Time : 0.52
INFO:root:2019-05-10 21:30:39, Epoch : 1, Step : 4333, Training Loss : 0.42893, Training Acc : 0.833, Run Time : 0.47
INFO:root:2019-05-10 21:30:48, Epoch : 1, Step : 4334, Training Loss : 0.50391, Training Acc : 0.744, Run Time : 8.86
INFO:root:2019-05-10 21:30:49, Epoch : 1, Step : 4335, Training Loss : 0.40364, Training Acc : 0.800, Run Time : 1.13
INFO:root:2019-05-10 21:30:49, Epoch : 1, Step : 4336, Training Loss : 0.50467, Training Acc : 0.739, Run Time : 0.47
INFO:root:2019-05-10 21:30:50, Epoch : 1, Step : 4337, Training Loss : 0.47746, Training Acc : 0.750, Run Time : 0.78
INFO:root:2019-05-10 21:31:00, Epoch : 1, Step : 4338, Training Loss : 0.48076, Training Acc : 0.756, Run Time : 9.86
INFO:root:2019-05-10 21:31:00, Epoch : 1, Step : 4339, Training Loss : 0.39923, Training Acc : 0.850, Run Time : 0.64
INFO:root:2019-05-10 21:31:01, Epoch : 1, Step : 4340, Training Loss : 0.39419, Training Acc : 0.833, Run Time : 0.46
INFO:root:2019-05-10 21:31:01, Epoch : 1, Step : 4341, Training Loss : 0.32654, Training Acc : 0.883, Run Time : 0.31
INFO:root:2019-05-10 21:31:14, Epoch : 1, Step : 4342, Training Loss : 0.43369, Training Acc : 0.811, Run Time : 12.65
INFO:root:2019-05-10 21:31:15, Epoch : 1, Step : 4343, Training Loss : 0.43316, Training Acc : 0.789, Run Time : 0.81
INFO:root:2019-05-10 21:31:15, Epoch : 1, Step : 4344, Training Loss : 0.43262, Training Acc : 0.850, Run Time : 0.45
INFO:root:2019-05-10 21:31:27, Epoch : 1, Step : 4345, Training Loss : 0.37175, Training Acc : 0.867, Run Time : 11.97
INFO:root:2019-05-10 21:31:27, Epoch : 1, Step : 4346, Training Loss : 0.48775, Training Acc : 0.767, Run Time : 0.21
INFO:root:2019-05-10 21:31:28, Epoch : 1, Step : 4347, Training Loss : 0.57196, Training Acc : 0.650, Run Time : 0.22
INFO:root:2019-05-10 21:31:28, Epoch : 1, Step : 4348, Training Loss : 0.59122, Training Acc : 0.683, Run Time : 0.21
INFO:root:2019-05-10 21:31:28, Epoch : 1, Step : 4349, Training Loss : 0.46172, Training Acc : 0.772, Run Time : 0.52
INFO:root:2019-05-10 21:31:51, Epoch : 1, Step : 4350, Training Loss : 0.41743, Training Acc : 0.833, Run Time : 22.22
INFO:root:2019-05-10 21:31:51, Epoch : 1, Step : 4351, Training Loss : 0.40074, Training Acc : 0.833, Run Time : 0.22
INFO:root:2019-05-10 21:31:51, Epoch : 1, Step : 4352, Training Loss : 0.42120, Training Acc : 0.789, Run Time : 0.22
INFO:root:2019-05-10 21:31:51, Epoch : 1, Step : 4353, Training Loss : 0.33536, Training Acc : 0.850, Run Time : 0.21
INFO:root:2019-05-10 21:31:52, Epoch : 1, Step : 4354, Training Loss : 0.33579, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 21:32:09, Epoch : 1, Step : 4355, Training Loss : 0.31823, Training Acc : 0.894, Run Time : 16.99
INFO:root:2019-05-10 21:32:09, Epoch : 1, Step : 4356, Training Loss : 0.35625, Training Acc : 0.872, Run Time : 0.22
INFO:root:2019-05-10 21:32:09, Epoch : 1, Step : 4357, Training Loss : 0.48486, Training Acc : 0.767, Run Time : 0.35
INFO:root:2019-05-10 21:32:10, Epoch : 1, Step : 4358, Training Loss : 0.39207, Training Acc : 0.844, Run Time : 0.46
INFO:root:2019-05-10 21:32:10, Epoch : 1, Step : 4359, Training Loss : 0.36697, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 21:32:26, Epoch : 1, Step : 4360, Training Loss : 0.44574, Training Acc : 0.794, Run Time : 15.70
INFO:root:2019-05-10 21:32:27, Epoch : 1, Step : 4361, Training Loss : 0.48086, Training Acc : 0.806, Run Time : 0.99
INFO:root:2019-05-10 21:32:27, Epoch : 1, Step : 4362, Training Loss : 0.28724, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-10 21:32:28, Epoch : 1, Step : 4363, Training Loss : 0.36887, Training Acc : 0.806, Run Time : 0.45
INFO:root:2019-05-10 21:32:29, Epoch : 1, Step : 4364, Training Loss : 0.38484, Training Acc : 0.861, Run Time : 1.46
INFO:root:2019-05-10 21:32:40, Epoch : 1, Step : 4365, Training Loss : 0.39006, Training Acc : 0.822, Run Time : 10.82
INFO:root:2019-05-10 21:32:42, Epoch : 1, Step : 4366, Training Loss : 0.26838, Training Acc : 0.894, Run Time : 2.10
INFO:root:2019-05-10 21:32:43, Epoch : 1, Step : 4367, Training Loss : 0.29545, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-10 21:32:43, Epoch : 1, Step : 4368, Training Loss : 0.27621, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 21:32:44, Epoch : 1, Step : 4369, Training Loss : 0.27198, Training Acc : 0.861, Run Time : 0.46
INFO:root:2019-05-10 21:32:44, Epoch : 1, Step : 4370, Training Loss : 0.23402, Training Acc : 0.917, Run Time : 0.60
INFO:root:2019-05-10 21:33:01, Epoch : 1, Step : 4371, Training Loss : 0.25593, Training Acc : 0.894, Run Time : 16.39
INFO:root:2019-05-10 21:33:01, Epoch : 1, Step : 4372, Training Loss : 0.23725, Training Acc : 0.933, Run Time : 0.30
INFO:root:2019-05-10 21:33:01, Epoch : 1, Step : 4373, Training Loss : 0.21765, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-10 21:33:14, Epoch : 1, Step : 4374, Training Loss : 0.26259, Training Acc : 0.894, Run Time : 12.34
INFO:root:2019-05-10 21:33:15, Epoch : 1, Step : 4375, Training Loss : 0.26688, Training Acc : 0.878, Run Time : 1.06
INFO:root:2019-05-10 21:33:15, Epoch : 1, Step : 4376, Training Loss : 0.29706, Training Acc : 0.850, Run Time : 0.44
INFO:root:2019-05-10 21:33:16, Epoch : 1, Step : 4377, Training Loss : 0.30849, Training Acc : 0.844, Run Time : 0.49
INFO:root:2019-05-10 21:33:16, Epoch : 1, Step : 4378, Training Loss : 0.31310, Training Acc : 0.828, Run Time : 0.53
INFO:root:2019-05-10 21:33:31, Epoch : 1, Step : 4379, Training Loss : 0.29430, Training Acc : 0.856, Run Time : 15.24
INFO:root:2019-05-10 21:33:32, Epoch : 1, Step : 4380, Training Loss : 0.30171, Training Acc : 0.861, Run Time : 0.32
INFO:root:2019-05-10 21:33:32, Epoch : 1, Step : 4381, Training Loss : 0.33693, Training Acc : 0.806, Run Time : 0.42
INFO:root:2019-05-10 21:33:33, Epoch : 1, Step : 4382, Training Loss : 0.24708, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-10 21:33:44, Epoch : 1, Step : 4383, Training Loss : 0.24720, Training Acc : 0.906, Run Time : 10.92
INFO:root:2019-05-10 21:33:44, Epoch : 1, Step : 4384, Training Loss : 0.45486, Training Acc : 0.806, Run Time : 0.73
INFO:root:2019-05-10 21:33:45, Epoch : 1, Step : 4385, Training Loss : 0.48328, Training Acc : 0.783, Run Time : 0.48
INFO:root:2019-05-10 21:33:45, Epoch : 1, Step : 4386, Training Loss : 0.41111, Training Acc : 0.783, Run Time : 0.47
INFO:root:2019-05-10 21:33:46, Epoch : 1, Step : 4387, Training Loss : 0.38477, Training Acc : 0.767, Run Time : 0.46
INFO:root:2019-05-10 21:34:03, Epoch : 1, Step : 4388, Training Loss : 0.44445, Training Acc : 0.783, Run Time : 17.33
INFO:root:2019-05-10 21:34:03, Epoch : 1, Step : 4389, Training Loss : 0.31633, Training Acc : 0.817, Run Time : 0.31
INFO:root:2019-05-10 21:34:04, Epoch : 1, Step : 4390, Training Loss : 0.31344, Training Acc : 0.822, Run Time : 0.34
INFO:root:2019-05-10 21:34:04, Epoch : 1, Step : 4391, Training Loss : 0.38216, Training Acc : 0.783, Run Time : 0.46
INFO:root:2019-05-10 21:34:18, Epoch : 1, Step : 4392, Training Loss : 0.50840, Training Acc : 0.767, Run Time : 14.21
INFO:root:2019-05-10 21:34:19, Epoch : 1, Step : 4393, Training Loss : 0.43268, Training Acc : 0.767, Run Time : 0.75
INFO:root:2019-05-10 21:34:20, Epoch : 1, Step : 4394, Training Loss : 0.30260, Training Acc : 0.833, Run Time : 0.49
INFO:root:2019-05-10 21:34:20, Epoch : 1, Step : 4395, Training Loss : 0.33535, Training Acc : 0.833, Run Time : 0.49
INFO:root:2019-05-10 21:34:20, Epoch : 1, Step : 4396, Training Loss : 0.28931, Training Acc : 0.861, Run Time : 0.45
INFO:root:2019-05-10 21:34:36, Epoch : 1, Step : 4397, Training Loss : 0.27784, Training Acc : 0.867, Run Time : 15.50
INFO:root:2019-05-10 21:34:37, Epoch : 1, Step : 4398, Training Loss : 0.20820, Training Acc : 0.906, Run Time : 0.55
INFO:root:2019-05-10 21:34:37, Epoch : 1, Step : 4399, Training Loss : 0.31462, Training Acc : 0.839, Run Time : 0.24
INFO:root:2019-05-10 21:34:37, Epoch : 1, Step : 4400, Training Loss : 0.25358, Training Acc : 0.872, Run Time : 0.24
INFO:root:2019-05-10 21:34:38, Epoch : 1, Step : 4401, Training Loss : 0.38322, Training Acc : 0.800, Run Time : 0.88
INFO:root:2019-05-10 21:34:55, Epoch : 1, Step : 4402, Training Loss : 0.37691, Training Acc : 0.806, Run Time : 17.41
INFO:root:2019-05-10 21:34:56, Epoch : 1, Step : 4403, Training Loss : 0.31574, Training Acc : 0.817, Run Time : 0.33
INFO:root:2019-05-10 21:34:56, Epoch : 1, Step : 4404, Training Loss : 0.33200, Training Acc : 0.822, Run Time : 0.37
INFO:root:2019-05-10 21:34:58, Epoch : 1, Step : 4405, Training Loss : 0.29770, Training Acc : 0.839, Run Time : 2.17
INFO:root:2019-05-10 21:35:10, Epoch : 1, Step : 4406, Training Loss : 0.29379, Training Acc : 0.872, Run Time : 11.82
INFO:root:2019-05-10 21:35:10, Epoch : 1, Step : 4407, Training Loss : 0.26696, Training Acc : 0.878, Run Time : 0.30
INFO:root:2019-05-10 21:35:11, Epoch : 1, Step : 4408, Training Loss : 0.23700, Training Acc : 0.900, Run Time : 0.21
INFO:root:2019-05-10 21:35:11, Epoch : 1, Step : 4409, Training Loss : 0.26532, Training Acc : 0.839, Run Time : 0.26
INFO:root:2019-05-10 21:35:11, Epoch : 1, Step : 4410, Training Loss : 0.29402, Training Acc : 0.850, Run Time : 0.69
INFO:root:2019-05-10 21:35:24, Epoch : 1, Step : 4411, Training Loss : 0.26298, Training Acc : 0.833, Run Time : 12.81
INFO:root:2019-05-10 21:35:27, Epoch : 1, Step : 4412, Training Loss : 0.34235, Training Acc : 0.817, Run Time : 3.02
INFO:root:2019-05-10 21:35:28, Epoch : 1, Step : 4413, Training Loss : 0.30668, Training Acc : 0.828, Run Time : 0.35
INFO:root:2019-05-10 21:35:28, Epoch : 1, Step : 4414, Training Loss : 0.29546, Training Acc : 0.861, Run Time : 0.44
INFO:root:2019-05-10 21:35:29, Epoch : 1, Step : 4415, Training Loss : 0.32015, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-10 21:35:29, Epoch : 1, Step : 4416, Training Loss : 0.32255, Training Acc : 0.844, Run Time : 0.50
INFO:root:2019-05-10 21:35:34, Epoch : 1, Step : 4417, Training Loss : 0.36289, Training Acc : 0.844, Run Time : 4.99
INFO:root:2019-05-10 21:35:34, Epoch : 1, Step : 4418, Training Loss : 0.25984, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-10 21:35:52, Epoch : 1, Step : 4419, Training Loss : 0.22209, Training Acc : 0.922, Run Time : 17.84
INFO:root:2019-05-10 21:35:53, Epoch : 1, Step : 4420, Training Loss : 0.24490, Training Acc : 0.872, Run Time : 0.30
INFO:root:2019-05-10 21:35:53, Epoch : 1, Step : 4421, Training Loss : 0.23678, Training Acc : 0.900, Run Time : 0.50
INFO:root:2019-05-10 21:35:54, Epoch : 1, Step : 4422, Training Loss : 0.23507, Training Acc : 0.894, Run Time : 0.42
INFO:root:2019-05-10 21:36:06, Epoch : 1, Step : 4423, Training Loss : 0.26862, Training Acc : 0.844, Run Time : 12.27
INFO:root:2019-05-10 21:36:07, Epoch : 1, Step : 4424, Training Loss : 0.31812, Training Acc : 0.817, Run Time : 1.56
INFO:root:2019-05-10 21:36:08, Epoch : 1, Step : 4425, Training Loss : 0.28831, Training Acc : 0.850, Run Time : 0.37
INFO:root:2019-05-10 21:36:08, Epoch : 1, Step : 4426, Training Loss : 0.17471, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-10 21:36:09, Epoch : 1, Step : 4427, Training Loss : 0.21387, Training Acc : 0.900, Run Time : 0.88
INFO:root:2019-05-10 21:36:24, Epoch : 1, Step : 4428, Training Loss : 0.19935, Training Acc : 0.894, Run Time : 14.75
INFO:root:2019-05-10 21:36:24, Epoch : 1, Step : 4429, Training Loss : 0.16963, Training Acc : 0.961, Run Time : 0.36
INFO:root:2019-05-10 21:36:25, Epoch : 1, Step : 4430, Training Loss : 0.19074, Training Acc : 0.961, Run Time : 0.46
INFO:root:2019-05-10 21:36:25, Epoch : 1, Step : 4431, Training Loss : 0.12962, Training Acc : 0.972, Run Time : 0.50
INFO:root:2019-05-10 21:36:25, Epoch : 1, Step : 4432, Training Loss : 0.15903, Training Acc : 0.950, Run Time : 0.34
INFO:root:2019-05-10 21:36:44, Epoch : 1, Step : 4433, Training Loss : 0.17102, Training Acc : 0.933, Run Time : 18.90
INFO:root:2019-05-10 21:36:45, Epoch : 1, Step : 4434, Training Loss : 0.19160, Training Acc : 0.900, Run Time : 0.49
INFO:root:2019-05-10 21:36:45, Epoch : 1, Step : 4435, Training Loss : 0.20604, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-10 21:36:46, Epoch : 1, Step : 4436, Training Loss : 0.22986, Training Acc : 0.900, Run Time : 0.37
INFO:root:2019-05-10 21:36:46, Epoch : 1, Step : 4437, Training Loss : 0.20439, Training Acc : 0.922, Run Time : 0.32
INFO:root:2019-05-10 21:37:03, Epoch : 1, Step : 4438, Training Loss : 0.23597, Training Acc : 0.894, Run Time : 16.68
INFO:root:2019-05-10 21:37:03, Epoch : 1, Step : 4439, Training Loss : 0.18720, Training Acc : 0.900, Run Time : 0.29
INFO:root:2019-05-10 21:37:03, Epoch : 1, Step : 4440, Training Loss : 0.23194, Training Acc : 0.900, Run Time : 0.45
INFO:root:2019-05-10 21:37:04, Epoch : 1, Step : 4441, Training Loss : 0.26718, Training Acc : 0.872, Run Time : 0.62
INFO:root:2019-05-10 21:37:05, Epoch : 1, Step : 4442, Training Loss : 0.28585, Training Acc : 0.861, Run Time : 0.46
INFO:root:2019-05-10 21:37:23, Epoch : 1, Step : 4443, Training Loss : 0.27872, Training Acc : 0.850, Run Time : 18.29
INFO:root:2019-05-10 21:37:23, Epoch : 1, Step : 4444, Training Loss : 0.26654, Training Acc : 0.878, Run Time : 0.24
INFO:root:2019-05-10 21:37:23, Epoch : 1, Step : 4445, Training Loss : 0.14643, Training Acc : 0.939, Run Time : 0.42
INFO:root:2019-05-10 21:37:24, Epoch : 1, Step : 4446, Training Loss : 0.18049, Training Acc : 0.922, Run Time : 0.51
INFO:root:2019-05-10 21:37:24, Epoch : 1, Step : 4447, Training Loss : 0.17267, Training Acc : 0.917, Run Time : 0.50
INFO:root:2019-05-10 21:37:43, Epoch : 1, Step : 4448, Training Loss : 0.24759, Training Acc : 0.894, Run Time : 18.50
INFO:root:2019-05-10 21:37:43, Epoch : 1, Step : 4449, Training Loss : 0.30174, Training Acc : 0.850, Run Time : 0.31
INFO:root:2019-05-10 21:37:44, Epoch : 1, Step : 4450, Training Loss : 0.27609, Training Acc : 0.861, Run Time : 0.37
INFO:root:2019-05-10 21:37:44, Epoch : 1, Step : 4451, Training Loss : 0.36207, Training Acc : 0.833, Run Time : 0.42
INFO:root:2019-05-10 21:37:45, Epoch : 1, Step : 4452, Training Loss : 0.31906, Training Acc : 0.839, Run Time : 1.02
INFO:root:2019-05-10 21:38:01, Epoch : 1, Step : 4453, Training Loss : 0.31251, Training Acc : 0.828, Run Time : 15.75
INFO:root:2019-05-10 21:38:01, Epoch : 1, Step : 4454, Training Loss : 0.27071, Training Acc : 0.861, Run Time : 0.33
INFO:root:2019-05-10 21:38:02, Epoch : 1, Step : 4455, Training Loss : 0.35318, Training Acc : 0.856, Run Time : 0.40
INFO:root:2019-05-10 21:38:03, Epoch : 1, Step : 4456, Training Loss : 0.18392, Training Acc : 0.917, Run Time : 1.38
INFO:root:2019-05-10 21:38:04, Epoch : 1, Step : 4457, Training Loss : 0.28046, Training Acc : 0.872, Run Time : 0.81
INFO:root:2019-05-10 21:38:20, Epoch : 1, Step : 4458, Training Loss : 0.28984, Training Acc : 0.856, Run Time : 16.31
INFO:root:2019-05-10 21:38:21, Epoch : 1, Step : 4459, Training Loss : 0.25420, Training Acc : 0.878, Run Time : 0.62
INFO:root:2019-05-10 21:38:21, Epoch : 1, Step : 4460, Training Loss : 0.19514, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-10 21:38:22, Epoch : 1, Step : 4461, Training Loss : 0.20686, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 21:38:22, Epoch : 1, Step : 4462, Training Loss : 0.26216, Training Acc : 0.878, Run Time : 0.61
INFO:root:2019-05-10 21:38:38, Epoch : 1, Step : 4463, Training Loss : 0.20130, Training Acc : 0.900, Run Time : 15.52
INFO:root:2019-05-10 21:38:39, Epoch : 1, Step : 4464, Training Loss : 0.27934, Training Acc : 0.883, Run Time : 0.91
INFO:root:2019-05-10 21:38:39, Epoch : 1, Step : 4465, Training Loss : 0.29145, Training Acc : 0.856, Run Time : 0.43
INFO:root:2019-05-10 21:38:40, Epoch : 1, Step : 4466, Training Loss : 0.24535, Training Acc : 0.878, Run Time : 0.45
INFO:root:2019-05-10 21:38:40, Epoch : 1, Step : 4467, Training Loss : 0.24317, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 21:38:59, Epoch : 1, Step : 4468, Training Loss : 0.37401, Training Acc : 0.844, Run Time : 18.80
INFO:root:2019-05-10 21:39:00, Epoch : 1, Step : 4469, Training Loss : 0.19350, Training Acc : 0.911, Run Time : 0.89
INFO:root:2019-05-10 21:39:00, Epoch : 1, Step : 4470, Training Loss : 0.22362, Training Acc : 0.917, Run Time : 0.65
INFO:root:2019-05-10 21:39:01, Epoch : 1, Step : 4471, Training Loss : 0.21788, Training Acc : 0.900, Run Time : 0.51
INFO:root:2019-05-10 21:39:11, Epoch : 1, Step : 4472, Training Loss : 0.24885, Training Acc : 0.894, Run Time : 10.31
INFO:root:2019-05-10 21:39:12, Epoch : 1, Step : 4473, Training Loss : 0.45803, Training Acc : 0.822, Run Time : 1.13
INFO:root:2019-05-10 21:39:13, Epoch : 1, Step : 4474, Training Loss : 0.23741, Training Acc : 0.889, Run Time : 0.23
INFO:root:2019-05-10 21:39:13, Epoch : 1, Step : 4475, Training Loss : 0.27409, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-10 21:39:13, Epoch : 1, Step : 4476, Training Loss : 0.34128, Training Acc : 0.817, Run Time : 0.30
INFO:root:2019-05-10 21:39:29, Epoch : 1, Step : 4477, Training Loss : 0.25832, Training Acc : 0.878, Run Time : 15.87
INFO:root:2019-05-10 21:39:30, Epoch : 1, Step : 4478, Training Loss : 0.14212, Training Acc : 0.956, Run Time : 0.99
INFO:root:2019-05-10 21:39:39, Epoch : 1, Step : 4479, Training Loss : 0.15710, Training Acc : 0.950, Run Time : 9.19
INFO:root:2019-05-10 21:39:48, Epoch : 1, Step : 4480, Training Loss : 0.27900, Training Acc : 0.878, Run Time : 8.83
INFO:root:2019-05-10 21:39:51, Epoch : 1, Step : 4481, Training Loss : 0.14099, Training Acc : 0.939, Run Time : 3.18
INFO:root:2019-05-10 21:39:52, Epoch : 1, Step : 4482, Training Loss : 0.17549, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-10 21:39:52, Epoch : 1, Step : 4483, Training Loss : 0.17360, Training Acc : 0.944, Run Time : 0.49
INFO:root:2019-05-10 21:39:53, Epoch : 1, Step : 4484, Training Loss : 0.19167, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 21:39:53, Epoch : 1, Step : 4485, Training Loss : 0.36271, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-10 21:40:12, Epoch : 1, Step : 4486, Training Loss : 0.23801, Training Acc : 0.917, Run Time : 18.37
INFO:root:2019-05-10 21:40:12, Epoch : 1, Step : 4487, Training Loss : 0.30555, Training Acc : 0.844, Run Time : 0.40
INFO:root:2019-05-10 21:40:12, Epoch : 1, Step : 4488, Training Loss : 0.21446, Training Acc : 0.917, Run Time : 0.26
INFO:root:2019-05-10 21:40:13, Epoch : 1, Step : 4489, Training Loss : 0.27145, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-10 21:40:13, Epoch : 1, Step : 4490, Training Loss : 0.49135, Training Acc : 0.794, Run Time : 0.48
INFO:root:2019-05-10 21:40:30, Epoch : 1, Step : 4491, Training Loss : 0.28984, Training Acc : 0.844, Run Time : 16.88
INFO:root:2019-05-10 21:40:30, Epoch : 1, Step : 4492, Training Loss : 0.27206, Training Acc : 0.878, Run Time : 0.23
INFO:root:2019-05-10 21:40:31, Epoch : 1, Step : 4493, Training Loss : 0.38444, Training Acc : 0.833, Run Time : 0.22
INFO:root:2019-05-10 21:40:31, Epoch : 1, Step : 4494, Training Loss : 0.26004, Training Acc : 0.894, Run Time : 0.22
INFO:root:2019-05-10 21:40:31, Epoch : 1, Step : 4495, Training Loss : 0.24399, Training Acc : 0.900, Run Time : 0.49
INFO:root:2019-05-10 21:40:50, Epoch : 1, Step : 4496, Training Loss : 0.21467, Training Acc : 0.928, Run Time : 18.75
INFO:root:2019-05-10 21:40:50, Epoch : 1, Step : 4497, Training Loss : 0.25070, Training Acc : 0.883, Run Time : 0.23
INFO:root:2019-05-10 21:40:50, Epoch : 1, Step : 4498, Training Loss : 0.30559, Training Acc : 0.861, Run Time : 0.24
INFO:root:2019-05-10 21:40:51, Epoch : 1, Step : 4499, Training Loss : 0.22346, Training Acc : 0.900, Run Time : 0.43
INFO:root:2019-05-10 21:40:51, Epoch : 1, Step : 4500, Training Loss : 0.30399, Training Acc : 0.872, Run Time : 0.54
INFO:root:2019-05-10 21:41:14, Epoch : 1, Step : 4501, Training Loss : 0.23648, Training Acc : 0.906, Run Time : 22.13
INFO:root:2019-05-10 21:41:14, Epoch : 1, Step : 4502, Training Loss : 0.22247, Training Acc : 0.889, Run Time : 0.54
INFO:root:2019-05-10 21:41:15, Epoch : 1, Step : 4503, Training Loss : 0.19072, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-10 21:41:26, Epoch : 1, Step : 4504, Training Loss : 0.31150, Training Acc : 0.867, Run Time : 11.34
INFO:root:2019-05-10 21:41:29, Epoch : 1, Step : 4505, Training Loss : 0.27039, Training Acc : 0.883, Run Time : 3.39
INFO:root:2019-05-10 21:41:30, Epoch : 1, Step : 4506, Training Loss : 0.27122, Training Acc : 0.889, Run Time : 0.27
INFO:root:2019-05-10 21:41:30, Epoch : 1, Step : 4507, Training Loss : 0.29713, Training Acc : 0.856, Run Time : 0.41
INFO:root:2019-05-10 21:41:44, Epoch : 1, Step : 4508, Training Loss : 0.30714, Training Acc : 0.867, Run Time : 13.94
INFO:root:2019-05-10 21:41:45, Epoch : 1, Step : 4509, Training Loss : 0.21782, Training Acc : 0.911, Run Time : 0.92
INFO:root:2019-05-10 21:41:45, Epoch : 1, Step : 4510, Training Loss : 0.22412, Training Acc : 0.928, Run Time : 0.43
INFO:root:2019-05-10 21:41:46, Epoch : 1, Step : 4511, Training Loss : 0.19530, Training Acc : 0.906, Run Time : 0.49
INFO:root:2019-05-10 21:41:46, Epoch : 1, Step : 4512, Training Loss : 0.23275, Training Acc : 0.928, Run Time : 0.49
INFO:root:2019-05-10 21:42:05, Epoch : 1, Step : 4513, Training Loss : 0.27397, Training Acc : 0.856, Run Time : 18.41
INFO:root:2019-05-10 21:42:05, Epoch : 1, Step : 4514, Training Loss : 0.24669, Training Acc : 0.900, Run Time : 0.28
INFO:root:2019-05-10 21:42:06, Epoch : 1, Step : 4515, Training Loss : 0.18836, Training Acc : 0.944, Run Time : 0.63
INFO:root:2019-05-10 21:42:06, Epoch : 1, Step : 4516, Training Loss : 0.21825, Training Acc : 0.894, Run Time : 0.50
INFO:root:2019-05-10 21:42:25, Epoch : 1, Step : 4517, Training Loss : 0.20062, Training Acc : 0.933, Run Time : 18.62
INFO:root:2019-05-10 21:42:25, Epoch : 1, Step : 4518, Training Loss : 0.18646, Training Acc : 0.928, Run Time : 0.51
INFO:root:2019-05-10 21:42:26, Epoch : 1, Step : 4519, Training Loss : 0.20917, Training Acc : 0.922, Run Time : 0.64
INFO:root:2019-05-10 21:42:28, Epoch : 1, Step : 4520, Training Loss : 0.26984, Training Acc : 0.900, Run Time : 2.27
INFO:root:2019-05-10 21:42:41, Epoch : 1, Step : 4521, Training Loss : 0.23557, Training Acc : 0.917, Run Time : 13.00
INFO:root:2019-05-10 21:42:42, Epoch : 1, Step : 4522, Training Loss : 0.20611, Training Acc : 0.928, Run Time : 0.70
INFO:root:2019-05-10 21:42:42, Epoch : 1, Step : 4523, Training Loss : 0.22485, Training Acc : 0.878, Run Time : 0.60
INFO:root:2019-05-10 21:42:43, Epoch : 1, Step : 4524, Training Loss : 0.21641, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-10 21:42:43, Epoch : 1, Step : 4525, Training Loss : 0.17870, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-10 21:43:03, Epoch : 1, Step : 4526, Training Loss : 0.20053, Training Acc : 0.917, Run Time : 20.10
INFO:root:2019-05-10 21:43:04, Epoch : 1, Step : 4527, Training Loss : 0.20599, Training Acc : 0.922, Run Time : 0.57
INFO:root:2019-05-10 21:43:05, Epoch : 1, Step : 4528, Training Loss : 0.29969, Training Acc : 0.850, Run Time : 0.65
INFO:root:2019-05-10 21:43:05, Epoch : 1, Step : 4529, Training Loss : 0.30890, Training Acc : 0.850, Run Time : 0.55
INFO:root:2019-05-10 21:43:21, Epoch : 1, Step : 4530, Training Loss : 0.22570, Training Acc : 0.894, Run Time : 16.15
INFO:root:2019-05-10 21:43:22, Epoch : 1, Step : 4531, Training Loss : 0.25740, Training Acc : 0.872, Run Time : 0.25
INFO:root:2019-05-10 21:43:22, Epoch : 1, Step : 4532, Training Loss : 0.26454, Training Acc : 0.889, Run Time : 0.23
INFO:root:2019-05-10 21:43:22, Epoch : 1, Step : 4533, Training Loss : 0.27442, Training Acc : 0.867, Run Time : 0.30
INFO:root:2019-05-10 21:43:24, Epoch : 1, Step : 4534, Training Loss : 0.39884, Training Acc : 0.772, Run Time : 1.54
INFO:root:2019-05-10 21:43:39, Epoch : 1, Step : 4535, Training Loss : 0.17562, Training Acc : 0.939, Run Time : 15.67
INFO:root:2019-05-10 21:43:40, Epoch : 1, Step : 4536, Training Loss : 0.22160, Training Acc : 0.894, Run Time : 0.41
INFO:root:2019-05-10 21:43:40, Epoch : 1, Step : 4537, Training Loss : 0.26448, Training Acc : 0.894, Run Time : 0.23
INFO:root:2019-05-10 21:43:40, Epoch : 1, Step : 4538, Training Loss : 0.23074, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-10 21:43:41, Epoch : 1, Step : 4539, Training Loss : 0.31226, Training Acc : 0.872, Run Time : 1.05
INFO:root:2019-05-10 21:44:00, Epoch : 1, Step : 4540, Training Loss : 0.30072, Training Acc : 0.889, Run Time : 18.41
INFO:root:2019-05-10 21:44:00, Epoch : 1, Step : 4541, Training Loss : 0.48088, Training Acc : 0.806, Run Time : 0.53
INFO:root:2019-05-10 21:44:01, Epoch : 1, Step : 4542, Training Loss : 0.25212, Training Acc : 0.894, Run Time : 0.34
INFO:root:2019-05-10 21:44:14, Epoch : 1, Step : 4543, Training Loss : 0.29860, Training Acc : 0.872, Run Time : 13.32
INFO:root:2019-05-10 21:44:15, Epoch : 1, Step : 4544, Training Loss : 0.42724, Training Acc : 0.806, Run Time : 1.12
INFO:root:2019-05-10 21:44:16, Epoch : 1, Step : 4545, Training Loss : 0.36439, Training Acc : 0.850, Run Time : 0.51
INFO:root:2019-05-10 21:44:16, Epoch : 1, Step : 4546, Training Loss : 0.44180, Training Acc : 0.817, Run Time : 0.48
INFO:root:2019-05-10 21:44:31, Epoch : 1, Step : 4547, Training Loss : 0.25650, Training Acc : 0.889, Run Time : 15.22
INFO:root:2019-05-10 21:44:32, Epoch : 1, Step : 4548, Training Loss : 0.26098, Training Acc : 0.889, Run Time : 0.22
INFO:root:2019-05-10 21:44:32, Epoch : 1, Step : 4549, Training Loss : 0.25329, Training Acc : 0.889, Run Time : 0.32
INFO:root:2019-05-10 21:44:32, Epoch : 1, Step : 4550, Training Loss : 0.29678, Training Acc : 0.861, Run Time : 0.37
INFO:root:2019-05-10 21:44:33, Epoch : 1, Step : 4551, Training Loss : 0.36805, Training Acc : 0.839, Run Time : 0.58
INFO:root:2019-05-10 21:44:49, Epoch : 1, Step : 4552, Training Loss : 0.22702, Training Acc : 0.900, Run Time : 15.97
INFO:root:2019-05-10 21:44:49, Epoch : 1, Step : 4553, Training Loss : 0.25352, Training Acc : 0.883, Run Time : 0.23
INFO:root:2019-05-10 21:44:50, Epoch : 1, Step : 4554, Training Loss : 0.38931, Training Acc : 0.800, Run Time : 0.54
INFO:root:2019-05-10 21:44:50, Epoch : 1, Step : 4555, Training Loss : 0.42972, Training Acc : 0.817, Run Time : 0.41
INFO:root:2019-05-10 21:44:51, Epoch : 1, Step : 4556, Training Loss : 0.25262, Training Acc : 0.878, Run Time : 0.49
INFO:root:2019-05-10 21:45:08, Epoch : 1, Step : 4557, Training Loss : 0.28709, Training Acc : 0.867, Run Time : 17.34
INFO:root:2019-05-10 21:45:09, Epoch : 1, Step : 4558, Training Loss : 0.39792, Training Acc : 0.856, Run Time : 1.16
INFO:root:2019-05-10 21:45:20, Epoch : 1, Step : 4559, Training Loss : 0.23351, Training Acc : 0.894, Run Time : 11.17
INFO:root:2019-05-10 21:45:21, Epoch : 1, Step : 4560, Training Loss : 0.30239, Training Acc : 0.844, Run Time : 0.66
INFO:root:2019-05-10 21:45:21, Epoch : 1, Step : 4561, Training Loss : 0.27688, Training Acc : 0.867, Run Time : 0.39
INFO:root:2019-05-10 21:45:22, Epoch : 1, Step : 4562, Training Loss : 0.37977, Training Acc : 0.828, Run Time : 0.46
INFO:root:2019-05-10 21:45:22, Epoch : 1, Step : 4563, Training Loss : 0.30112, Training Acc : 0.856, Run Time : 0.49
INFO:root:2019-05-10 21:45:38, Epoch : 1, Step : 4564, Training Loss : 0.27245, Training Acc : 0.844, Run Time : 15.99
INFO:root:2019-05-10 21:45:39, Epoch : 1, Step : 4565, Training Loss : 0.19418, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 21:45:39, Epoch : 1, Step : 4566, Training Loss : 0.17461, Training Acc : 0.928, Run Time : 0.64
INFO:root:2019-05-10 21:45:40, Epoch : 1, Step : 4567, Training Loss : 0.21607, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 21:45:40, Epoch : 1, Step : 4568, Training Loss : 0.27005, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 21:45:57, Epoch : 1, Step : 4569, Training Loss : 0.17138, Training Acc : 0.944, Run Time : 16.59
INFO:root:2019-05-10 21:45:58, Epoch : 1, Step : 4570, Training Loss : 0.17193, Training Acc : 0.933, Run Time : 0.65
INFO:root:2019-05-10 21:45:58, Epoch : 1, Step : 4571, Training Loss : 0.21419, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-10 21:45:58, Epoch : 1, Step : 4572, Training Loss : 0.18761, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-10 21:45:59, Epoch : 1, Step : 4573, Training Loss : 0.13860, Training Acc : 0.950, Run Time : 0.67
INFO:root:2019-05-10 21:46:18, Epoch : 1, Step : 4574, Training Loss : 0.13234, Training Acc : 0.956, Run Time : 18.88
INFO:root:2019-05-10 21:46:19, Epoch : 1, Step : 4575, Training Loss : 0.19271, Training Acc : 0.922, Run Time : 0.62
INFO:root:2019-05-10 21:46:19, Epoch : 1, Step : 4576, Training Loss : 0.19067, Training Acc : 0.922, Run Time : 0.44
INFO:root:2019-05-10 21:46:19, Epoch : 1, Step : 4577, Training Loss : 0.15447, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 21:46:20, Epoch : 1, Step : 4578, Training Loss : 0.17814, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 21:46:36, Epoch : 1, Step : 4579, Training Loss : 0.16506, Training Acc : 0.939, Run Time : 16.39
INFO:root:2019-05-10 21:46:37, Epoch : 1, Step : 4580, Training Loss : 0.15983, Training Acc : 0.928, Run Time : 0.51
INFO:root:2019-05-10 21:46:37, Epoch : 1, Step : 4581, Training Loss : 0.21899, Training Acc : 0.878, Run Time : 0.50
INFO:root:2019-05-10 21:46:44, Epoch : 1, Step : 4582, Training Loss : 0.21167, Training Acc : 0.922, Run Time : 6.81
INFO:root:2019-05-10 21:46:44, Epoch : 1, Step : 4583, Training Loss : 0.18016, Training Acc : 0.911, Run Time : 0.28
INFO:root:2019-05-10 21:46:45, Epoch : 1, Step : 4584, Training Loss : 0.14058, Training Acc : 0.956, Run Time : 0.35
INFO:root:2019-05-10 21:46:45, Epoch : 1, Step : 4585, Training Loss : 0.07547, Training Acc : 1.000, Run Time : 0.63
INFO:root:2019-05-10 21:46:46, Epoch : 1, Step : 4586, Training Loss : 0.14997, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-10 21:47:03, Epoch : 1, Step : 4587, Training Loss : 0.10839, Training Acc : 0.956, Run Time : 17.37
INFO:root:2019-05-10 21:47:04, Epoch : 1, Step : 4588, Training Loss : 0.12748, Training Acc : 0.950, Run Time : 0.79
INFO:root:2019-05-10 21:47:04, Epoch : 1, Step : 4589, Training Loss : 0.12003, Training Acc : 0.978, Run Time : 0.45
INFO:root:2019-05-10 21:47:14, Epoch : 1, Step : 4590, Training Loss : 0.17766, Training Acc : 0.928, Run Time : 9.63
INFO:root:2019-05-10 21:47:15, Epoch : 1, Step : 4591, Training Loss : 0.18530, Training Acc : 0.911, Run Time : 0.61
INFO:root:2019-05-10 21:47:15, Epoch : 1, Step : 4592, Training Loss : 0.15925, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-10 21:47:16, Epoch : 1, Step : 4593, Training Loss : 0.22157, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-10 21:47:28, Epoch : 1, Step : 4594, Training Loss : 0.33082, Training Acc : 0.878, Run Time : 12.69
INFO:root:2019-05-10 21:47:29, Epoch : 1, Step : 4595, Training Loss : 0.33325, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-10 21:47:29, Epoch : 1, Step : 4596, Training Loss : 0.37295, Training Acc : 0.900, Run Time : 0.44
INFO:root:2019-05-10 21:47:30, Epoch : 1, Step : 4597, Training Loss : 0.33633, Training Acc : 0.872, Run Time : 0.50
INFO:root:2019-05-10 21:47:30, Epoch : 1, Step : 4598, Training Loss : 0.29332, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 21:47:49, Epoch : 1, Step : 4599, Training Loss : 0.36310, Training Acc : 0.867, Run Time : 18.39
INFO:root:2019-05-10 21:47:49, Epoch : 1, Step : 4600, Training Loss : 0.29550, Training Acc : 0.867, Run Time : 0.24
INFO:root:2019-05-10 21:47:50, Epoch : 1, Step : 4601, Training Loss : 0.41955, Training Acc : 0.817, Run Time : 0.81
INFO:root:2019-05-10 21:47:50, Epoch : 1, Step : 4602, Training Loss : 0.27024, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 21:48:03, Epoch : 1, Step : 4603, Training Loss : 0.24119, Training Acc : 0.894, Run Time : 12.61
INFO:root:2019-05-10 21:48:03, Epoch : 1, Step : 4604, Training Loss : 0.52273, Training Acc : 0.794, Run Time : 0.67
INFO:root:2019-05-10 21:48:04, Epoch : 1, Step : 4605, Training Loss : 0.28639, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 21:48:04, Epoch : 1, Step : 4606, Training Loss : 0.32207, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-10 21:48:18, Epoch : 1, Step : 4607, Training Loss : 0.32621, Training Acc : 0.856, Run Time : 14.05
INFO:root:2019-05-10 21:48:19, Epoch : 1, Step : 4608, Training Loss : 0.41703, Training Acc : 0.839, Run Time : 0.25
INFO:root:2019-05-10 21:48:19, Epoch : 1, Step : 4609, Training Loss : 0.35937, Training Acc : 0.839, Run Time : 0.29
INFO:root:2019-05-10 21:48:19, Epoch : 1, Step : 4610, Training Loss : 0.34862, Training Acc : 0.861, Run Time : 0.47
INFO:root:2019-05-10 21:48:20, Epoch : 1, Step : 4611, Training Loss : 0.28232, Training Acc : 0.856, Run Time : 0.48
INFO:root:2019-05-10 21:48:36, Epoch : 1, Step : 4612, Training Loss : 0.32952, Training Acc : 0.850, Run Time : 15.75
INFO:root:2019-05-10 21:48:36, Epoch : 1, Step : 4613, Training Loss : 0.39940, Training Acc : 0.822, Run Time : 0.51
INFO:root:2019-05-10 21:48:37, Epoch : 1, Step : 4614, Training Loss : 0.33469, Training Acc : 0.828, Run Time : 0.93
INFO:root:2019-05-10 21:48:38, Epoch : 1, Step : 4615, Training Loss : 0.35925, Training Acc : 0.833, Run Time : 1.32
INFO:root:2019-05-10 21:48:39, Epoch : 1, Step : 4616, Training Loss : 0.28701, Training Acc : 0.850, Run Time : 0.49
INFO:root:2019-05-10 21:48:41, Epoch : 1, Step : 4617, Training Loss : 0.23249, Training Acc : 0.861, Run Time : 2.20
INFO:root:2019-05-10 21:48:42, Epoch : 1, Step : 4618, Training Loss : 0.26967, Training Acc : 0.850, Run Time : 0.83
INFO:root:2019-05-10 21:48:57, Epoch : 1, Step : 4619, Training Loss : 0.28827, Training Acc : 0.872, Run Time : 15.60
INFO:root:2019-05-10 21:48:58, Epoch : 1, Step : 4620, Training Loss : 0.25773, Training Acc : 0.872, Run Time : 0.22
INFO:root:2019-05-10 21:48:58, Epoch : 1, Step : 4621, Training Loss : 0.20366, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-10 21:48:58, Epoch : 1, Step : 4622, Training Loss : 0.21530, Training Acc : 0.900, Run Time : 0.44
INFO:root:2019-05-10 21:48:59, Epoch : 1, Step : 4623, Training Loss : 0.23871, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-10 21:49:17, Epoch : 1, Step : 4624, Training Loss : 0.22925, Training Acc : 0.900, Run Time : 18.11
INFO:root:2019-05-10 21:49:18, Epoch : 1, Step : 4625, Training Loss : 0.23985, Training Acc : 0.911, Run Time : 1.03
INFO:root:2019-05-10 21:49:19, Epoch : 1, Step : 4626, Training Loss : 0.23522, Training Acc : 0.906, Run Time : 0.62
INFO:root:2019-05-10 21:49:19, Epoch : 1, Step : 4627, Training Loss : 0.20666, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-10 21:49:20, Epoch : 1, Step : 4628, Training Loss : 0.31753, Training Acc : 0.822, Run Time : 0.47
INFO:root:2019-05-10 21:49:37, Epoch : 1, Step : 4629, Training Loss : 0.22919, Training Acc : 0.900, Run Time : 17.33
INFO:root:2019-05-10 21:49:37, Epoch : 1, Step : 4630, Training Loss : 0.22427, Training Acc : 0.906, Run Time : 0.27
INFO:root:2019-05-10 21:49:38, Epoch : 1, Step : 4631, Training Loss : 0.20101, Training Acc : 0.939, Run Time : 0.41
INFO:root:2019-05-10 21:49:38, Epoch : 1, Step : 4632, Training Loss : 0.18663, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-10 21:49:39, Epoch : 1, Step : 4633, Training Loss : 0.20255, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 21:49:45, Epoch : 1, Step : 4634, Training Loss : 0.17205, Training Acc : 0.933, Run Time : 6.56
INFO:root:2019-05-10 21:49:46, Epoch : 1, Step : 4635, Training Loss : 0.14604, Training Acc : 0.939, Run Time : 0.56
INFO:root:2019-05-10 21:50:01, Epoch : 1, Step : 4636, Training Loss : 0.21987, Training Acc : 0.928, Run Time : 15.44
INFO:root:2019-05-10 21:50:01, Epoch : 1, Step : 4637, Training Loss : 0.23199, Training Acc : 0.906, Run Time : 0.32
INFO:root:2019-05-10 21:50:02, Epoch : 1, Step : 4638, Training Loss : 0.28973, Training Acc : 0.850, Run Time : 0.54
INFO:root:2019-05-10 21:50:02, Epoch : 1, Step : 4639, Training Loss : 0.20757, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-10 21:50:03, Epoch : 1, Step : 4640, Training Loss : 0.14925, Training Acc : 0.950, Run Time : 0.50
INFO:root:2019-05-10 21:50:19, Epoch : 1, Step : 4641, Training Loss : 0.19218, Training Acc : 0.922, Run Time : 16.24
INFO:root:2019-05-10 21:50:19, Epoch : 1, Step : 4642, Training Loss : 0.16951, Training Acc : 0.933, Run Time : 0.21
INFO:root:2019-05-10 21:50:20, Epoch : 1, Step : 4643, Training Loss : 0.16051, Training Acc : 0.944, Run Time : 0.22
INFO:root:2019-05-10 21:50:20, Epoch : 1, Step : 4644, Training Loss : 0.16416, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-10 21:50:21, Epoch : 1, Step : 4645, Training Loss : 0.15728, Training Acc : 0.956, Run Time : 0.48
INFO:root:2019-05-10 21:50:40, Epoch : 1, Step : 4646, Training Loss : 0.19206, Training Acc : 0.917, Run Time : 19.94
INFO:root:2019-05-10 21:50:41, Epoch : 1, Step : 4647, Training Loss : 0.14281, Training Acc : 0.972, Run Time : 0.24
INFO:root:2019-05-10 21:50:41, Epoch : 1, Step : 4648, Training Loss : 0.21164, Training Acc : 0.950, Run Time : 0.21
INFO:root:2019-05-10 21:50:41, Epoch : 1, Step : 4649, Training Loss : 0.18455, Training Acc : 0.939, Run Time : 0.31
INFO:root:2019-05-10 21:50:42, Epoch : 1, Step : 4650, Training Loss : 0.22647, Training Acc : 0.900, Run Time : 0.56
INFO:root:2019-05-10 21:51:00, Epoch : 1, Step : 4651, Training Loss : 0.19031, Training Acc : 0.922, Run Time : 18.21
INFO:root:2019-05-10 21:51:00, Epoch : 1, Step : 4652, Training Loss : 0.14619, Training Acc : 0.933, Run Time : 0.26
INFO:root:2019-05-10 21:51:01, Epoch : 1, Step : 4653, Training Loss : 0.20798, Training Acc : 0.906, Run Time : 0.26
INFO:root:2019-05-10 21:51:01, Epoch : 1, Step : 4654, Training Loss : 0.20982, Training Acc : 0.922, Run Time : 0.45
INFO:root:2019-05-10 21:51:01, Epoch : 1, Step : 4655, Training Loss : 0.17349, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-10 21:51:20, Epoch : 1, Step : 4656, Training Loss : 0.18504, Training Acc : 0.928, Run Time : 18.10
INFO:root:2019-05-10 21:51:20, Epoch : 1, Step : 4657, Training Loss : 0.18445, Training Acc : 0.939, Run Time : 0.23
INFO:root:2019-05-10 21:51:20, Epoch : 1, Step : 4658, Training Loss : 0.24138, Training Acc : 0.911, Run Time : 0.22
INFO:root:2019-05-10 21:51:21, Epoch : 1, Step : 4659, Training Loss : 0.16908, Training Acc : 0.933, Run Time : 0.56
INFO:root:2019-05-10 21:51:21, Epoch : 1, Step : 4660, Training Loss : 0.23828, Training Acc : 0.917, Run Time : 0.48
INFO:root:2019-05-10 21:51:39, Epoch : 1, Step : 4661, Training Loss : 0.34755, Training Acc : 0.867, Run Time : 17.90
INFO:root:2019-05-10 21:51:39, Epoch : 1, Step : 4662, Training Loss : 0.39705, Training Acc : 0.828, Run Time : 0.25
INFO:root:2019-05-10 21:51:39, Epoch : 1, Step : 4663, Training Loss : 0.29451, Training Acc : 0.878, Run Time : 0.22
INFO:root:2019-05-10 21:51:40, Epoch : 1, Step : 4664, Training Loss : 0.38402, Training Acc : 0.822, Run Time : 0.46
INFO:root:2019-05-10 21:51:40, Epoch : 1, Step : 4665, Training Loss : 0.47262, Training Acc : 0.811, Run Time : 0.51
INFO:root:2019-05-10 21:51:57, Epoch : 1, Step : 4666, Training Loss : 0.31374, Training Acc : 0.850, Run Time : 16.51
INFO:root:2019-05-10 21:51:57, Epoch : 1, Step : 4667, Training Loss : 0.30901, Training Acc : 0.878, Run Time : 0.50
INFO:root:2019-05-10 21:51:58, Epoch : 1, Step : 4668, Training Loss : 0.35420, Training Acc : 0.856, Run Time : 0.44
INFO:root:2019-05-10 21:51:58, Epoch : 1, Step : 4669, Training Loss : 0.22543, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-10 21:52:03, Epoch : 1, Step : 4670, Training Loss : 0.24645, Training Acc : 0.933, Run Time : 5.03
INFO:root:2019-05-10 21:52:12, Epoch : 1, Step : 4671, Training Loss : 0.18025, Training Acc : 0.933, Run Time : 8.32
INFO:root:2019-05-10 21:52:12, Epoch : 1, Step : 4672, Training Loss : 0.21610, Training Acc : 0.933, Run Time : 0.49
INFO:root:2019-05-10 21:52:13, Epoch : 1, Step : 4673, Training Loss : 0.30980, Training Acc : 0.850, Run Time : 0.45
INFO:root:2019-05-10 21:52:25, Epoch : 1, Step : 4674, Training Loss : 0.26012, Training Acc : 0.883, Run Time : 12.68
INFO:root:2019-05-10 21:52:26, Epoch : 1, Step : 4675, Training Loss : 0.22580, Training Acc : 0.917, Run Time : 0.68
INFO:root:2019-05-10 21:52:28, Epoch : 1, Step : 4676, Training Loss : 0.22311, Training Acc : 0.928, Run Time : 1.83
INFO:root:2019-05-10 21:52:39, Epoch : 1, Step : 4677, Training Loss : 0.23239, Training Acc : 0.917, Run Time : 11.71
INFO:root:2019-05-10 21:52:40, Epoch : 1, Step : 4678, Training Loss : 0.24496, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-10 21:52:40, Epoch : 1, Step : 4679, Training Loss : 0.21948, Training Acc : 0.928, Run Time : 0.33
INFO:root:2019-05-10 21:52:53, Epoch : 1, Step : 4680, Training Loss : 0.37792, Training Acc : 0.867, Run Time : 12.44
INFO:root:2019-05-10 21:52:54, Epoch : 1, Step : 4681, Training Loss : 0.23487, Training Acc : 0.906, Run Time : 1.26
INFO:root:2019-05-10 21:52:54, Epoch : 1, Step : 4682, Training Loss : 0.22005, Training Acc : 0.911, Run Time : 0.50
INFO:root:2019-05-10 21:52:55, Epoch : 1, Step : 4683, Training Loss : 0.26472, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-10 21:53:09, Epoch : 1, Step : 4684, Training Loss : 0.18735, Training Acc : 0.939, Run Time : 14.59
INFO:root:2019-05-10 21:53:10, Epoch : 1, Step : 4685, Training Loss : 0.35224, Training Acc : 0.844, Run Time : 0.47
INFO:root:2019-05-10 21:53:10, Epoch : 1, Step : 4686, Training Loss : 0.15462, Training Acc : 0.939, Run Time : 0.43
INFO:root:2019-05-10 21:53:11, Epoch : 1, Step : 4687, Training Loss : 0.23711, Training Acc : 0.906, Run Time : 0.64
INFO:root:2019-05-10 21:53:12, Epoch : 1, Step : 4688, Training Loss : 0.17268, Training Acc : 0.939, Run Time : 0.59
INFO:root:2019-05-10 21:53:30, Epoch : 1, Step : 4689, Training Loss : 0.20841, Training Acc : 0.922, Run Time : 18.40
INFO:root:2019-05-10 21:53:30, Epoch : 1, Step : 4690, Training Loss : 0.12351, Training Acc : 0.972, Run Time : 0.30
INFO:root:2019-05-10 21:53:31, Epoch : 1, Step : 4691, Training Loss : 0.12446, Training Acc : 0.950, Run Time : 0.22
INFO:root:2019-05-10 21:53:31, Epoch : 1, Step : 4692, Training Loss : 0.13167, Training Acc : 0.956, Run Time : 0.73
INFO:root:2019-05-10 21:53:33, Epoch : 1, Step : 4693, Training Loss : 0.14040, Training Acc : 0.939, Run Time : 1.29
INFO:root:2019-05-10 21:53:55, Epoch : 1, Step : 4694, Training Loss : 0.11478, Training Acc : 0.967, Run Time : 22.73
INFO:root:2019-05-10 21:53:56, Epoch : 1, Step : 4695, Training Loss : 0.09204, Training Acc : 0.978, Run Time : 0.71
INFO:root:2019-05-10 21:53:57, Epoch : 1, Step : 4696, Training Loss : 0.09781, Training Acc : 0.972, Run Time : 0.95
INFO:root:2019-05-10 21:53:57, Epoch : 1, Step : 4697, Training Loss : 0.18125, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-10 21:53:58, Epoch : 1, Step : 4698, Training Loss : 0.16230, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 21:54:15, Epoch : 1, Step : 4699, Training Loss : 0.15121, Training Acc : 0.933, Run Time : 17.04
INFO:root:2019-05-10 21:54:16, Epoch : 1, Step : 4700, Training Loss : 0.15012, Training Acc : 0.928, Run Time : 0.57
INFO:root:2019-05-10 21:54:23, Epoch : 1, Step : 4701, Training Loss : 0.14320, Training Acc : 0.939, Run Time : 7.12
INFO:root:2019-05-10 21:54:23, Epoch : 1, Step : 4702, Training Loss : 0.14623, Training Acc : 0.956, Run Time : 0.32
INFO:root:2019-05-10 21:54:25, Epoch : 1, Step : 4703, Training Loss : 0.12865, Training Acc : 0.928, Run Time : 1.57
INFO:root:2019-05-10 21:54:37, Epoch : 1, Step : 4704, Training Loss : 0.15977, Training Acc : 0.922, Run Time : 12.14
INFO:root:2019-05-10 21:54:37, Epoch : 1, Step : 4705, Training Loss : 0.12580, Training Acc : 0.956, Run Time : 0.56
INFO:root:2019-05-10 21:54:38, Epoch : 1, Step : 4706, Training Loss : 0.15072, Training Acc : 0.917, Run Time : 0.37
INFO:root:2019-05-10 21:54:38, Epoch : 1, Step : 4707, Training Loss : 0.17707, Training Acc : 0.928, Run Time : 0.43
INFO:root:2019-05-10 21:54:39, Epoch : 1, Step : 4708, Training Loss : 0.07435, Training Acc : 0.978, Run Time : 1.03
INFO:root:2019-05-10 21:54:57, Epoch : 1, Step : 4709, Training Loss : 0.17129, Training Acc : 0.939, Run Time : 17.48
INFO:root:2019-05-10 21:54:57, Epoch : 1, Step : 4710, Training Loss : 0.19342, Training Acc : 0.939, Run Time : 0.60
INFO:root:2019-05-10 21:54:58, Epoch : 1, Step : 4711, Training Loss : 0.18518, Training Acc : 0.906, Run Time : 0.55
INFO:root:2019-05-10 21:54:58, Epoch : 1, Step : 4712, Training Loss : 0.19109, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-10 21:55:00, Epoch : 1, Step : 4713, Training Loss : 0.18958, Training Acc : 0.933, Run Time : 2.33
INFO:root:2019-05-10 21:55:17, Epoch : 1, Step : 4714, Training Loss : 0.11850, Training Acc : 0.956, Run Time : 16.08
INFO:root:2019-05-10 21:55:17, Epoch : 1, Step : 4715, Training Loss : 0.27967, Training Acc : 0.872, Run Time : 0.61
INFO:root:2019-05-10 21:55:28, Epoch : 1, Step : 4716, Training Loss : 0.22665, Training Acc : 0.889, Run Time : 10.96
INFO:root:2019-05-10 21:55:29, Epoch : 1, Step : 4717, Training Loss : 0.19974, Training Acc : 0.900, Run Time : 1.29
INFO:root:2019-05-10 21:55:30, Epoch : 1, Step : 4718, Training Loss : 0.24487, Training Acc : 0.889, Run Time : 0.83
INFO:root:2019-05-10 21:55:31, Epoch : 1, Step : 4719, Training Loss : 0.26565, Training Acc : 0.867, Run Time : 0.45
INFO:root:2019-05-10 21:55:42, Epoch : 1, Step : 4720, Training Loss : 0.20995, Training Acc : 0.906, Run Time : 11.39
INFO:root:2019-05-10 21:55:43, Epoch : 1, Step : 4721, Training Loss : 0.21843, Training Acc : 0.944, Run Time : 0.65
INFO:root:2019-05-10 21:55:43, Epoch : 1, Step : 4722, Training Loss : 0.16397, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-10 21:55:44, Epoch : 1, Step : 4723, Training Loss : 0.15895, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-10 21:55:44, Epoch : 1, Step : 4724, Training Loss : 0.16574, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 21:56:02, Epoch : 1, Step : 4725, Training Loss : 0.17757, Training Acc : 0.933, Run Time : 18.25
INFO:root:2019-05-10 21:56:03, Epoch : 1, Step : 4726, Training Loss : 0.18160, Training Acc : 0.911, Run Time : 0.59
INFO:root:2019-05-10 21:56:03, Epoch : 1, Step : 4727, Training Loss : 0.23883, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-10 21:56:04, Epoch : 1, Step : 4728, Training Loss : 0.13409, Training Acc : 0.956, Run Time : 0.40
INFO:root:2019-05-10 21:56:04, Epoch : 1, Step : 4729, Training Loss : 0.17520, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 21:56:24, Epoch : 1, Step : 4730, Training Loss : 0.25290, Training Acc : 0.894, Run Time : 19.60
INFO:root:2019-05-10 21:56:24, Epoch : 1, Step : 4731, Training Loss : 0.16629, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 21:56:25, Epoch : 1, Step : 4732, Training Loss : 0.26914, Training Acc : 0.878, Run Time : 0.45
INFO:root:2019-05-10 21:56:25, Epoch : 1, Step : 4733, Training Loss : 0.25392, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-10 21:56:26, Epoch : 1, Step : 4734, Training Loss : 0.11892, Training Acc : 0.978, Run Time : 1.05
INFO:root:2019-05-10 21:56:43, Epoch : 1, Step : 4735, Training Loss : 0.19696, Training Acc : 0.917, Run Time : 16.86
INFO:root:2019-05-10 21:56:44, Epoch : 1, Step : 4736, Training Loss : 0.12392, Training Acc : 0.961, Run Time : 0.36
INFO:root:2019-05-10 21:56:44, Epoch : 1, Step : 4737, Training Loss : 0.15036, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-10 21:56:44, Epoch : 1, Step : 4738, Training Loss : 0.14897, Training Acc : 0.944, Run Time : 0.30
INFO:root:2019-05-10 21:56:58, Epoch : 1, Step : 4739, Training Loss : 0.12677, Training Acc : 0.950, Run Time : 14.07
INFO:root:2019-05-10 21:56:59, Epoch : 1, Step : 4740, Training Loss : 0.15835, Training Acc : 0.939, Run Time : 0.21
INFO:root:2019-05-10 21:56:59, Epoch : 1, Step : 4741, Training Loss : 0.26497, Training Acc : 0.889, Run Time : 0.24
INFO:root:2019-05-10 21:56:59, Epoch : 1, Step : 4742, Training Loss : 0.16717, Training Acc : 0.928, Run Time : 0.49
INFO:root:2019-05-10 21:57:00, Epoch : 1, Step : 4743, Training Loss : 0.20882, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-10 21:57:16, Epoch : 1, Step : 4744, Training Loss : 0.24345, Training Acc : 0.867, Run Time : 16.52
INFO:root:2019-05-10 21:57:17, Epoch : 1, Step : 4745, Training Loss : 0.13747, Training Acc : 0.944, Run Time : 0.67
INFO:root:2019-05-10 21:57:17, Epoch : 1, Step : 4746, Training Loss : 0.23295, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-10 21:57:18, Epoch : 1, Step : 4747, Training Loss : 0.14987, Training Acc : 0.956, Run Time : 0.48
INFO:root:2019-05-10 21:57:18, Epoch : 1, Step : 4748, Training Loss : 0.17914, Training Acc : 0.944, Run Time : 0.49
INFO:root:2019-05-10 21:57:22, Epoch : 1, Step : 4749, Training Loss : 0.27336, Training Acc : 0.872, Run Time : 3.36
INFO:root:2019-05-10 21:57:34, Epoch : 1, Step : 4750, Training Loss : 0.27924, Training Acc : 0.867, Run Time : 12.59
INFO:root:2019-05-10 21:57:35, Epoch : 1, Step : 4751, Training Loss : 0.43317, Training Acc : 0.811, Run Time : 0.45
INFO:root:2019-05-10 21:57:35, Epoch : 1, Step : 4752, Training Loss : 0.23977, Training Acc : 0.900, Run Time : 0.45
INFO:root:2019-05-10 21:57:36, Epoch : 1, Step : 4753, Training Loss : 0.32345, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-10 21:57:36, Epoch : 1, Step : 4754, Training Loss : 0.25996, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 21:57:53, Epoch : 1, Step : 4755, Training Loss : 0.19707, Training Acc : 0.922, Run Time : 17.21
INFO:root:2019-05-10 21:57:54, Epoch : 1, Step : 4756, Training Loss : 0.30034, Training Acc : 0.883, Run Time : 0.34
INFO:root:2019-05-10 21:57:54, Epoch : 1, Step : 4757, Training Loss : 0.82221, Training Acc : 0.678, Run Time : 0.44
INFO:root:2019-05-10 21:57:55, Epoch : 1, Step : 4758, Training Loss : 0.23904, Training Acc : 0.900, Run Time : 0.49
INFO:root:2019-05-10 21:57:55, Epoch : 1, Step : 4759, Training Loss : 0.39480, Training Acc : 0.817, Run Time : 0.53
INFO:root:2019-05-10 21:58:13, Epoch : 1, Step : 4760, Training Loss : 0.38322, Training Acc : 0.856, Run Time : 18.08
INFO:root:2019-05-10 21:58:14, Epoch : 1, Step : 4761, Training Loss : 0.30303, Training Acc : 0.861, Run Time : 0.27
INFO:root:2019-05-10 21:58:14, Epoch : 1, Step : 4762, Training Loss : 0.19173, Training Acc : 0.922, Run Time : 0.45
INFO:root:2019-05-10 21:58:15, Epoch : 1, Step : 4763, Training Loss : 0.21394, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-10 21:58:17, Epoch : 1, Step : 4764, Training Loss : 0.29173, Training Acc : 0.856, Run Time : 2.22
INFO:root:2019-05-10 21:58:31, Epoch : 1, Step : 4765, Training Loss : 0.29629, Training Acc : 0.883, Run Time : 14.57
INFO:root:2019-05-10 21:58:32, Epoch : 1, Step : 4766, Training Loss : 0.29976, Training Acc : 0.844, Run Time : 0.59
INFO:root:2019-05-10 21:58:32, Epoch : 1, Step : 4767, Training Loss : 0.22527, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-10 21:58:33, Epoch : 1, Step : 4768, Training Loss : 0.26060, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-10 21:58:33, Epoch : 1, Step : 4769, Training Loss : 0.18252, Training Acc : 0.928, Run Time : 0.49
INFO:root:2019-05-10 21:58:50, Epoch : 1, Step : 4770, Training Loss : 0.28304, Training Acc : 0.872, Run Time : 16.58
INFO:root:2019-05-10 21:58:50, Epoch : 1, Step : 4771, Training Loss : 0.25436, Training Acc : 0.900, Run Time : 0.23
INFO:root:2019-05-10 21:58:51, Epoch : 1, Step : 4772, Training Loss : 0.25872, Training Acc : 0.883, Run Time : 0.43
INFO:root:2019-05-10 21:58:51, Epoch : 1, Step : 4773, Training Loss : 0.34356, Training Acc : 0.822, Run Time : 0.45
INFO:root:2019-05-10 21:58:51, Epoch : 1, Step : 4774, Training Loss : 0.23417, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-10 21:59:10, Epoch : 1, Step : 4775, Training Loss : 0.21730, Training Acc : 0.883, Run Time : 18.32
INFO:root:2019-05-10 21:59:10, Epoch : 1, Step : 4776, Training Loss : 0.21486, Training Acc : 0.894, Run Time : 0.57
INFO:root:2019-05-10 21:59:11, Epoch : 1, Step : 4777, Training Loss : 0.22103, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-10 21:59:11, Epoch : 1, Step : 4778, Training Loss : 0.14241, Training Acc : 0.956, Run Time : 0.45
INFO:root:2019-05-10 21:59:12, Epoch : 1, Step : 4779, Training Loss : 0.17030, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 21:59:29, Epoch : 1, Step : 4780, Training Loss : 0.22126, Training Acc : 0.889, Run Time : 16.78
INFO:root:2019-05-10 21:59:29, Epoch : 1, Step : 4781, Training Loss : 0.23992, Training Acc : 0.911, Run Time : 0.23
INFO:root:2019-05-10 21:59:29, Epoch : 1, Step : 4782, Training Loss : 0.21090, Training Acc : 0.900, Run Time : 0.35
INFO:root:2019-05-10 21:59:30, Epoch : 1, Step : 4783, Training Loss : 0.27848, Training Acc : 0.900, Run Time : 0.41
INFO:root:2019-05-10 21:59:30, Epoch : 1, Step : 4784, Training Loss : 0.29613, Training Acc : 0.883, Run Time : 0.40
INFO:root:2019-05-10 21:59:39, Epoch : 1, Step : 4785, Training Loss : 0.19345, Training Acc : 0.900, Run Time : 9.40
INFO:root:2019-05-10 21:59:45, Epoch : 1, Step : 4786, Training Loss : 0.15858, Training Acc : 0.928, Run Time : 6.07
INFO:root:2019-05-10 21:59:46, Epoch : 1, Step : 4787, Training Loss : 0.10193, Training Acc : 0.961, Run Time : 0.44
INFO:root:2019-05-10 21:59:46, Epoch : 1, Step : 4788, Training Loss : 0.09303, Training Acc : 0.983, Run Time : 0.43
INFO:root:2019-05-10 22:00:02, Epoch : 1, Step : 4789, Training Loss : 0.11809, Training Acc : 0.956, Run Time : 15.59
INFO:root:2019-05-10 22:00:03, Epoch : 1, Step : 4790, Training Loss : 0.18207, Training Acc : 0.944, Run Time : 0.79
INFO:root:2019-05-10 22:00:03, Epoch : 1, Step : 4791, Training Loss : 0.12487, Training Acc : 0.961, Run Time : 0.55
INFO:root:2019-05-10 22:00:04, Epoch : 1, Step : 4792, Training Loss : 0.18270, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-10 22:00:05, Epoch : 1, Step : 4793, Training Loss : 0.18387, Training Acc : 0.928, Run Time : 1.11
INFO:root:2019-05-10 22:00:22, Epoch : 1, Step : 4794, Training Loss : 0.10030, Training Acc : 0.978, Run Time : 17.21
INFO:root:2019-05-10 22:00:22, Epoch : 1, Step : 4795, Training Loss : 0.16393, Training Acc : 0.939, Run Time : 0.32
INFO:root:2019-05-10 22:00:23, Epoch : 1, Step : 4796, Training Loss : 0.16379, Training Acc : 0.911, Run Time : 0.52
INFO:root:2019-05-10 22:00:23, Epoch : 1, Step : 4797, Training Loss : 0.22837, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 22:00:24, Epoch : 1, Step : 4798, Training Loss : 0.30630, Training Acc : 0.878, Run Time : 0.51
INFO:root:2019-05-10 22:00:41, Epoch : 1, Step : 4799, Training Loss : 0.21676, Training Acc : 0.917, Run Time : 17.37
INFO:root:2019-05-10 22:00:41, Epoch : 1, Step : 4800, Training Loss : 0.24823, Training Acc : 0.911, Run Time : 0.33
INFO:root:2019-05-10 22:00:43, Epoch : 1, Step : 4801, Training Loss : 0.98246, Training Acc : 0.711, Run Time : 1.82
INFO:root:2019-05-10 22:00:45, Epoch : 1, Step : 4802, Training Loss : 0.86139, Training Acc : 0.689, Run Time : 1.64
INFO:root:2019-05-10 22:00:54, Epoch : 1, Step : 4803, Training Loss : 0.60618, Training Acc : 0.722, Run Time : 8.92
INFO:root:2019-05-10 22:00:54, Epoch : 1, Step : 4804, Training Loss : 0.51931, Training Acc : 0.789, Run Time : 0.64
INFO:root:2019-05-10 22:00:55, Epoch : 1, Step : 4805, Training Loss : 0.52190, Training Acc : 0.783, Run Time : 0.22
INFO:root:2019-05-10 22:00:55, Epoch : 1, Step : 4806, Training Loss : 0.32915, Training Acc : 0.856, Run Time : 0.73
INFO:root:2019-05-10 22:00:59, Epoch : 1, Step : 4807, Training Loss : 0.67490, Training Acc : 0.717, Run Time : 3.21
INFO:root:2019-05-10 22:01:08, Epoch : 1, Step : 4808, Training Loss : 0.24045, Training Acc : 0.894, Run Time : 9.53
INFO:root:2019-05-10 22:01:09, Epoch : 1, Step : 4809, Training Loss : 0.16579, Training Acc : 0.922, Run Time : 0.73
INFO:root:2019-05-10 22:01:10, Epoch : 1, Step : 4810, Training Loss : 0.07092, Training Acc : 0.978, Run Time : 0.63
INFO:root:2019-05-10 22:01:11, Epoch : 1, Step : 4811, Training Loss : 0.26093, Training Acc : 0.883, Run Time : 1.96
INFO:root:2019-05-10 22:01:12, Epoch : 1, Step : 4812, Training Loss : 0.11355, Training Acc : 0.956, Run Time : 0.51
INFO:root:2019-05-10 22:01:13, Epoch : 1, Step : 4813, Training Loss : 0.19258, Training Acc : 0.894, Run Time : 1.09
INFO:root:2019-05-10 22:01:15, Epoch : 1, Step : 4814, Training Loss : 0.18260, Training Acc : 0.928, Run Time : 1.86
INFO:root:2019-05-10 22:01:45, Epoch : 1, Step : 4815, Training Loss : 0.45971, Training Acc : 0.811, Run Time : 29.93
INFO:root:2019-05-10 22:01:45, Epoch : 1, Step : 4816, Training Loss : 0.15828, Training Acc : 0.944, Run Time : 0.23
INFO:root:2019-05-10 22:01:45, Epoch : 1, Step : 4817, Training Loss : 0.17900, Training Acc : 0.917, Run Time : 0.30
INFO:root:2019-05-10 22:01:46, Epoch : 1, Step : 4818, Training Loss : 0.22104, Training Acc : 0.922, Run Time : 0.21
INFO:root:2019-05-10 22:01:46, Epoch : 1, Step : 4819, Training Loss : 0.16324, Training Acc : 0.922, Run Time : 0.36
INFO:root:2019-05-10 22:02:16, Epoch : 1, Step : 4820, Training Loss : 0.24297, Training Acc : 0.939, Run Time : 30.19
INFO:root:2019-05-10 22:02:30, Epoch : 1, Step : 4821, Training Loss : 0.13943, Training Acc : 0.944, Run Time : 14.08
INFO:root:2019-05-10 22:02:31, Epoch : 1, Step : 4822, Training Loss : 0.11699, Training Acc : 0.972, Run Time : 1.04
INFO:root:2019-05-10 22:02:32, Epoch : 1, Step : 4823, Training Loss : 0.29283, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-10 22:02:32, Epoch : 1, Step : 4824, Training Loss : 0.41174, Training Acc : 0.900, Run Time : 0.50
INFO:root:2019-05-10 22:02:33, Epoch : 1, Step : 4825, Training Loss : 0.16896, Training Acc : 0.950, Run Time : 0.53
INFO:root:2019-05-10 22:02:47, Epoch : 1, Step : 4826, Training Loss : 0.08053, Training Acc : 0.972, Run Time : 14.48
INFO:root:2019-05-10 22:02:47, Epoch : 1, Step : 4827, Training Loss : 0.05258, Training Acc : 0.983, Run Time : 0.21
INFO:root:2019-05-10 22:02:48, Epoch : 1, Step : 4828, Training Loss : 0.10322, Training Acc : 0.961, Run Time : 0.35
INFO:root:2019-05-10 22:02:48, Epoch : 1, Step : 4829, Training Loss : 0.14592, Training Acc : 0.961, Run Time : 0.44
INFO:root:2019-05-10 22:02:49, Epoch : 1, Step : 4830, Training Loss : 0.04704, Training Acc : 0.989, Run Time : 0.50
INFO:root:2019-05-10 22:03:06, Epoch : 1, Step : 4831, Training Loss : 0.03085, Training Acc : 0.994, Run Time : 17.40
INFO:root:2019-05-10 22:03:07, Epoch : 1, Step : 4832, Training Loss : 0.09787, Training Acc : 0.972, Run Time : 0.87
INFO:root:2019-05-10 22:03:07, Epoch : 1, Step : 4833, Training Loss : 0.04611, Training Acc : 0.989, Run Time : 0.28
INFO:root:2019-05-10 22:03:08, Epoch : 1, Step : 4834, Training Loss : 0.02334, Training Acc : 1.000, Run Time : 0.47
INFO:root:2019-05-10 22:03:08, Epoch : 1, Step : 4835, Training Loss : 0.06319, Training Acc : 0.978, Run Time : 0.47
INFO:root:2019-05-10 22:03:24, Epoch : 1, Step : 4836, Training Loss : 0.09106, Training Acc : 0.961, Run Time : 15.76
INFO:root:2019-05-10 22:03:24, Epoch : 1, Step : 4837, Training Loss : 0.16352, Training Acc : 0.939, Run Time : 0.52
INFO:root:2019-05-10 22:03:25, Epoch : 1, Step : 4838, Training Loss : 0.21441, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-10 22:03:25, Epoch : 1, Step : 4839, Training Loss : 0.19713, Training Acc : 0.950, Run Time : 0.43
INFO:root:2019-05-10 22:03:37, Epoch : 1, Step : 4840, Training Loss : 0.23047, Training Acc : 0.950, Run Time : 12.04
INFO:root:2019-05-10 22:03:38, Epoch : 1, Step : 4841, Training Loss : 0.19535, Training Acc : 0.928, Run Time : 0.79
INFO:root:2019-05-10 22:03:39, Epoch : 1, Step : 4842, Training Loss : 0.12757, Training Acc : 0.967, Run Time : 0.39
INFO:root:2019-05-10 22:03:39, Epoch : 1, Step : 4843, Training Loss : 0.19190, Training Acc : 0.944, Run Time : 0.49
INFO:root:2019-05-10 22:03:40, Epoch : 1, Step : 4844, Training Loss : 0.20796, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-10 22:03:56, Epoch : 1, Step : 4845, Training Loss : 0.09695, Training Acc : 0.967, Run Time : 16.10
INFO:root:2019-05-10 22:03:56, Epoch : 1, Step : 4846, Training Loss : 0.13314, Training Acc : 0.961, Run Time : 0.30
INFO:root:2019-05-10 22:03:57, Epoch : 1, Step : 4847, Training Loss : 0.09116, Training Acc : 0.961, Run Time : 1.43
INFO:root:2019-05-10 22:04:10, Epoch : 1, Step : 4848, Training Loss : 0.23565, Training Acc : 0.911, Run Time : 12.40
INFO:root:2019-05-10 22:04:10, Epoch : 1, Step : 4849, Training Loss : 0.11579, Training Acc : 0.972, Run Time : 0.24
INFO:root:2019-05-10 22:04:10, Epoch : 1, Step : 4850, Training Loss : 0.08359, Training Acc : 0.972, Run Time : 0.22
INFO:root:2019-05-10 22:04:10, Epoch : 1, Step : 4851, Training Loss : 0.08617, Training Acc : 0.972, Run Time : 0.21
INFO:root:2019-05-10 22:04:11, Epoch : 1, Step : 4852, Training Loss : 0.10085, Training Acc : 0.956, Run Time : 0.52
INFO:root:2019-05-10 22:04:31, Epoch : 1, Step : 4853, Training Loss : 0.14562, Training Acc : 0.933, Run Time : 19.65
INFO:root:2019-05-10 22:04:31, Epoch : 1, Step : 4854, Training Loss : 0.04399, Training Acc : 1.000, Run Time : 0.66
INFO:root:2019-05-10 22:04:32, Epoch : 1, Step : 4855, Training Loss : 0.18294, Training Acc : 0.939, Run Time : 0.28
INFO:root:2019-05-10 22:04:32, Epoch : 1, Step : 4856, Training Loss : 0.08567, Training Acc : 0.983, Run Time : 0.40
INFO:root:2019-05-10 22:04:32, Epoch : 1, Step : 4857, Training Loss : 0.33125, Training Acc : 0.889, Run Time : 0.43
INFO:root:2019-05-10 22:04:49, Epoch : 1, Step : 4858, Training Loss : 0.29501, Training Acc : 0.894, Run Time : 16.68
INFO:root:2019-05-10 22:04:49, Epoch : 1, Step : 4859, Training Loss : 0.07112, Training Acc : 0.978, Run Time : 0.22
INFO:root:2019-05-10 22:04:50, Epoch : 1, Step : 4860, Training Loss : 0.10851, Training Acc : 0.978, Run Time : 0.23
INFO:root:2019-05-10 22:04:50, Epoch : 1, Step : 4861, Training Loss : 0.13729, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-10 22:04:50, Epoch : 1, Step : 4862, Training Loss : 0.24849, Training Acc : 0.906, Run Time : 0.40
INFO:root:2019-05-10 22:05:10, Epoch : 1, Step : 4863, Training Loss : 0.21868, Training Acc : 0.933, Run Time : 19.56
INFO:root:2019-05-10 22:05:10, Epoch : 1, Step : 4864, Training Loss : 0.50563, Training Acc : 0.872, Run Time : 0.23
INFO:root:2019-05-10 22:05:10, Epoch : 1, Step : 4865, Training Loss : 0.68994, Training Acc : 0.817, Run Time : 0.22
INFO:root:2019-05-10 22:05:11, Epoch : 1, Step : 4866, Training Loss : 0.30302, Training Acc : 0.939, Run Time : 0.21
INFO:root:2019-05-10 22:05:11, Epoch : 1, Step : 4867, Training Loss : 0.35405, Training Acc : 0.839, Run Time : 0.21
INFO:root:2019-05-10 22:05:30, Epoch : 1, Step : 4868, Training Loss : 0.53353, Training Acc : 0.806, Run Time : 18.69
INFO:root:2019-05-10 22:05:30, Epoch : 1, Step : 4869, Training Loss : 0.43722, Training Acc : 0.828, Run Time : 0.77
INFO:root:2019-05-10 22:05:30, Epoch : 1, Step : 4870, Training Loss : 0.55304, Training Acc : 0.822, Run Time : 0.22
INFO:root:2019-05-10 22:05:31, Epoch : 1, Step : 4871, Training Loss : 0.34338, Training Acc : 0.872, Run Time : 0.20
INFO:root:2019-05-10 22:05:31, Epoch : 1, Step : 4872, Training Loss : 0.36824, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 22:05:48, Epoch : 1, Step : 4873, Training Loss : 0.61643, Training Acc : 0.772, Run Time : 17.04
INFO:root:2019-05-10 22:05:48, Epoch : 1, Step : 4874, Training Loss : 0.36970, Training Acc : 0.883, Run Time : 0.23
INFO:root:2019-05-10 22:05:49, Epoch : 1, Step : 4875, Training Loss : 0.73705, Training Acc : 0.761, Run Time : 0.36
INFO:root:2019-05-10 22:05:49, Epoch : 1, Step : 4876, Training Loss : 0.41060, Training Acc : 0.850, Run Time : 0.45
INFO:root:2019-05-10 22:05:50, Epoch : 1, Step : 4877, Training Loss : 0.27683, Training Acc : 0.878, Run Time : 0.44
INFO:root:2019-05-10 22:06:05, Epoch : 1, Step : 4878, Training Loss : 0.64950, Training Acc : 0.778, Run Time : 15.80
INFO:root:2019-05-10 22:06:06, Epoch : 1, Step : 4879, Training Loss : 0.85505, Training Acc : 0.739, Run Time : 0.47
INFO:root:2019-05-10 22:06:06, Epoch : 1, Step : 4880, Training Loss : 0.85187, Training Acc : 0.711, Run Time : 0.21
INFO:root:2019-05-10 22:06:07, Epoch : 1, Step : 4881, Training Loss : 0.48463, Training Acc : 0.767, Run Time : 1.23
INFO:root:2019-05-10 22:06:18, Epoch : 1, Step : 4882, Training Loss : 0.32448, Training Acc : 0.883, Run Time : 10.43
INFO:root:2019-05-10 22:06:19, Epoch : 1, Step : 4883, Training Loss : 0.43144, Training Acc : 0.833, Run Time : 1.21
INFO:root:2019-05-10 22:06:19, Epoch : 1, Step : 4884, Training Loss : 0.22925, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-10 22:06:20, Epoch : 1, Step : 4885, Training Loss : 0.60460, Training Acc : 0.733, Run Time : 0.47
INFO:root:2019-05-10 22:06:22, Epoch : 1, Step : 4886, Training Loss : 0.75905, Training Acc : 0.689, Run Time : 1.77
INFO:root:2019-05-10 22:06:35, Epoch : 1, Step : 4887, Training Loss : 0.89082, Training Acc : 0.700, Run Time : 13.55
INFO:root:2019-05-10 22:06:36, Epoch : 1, Step : 4888, Training Loss : 0.76240, Training Acc : 0.694, Run Time : 0.60
INFO:root:2019-05-10 22:06:36, Epoch : 1, Step : 4889, Training Loss : 0.44894, Training Acc : 0.850, Run Time : 0.25
INFO:root:2019-05-10 22:06:48, Epoch : 1, Step : 4890, Training Loss : 0.42479, Training Acc : 0.861, Run Time : 11.82
INFO:root:2019-05-10 22:06:49, Epoch : 1, Step : 4891, Training Loss : 0.38488, Training Acc : 0.800, Run Time : 0.59
INFO:root:2019-05-10 22:06:49, Epoch : 1, Step : 4892, Training Loss : 0.32057, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 22:06:49, Epoch : 1, Step : 4893, Training Loss : 0.61330, Training Acc : 0.750, Run Time : 0.45
INFO:root:2019-05-10 22:06:50, Epoch : 1, Step : 4894, Training Loss : 0.50348, Training Acc : 0.778, Run Time : 0.47
INFO:root:2019-05-10 22:07:05, Epoch : 1, Step : 4895, Training Loss : 0.32262, Training Acc : 0.906, Run Time : 15.13
INFO:root:2019-05-10 22:07:05, Epoch : 1, Step : 4896, Training Loss : 0.20260, Training Acc : 0.972, Run Time : 0.43
INFO:root:2019-05-10 22:07:06, Epoch : 1, Step : 4897, Training Loss : 0.37686, Training Acc : 0.772, Run Time : 0.48
INFO:root:2019-05-10 22:07:19, Epoch : 1, Step : 4898, Training Loss : 0.34358, Training Acc : 0.822, Run Time : 13.14
INFO:root:2019-05-10 22:07:20, Epoch : 1, Step : 4899, Training Loss : 0.38705, Training Acc : 0.894, Run Time : 0.44
INFO:root:2019-05-10 22:07:20, Epoch : 1, Step : 4900, Training Loss : 0.36826, Training Acc : 0.811, Run Time : 0.23
INFO:root:2019-05-10 22:07:32, Epoch : 1, Step : 4901, Training Loss : 0.28328, Training Acc : 0.939, Run Time : 12.25
INFO:root:2019-05-10 22:07:33, Epoch : 1, Step : 4902, Training Loss : 0.23905, Training Acc : 0.939, Run Time : 0.78
INFO:root:2019-05-10 22:07:33, Epoch : 1, Step : 4903, Training Loss : 0.36312, Training Acc : 0.844, Run Time : 0.42
INFO:root:2019-05-10 22:07:35, Epoch : 1, Step : 4904, Training Loss : 0.26090, Training Acc : 0.894, Run Time : 1.65
INFO:root:2019-05-10 22:07:35, Epoch : 1, Step : 4905, Training Loss : 0.43134, Training Acc : 0.800, Run Time : 0.48
INFO:root:2019-05-10 22:07:51, Epoch : 1, Step : 4906, Training Loss : 0.35070, Training Acc : 0.878, Run Time : 15.74
INFO:root:2019-05-10 22:07:51, Epoch : 1, Step : 4907, Training Loss : 0.48480, Training Acc : 0.794, Run Time : 0.24
INFO:root:2019-05-10 22:07:52, Epoch : 1, Step : 4908, Training Loss : 0.27586, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-10 22:07:52, Epoch : 1, Step : 4909, Training Loss : 0.31970, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-10 22:07:53, Epoch : 1, Step : 4910, Training Loss : 0.29171, Training Acc : 0.906, Run Time : 0.68
INFO:root:2019-05-10 22:08:10, Epoch : 1, Step : 4911, Training Loss : 0.34681, Training Acc : 0.844, Run Time : 17.32
INFO:root:2019-05-10 22:08:10, Epoch : 1, Step : 4912, Training Loss : 0.47121, Training Acc : 0.767, Run Time : 0.22
INFO:root:2019-05-10 22:08:11, Epoch : 1, Step : 4913, Training Loss : 0.48155, Training Acc : 0.756, Run Time : 0.29
INFO:root:2019-05-10 22:08:11, Epoch : 1, Step : 4914, Training Loss : 0.42642, Training Acc : 0.789, Run Time : 0.55
INFO:root:2019-05-10 22:08:26, Epoch : 1, Step : 4915, Training Loss : 0.57653, Training Acc : 0.794, Run Time : 14.59
INFO:root:2019-05-10 22:08:27, Epoch : 1, Step : 4916, Training Loss : 0.48244, Training Acc : 0.778, Run Time : 1.15
INFO:root:2019-05-10 22:08:27, Epoch : 1, Step : 4917, Training Loss : 0.31840, Training Acc : 0.850, Run Time : 0.43
INFO:root:2019-05-10 22:08:28, Epoch : 1, Step : 4918, Training Loss : 0.38495, Training Acc : 0.844, Run Time : 0.45
INFO:root:2019-05-10 22:08:28, Epoch : 1, Step : 4919, Training Loss : 0.69643, Training Acc : 0.633, Run Time : 0.47
INFO:root:2019-05-10 22:08:43, Epoch : 1, Step : 4920, Training Loss : 0.61634, Training Acc : 0.678, Run Time : 14.28
INFO:root:2019-05-10 22:08:44, Epoch : 1, Step : 4921, Training Loss : 0.41553, Training Acc : 0.839, Run Time : 0.93
INFO:root:2019-05-10 22:08:44, Epoch : 1, Step : 4922, Training Loss : 0.42751, Training Acc : 0.828, Run Time : 0.39
INFO:root:2019-05-10 22:08:46, Epoch : 1, Step : 4923, Training Loss : 0.57700, Training Acc : 0.661, Run Time : 1.98
INFO:root:2019-05-10 22:08:56, Epoch : 1, Step : 4924, Training Loss : 0.49183, Training Acc : 0.789, Run Time : 9.54
INFO:root:2019-05-10 22:08:58, Epoch : 1, Step : 4925, Training Loss : 0.31401, Training Acc : 0.867, Run Time : 2.96
INFO:root:2019-05-10 22:08:59, Epoch : 1, Step : 4926, Training Loss : 0.40038, Training Acc : 0.806, Run Time : 0.39
INFO:root:2019-05-10 22:08:59, Epoch : 1, Step : 4927, Training Loss : 0.36756, Training Acc : 0.828, Run Time : 0.47
INFO:root:2019-05-10 22:09:00, Epoch : 1, Step : 4928, Training Loss : 0.27127, Training Acc : 0.917, Run Time : 0.52
INFO:root:2019-05-10 22:09:00, Epoch : 1, Step : 4929, Training Loss : 0.27649, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-10 22:09:04, Epoch : 1, Step : 4930, Training Loss : 0.47195, Training Acc : 0.828, Run Time : 3.95
INFO:root:2019-05-10 22:09:15, Epoch : 1, Step : 4931, Training Loss : 0.44804, Training Acc : 0.872, Run Time : 11.14
INFO:root:2019-05-10 22:09:19, Epoch : 1, Step : 4932, Training Loss : 0.57019, Training Acc : 0.750, Run Time : 3.53
INFO:root:2019-05-10 22:09:19, Epoch : 1, Step : 4933, Training Loss : 0.49461, Training Acc : 0.794, Run Time : 0.28
INFO:root:2019-05-10 22:09:20, Epoch : 1, Step : 4934, Training Loss : 0.40173, Training Acc : 0.811, Run Time : 0.61
INFO:root:2019-05-10 22:09:20, Epoch : 1, Step : 4935, Training Loss : 0.69760, Training Acc : 0.578, Run Time : 0.52
INFO:root:2019-05-10 22:09:21, Epoch : 1, Step : 4936, Training Loss : 0.63403, Training Acc : 0.672, Run Time : 0.49
INFO:root:2019-05-10 22:09:41, Epoch : 1, Step : 4937, Training Loss : 0.62011, Training Acc : 0.694, Run Time : 19.86
INFO:root:2019-05-10 22:09:41, Epoch : 1, Step : 4938, Training Loss : 0.66511, Training Acc : 0.578, Run Time : 0.22
INFO:root:2019-05-10 22:09:41, Epoch : 1, Step : 4939, Training Loss : 0.60203, Training Acc : 0.644, Run Time : 0.23
INFO:root:2019-05-10 22:09:41, Epoch : 1, Step : 4940, Training Loss : 0.64215, Training Acc : 0.678, Run Time : 0.35
INFO:root:2019-05-10 22:09:42, Epoch : 1, Step : 4941, Training Loss : 0.56097, Training Acc : 0.750, Run Time : 0.43
INFO:root:2019-05-10 22:09:58, Epoch : 1, Step : 4942, Training Loss : 0.54391, Training Acc : 0.722, Run Time : 16.14
INFO:root:2019-05-10 22:09:59, Epoch : 1, Step : 4943, Training Loss : 0.35845, Training Acc : 0.844, Run Time : 0.67
INFO:root:2019-05-10 22:09:59, Epoch : 1, Step : 4944, Training Loss : 0.53534, Training Acc : 0.756, Run Time : 0.45
INFO:root:2019-05-10 22:10:00, Epoch : 1, Step : 4945, Training Loss : 0.57140, Training Acc : 0.756, Run Time : 0.45
INFO:root:2019-05-10 22:10:12, Epoch : 1, Step : 4946, Training Loss : 0.40141, Training Acc : 0.806, Run Time : 12.04
INFO:root:2019-05-10 22:10:12, Epoch : 1, Step : 4947, Training Loss : 0.39584, Training Acc : 0.850, Run Time : 0.76
INFO:root:2019-05-10 22:10:13, Epoch : 1, Step : 4948, Training Loss : 0.61756, Training Acc : 0.644, Run Time : 0.44
INFO:root:2019-05-10 22:10:29, Epoch : 1, Step : 4949, Training Loss : 0.42983, Training Acc : 0.778, Run Time : 16.43
INFO:root:2019-05-10 22:10:30, Epoch : 1, Step : 4950, Training Loss : 0.51491, Training Acc : 0.761, Run Time : 0.23
INFO:root:2019-05-10 22:10:30, Epoch : 1, Step : 4951, Training Loss : 0.62265, Training Acc : 0.683, Run Time : 0.24
INFO:root:2019-05-10 22:10:30, Epoch : 1, Step : 4952, Training Loss : 0.37212, Training Acc : 0.839, Run Time : 0.41
INFO:root:2019-05-10 22:10:31, Epoch : 1, Step : 4953, Training Loss : 0.44529, Training Acc : 0.783, Run Time : 0.52
INFO:root:2019-05-10 22:10:50, Epoch : 1, Step : 4954, Training Loss : 0.41108, Training Acc : 0.833, Run Time : 19.36
INFO:root:2019-05-10 22:10:50, Epoch : 1, Step : 4955, Training Loss : 0.37211, Training Acc : 0.828, Run Time : 0.22
INFO:root:2019-05-10 22:10:51, Epoch : 1, Step : 4956, Training Loss : 0.55944, Training Acc : 0.733, Run Time : 0.25
INFO:root:2019-05-10 22:10:51, Epoch : 1, Step : 4957, Training Loss : 0.34140, Training Acc : 0.811, Run Time : 0.46
INFO:root:2019-05-10 22:10:52, Epoch : 1, Step : 4958, Training Loss : 0.39585, Training Acc : 0.806, Run Time : 0.52
INFO:root:2019-05-10 22:11:13, Epoch : 1, Step : 4959, Training Loss : 0.50619, Training Acc : 0.744, Run Time : 21.01
INFO:root:2019-05-10 22:11:13, Epoch : 1, Step : 4960, Training Loss : 0.51466, Training Acc : 0.761, Run Time : 0.72
INFO:root:2019-05-10 22:11:28, Epoch : 1, Step : 4961, Training Loss : 0.48620, Training Acc : 0.744, Run Time : 14.82
INFO:root:2019-05-10 22:11:31, Epoch : 1, Step : 4962, Training Loss : 0.40062, Training Acc : 0.806, Run Time : 3.31
INFO:root:2019-05-10 22:11:32, Epoch : 1, Step : 4963, Training Loss : 0.62265, Training Acc : 0.728, Run Time : 0.32
INFO:root:2019-05-10 22:11:32, Epoch : 1, Step : 4964, Training Loss : 0.40760, Training Acc : 0.794, Run Time : 0.49
INFO:root:2019-05-10 22:11:33, Epoch : 1, Step : 4965, Training Loss : 0.60774, Training Acc : 0.711, Run Time : 0.46
INFO:root:2019-05-10 22:11:34, Epoch : 1, Step : 4966, Training Loss : 0.49320, Training Acc : 0.794, Run Time : 0.90
INFO:root:2019-05-10 22:11:49, Epoch : 1, Step : 4967, Training Loss : 0.46490, Training Acc : 0.728, Run Time : 15.18
INFO:root:2019-05-10 22:11:49, Epoch : 1, Step : 4968, Training Loss : 0.64937, Training Acc : 0.644, Run Time : 0.22
INFO:root:2019-05-10 22:11:49, Epoch : 1, Step : 4969, Training Loss : 0.48529, Training Acc : 0.761, Run Time : 0.21
INFO:root:2019-05-10 22:11:50, Epoch : 1, Step : 4970, Training Loss : 0.29215, Training Acc : 0.889, Run Time : 0.50
INFO:root:2019-05-10 22:11:51, Epoch : 1, Step : 4971, Training Loss : 0.35127, Training Acc : 0.817, Run Time : 0.97
INFO:root:2019-05-10 22:12:08, Epoch : 1, Step : 4972, Training Loss : 0.62507, Training Acc : 0.683, Run Time : 17.54
INFO:root:2019-05-10 22:12:08, Epoch : 1, Step : 4973, Training Loss : 0.46178, Training Acc : 0.850, Run Time : 0.23
INFO:root:2019-05-10 22:12:09, Epoch : 1, Step : 4974, Training Loss : 0.49275, Training Acc : 0.756, Run Time : 0.25
INFO:root:2019-05-10 22:12:09, Epoch : 1, Step : 4975, Training Loss : 0.38799, Training Acc : 0.806, Run Time : 0.46
INFO:root:2019-05-10 22:12:10, Epoch : 1, Step : 4976, Training Loss : 0.37664, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-10 22:12:35, Epoch : 1, Step : 4977, Training Loss : 0.39906, Training Acc : 0.839, Run Time : 25.05
INFO:root:2019-05-10 22:12:35, Epoch : 1, Step : 4978, Training Loss : 0.51525, Training Acc : 0.789, Run Time : 0.45
INFO:root:2019-05-10 22:12:36, Epoch : 1, Step : 4979, Training Loss : 0.58998, Training Acc : 0.733, Run Time : 0.90
INFO:root:2019-05-10 22:12:48, Epoch : 1, Step : 4980, Training Loss : 0.65970, Training Acc : 0.600, Run Time : 12.46
INFO:root:2019-05-10 22:12:49, Epoch : 1, Step : 4981, Training Loss : 0.55547, Training Acc : 0.672, Run Time : 0.22
INFO:root:2019-05-10 22:12:49, Epoch : 1, Step : 4982, Training Loss : 0.55482, Training Acc : 0.717, Run Time : 0.24
INFO:root:2019-05-10 22:12:49, Epoch : 1, Step : 4983, Training Loss : 0.43700, Training Acc : 0.789, Run Time : 0.20
INFO:root:2019-05-10 22:12:49, Epoch : 1, Step : 4984, Training Loss : 0.53684, Training Acc : 0.744, Run Time : 0.32
INFO:root:2019-05-10 22:12:54, Epoch : 1, Step : 4985, Training Loss : 0.50069, Training Acc : 0.772, Run Time : 4.86
INFO:root:2019-05-10 22:12:56, Epoch : 1, Step : 4986, Training Loss : 0.42371, Training Acc : 0.722, Run Time : 1.40
INFO:root:2019-05-10 22:13:14, Epoch : 1, Step : 4987, Training Loss : 0.42752, Training Acc : 0.817, Run Time : 17.97
INFO:root:2019-05-10 22:13:15, Epoch : 1, Step : 4988, Training Loss : 0.42701, Training Acc : 0.756, Run Time : 1.04
INFO:root:2019-05-10 22:13:15, Epoch : 1, Step : 4989, Training Loss : 0.41917, Training Acc : 0.806, Run Time : 0.58
INFO:root:2019-05-10 22:13:16, Epoch : 1, Step : 4990, Training Loss : 0.63730, Training Acc : 0.672, Run Time : 0.38
INFO:root:2019-05-10 22:13:25, Epoch : 1, Step : 4991, Training Loss : 0.84166, Training Acc : 0.556, Run Time : 9.14
INFO:root:2019-05-10 22:13:25, Epoch : 1, Step : 4992, Training Loss : 0.53212, Training Acc : 0.722, Run Time : 0.58
INFO:root:2019-05-10 22:13:26, Epoch : 1, Step : 4993, Training Loss : 0.59730, Training Acc : 0.700, Run Time : 0.70
INFO:root:2019-05-10 22:13:44, Epoch : 1, Step : 4994, Training Loss : 0.60533, Training Acc : 0.711, Run Time : 18.05
INFO:root:2019-05-10 22:13:44, Epoch : 1, Step : 4995, Training Loss : 0.64363, Training Acc : 0.661, Run Time : 0.22
INFO:root:2019-05-10 22:13:45, Epoch : 1, Step : 4996, Training Loss : 0.63782, Training Acc : 0.733, Run Time : 0.21
INFO:root:2019-05-10 22:13:45, Epoch : 1, Step : 4997, Training Loss : 0.77580, Training Acc : 0.606, Run Time : 0.26
INFO:root:2019-05-10 22:13:45, Epoch : 1, Step : 4998, Training Loss : 0.57773, Training Acc : 0.700, Run Time : 0.36
INFO:root:2019-05-10 22:14:11, Epoch : 1, Step : 4999, Training Loss : 0.65580, Training Acc : 0.600, Run Time : 25.50
INFO:root:2019-05-10 22:14:11, Epoch : 1, Step : 5000, Training Loss : 0.51697, Training Acc : 0.733, Run Time : 0.24
INFO:root:2019-05-10 22:14:12, Epoch : 1, Step : 5001, Training Loss : 0.97659, Training Acc : 0.417, Run Time : 0.84
INFO:root:2019-05-10 22:14:12, Epoch : 1, Step : 5002, Training Loss : 0.61123, Training Acc : 0.650, Run Time : 0.32
INFO:root:2019-05-10 22:14:13, Epoch : 1, Step : 5003, Training Loss : 0.61866, Training Acc : 0.644, Run Time : 0.42
INFO:root:2019-05-10 22:14:28, Epoch : 1, Step : 5004, Training Loss : 0.78576, Training Acc : 0.611, Run Time : 15.54
INFO:root:2019-05-10 22:14:28, Epoch : 1, Step : 5005, Training Loss : 0.72010, Training Acc : 0.633, Run Time : 0.23
INFO:root:2019-05-10 22:14:29, Epoch : 1, Step : 5006, Training Loss : 0.97586, Training Acc : 0.494, Run Time : 0.41
INFO:root:2019-05-10 22:14:29, Epoch : 1, Step : 5007, Training Loss : 0.90071, Training Acc : 0.461, Run Time : 0.45
INFO:root:2019-05-10 22:14:29, Epoch : 1, Step : 5008, Training Loss : 0.64436, Training Acc : 0.650, Run Time : 0.23
INFO:root:2019-05-10 22:14:50, Epoch : 1, Step : 5009, Training Loss : 0.82886, Training Acc : 0.478, Run Time : 20.44
INFO:root:2019-05-10 22:14:50, Epoch : 1, Step : 5010, Training Loss : 0.79175, Training Acc : 0.556, Run Time : 0.55
INFO:root:2019-05-10 22:14:51, Epoch : 1, Step : 5011, Training Loss : 0.69774, Training Acc : 0.583, Run Time : 0.40
INFO:root:2019-05-10 22:14:51, Epoch : 1, Step : 5012, Training Loss : 0.72262, Training Acc : 0.600, Run Time : 0.39
INFO:root:2019-05-10 22:14:52, Epoch : 1, Step : 5013, Training Loss : 0.87253, Training Acc : 0.528, Run Time : 0.52
INFO:root:2019-05-10 22:15:13, Epoch : 1, Step : 5014, Training Loss : 0.66274, Training Acc : 0.678, Run Time : 21.67
INFO:root:2019-05-10 22:15:14, Epoch : 1, Step : 5015, Training Loss : 0.69619, Training Acc : 0.606, Run Time : 0.55
INFO:root:2019-05-10 22:15:14, Epoch : 1, Step : 5016, Training Loss : 0.60858, Training Acc : 0.644, Run Time : 0.51
INFO:root:2019-05-10 22:15:15, Epoch : 1, Step : 5017, Training Loss : 0.65432, Training Acc : 0.611, Run Time : 0.46
INFO:root:2019-05-10 22:15:15, Epoch : 1, Step : 5018, Training Loss : 0.56491, Training Acc : 0.694, Run Time : 0.50
INFO:root:2019-05-10 22:15:33, Epoch : 1, Step : 5019, Training Loss : 0.59320, Training Acc : 0.678, Run Time : 17.81
INFO:root:2019-05-10 22:15:33, Epoch : 1, Step : 5020, Training Loss : 0.52144, Training Acc : 0.800, Run Time : 0.30
INFO:root:2019-05-10 22:15:35, Epoch : 1, Step : 5021, Training Loss : 0.64525, Training Acc : 0.617, Run Time : 1.09
INFO:root:2019-05-10 22:15:35, Epoch : 1, Step : 5022, Training Loss : 0.47594, Training Acc : 0.767, Run Time : 0.43
INFO:root:2019-05-10 22:15:35, Epoch : 1, Step : 5023, Training Loss : 0.63302, Training Acc : 0.717, Run Time : 0.47
INFO:root:2019-05-10 22:16:00, Epoch : 1, Step : 5024, Training Loss : 0.68622, Training Acc : 0.617, Run Time : 24.65
INFO:root:2019-05-10 22:16:01, Epoch : 1, Step : 5025, Training Loss : 0.53371, Training Acc : 0.739, Run Time : 0.96
INFO:root:2019-05-10 22:16:02, Epoch : 1, Step : 5026, Training Loss : 0.54079, Training Acc : 0.711, Run Time : 0.46
INFO:root:2019-05-10 22:16:02, Epoch : 1, Step : 5027, Training Loss : 0.60175, Training Acc : 0.678, Run Time : 0.62
INFO:root:2019-05-10 22:16:03, Epoch : 1, Step : 5028, Training Loss : 0.57459, Training Acc : 0.694, Run Time : 0.44
INFO:root:2019-05-10 22:16:27, Epoch : 1, Step : 5029, Training Loss : 0.49663, Training Acc : 0.772, Run Time : 24.03
INFO:root:2019-05-10 22:16:27, Epoch : 1, Step : 5030, Training Loss : 0.60935, Training Acc : 0.722, Run Time : 0.27
INFO:root:2019-05-10 22:16:27, Epoch : 1, Step : 5031, Training Loss : 0.58628, Training Acc : 0.717, Run Time : 0.46
INFO:root:2019-05-10 22:16:45, Epoch : 1, Step : 5032, Training Loss : 0.60691, Training Acc : 0.656, Run Time : 17.50
INFO:root:2019-05-10 22:16:46, Epoch : 1, Step : 5033, Training Loss : 0.49605, Training Acc : 0.761, Run Time : 0.92
INFO:root:2019-05-10 22:16:46, Epoch : 1, Step : 5034, Training Loss : 0.59979, Training Acc : 0.689, Run Time : 0.44
INFO:root:2019-05-10 22:17:00, Epoch : 1, Step : 5035, Training Loss : 0.43182, Training Acc : 0.817, Run Time : 13.35
INFO:root:2019-05-10 22:17:00, Epoch : 1, Step : 5036, Training Loss : 0.53750, Training Acc : 0.767, Run Time : 0.88
INFO:root:2019-05-10 22:17:01, Epoch : 1, Step : 5037, Training Loss : 0.44372, Training Acc : 0.822, Run Time : 0.53
INFO:root:2019-05-10 22:17:01, Epoch : 1, Step : 5038, Training Loss : 0.37345, Training Acc : 0.872, Run Time : 0.52
INFO:root:2019-05-10 22:17:02, Epoch : 1, Step : 5039, Training Loss : 0.44657, Training Acc : 0.828, Run Time : 0.45
INFO:root:2019-05-10 22:17:21, Epoch : 1, Step : 5040, Training Loss : 0.45011, Training Acc : 0.778, Run Time : 19.29
INFO:root:2019-05-10 22:17:21, Epoch : 1, Step : 5041, Training Loss : 0.53617, Training Acc : 0.772, Run Time : 0.22
INFO:root:2019-05-10 22:17:22, Epoch : 1, Step : 5042, Training Loss : 0.42098, Training Acc : 0.839, Run Time : 0.39
INFO:root:2019-05-10 22:17:22, Epoch : 1, Step : 5043, Training Loss : 0.28448, Training Acc : 0.961, Run Time : 0.46
INFO:root:2019-05-10 22:17:23, Epoch : 1, Step : 5044, Training Loss : 0.47024, Training Acc : 0.778, Run Time : 0.40
INFO:root:2019-05-10 22:17:52, Epoch : 1, Step : 5045, Training Loss : 0.54442, Training Acc : 0.789, Run Time : 29.32
INFO:root:2019-05-10 22:17:53, Epoch : 1, Step : 5046, Training Loss : 0.36566, Training Acc : 0.844, Run Time : 1.24
INFO:root:2019-05-10 22:17:56, Epoch : 1, Step : 5047, Training Loss : 0.34827, Training Acc : 0.883, Run Time : 2.60
INFO:root:2019-05-10 22:17:57, Epoch : 1, Step : 5048, Training Loss : 0.49305, Training Acc : 0.783, Run Time : 0.94
INFO:root:2019-05-10 22:18:01, Epoch : 1, Step : 5049, Training Loss : 0.52378, Training Acc : 0.800, Run Time : 4.61
INFO:root:2019-05-10 22:18:04, Epoch : 1, Step : 5050, Training Loss : 0.39337, Training Acc : 0.839, Run Time : 2.21
INFO:root:2019-05-10 22:18:14, Epoch : 1, Step : 5051, Training Loss : 0.50121, Training Acc : 0.733, Run Time : 10.45
INFO:root:2019-05-10 22:18:15, Epoch : 1, Step : 5052, Training Loss : 0.27462, Training Acc : 0.917, Run Time : 0.59
INFO:root:2019-05-10 22:18:15, Epoch : 1, Step : 5053, Training Loss : 0.43958, Training Acc : 0.778, Run Time : 0.45
INFO:root:2019-05-10 22:18:16, Epoch : 1, Step : 5054, Training Loss : 0.32629, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-10 22:18:16, Epoch : 1, Step : 5055, Training Loss : 0.29068, Training Acc : 0.928, Run Time : 0.51
INFO:root:2019-05-10 22:18:35, Epoch : 1, Step : 5056, Training Loss : 0.25025, Training Acc : 0.917, Run Time : 19.08
INFO:root:2019-05-10 22:18:36, Epoch : 1, Step : 5057, Training Loss : 0.46847, Training Acc : 0.783, Run Time : 1.02
INFO:root:2019-05-10 22:18:51, Epoch : 1, Step : 5058, Training Loss : 0.32409, Training Acc : 0.861, Run Time : 14.83
INFO:root:2019-05-10 22:18:51, Epoch : 1, Step : 5059, Training Loss : 0.40587, Training Acc : 0.822, Run Time : 0.23
INFO:root:2019-05-10 22:18:52, Epoch : 1, Step : 5060, Training Loss : 0.38578, Training Acc : 0.806, Run Time : 0.24
INFO:root:2019-05-10 22:18:52, Epoch : 1, Step : 5061, Training Loss : 0.27756, Training Acc : 0.900, Run Time : 0.39
INFO:root:2019-05-10 22:18:52, Epoch : 1, Step : 5062, Training Loss : 0.31316, Training Acc : 0.906, Run Time : 0.43
INFO:root:2019-05-10 22:19:08, Epoch : 1, Step : 5063, Training Loss : 0.28685, Training Acc : 0.911, Run Time : 15.87
INFO:root:2019-05-10 22:19:09, Epoch : 1, Step : 5064, Training Loss : 0.70498, Training Acc : 0.656, Run Time : 0.85
INFO:root:2019-05-10 22:19:09, Epoch : 1, Step : 5065, Training Loss : 0.40946, Training Acc : 0.811, Run Time : 0.45
INFO:root:2019-05-10 22:19:10, Epoch : 1, Step : 5066, Training Loss : 0.29440, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 22:19:10, Epoch : 1, Step : 5067, Training Loss : 0.33457, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 22:19:29, Epoch : 1, Step : 5068, Training Loss : 0.24994, Training Acc : 0.933, Run Time : 18.89
INFO:root:2019-05-10 22:19:30, Epoch : 1, Step : 5069, Training Loss : 0.28788, Training Acc : 0.861, Run Time : 0.56
INFO:root:2019-05-10 22:19:30, Epoch : 1, Step : 5070, Training Loss : 0.22107, Training Acc : 0.956, Run Time : 0.42
INFO:root:2019-05-10 22:19:31, Epoch : 1, Step : 5071, Training Loss : 0.29382, Training Acc : 0.822, Run Time : 0.46
INFO:root:2019-05-10 22:19:43, Epoch : 1, Step : 5072, Training Loss : 0.26316, Training Acc : 0.922, Run Time : 11.91
INFO:root:2019-05-10 22:19:45, Epoch : 1, Step : 5073, Training Loss : 0.33431, Training Acc : 0.856, Run Time : 2.27
INFO:root:2019-05-10 22:19:45, Epoch : 1, Step : 5074, Training Loss : 0.29390, Training Acc : 0.861, Run Time : 0.50
INFO:root:2019-05-10 22:19:46, Epoch : 1, Step : 5075, Training Loss : 0.27055, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 22:19:54, Epoch : 1, Step : 5076, Training Loss : 0.31193, Training Acc : 0.861, Run Time : 8.04
INFO:root:2019-05-10 22:19:56, Epoch : 1, Step : 5077, Training Loss : 0.68151, Training Acc : 0.667, Run Time : 1.87
INFO:root:2019-05-10 22:19:56, Epoch : 1, Step : 5078, Training Loss : 0.32799, Training Acc : 0.844, Run Time : 0.30
INFO:root:2019-05-10 22:19:57, Epoch : 1, Step : 5079, Training Loss : 0.40626, Training Acc : 0.878, Run Time : 0.57
INFO:root:2019-05-10 22:19:57, Epoch : 1, Step : 5080, Training Loss : 0.33083, Training Acc : 0.822, Run Time : 0.45
INFO:root:2019-05-10 22:20:17, Epoch : 1, Step : 5081, Training Loss : 0.28915, Training Acc : 0.883, Run Time : 20.10
INFO:root:2019-05-10 22:20:17, Epoch : 1, Step : 5082, Training Loss : 0.28649, Training Acc : 0.844, Run Time : 0.24
INFO:root:2019-05-10 22:20:18, Epoch : 1, Step : 5083, Training Loss : 0.47104, Training Acc : 0.806, Run Time : 0.35
INFO:root:2019-05-10 22:20:18, Epoch : 1, Step : 5084, Training Loss : 0.72107, Training Acc : 0.639, Run Time : 0.49
INFO:root:2019-05-10 22:20:19, Epoch : 1, Step : 5085, Training Loss : 0.54341, Training Acc : 0.694, Run Time : 1.06
INFO:root:2019-05-10 22:20:36, Epoch : 1, Step : 5086, Training Loss : 0.34981, Training Acc : 0.833, Run Time : 16.96
INFO:root:2019-05-10 22:20:37, Epoch : 1, Step : 5087, Training Loss : 0.48724, Training Acc : 0.800, Run Time : 1.05
INFO:root:2019-05-10 22:20:40, Epoch : 1, Step : 5088, Training Loss : 0.33368, Training Acc : 0.828, Run Time : 2.43
INFO:root:2019-05-10 22:20:41, Epoch : 1, Step : 5089, Training Loss : 0.41592, Training Acc : 0.800, Run Time : 0.84
INFO:root:2019-05-10 22:20:41, Epoch : 1, Step : 5090, Training Loss : 0.28531, Training Acc : 0.889, Run Time : 0.40
INFO:root:2019-05-10 22:20:44, Epoch : 1, Step : 5091, Training Loss : 0.29374, Training Acc : 0.861, Run Time : 2.64
INFO:root:2019-05-10 22:20:45, Epoch : 1, Step : 5092, Training Loss : 0.22057, Training Acc : 0.917, Run Time : 1.29
INFO:root:2019-05-10 22:21:09, Epoch : 1, Step : 5093, Training Loss : 0.41095, Training Acc : 0.794, Run Time : 24.39
INFO:root:2019-05-10 22:21:10, Epoch : 1, Step : 5094, Training Loss : 0.41329, Training Acc : 0.828, Run Time : 0.63
INFO:root:2019-05-10 22:21:10, Epoch : 1, Step : 5095, Training Loss : 0.29529, Training Acc : 0.922, Run Time : 0.24
INFO:root:2019-05-10 22:21:11, Epoch : 1, Step : 5096, Training Loss : 0.23180, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 22:21:11, Epoch : 1, Step : 5097, Training Loss : 0.35791, Training Acc : 0.828, Run Time : 0.49
INFO:root:2019-05-10 22:21:16, Epoch : 1, Step : 5098, Training Loss : 0.35793, Training Acc : 0.839, Run Time : 5.11
INFO:root:2019-05-10 22:21:24, Epoch : 1, Step : 5099, Training Loss : 0.30015, Training Acc : 0.872, Run Time : 8.14
INFO:root:2019-05-10 22:21:25, Epoch : 1, Step : 5100, Training Loss : 0.36129, Training Acc : 0.856, Run Time : 0.45
INFO:root:2019-05-10 22:21:39, Epoch : 1, Step : 5101, Training Loss : 0.52670, Training Acc : 0.706, Run Time : 14.58
INFO:root:2019-05-10 22:21:40, Epoch : 1, Step : 5102, Training Loss : 0.45262, Training Acc : 0.767, Run Time : 0.35
INFO:root:2019-05-10 22:21:40, Epoch : 1, Step : 5103, Training Loss : 0.45218, Training Acc : 0.733, Run Time : 0.24
INFO:root:2019-05-10 22:21:41, Epoch : 1, Step : 5104, Training Loss : 0.31542, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 22:21:41, Epoch : 1, Step : 5105, Training Loss : 0.36991, Training Acc : 0.850, Run Time : 0.29
INFO:root:2019-05-10 22:22:07, Epoch : 1, Step : 5106, Training Loss : 0.43951, Training Acc : 0.833, Run Time : 26.17
INFO:root:2019-05-10 22:22:07, Epoch : 1, Step : 5107, Training Loss : 0.45678, Training Acc : 0.739, Run Time : 0.32
INFO:root:2019-05-10 22:22:08, Epoch : 1, Step : 5108, Training Loss : 0.49927, Training Acc : 0.789, Run Time : 1.05
INFO:root:2019-05-10 22:22:09, Epoch : 1, Step : 5109, Training Loss : 0.45320, Training Acc : 0.772, Run Time : 0.47
INFO:root:2019-05-10 22:22:09, Epoch : 1, Step : 5110, Training Loss : 0.40153, Training Acc : 0.806, Run Time : 0.47
INFO:root:2019-05-10 22:22:35, Epoch : 1, Step : 5111, Training Loss : 0.43836, Training Acc : 0.794, Run Time : 26.09
INFO:root:2019-05-10 22:22:36, Epoch : 1, Step : 5112, Training Loss : 0.41441, Training Acc : 0.783, Run Time : 0.30
INFO:root:2019-05-10 22:22:36, Epoch : 1, Step : 5113, Training Loss : 0.33725, Training Acc : 0.839, Run Time : 0.29
INFO:root:2019-05-10 22:22:38, Epoch : 1, Step : 5114, Training Loss : 0.56355, Training Acc : 0.783, Run Time : 2.25
INFO:root:2019-05-10 22:22:50, Epoch : 1, Step : 5115, Training Loss : 0.53749, Training Acc : 0.694, Run Time : 11.47
INFO:root:2019-05-10 22:22:50, Epoch : 1, Step : 5116, Training Loss : 0.49652, Training Acc : 0.739, Run Time : 0.25
INFO:root:2019-05-10 22:22:50, Epoch : 1, Step : 5117, Training Loss : 0.51952, Training Acc : 0.694, Run Time : 0.44
INFO:root:2019-05-10 22:22:51, Epoch : 1, Step : 5118, Training Loss : 0.47508, Training Acc : 0.750, Run Time : 0.55
INFO:root:2019-05-10 22:22:52, Epoch : 1, Step : 5119, Training Loss : 0.25545, Training Acc : 0.922, Run Time : 0.61
INFO:root:2019-05-10 22:23:09, Epoch : 1, Step : 5120, Training Loss : 0.59304, Training Acc : 0.717, Run Time : 17.86
INFO:root:2019-05-10 22:23:10, Epoch : 1, Step : 5121, Training Loss : 0.49278, Training Acc : 0.756, Run Time : 0.25
INFO:root:2019-05-10 22:23:10, Epoch : 1, Step : 5122, Training Loss : 0.29651, Training Acc : 0.872, Run Time : 0.24
INFO:root:2019-05-10 22:23:10, Epoch : 1, Step : 5123, Training Loss : 0.59623, Training Acc : 0.711, Run Time : 0.21
INFO:root:2019-05-10 22:23:11, Epoch : 1, Step : 5124, Training Loss : 0.50779, Training Acc : 0.756, Run Time : 0.49
INFO:root:2019-05-10 22:23:31, Epoch : 1, Step : 5125, Training Loss : 0.29738, Training Acc : 0.872, Run Time : 20.86
INFO:root:2019-05-10 22:23:32, Epoch : 1, Step : 5126, Training Loss : 0.65721, Training Acc : 0.689, Run Time : 0.60
INFO:root:2019-05-10 22:23:32, Epoch : 1, Step : 5127, Training Loss : 0.40859, Training Acc : 0.833, Run Time : 0.26
INFO:root:2019-05-10 22:23:33, Epoch : 1, Step : 5128, Training Loss : 0.97663, Training Acc : 0.533, Run Time : 0.47
INFO:root:2019-05-10 22:23:33, Epoch : 1, Step : 5129, Training Loss : 0.62746, Training Acc : 0.694, Run Time : 0.45
INFO:root:2019-05-10 22:23:54, Epoch : 1, Step : 5130, Training Loss : 0.72700, Training Acc : 0.711, Run Time : 20.71
INFO:root:2019-05-10 22:23:54, Epoch : 1, Step : 5131, Training Loss : 0.93448, Training Acc : 0.539, Run Time : 0.25
INFO:root:2019-05-10 22:23:55, Epoch : 1, Step : 5132, Training Loss : 0.52967, Training Acc : 0.783, Run Time : 0.52
INFO:root:2019-05-10 22:23:55, Epoch : 1, Step : 5133, Training Loss : 0.55717, Training Acc : 0.744, Run Time : 0.49
INFO:root:2019-05-10 22:23:56, Epoch : 1, Step : 5134, Training Loss : 0.42244, Training Acc : 0.839, Run Time : 0.44
INFO:root:2019-05-10 22:24:12, Epoch : 1, Step : 5135, Training Loss : 0.71851, Training Acc : 0.656, Run Time : 16.58
INFO:root:2019-05-10 22:24:13, Epoch : 1, Step : 5136, Training Loss : 0.46097, Training Acc : 0.822, Run Time : 0.26
INFO:root:2019-05-10 22:24:13, Epoch : 1, Step : 5137, Training Loss : 0.35326, Training Acc : 0.872, Run Time : 0.43
INFO:root:2019-05-10 22:24:13, Epoch : 1, Step : 5138, Training Loss : 0.28789, Training Acc : 0.911, Run Time : 0.44
INFO:root:2019-05-10 22:24:14, Epoch : 1, Step : 5139, Training Loss : 0.31550, Training Acc : 0.878, Run Time : 0.71
INFO:root:2019-05-10 22:24:30, Epoch : 1, Step : 5140, Training Loss : 0.57875, Training Acc : 0.694, Run Time : 16.26
INFO:root:2019-05-10 22:24:31, Epoch : 1, Step : 5141, Training Loss : 0.36835, Training Acc : 0.828, Run Time : 0.31
INFO:root:2019-05-10 22:24:31, Epoch : 1, Step : 5142, Training Loss : 0.47216, Training Acc : 0.772, Run Time : 0.44
INFO:root:2019-05-10 22:24:32, Epoch : 1, Step : 5143, Training Loss : 0.39348, Training Acc : 0.794, Run Time : 0.47
INFO:root:2019-05-10 22:24:32, Epoch : 1, Step : 5144, Training Loss : 0.64640, Training Acc : 0.633, Run Time : 0.42
INFO:root:2019-05-10 22:24:48, Epoch : 1, Step : 5145, Training Loss : 0.35198, Training Acc : 0.867, Run Time : 15.94
INFO:root:2019-05-10 22:24:48, Epoch : 1, Step : 5146, Training Loss : 0.35625, Training Acc : 0.839, Run Time : 0.31
INFO:root:2019-05-10 22:24:49, Epoch : 1, Step : 5147, Training Loss : 0.32592, Training Acc : 0.872, Run Time : 0.31
INFO:root:2019-05-10 22:24:49, Epoch : 1, Step : 5148, Training Loss : 0.30581, Training Acc : 0.889, Run Time : 0.21
INFO:root:2019-05-10 22:24:49, Epoch : 1, Step : 5149, Training Loss : 0.42200, Training Acc : 0.817, Run Time : 0.21
INFO:root:2019-05-10 22:25:00, Epoch : 1, Step : 5150, Training Loss : 0.30961, Training Acc : 0.883, Run Time : 11.01
INFO:root:2019-05-10 22:25:09, Epoch : 1, Step : 5151, Training Loss : 0.28766, Training Acc : 0.878, Run Time : 9.06
INFO:root:2019-05-10 22:25:09, Epoch : 1, Step : 5152, Training Loss : 0.41681, Training Acc : 0.783, Run Time : 0.35
INFO:root:2019-05-10 22:25:10, Epoch : 1, Step : 5153, Training Loss : 0.34503, Training Acc : 0.844, Run Time : 0.42
INFO:root:2019-05-10 22:25:10, Epoch : 1, Step : 5154, Training Loss : 0.41934, Training Acc : 0.828, Run Time : 0.47
INFO:root:2019-05-10 22:25:11, Epoch : 1, Step : 5155, Training Loss : 0.27246, Training Acc : 0.900, Run Time : 0.48
INFO:root:2019-05-10 22:25:26, Epoch : 1, Step : 5156, Training Loss : 0.45561, Training Acc : 0.761, Run Time : 15.22
INFO:root:2019-05-10 22:25:26, Epoch : 1, Step : 5157, Training Loss : 0.42707, Training Acc : 0.761, Run Time : 0.31
INFO:root:2019-05-10 22:25:27, Epoch : 1, Step : 5158, Training Loss : 0.43976, Training Acc : 0.756, Run Time : 0.90
INFO:root:2019-05-10 22:25:28, Epoch : 1, Step : 5159, Training Loss : 0.72499, Training Acc : 0.661, Run Time : 1.00
INFO:root:2019-05-10 22:25:36, Epoch : 1, Step : 5160, Training Loss : 0.61725, Training Acc : 0.694, Run Time : 7.50
INFO:root:2019-05-10 22:25:36, Epoch : 1, Step : 5161, Training Loss : 0.48100, Training Acc : 0.750, Run Time : 0.52
INFO:root:2019-05-10 22:25:49, Epoch : 1, Step : 5162, Training Loss : 0.40244, Training Acc : 0.817, Run Time : 12.52
INFO:root:2019-05-10 22:25:49, Epoch : 1, Step : 5163, Training Loss : 0.53648, Training Acc : 0.739, Run Time : 0.70
INFO:root:2019-05-10 22:25:50, Epoch : 1, Step : 5164, Training Loss : 0.40759, Training Acc : 0.806, Run Time : 0.25
INFO:root:2019-05-10 22:25:50, Epoch : 1, Step : 5165, Training Loss : 0.32395, Training Acc : 0.844, Run Time : 0.75
INFO:root:2019-05-10 22:25:51, Epoch : 1, Step : 5166, Training Loss : 0.24890, Training Acc : 0.922, Run Time : 0.24
INFO:root:2019-05-10 22:26:19, Epoch : 1, Step : 5167, Training Loss : 0.30189, Training Acc : 0.867, Run Time : 28.63
INFO:root:2019-05-10 22:26:20, Epoch : 1, Step : 5168, Training Loss : 0.42548, Training Acc : 0.778, Run Time : 0.33
INFO:root:2019-05-10 22:26:20, Epoch : 1, Step : 5169, Training Loss : 0.42936, Training Acc : 0.811, Run Time : 0.23
INFO:root:2019-05-10 22:26:20, Epoch : 1, Step : 5170, Training Loss : 0.41727, Training Acc : 0.811, Run Time : 0.47
INFO:root:2019-05-10 22:26:30, Epoch : 1, Step : 5171, Training Loss : 0.44974, Training Acc : 0.822, Run Time : 9.79
INFO:root:2019-05-10 22:26:31, Epoch : 1, Step : 5172, Training Loss : 0.29469, Training Acc : 0.883, Run Time : 0.72
INFO:root:2019-05-10 22:26:31, Epoch : 1, Step : 5173, Training Loss : 0.29319, Training Acc : 0.889, Run Time : 0.59
INFO:root:2019-05-10 22:26:32, Epoch : 1, Step : 5174, Training Loss : 0.40114, Training Acc : 0.811, Run Time : 0.45
INFO:root:2019-05-10 22:26:35, Epoch : 1, Step : 5175, Training Loss : 0.28268, Training Acc : 0.900, Run Time : 2.62
INFO:root:2019-05-10 22:26:46, Epoch : 1, Step : 5176, Training Loss : 0.40293, Training Acc : 0.867, Run Time : 11.35
INFO:root:2019-05-10 22:26:46, Epoch : 1, Step : 5177, Training Loss : 0.38950, Training Acc : 0.817, Run Time : 0.32
INFO:root:2019-05-10 22:26:48, Epoch : 1, Step : 5178, Training Loss : 0.55214, Training Acc : 0.756, Run Time : 1.84
INFO:root:2019-05-10 22:26:55, Epoch : 1, Step : 5179, Training Loss : 0.37260, Training Acc : 0.839, Run Time : 7.13
INFO:root:2019-05-10 22:26:55, Epoch : 1, Step : 5180, Training Loss : 0.23939, Training Acc : 0.933, Run Time : 0.28
INFO:root:2019-05-10 22:26:56, Epoch : 1, Step : 5181, Training Loss : 0.43751, Training Acc : 0.794, Run Time : 0.57
INFO:root:2019-05-10 22:27:14, Epoch : 1, Step : 5182, Training Loss : 0.30740, Training Acc : 0.889, Run Time : 17.98
INFO:root:2019-05-10 22:27:18, Epoch : 1, Step : 5183, Training Loss : 0.44200, Training Acc : 0.778, Run Time : 4.15
INFO:root:2019-05-10 22:27:18, Epoch : 1, Step : 5184, Training Loss : 0.37297, Training Acc : 0.844, Run Time : 0.31
INFO:root:2019-05-10 22:27:23, Epoch : 1, Step : 5185, Training Loss : 0.35621, Training Acc : 0.850, Run Time : 4.70
INFO:root:2019-05-10 22:27:34, Epoch : 1, Step : 5186, Training Loss : 0.30429, Training Acc : 0.861, Run Time : 10.58
INFO:root:2019-05-10 22:27:47, Epoch : 1, Step : 5187, Training Loss : 0.35233, Training Acc : 0.839, Run Time : 13.40
INFO:root:2019-05-10 22:27:48, Epoch : 1, Step : 5188, Training Loss : 0.31899, Training Acc : 0.856, Run Time : 1.19
INFO:root:2019-05-10 22:27:49, Epoch : 1, Step : 5189, Training Loss : 0.27616, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-10 22:27:50, Epoch : 1, Step : 5190, Training Loss : 0.34491, Training Acc : 0.844, Run Time : 1.21
INFO:root:2019-05-10 22:27:51, Epoch : 1, Step : 5191, Training Loss : 0.39918, Training Acc : 0.806, Run Time : 0.96
INFO:root:2019-05-10 22:28:09, Epoch : 1, Step : 5192, Training Loss : 0.40488, Training Acc : 0.833, Run Time : 18.04
INFO:root:2019-05-10 22:28:11, Epoch : 1, Step : 5193, Training Loss : 0.35508, Training Acc : 0.833, Run Time : 1.75
INFO:root:2019-05-10 22:28:19, Epoch : 1, Step : 5194, Training Loss : 0.33203, Training Acc : 0.856, Run Time : 8.49
INFO:root:2019-05-10 22:28:19, Epoch : 1, Step : 5195, Training Loss : 0.33298, Training Acc : 0.839, Run Time : 0.25
INFO:root:2019-05-10 22:28:20, Epoch : 1, Step : 5196, Training Loss : 0.28710, Training Acc : 0.889, Run Time : 0.21
INFO:root:2019-05-10 22:28:28, Epoch : 1, Step : 5197, Training Loss : 0.33989, Training Acc : 0.856, Run Time : 8.71
INFO:root:2019-05-10 22:28:32, Epoch : 1, Step : 5198, Training Loss : 0.33988, Training Acc : 0.844, Run Time : 3.45
INFO:root:2019-05-10 22:28:33, Epoch : 1, Step : 5199, Training Loss : 0.50308, Training Acc : 0.789, Run Time : 0.71
INFO:root:2019-05-10 22:28:33, Epoch : 1, Step : 5200, Training Loss : 0.52308, Training Acc : 0.772, Run Time : 0.61
INFO:root:2019-05-10 22:28:35, Epoch : 1, Step : 5201, Training Loss : 0.94851, Training Acc : 0.622, Run Time : 1.38
INFO:root:2019-05-10 22:28:35, Epoch : 1, Step : 5202, Training Loss : 0.90942, Training Acc : 0.622, Run Time : 0.42
INFO:root:2019-05-10 22:28:50, Epoch : 1, Step : 5203, Training Loss : 0.87278, Training Acc : 0.661, Run Time : 14.58
INFO:root:2019-05-10 22:28:50, Epoch : 1, Step : 5204, Training Loss : 0.86102, Training Acc : 0.650, Run Time : 0.30
INFO:root:2019-05-10 22:28:50, Epoch : 1, Step : 5205, Training Loss : 0.72624, Training Acc : 0.639, Run Time : 0.49
INFO:root:2019-05-10 22:28:51, Epoch : 1, Step : 5206, Training Loss : 0.48900, Training Acc : 0.733, Run Time : 0.46
INFO:root:2019-05-10 22:28:51, Epoch : 1, Step : 5207, Training Loss : 0.66122, Training Acc : 0.644, Run Time : 0.51
INFO:root:2019-05-10 22:29:09, Epoch : 1, Step : 5208, Training Loss : 0.44327, Training Acc : 0.778, Run Time : 17.23
INFO:root:2019-05-10 22:29:09, Epoch : 1, Step : 5209, Training Loss : 0.43534, Training Acc : 0.767, Run Time : 0.22
INFO:root:2019-05-10 22:29:09, Epoch : 1, Step : 5210, Training Loss : 0.72489, Training Acc : 0.628, Run Time : 0.31
INFO:root:2019-05-10 22:29:10, Epoch : 1, Step : 5211, Training Loss : 0.75185, Training Acc : 0.650, Run Time : 0.49
INFO:root:2019-05-10 22:29:21, Epoch : 1, Step : 5212, Training Loss : 0.56340, Training Acc : 0.689, Run Time : 11.95
INFO:root:2019-05-10 22:29:22, Epoch : 1, Step : 5213, Training Loss : 0.50594, Training Acc : 0.750, Run Time : 0.84
INFO:root:2019-05-10 22:29:23, Epoch : 1, Step : 5214, Training Loss : 0.58729, Training Acc : 0.744, Run Time : 0.44
INFO:root:2019-05-10 22:29:23, Epoch : 1, Step : 5215, Training Loss : 0.66324, Training Acc : 0.661, Run Time : 0.47
INFO:root:2019-05-10 22:29:24, Epoch : 1, Step : 5216, Training Loss : 0.49738, Training Acc : 0.744, Run Time : 0.47
INFO:root:2019-05-10 22:29:41, Epoch : 1, Step : 5217, Training Loss : 0.51676, Training Acc : 0.711, Run Time : 17.10
INFO:root:2019-05-10 22:29:41, Epoch : 1, Step : 5218, Training Loss : 0.44215, Training Acc : 0.778, Run Time : 0.32
INFO:root:2019-05-10 22:29:42, Epoch : 1, Step : 5219, Training Loss : 0.52532, Training Acc : 0.767, Run Time : 0.49
INFO:root:2019-05-10 22:29:42, Epoch : 1, Step : 5220, Training Loss : 0.47780, Training Acc : 0.817, Run Time : 0.45
INFO:root:2019-05-10 22:29:43, Epoch : 1, Step : 5221, Training Loss : 0.48867, Training Acc : 0.756, Run Time : 0.84
INFO:root:2019-05-10 22:30:13, Epoch : 1, Step : 5222, Training Loss : 0.50964, Training Acc : 0.767, Run Time : 30.48
INFO:root:2019-05-10 22:30:15, Epoch : 1, Step : 5223, Training Loss : 0.44882, Training Acc : 0.817, Run Time : 1.77
INFO:root:2019-05-10 22:30:16, Epoch : 1, Step : 5224, Training Loss : 0.50027, Training Acc : 0.789, Run Time : 0.47
INFO:root:2019-05-10 22:30:16, Epoch : 1, Step : 5225, Training Loss : 0.55701, Training Acc : 0.711, Run Time : 0.46
INFO:root:2019-05-10 22:30:34, Epoch : 1, Step : 5226, Training Loss : 0.55392, Training Acc : 0.706, Run Time : 18.34
INFO:root:2019-05-10 22:30:35, Epoch : 1, Step : 5227, Training Loss : 0.49445, Training Acc : 0.756, Run Time : 0.47
INFO:root:2019-05-10 22:30:35, Epoch : 1, Step : 5228, Training Loss : 0.52091, Training Acc : 0.728, Run Time : 0.23
INFO:root:2019-05-10 22:30:35, Epoch : 1, Step : 5229, Training Loss : 0.66202, Training Acc : 0.622, Run Time : 0.32
INFO:root:2019-05-10 22:30:36, Epoch : 1, Step : 5230, Training Loss : 0.63801, Training Acc : 0.667, Run Time : 0.83
INFO:root:2019-05-10 22:31:00, Epoch : 1, Step : 5231, Training Loss : 0.65146, Training Acc : 0.694, Run Time : 24.11
INFO:root:2019-05-10 22:31:01, Epoch : 1, Step : 5232, Training Loss : 0.55556, Training Acc : 0.767, Run Time : 0.32
INFO:root:2019-05-10 22:31:01, Epoch : 1, Step : 5233, Training Loss : 0.64208, Training Acc : 0.739, Run Time : 0.52
INFO:root:2019-05-10 22:31:02, Epoch : 1, Step : 5234, Training Loss : 0.42820, Training Acc : 0.828, Run Time : 0.35
INFO:root:2019-05-10 22:31:02, Epoch : 1, Step : 5235, Training Loss : 0.45122, Training Acc : 0.772, Run Time : 0.51
INFO:root:2019-05-10 22:31:22, Epoch : 1, Step : 5236, Training Loss : 0.47403, Training Acc : 0.761, Run Time : 19.82
INFO:root:2019-05-10 22:31:22, Epoch : 1, Step : 5237, Training Loss : 0.46573, Training Acc : 0.778, Run Time : 0.24
INFO:root:2019-05-10 22:31:22, Epoch : 1, Step : 5238, Training Loss : 0.40626, Training Acc : 0.806, Run Time : 0.31
INFO:root:2019-05-10 22:31:23, Epoch : 1, Step : 5239, Training Loss : 0.42274, Training Acc : 0.767, Run Time : 0.55
INFO:root:2019-05-10 22:31:24, Epoch : 1, Step : 5240, Training Loss : 0.42055, Training Acc : 0.800, Run Time : 0.49
INFO:root:2019-05-10 22:31:45, Epoch : 1, Step : 5241, Training Loss : 0.39486, Training Acc : 0.811, Run Time : 21.57
INFO:root:2019-05-10 22:31:45, Epoch : 1, Step : 5242, Training Loss : 0.38246, Training Acc : 0.828, Run Time : 0.31
INFO:root:2019-05-10 22:31:46, Epoch : 1, Step : 5243, Training Loss : 0.30431, Training Acc : 0.872, Run Time : 0.50
INFO:root:2019-05-10 22:31:46, Epoch : 1, Step : 5244, Training Loss : 0.32421, Training Acc : 0.817, Run Time : 0.46
INFO:root:2019-05-10 22:32:01, Epoch : 1, Step : 5245, Training Loss : 0.30841, Training Acc : 0.856, Run Time : 14.28
INFO:root:2019-05-10 22:32:01, Epoch : 1, Step : 5246, Training Loss : 0.24636, Training Acc : 0.894, Run Time : 0.22
INFO:root:2019-05-10 22:32:01, Epoch : 1, Step : 5247, Training Loss : 0.21802, Training Acc : 0.922, Run Time : 0.22
INFO:root:2019-05-10 22:32:01, Epoch : 1, Step : 5248, Training Loss : 0.25054, Training Acc : 0.906, Run Time : 0.29
INFO:root:2019-05-10 22:32:11, Epoch : 1, Step : 5249, Training Loss : 0.53508, Training Acc : 0.817, Run Time : 9.75
INFO:root:2019-05-10 22:32:14, Epoch : 1, Step : 5250, Training Loss : 0.57097, Training Acc : 0.722, Run Time : 3.28
INFO:root:2019-05-10 22:32:15, Epoch : 1, Step : 5251, Training Loss : 0.67685, Training Acc : 0.611, Run Time : 0.34
INFO:root:2019-05-10 22:32:15, Epoch : 1, Step : 5252, Training Loss : 0.56916, Training Acc : 0.728, Run Time : 0.41
INFO:root:2019-05-10 22:32:16, Epoch : 1, Step : 5253, Training Loss : 0.91266, Training Acc : 0.617, Run Time : 0.94
INFO:root:2019-05-10 22:32:32, Epoch : 1, Step : 5254, Training Loss : 0.43171, Training Acc : 0.806, Run Time : 16.04
INFO:root:2019-05-10 22:32:33, Epoch : 1, Step : 5255, Training Loss : 0.36621, Training Acc : 0.822, Run Time : 0.78
INFO:root:2019-05-10 22:32:33, Epoch : 1, Step : 5256, Training Loss : 0.31112, Training Acc : 0.839, Run Time : 0.41
INFO:root:2019-05-10 22:32:34, Epoch : 1, Step : 5257, Training Loss : 0.31320, Training Acc : 0.844, Run Time : 0.58
INFO:root:2019-05-10 22:32:34, Epoch : 1, Step : 5258, Training Loss : 0.30520, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-10 22:32:56, Epoch : 1, Step : 5259, Training Loss : 0.35102, Training Acc : 0.861, Run Time : 21.64
INFO:root:2019-05-10 22:32:56, Epoch : 1, Step : 5260, Training Loss : 0.31977, Training Acc : 0.839, Run Time : 0.30
INFO:root:2019-05-10 22:32:57, Epoch : 1, Step : 5261, Training Loss : 0.36716, Training Acc : 0.833, Run Time : 0.69
INFO:root:2019-05-10 22:32:58, Epoch : 1, Step : 5262, Training Loss : 0.30287, Training Acc : 0.878, Run Time : 1.37
INFO:root:2019-05-10 22:32:59, Epoch : 1, Step : 5263, Training Loss : 0.31863, Training Acc : 0.878, Run Time : 0.52
INFO:root:2019-05-10 22:33:14, Epoch : 1, Step : 5264, Training Loss : 0.30134, Training Acc : 0.867, Run Time : 15.21
INFO:root:2019-05-10 22:33:15, Epoch : 1, Step : 5265, Training Loss : 0.30635, Training Acc : 0.867, Run Time : 0.84
INFO:root:2019-05-10 22:33:15, Epoch : 1, Step : 5266, Training Loss : 0.23579, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 22:33:16, Epoch : 1, Step : 5267, Training Loss : 0.35225, Training Acc : 0.850, Run Time : 0.48
INFO:root:2019-05-10 22:33:31, Epoch : 1, Step : 5268, Training Loss : 0.22976, Training Acc : 0.917, Run Time : 14.67
INFO:root:2019-05-10 22:33:31, Epoch : 1, Step : 5269, Training Loss : 0.30506, Training Acc : 0.900, Run Time : 0.21
INFO:root:2019-05-10 22:33:31, Epoch : 1, Step : 5270, Training Loss : 0.32006, Training Acc : 0.828, Run Time : 0.21
INFO:root:2019-05-10 22:33:31, Epoch : 1, Step : 5271, Training Loss : 0.31566, Training Acc : 0.900, Run Time : 0.50
INFO:root:2019-05-10 22:33:32, Epoch : 1, Step : 5272, Training Loss : 0.29938, Training Acc : 0.883, Run Time : 0.43
INFO:root:2019-05-10 22:33:50, Epoch : 1, Step : 5273, Training Loss : 0.28189, Training Acc : 0.883, Run Time : 17.89
INFO:root:2019-05-10 22:33:50, Epoch : 1, Step : 5274, Training Loss : 0.35247, Training Acc : 0.839, Run Time : 0.21
INFO:root:2019-05-10 22:33:50, Epoch : 1, Step : 5275, Training Loss : 0.28905, Training Acc : 0.867, Run Time : 0.23
INFO:root:2019-05-10 22:33:51, Epoch : 1, Step : 5276, Training Loss : 0.29494, Training Acc : 0.872, Run Time : 0.82
INFO:root:2019-05-10 22:33:54, Epoch : 1, Step : 5277, Training Loss : 0.30767, Training Acc : 0.878, Run Time : 2.92
INFO:root:2019-05-10 22:33:56, Epoch : 1, Step : 5278, Training Loss : 0.19642, Training Acc : 0.922, Run Time : 1.89
INFO:root:2019-05-10 22:34:16, Epoch : 1, Step : 5279, Training Loss : 0.20630, Training Acc : 0.928, Run Time : 20.34
INFO:root:2019-05-10 22:34:17, Epoch : 1, Step : 5280, Training Loss : 0.20366, Training Acc : 0.939, Run Time : 1.28
INFO:root:2019-05-10 22:34:18, Epoch : 1, Step : 5281, Training Loss : 0.22892, Training Acc : 0.928, Run Time : 0.31
INFO:root:2019-05-10 22:34:18, Epoch : 1, Step : 5282, Training Loss : 0.22331, Training Acc : 0.928, Run Time : 0.40
INFO:root:2019-05-10 22:34:19, Epoch : 1, Step : 5283, Training Loss : 0.28755, Training Acc : 0.894, Run Time : 0.50
INFO:root:2019-05-10 22:34:24, Epoch : 1, Step : 5284, Training Loss : 0.25087, Training Acc : 0.939, Run Time : 4.94
INFO:root:2019-05-10 22:34:25, Epoch : 1, Step : 5285, Training Loss : 0.31317, Training Acc : 0.850, Run Time : 1.42
INFO:root:2019-05-10 22:34:39, Epoch : 1, Step : 5286, Training Loss : 0.22500, Training Acc : 0.917, Run Time : 13.97
INFO:root:2019-05-10 22:34:39, Epoch : 1, Step : 5287, Training Loss : 0.16681, Training Acc : 0.961, Run Time : 0.27
INFO:root:2019-05-10 22:34:40, Epoch : 1, Step : 5288, Training Loss : 0.15648, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-10 22:34:40, Epoch : 1, Step : 5289, Training Loss : 0.17731, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-10 22:34:52, Epoch : 1, Step : 5290, Training Loss : 0.18061, Training Acc : 0.956, Run Time : 12.00
INFO:root:2019-05-10 22:34:53, Epoch : 1, Step : 5291, Training Loss : 0.15159, Training Acc : 0.961, Run Time : 0.62
INFO:root:2019-05-10 22:34:53, Epoch : 1, Step : 5292, Training Loss : 0.17183, Training Acc : 0.950, Run Time : 0.23
INFO:root:2019-05-10 22:34:54, Epoch : 1, Step : 5293, Training Loss : 0.12596, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-10 22:34:54, Epoch : 1, Step : 5294, Training Loss : 0.19777, Training Acc : 0.922, Run Time : 0.51
INFO:root:2019-05-10 22:35:12, Epoch : 1, Step : 5295, Training Loss : 0.24506, Training Acc : 0.906, Run Time : 18.25
INFO:root:2019-05-10 22:35:13, Epoch : 1, Step : 5296, Training Loss : 0.31425, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-10 22:35:13, Epoch : 1, Step : 5297, Training Loss : 0.18175, Training Acc : 0.928, Run Time : 0.44
INFO:root:2019-05-10 22:35:24, Epoch : 1, Step : 5298, Training Loss : 0.32519, Training Acc : 0.856, Run Time : 11.09
INFO:root:2019-05-10 22:35:25, Epoch : 1, Step : 5299, Training Loss : 0.23501, Training Acc : 0.933, Run Time : 0.61
INFO:root:2019-05-10 22:35:25, Epoch : 1, Step : 5300, Training Loss : 0.26350, Training Acc : 0.906, Run Time : 0.23
INFO:root:2019-05-10 22:35:26, Epoch : 1, Step : 5301, Training Loss : 0.27457, Training Acc : 0.889, Run Time : 0.77
INFO:root:2019-05-10 22:35:26, Epoch : 1, Step : 5302, Training Loss : 0.35055, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 22:35:44, Epoch : 1, Step : 5303, Training Loss : 0.21601, Training Acc : 0.922, Run Time : 17.98
INFO:root:2019-05-10 22:35:45, Epoch : 1, Step : 5304, Training Loss : 0.26800, Training Acc : 0.867, Run Time : 0.27
INFO:root:2019-05-10 22:35:45, Epoch : 1, Step : 5305, Training Loss : 0.30097, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-10 22:35:46, Epoch : 1, Step : 5306, Training Loss : 0.24842, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 22:35:46, Epoch : 1, Step : 5307, Training Loss : 0.28358, Training Acc : 0.900, Run Time : 0.68
INFO:root:2019-05-10 22:36:03, Epoch : 1, Step : 5308, Training Loss : 0.29042, Training Acc : 0.861, Run Time : 16.61
INFO:root:2019-05-10 22:36:03, Epoch : 1, Step : 5309, Training Loss : 0.27182, Training Acc : 0.872, Run Time : 0.29
INFO:root:2019-05-10 22:36:03, Epoch : 1, Step : 5310, Training Loss : 0.22399, Training Acc : 0.883, Run Time : 0.37
INFO:root:2019-05-10 22:36:04, Epoch : 1, Step : 5311, Training Loss : 0.22449, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-10 22:36:04, Epoch : 1, Step : 5312, Training Loss : 0.25013, Training Acc : 0.889, Run Time : 0.44
INFO:root:2019-05-10 22:36:22, Epoch : 1, Step : 5313, Training Loss : 0.22045, Training Acc : 0.917, Run Time : 17.52
INFO:root:2019-05-10 22:36:22, Epoch : 1, Step : 5314, Training Loss : 0.22524, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-10 22:36:22, Epoch : 1, Step : 5315, Training Loss : 0.20783, Training Acc : 0.900, Run Time : 0.23
INFO:root:2019-05-10 22:36:23, Epoch : 1, Step : 5316, Training Loss : 0.18522, Training Acc : 0.928, Run Time : 0.34
INFO:root:2019-05-10 22:36:24, Epoch : 1, Step : 5317, Training Loss : 0.20628, Training Acc : 0.911, Run Time : 1.66
INFO:root:2019-05-10 22:36:41, Epoch : 1, Step : 5318, Training Loss : 0.28662, Training Acc : 0.867, Run Time : 16.29
INFO:root:2019-05-10 22:36:41, Epoch : 1, Step : 5319, Training Loss : 0.24952, Training Acc : 0.889, Run Time : 0.25
INFO:root:2019-05-10 22:36:42, Epoch : 1, Step : 5320, Training Loss : 0.25446, Training Acc : 0.867, Run Time : 0.50
INFO:root:2019-05-10 22:36:42, Epoch : 1, Step : 5321, Training Loss : 0.24905, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 22:36:46, Epoch : 1, Step : 5322, Training Loss : 0.30090, Training Acc : 0.856, Run Time : 4.34
INFO:root:2019-05-10 22:36:55, Epoch : 1, Step : 5323, Training Loss : 0.27135, Training Acc : 0.861, Run Time : 9.14
INFO:root:2019-05-10 22:36:56, Epoch : 1, Step : 5324, Training Loss : 0.27775, Training Acc : 0.861, Run Time : 0.72
INFO:root:2019-05-10 22:37:10, Epoch : 1, Step : 5325, Training Loss : 0.32718, Training Acc : 0.844, Run Time : 13.34
INFO:root:2019-05-10 22:37:10, Epoch : 1, Step : 5326, Training Loss : 0.27521, Training Acc : 0.867, Run Time : 0.94
INFO:root:2019-05-10 22:37:11, Epoch : 1, Step : 5327, Training Loss : 0.24472, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-10 22:37:11, Epoch : 1, Step : 5328, Training Loss : 0.29128, Training Acc : 0.844, Run Time : 0.48
INFO:root:2019-05-10 22:37:12, Epoch : 1, Step : 5329, Training Loss : 0.29014, Training Acc : 0.867, Run Time : 0.71
INFO:root:2019-05-10 22:37:28, Epoch : 1, Step : 5330, Training Loss : 0.27327, Training Acc : 0.872, Run Time : 15.69
INFO:root:2019-05-10 22:37:29, Epoch : 1, Step : 5331, Training Loss : 0.25059, Training Acc : 0.889, Run Time : 0.73
INFO:root:2019-05-10 22:37:29, Epoch : 1, Step : 5332, Training Loss : 0.22740, Training Acc : 0.900, Run Time : 0.56
INFO:root:2019-05-10 22:37:30, Epoch : 1, Step : 5333, Training Loss : 0.23570, Training Acc : 0.900, Run Time : 0.53
INFO:root:2019-05-10 22:37:30, Epoch : 1, Step : 5334, Training Loss : 0.33084, Training Acc : 0.833, Run Time : 0.46
INFO:root:2019-05-10 22:37:34, Epoch : 1, Step : 5335, Training Loss : 0.31696, Training Acc : 0.828, Run Time : 4.23
INFO:root:2019-05-10 22:37:35, Epoch : 1, Step : 5336, Training Loss : 0.31545, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-10 22:37:51, Epoch : 1, Step : 5337, Training Loss : 0.23979, Training Acc : 0.883, Run Time : 16.79
INFO:root:2019-05-10 22:37:52, Epoch : 1, Step : 5338, Training Loss : 0.24685, Training Acc : 0.900, Run Time : 0.41
INFO:root:2019-05-10 22:37:52, Epoch : 1, Step : 5339, Training Loss : 0.30973, Training Acc : 0.861, Run Time : 0.54
INFO:root:2019-05-10 22:37:53, Epoch : 1, Step : 5340, Training Loss : 0.28773, Training Acc : 0.872, Run Time : 0.49
INFO:root:2019-05-10 22:37:53, Epoch : 1, Step : 5341, Training Loss : 0.31560, Training Acc : 0.817, Run Time : 0.53
INFO:root:2019-05-10 22:38:09, Epoch : 1, Step : 5342, Training Loss : 0.26731, Training Acc : 0.861, Run Time : 15.30
INFO:root:2019-05-10 22:38:09, Epoch : 1, Step : 5343, Training Loss : 0.27790, Training Acc : 0.856, Run Time : 0.24
INFO:root:2019-05-10 22:38:09, Epoch : 1, Step : 5344, Training Loss : 0.26406, Training Acc : 0.872, Run Time : 0.21
INFO:root:2019-05-10 22:38:10, Epoch : 1, Step : 5345, Training Loss : 0.25439, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-10 22:38:10, Epoch : 1, Step : 5346, Training Loss : 0.28393, Training Acc : 0.861, Run Time : 0.53
INFO:root:2019-05-10 22:38:31, Epoch : 1, Step : 5347, Training Loss : 0.26358, Training Acc : 0.878, Run Time : 20.47
INFO:root:2019-05-10 22:38:31, Epoch : 1, Step : 5348, Training Loss : 0.24152, Training Acc : 0.894, Run Time : 0.32
INFO:root:2019-05-10 22:38:31, Epoch : 1, Step : 5349, Training Loss : 0.53712, Training Acc : 0.783, Run Time : 0.22
INFO:root:2019-05-10 22:38:32, Epoch : 1, Step : 5350, Training Loss : 0.49810, Training Acc : 0.789, Run Time : 0.49
INFO:root:2019-05-10 22:38:32, Epoch : 1, Step : 5351, Training Loss : 0.47618, Training Acc : 0.806, Run Time : 0.46
INFO:root:2019-05-10 22:38:52, Epoch : 1, Step : 5352, Training Loss : 0.40490, Training Acc : 0.861, Run Time : 19.79
INFO:root:2019-05-10 22:38:52, Epoch : 1, Step : 5353, Training Loss : 0.41497, Training Acc : 0.794, Run Time : 0.25
INFO:root:2019-05-10 22:38:53, Epoch : 1, Step : 5354, Training Loss : 0.74380, Training Acc : 0.700, Run Time : 0.58
INFO:root:2019-05-10 22:38:53, Epoch : 1, Step : 5355, Training Loss : 0.52589, Training Acc : 0.772, Run Time : 0.46
INFO:root:2019-05-10 22:38:54, Epoch : 1, Step : 5356, Training Loss : 0.51648, Training Acc : 0.761, Run Time : 0.41
INFO:root:2019-05-10 22:39:11, Epoch : 1, Step : 5357, Training Loss : 0.50026, Training Acc : 0.767, Run Time : 16.92
INFO:root:2019-05-10 22:39:11, Epoch : 1, Step : 5358, Training Loss : 0.49732, Training Acc : 0.783, Run Time : 0.33
INFO:root:2019-05-10 22:39:11, Epoch : 1, Step : 5359, Training Loss : 0.43608, Training Acc : 0.783, Run Time : 0.45
INFO:root:2019-05-10 22:39:12, Epoch : 1, Step : 5360, Training Loss : 0.58094, Training Acc : 0.728, Run Time : 0.31
INFO:root:2019-05-10 22:39:25, Epoch : 1, Step : 5361, Training Loss : 0.59035, Training Acc : 0.711, Run Time : 13.50
INFO:root:2019-05-10 22:39:26, Epoch : 1, Step : 5362, Training Loss : 0.60320, Training Acc : 0.722, Run Time : 0.60
INFO:root:2019-05-10 22:39:26, Epoch : 1, Step : 5363, Training Loss : 0.40756, Training Acc : 0.794, Run Time : 0.36
INFO:root:2019-05-10 22:39:41, Epoch : 1, Step : 5364, Training Loss : 0.35701, Training Acc : 0.833, Run Time : 15.01
INFO:root:2019-05-10 22:39:42, Epoch : 1, Step : 5365, Training Loss : 0.42235, Training Acc : 0.817, Run Time : 0.46
INFO:root:2019-05-10 22:39:43, Epoch : 1, Step : 5366, Training Loss : 0.48460, Training Acc : 0.744, Run Time : 1.23
INFO:root:2019-05-10 22:39:53, Epoch : 1, Step : 5367, Training Loss : 0.39985, Training Acc : 0.817, Run Time : 10.55
INFO:root:2019-05-10 22:39:54, Epoch : 1, Step : 5368, Training Loss : 0.55436, Training Acc : 0.733, Run Time : 0.87
INFO:root:2019-05-10 22:39:55, Epoch : 1, Step : 5369, Training Loss : 0.44925, Training Acc : 0.794, Run Time : 0.44
INFO:root:2019-05-10 22:40:07, Epoch : 1, Step : 5370, Training Loss : 0.65717, Training Acc : 0.650, Run Time : 12.61
INFO:root:2019-05-10 22:40:08, Epoch : 1, Step : 5371, Training Loss : 0.67763, Training Acc : 0.661, Run Time : 0.50
INFO:root:2019-05-10 22:40:08, Epoch : 1, Step : 5372, Training Loss : 0.62519, Training Acc : 0.706, Run Time : 0.32
INFO:root:2019-05-10 22:40:09, Epoch : 1, Step : 5373, Training Loss : 0.53826, Training Acc : 0.717, Run Time : 0.47
INFO:root:2019-05-10 22:40:09, Epoch : 1, Step : 5374, Training Loss : 0.69271, Training Acc : 0.694, Run Time : 0.49
INFO:root:2019-05-10 22:40:30, Epoch : 1, Step : 5375, Training Loss : 0.42099, Training Acc : 0.800, Run Time : 21.03
INFO:root:2019-05-10 22:40:30, Epoch : 1, Step : 5376, Training Loss : 0.56618, Training Acc : 0.733, Run Time : 0.24
INFO:root:2019-05-10 22:40:31, Epoch : 1, Step : 5377, Training Loss : 0.43787, Training Acc : 0.778, Run Time : 0.27
INFO:root:2019-05-10 22:40:31, Epoch : 1, Step : 5378, Training Loss : 0.45338, Training Acc : 0.772, Run Time : 0.46
INFO:root:2019-05-10 22:40:32, Epoch : 1, Step : 5379, Training Loss : 0.55976, Training Acc : 0.733, Run Time : 0.48
INFO:root:2019-05-10 22:40:54, Epoch : 1, Step : 5380, Training Loss : 0.49493, Training Acc : 0.783, Run Time : 22.12
INFO:root:2019-05-10 22:40:54, Epoch : 1, Step : 5381, Training Loss : 0.30749, Training Acc : 0.844, Run Time : 0.29
INFO:root:2019-05-10 22:40:54, Epoch : 1, Step : 5382, Training Loss : 0.45805, Training Acc : 0.800, Run Time : 0.40
INFO:root:2019-05-10 22:40:56, Epoch : 1, Step : 5383, Training Loss : 0.38985, Training Acc : 0.867, Run Time : 1.51
INFO:root:2019-05-10 22:40:56, Epoch : 1, Step : 5384, Training Loss : 0.48633, Training Acc : 0.811, Run Time : 0.25
INFO:root:2019-05-10 22:41:14, Epoch : 1, Step : 5385, Training Loss : 0.59728, Training Acc : 0.744, Run Time : 17.64
INFO:root:2019-05-10 22:41:14, Epoch : 1, Step : 5386, Training Loss : 0.35591, Training Acc : 0.822, Run Time : 0.25
INFO:root:2019-05-10 22:41:14, Epoch : 1, Step : 5387, Training Loss : 0.36559, Training Acc : 0.856, Run Time : 0.43
INFO:root:2019-05-10 22:41:15, Epoch : 1, Step : 5388, Training Loss : 0.67485, Training Acc : 0.694, Run Time : 0.56
INFO:root:2019-05-10 22:41:15, Epoch : 1, Step : 5389, Training Loss : 0.61180, Training Acc : 0.733, Run Time : 0.44
INFO:root:2019-05-10 22:41:34, Epoch : 1, Step : 5390, Training Loss : 0.30676, Training Acc : 0.844, Run Time : 19.08
INFO:root:2019-05-10 22:41:35, Epoch : 1, Step : 5391, Training Loss : 0.39296, Training Acc : 0.839, Run Time : 0.39
INFO:root:2019-05-10 22:41:35, Epoch : 1, Step : 5392, Training Loss : 0.51384, Training Acc : 0.756, Run Time : 0.42
INFO:root:2019-05-10 22:41:36, Epoch : 1, Step : 5393, Training Loss : 0.25774, Training Acc : 0.872, Run Time : 0.45
INFO:root:2019-05-10 22:41:36, Epoch : 1, Step : 5394, Training Loss : 0.25939, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 22:41:56, Epoch : 1, Step : 5395, Training Loss : 0.38928, Training Acc : 0.833, Run Time : 19.58
INFO:root:2019-05-10 22:41:56, Epoch : 1, Step : 5396, Training Loss : 0.31460, Training Acc : 0.861, Run Time : 0.30
INFO:root:2019-05-10 22:41:58, Epoch : 1, Step : 5397, Training Loss : 0.38239, Training Acc : 0.811, Run Time : 1.98
INFO:root:2019-05-10 22:41:59, Epoch : 1, Step : 5398, Training Loss : 0.34679, Training Acc : 0.850, Run Time : 0.57
INFO:root:2019-05-10 22:41:59, Epoch : 1, Step : 5399, Training Loss : 0.26921, Training Acc : 0.911, Run Time : 0.62
INFO:root:2019-05-10 22:42:17, Epoch : 1, Step : 5400, Training Loss : 0.29398, Training Acc : 0.883, Run Time : 17.54
INFO:root:2019-05-10 22:42:18, Epoch : 1, Step : 5401, Training Loss : 0.41177, Training Acc : 0.817, Run Time : 1.08
INFO:root:2019-05-10 22:42:18, Epoch : 1, Step : 5402, Training Loss : 0.47696, Training Acc : 0.783, Run Time : 0.41
INFO:root:2019-05-10 22:42:26, Epoch : 1, Step : 5403, Training Loss : 0.36609, Training Acc : 0.828, Run Time : 7.42
INFO:root:2019-05-10 22:42:26, Epoch : 1, Step : 5404, Training Loss : 0.37507, Training Acc : 0.811, Run Time : 0.42
INFO:root:2019-05-10 22:42:41, Epoch : 1, Step : 5405, Training Loss : 0.38449, Training Acc : 0.806, Run Time : 14.83
INFO:root:2019-05-10 22:42:42, Epoch : 1, Step : 5406, Training Loss : 0.36602, Training Acc : 0.833, Run Time : 0.54
INFO:root:2019-05-10 22:42:42, Epoch : 1, Step : 5407, Training Loss : 0.36263, Training Acc : 0.839, Run Time : 0.43
INFO:root:2019-05-10 22:42:42, Epoch : 1, Step : 5408, Training Loss : 0.28318, Training Acc : 0.867, Run Time : 0.44
INFO:root:2019-05-10 22:42:43, Epoch : 1, Step : 5409, Training Loss : 0.36882, Training Acc : 0.811, Run Time : 0.48
INFO:root:2019-05-10 22:43:01, Epoch : 1, Step : 5410, Training Loss : 0.28074, Training Acc : 0.878, Run Time : 18.13
INFO:root:2019-05-10 22:43:01, Epoch : 1, Step : 5411, Training Loss : 0.24782, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-10 22:43:02, Epoch : 1, Step : 5412, Training Loss : 0.26908, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-10 22:43:15, Epoch : 1, Step : 5413, Training Loss : 0.23996, Training Acc : 0.889, Run Time : 13.58
INFO:root:2019-05-10 22:43:16, Epoch : 1, Step : 5414, Training Loss : 0.24346, Training Acc : 0.906, Run Time : 0.60
INFO:root:2019-05-10 22:43:17, Epoch : 1, Step : 5415, Training Loss : 0.22871, Training Acc : 0.906, Run Time : 1.39
INFO:root:2019-05-10 22:43:18, Epoch : 1, Step : 5416, Training Loss : 0.25742, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-10 22:43:30, Epoch : 1, Step : 5417, Training Loss : 0.23577, Training Acc : 0.906, Run Time : 12.07
INFO:root:2019-05-10 22:43:31, Epoch : 1, Step : 5418, Training Loss : 0.23882, Training Acc : 0.889, Run Time : 1.05
INFO:root:2019-05-10 22:43:31, Epoch : 1, Step : 5419, Training Loss : 0.20919, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-10 22:43:32, Epoch : 1, Step : 5420, Training Loss : 0.29174, Training Acc : 0.906, Run Time : 0.49
INFO:root:2019-05-10 22:43:32, Epoch : 1, Step : 5421, Training Loss : 0.17910, Training Acc : 0.917, Run Time : 0.50
INFO:root:2019-05-10 22:43:52, Epoch : 1, Step : 5422, Training Loss : 0.18048, Training Acc : 0.928, Run Time : 19.14
INFO:root:2019-05-10 22:43:52, Epoch : 1, Step : 5423, Training Loss : 0.18181, Training Acc : 0.922, Run Time : 0.29
INFO:root:2019-05-10 22:43:52, Epoch : 1, Step : 5424, Training Loss : 0.22119, Training Acc : 0.906, Run Time : 0.22
INFO:root:2019-05-10 22:43:52, Epoch : 1, Step : 5425, Training Loss : 0.20494, Training Acc : 0.917, Run Time : 0.32
INFO:root:2019-05-10 22:43:53, Epoch : 1, Step : 5426, Training Loss : 0.25624, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-10 22:44:13, Epoch : 1, Step : 5427, Training Loss : 0.22884, Training Acc : 0.906, Run Time : 19.98
INFO:root:2019-05-10 22:44:13, Epoch : 1, Step : 5428, Training Loss : 0.24101, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-10 22:44:14, Epoch : 1, Step : 5429, Training Loss : 0.22061, Training Acc : 0.894, Run Time : 0.51
INFO:root:2019-05-10 22:44:14, Epoch : 1, Step : 5430, Training Loss : 0.19275, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-10 22:44:15, Epoch : 1, Step : 5431, Training Loss : 0.23333, Training Acc : 0.922, Run Time : 0.52
INFO:root:2019-05-10 22:44:33, Epoch : 1, Step : 5432, Training Loss : 0.18562, Training Acc : 0.922, Run Time : 18.13
INFO:root:2019-05-10 22:44:33, Epoch : 1, Step : 5433, Training Loss : 0.20356, Training Acc : 0.900, Run Time : 0.32
INFO:root:2019-05-10 22:44:34, Epoch : 1, Step : 5434, Training Loss : 0.20033, Training Acc : 0.933, Run Time : 0.32
INFO:root:2019-05-10 22:44:36, Epoch : 1, Step : 5435, Training Loss : 0.20308, Training Acc : 0.917, Run Time : 2.10
INFO:root:2019-05-10 22:44:48, Epoch : 1, Step : 5436, Training Loss : 0.21255, Training Acc : 0.889, Run Time : 12.27
INFO:root:2019-05-10 22:44:49, Epoch : 1, Step : 5437, Training Loss : 0.18668, Training Acc : 0.922, Run Time : 0.69
INFO:root:2019-05-10 22:44:49, Epoch : 1, Step : 5438, Training Loss : 0.17952, Training Acc : 0.928, Run Time : 0.22
INFO:root:2019-05-10 22:44:50, Epoch : 1, Step : 5439, Training Loss : 0.21844, Training Acc : 0.922, Run Time : 0.89
INFO:root:2019-05-10 22:44:51, Epoch : 1, Step : 5440, Training Loss : 0.23762, Training Acc : 0.900, Run Time : 1.65
INFO:root:2019-05-10 22:45:07, Epoch : 1, Step : 5441, Training Loss : 0.32320, Training Acc : 0.822, Run Time : 15.79
INFO:root:2019-05-10 22:45:08, Epoch : 1, Step : 5442, Training Loss : 0.29412, Training Acc : 0.839, Run Time : 0.44
INFO:root:2019-05-10 22:45:08, Epoch : 1, Step : 5443, Training Loss : 0.33836, Training Acc : 0.839, Run Time : 0.62
INFO:root:2019-05-10 22:45:09, Epoch : 1, Step : 5444, Training Loss : 0.38358, Training Acc : 0.811, Run Time : 0.55
INFO:root:2019-05-10 22:45:11, Epoch : 1, Step : 5445, Training Loss : 0.28352, Training Acc : 0.894, Run Time : 2.12
INFO:root:2019-05-10 22:45:13, Epoch : 1, Step : 5446, Training Loss : 0.24393, Training Acc : 0.894, Run Time : 1.99
INFO:root:2019-05-10 22:45:13, Epoch : 1, Step : 5447, Training Loss : 0.24715, Training Acc : 0.867, Run Time : 0.49
INFO:root:2019-05-10 22:45:32, Epoch : 1, Step : 5448, Training Loss : 0.25229, Training Acc : 0.867, Run Time : 18.71
INFO:root:2019-05-10 22:45:32, Epoch : 1, Step : 5449, Training Loss : 0.22111, Training Acc : 0.894, Run Time : 0.32
INFO:root:2019-05-10 22:45:33, Epoch : 1, Step : 5450, Training Loss : 0.37081, Training Acc : 0.844, Run Time : 0.45
INFO:root:2019-05-10 22:45:34, Epoch : 1, Step : 5451, Training Loss : 0.28294, Training Acc : 0.867, Run Time : 0.65
INFO:root:2019-05-10 22:45:34, Epoch : 1, Step : 5452, Training Loss : 0.31195, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 22:45:50, Epoch : 1, Step : 5453, Training Loss : 0.19231, Training Acc : 0.939, Run Time : 15.83
INFO:root:2019-05-10 22:45:50, Epoch : 1, Step : 5454, Training Loss : 0.34995, Training Acc : 0.872, Run Time : 0.21
INFO:root:2019-05-10 22:45:50, Epoch : 1, Step : 5455, Training Loss : 0.31747, Training Acc : 0.850, Run Time : 0.23
INFO:root:2019-05-10 22:45:51, Epoch : 1, Step : 5456, Training Loss : 0.37623, Training Acc : 0.850, Run Time : 0.48
INFO:root:2019-05-10 22:45:52, Epoch : 1, Step : 5457, Training Loss : 0.23376, Training Acc : 0.906, Run Time : 1.47
INFO:root:2019-05-10 22:46:08, Epoch : 1, Step : 5458, Training Loss : 0.35761, Training Acc : 0.850, Run Time : 15.69
INFO:root:2019-05-10 22:46:08, Epoch : 1, Step : 5459, Training Loss : 0.24492, Training Acc : 0.911, Run Time : 0.21
INFO:root:2019-05-10 22:46:08, Epoch : 1, Step : 5460, Training Loss : 0.26688, Training Acc : 0.867, Run Time : 0.33
INFO:root:2019-05-10 22:46:09, Epoch : 1, Step : 5461, Training Loss : 0.31478, Training Acc : 0.839, Run Time : 0.26
INFO:root:2019-05-10 22:46:09, Epoch : 1, Step : 5462, Training Loss : 0.26184, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-10 22:46:16, Epoch : 1, Step : 5463, Training Loss : 0.27105, Training Acc : 0.861, Run Time : 6.53
INFO:root:2019-05-10 22:46:16, Epoch : 1, Step : 5464, Training Loss : 0.28316, Training Acc : 0.839, Run Time : 0.44
INFO:root:2019-05-10 22:46:35, Epoch : 1, Step : 5465, Training Loss : 0.23239, Training Acc : 0.889, Run Time : 18.54
INFO:root:2019-05-10 22:46:35, Epoch : 1, Step : 5466, Training Loss : 0.20329, Training Acc : 0.900, Run Time : 0.23
INFO:root:2019-05-10 22:46:35, Epoch : 1, Step : 5467, Training Loss : 0.19166, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-10 22:46:36, Epoch : 1, Step : 5468, Training Loss : 0.17890, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 22:46:36, Epoch : 1, Step : 5469, Training Loss : 0.14698, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-10 22:46:54, Epoch : 1, Step : 5470, Training Loss : 0.15752, Training Acc : 0.967, Run Time : 17.95
INFO:root:2019-05-10 22:46:55, Epoch : 1, Step : 5471, Training Loss : 0.14065, Training Acc : 0.944, Run Time : 0.70
INFO:root:2019-05-10 22:46:56, Epoch : 1, Step : 5472, Training Loss : 0.12145, Training Acc : 0.972, Run Time : 0.66
INFO:root:2019-05-10 22:46:56, Epoch : 1, Step : 5473, Training Loss : 0.16374, Training Acc : 0.928, Run Time : 0.50
INFO:root:2019-05-10 22:47:05, Epoch : 1, Step : 5474, Training Loss : 0.13629, Training Acc : 0.928, Run Time : 8.44
INFO:root:2019-05-10 22:47:05, Epoch : 1, Step : 5475, Training Loss : 0.28427, Training Acc : 0.883, Run Time : 0.59
INFO:root:2019-05-10 22:47:06, Epoch : 1, Step : 5476, Training Loss : 0.23700, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-10 22:47:19, Epoch : 1, Step : 5477, Training Loss : 0.13930, Training Acc : 0.944, Run Time : 13.42
INFO:root:2019-05-10 22:47:19, Epoch : 1, Step : 5478, Training Loss : 0.13647, Training Acc : 0.933, Run Time : 0.43
INFO:root:2019-05-10 22:47:20, Epoch : 1, Step : 5479, Training Loss : 0.09896, Training Acc : 0.972, Run Time : 0.25
INFO:root:2019-05-10 22:47:20, Epoch : 1, Step : 5480, Training Loss : 0.14001, Training Acc : 0.944, Run Time : 0.29
INFO:root:2019-05-10 22:47:20, Epoch : 1, Step : 5481, Training Loss : 0.10342, Training Acc : 0.967, Run Time : 0.40
INFO:root:2019-05-10 22:47:26, Epoch : 1, Step : 5482, Training Loss : 0.15505, Training Acc : 0.933, Run Time : 5.26
INFO:root:2019-05-10 22:47:26, Epoch : 1, Step : 5483, Training Loss : 0.33765, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-10 22:47:45, Epoch : 1, Step : 5484, Training Loss : 0.40178, Training Acc : 0.872, Run Time : 19.11
INFO:root:2019-05-10 22:47:46, Epoch : 1, Step : 5485, Training Loss : 0.36746, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-10 22:47:46, Epoch : 1, Step : 5486, Training Loss : 0.35775, Training Acc : 0.861, Run Time : 0.42
INFO:root:2019-05-10 22:47:59, Epoch : 1, Step : 5487, Training Loss : 0.36778, Training Acc : 0.833, Run Time : 12.49
INFO:root:2019-05-10 22:47:59, Epoch : 1, Step : 5488, Training Loss : 0.41429, Training Acc : 0.833, Run Time : 0.23
INFO:root:2019-05-10 22:47:59, Epoch : 1, Step : 5489, Training Loss : 0.42443, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-10 22:48:00, Epoch : 1, Step : 5490, Training Loss : 0.25453, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-10 22:48:00, Epoch : 1, Step : 5491, Training Loss : 0.53013, Training Acc : 0.794, Run Time : 0.47
INFO:root:2019-05-10 22:48:04, Epoch : 1, Step : 5492, Training Loss : 0.46255, Training Acc : 0.811, Run Time : 3.94
INFO:root:2019-05-10 22:48:05, Epoch : 1, Step : 5493, Training Loss : 0.71858, Training Acc : 0.739, Run Time : 0.45
INFO:root:2019-05-10 22:48:22, Epoch : 1, Step : 5494, Training Loss : 0.34625, Training Acc : 0.839, Run Time : 17.43
INFO:root:2019-05-10 22:48:22, Epoch : 1, Step : 5495, Training Loss : 0.53644, Training Acc : 0.772, Run Time : 0.33
INFO:root:2019-05-10 22:48:23, Epoch : 1, Step : 5496, Training Loss : 0.27487, Training Acc : 0.911, Run Time : 0.58
INFO:root:2019-05-10 22:48:23, Epoch : 1, Step : 5497, Training Loss : 0.52521, Training Acc : 0.789, Run Time : 0.54
INFO:root:2019-05-10 22:48:24, Epoch : 1, Step : 5498, Training Loss : 0.29781, Training Acc : 0.878, Run Time : 0.57
INFO:root:2019-05-10 22:48:40, Epoch : 1, Step : 5499, Training Loss : 0.20963, Training Acc : 0.928, Run Time : 15.53
INFO:root:2019-05-10 22:48:40, Epoch : 1, Step : 5500, Training Loss : 0.23772, Training Acc : 0.900, Run Time : 0.23
INFO:root:2019-05-10 22:48:55, Epoch : 1, Step : 5501, Training Loss : 0.29628, Training Acc : 0.878, Run Time : 15.62
INFO:root:2019-05-10 22:48:56, Epoch : 1, Step : 5502, Training Loss : 0.43299, Training Acc : 0.778, Run Time : 0.43
INFO:root:2019-05-10 22:48:57, Epoch : 1, Step : 5503, Training Loss : 0.30202, Training Acc : 0.850, Run Time : 1.39
INFO:root:2019-05-10 22:49:10, Epoch : 1, Step : 5504, Training Loss : 0.21975, Training Acc : 0.911, Run Time : 12.53
INFO:root:2019-05-10 22:49:12, Epoch : 1, Step : 5505, Training Loss : 0.32242, Training Acc : 0.850, Run Time : 1.86
INFO:root:2019-05-10 22:49:12, Epoch : 1, Step : 5506, Training Loss : 0.29208, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-10 22:49:13, Epoch : 1, Step : 5507, Training Loss : 0.29720, Training Acc : 0.850, Run Time : 0.59
INFO:root:2019-05-10 22:49:13, Epoch : 1, Step : 5508, Training Loss : 0.25256, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 22:49:32, Epoch : 1, Step : 5509, Training Loss : 0.29752, Training Acc : 0.883, Run Time : 18.61
INFO:root:2019-05-10 22:49:32, Epoch : 1, Step : 5510, Training Loss : 0.22281, Training Acc : 0.900, Run Time : 0.58
INFO:root:2019-05-10 22:49:33, Epoch : 1, Step : 5511, Training Loss : 0.21429, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-10 22:49:33, Epoch : 1, Step : 5512, Training Loss : 0.28096, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-10 22:49:34, Epoch : 1, Step : 5513, Training Loss : 0.21149, Training Acc : 0.906, Run Time : 0.50
INFO:root:2019-05-10 22:49:47, Epoch : 1, Step : 5514, Training Loss : 0.18594, Training Acc : 0.917, Run Time : 13.47
INFO:root:2019-05-10 22:49:47, Epoch : 1, Step : 5515, Training Loss : 0.20092, Training Acc : 0.911, Run Time : 0.24
INFO:root:2019-05-10 22:49:48, Epoch : 1, Step : 5516, Training Loss : 0.19301, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-10 22:49:48, Epoch : 1, Step : 5517, Training Loss : 0.38637, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-10 22:49:49, Epoch : 1, Step : 5518, Training Loss : 0.30255, Training Acc : 0.867, Run Time : 0.49
INFO:root:2019-05-10 22:50:05, Epoch : 1, Step : 5519, Training Loss : 0.42745, Training Acc : 0.867, Run Time : 16.33
INFO:root:2019-05-10 22:50:06, Epoch : 1, Step : 5520, Training Loss : 0.22606, Training Acc : 0.900, Run Time : 0.76
INFO:root:2019-05-10 22:50:06, Epoch : 1, Step : 5521, Training Loss : 0.40530, Training Acc : 0.844, Run Time : 0.43
INFO:root:2019-05-10 22:50:20, Epoch : 1, Step : 5522, Training Loss : 0.33350, Training Acc : 0.872, Run Time : 13.25
INFO:root:2019-05-10 22:50:20, Epoch : 1, Step : 5523, Training Loss : 0.53482, Training Acc : 0.817, Run Time : 0.23
INFO:root:2019-05-10 22:50:20, Epoch : 1, Step : 5524, Training Loss : 0.40282, Training Acc : 0.828, Run Time : 0.23
INFO:root:2019-05-10 22:50:20, Epoch : 1, Step : 5525, Training Loss : 0.49672, Training Acc : 0.767, Run Time : 0.48
INFO:root:2019-05-10 22:50:21, Epoch : 1, Step : 5526, Training Loss : 0.26110, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-10 22:50:34, Epoch : 1, Step : 5527, Training Loss : 0.47449, Training Acc : 0.806, Run Time : 13.56
INFO:root:2019-05-10 22:50:35, Epoch : 1, Step : 5528, Training Loss : 0.64019, Training Acc : 0.767, Run Time : 0.51
INFO:root:2019-05-10 22:50:35, Epoch : 1, Step : 5529, Training Loss : 0.21730, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-10 22:50:36, Epoch : 1, Step : 5530, Training Loss : 0.36462, Training Acc : 0.833, Run Time : 0.44
INFO:root:2019-05-10 22:50:38, Epoch : 1, Step : 5531, Training Loss : 0.40118, Training Acc : 0.822, Run Time : 1.78
INFO:root:2019-05-10 22:50:53, Epoch : 1, Step : 5532, Training Loss : 0.32347, Training Acc : 0.839, Run Time : 15.16
INFO:root:2019-05-10 22:50:53, Epoch : 1, Step : 5533, Training Loss : 0.52666, Training Acc : 0.767, Run Time : 0.38
INFO:root:2019-05-10 22:50:54, Epoch : 1, Step : 5534, Training Loss : 0.51505, Training Acc : 0.789, Run Time : 0.55
INFO:root:2019-05-10 22:50:54, Epoch : 1, Step : 5535, Training Loss : 0.54767, Training Acc : 0.711, Run Time : 0.47
INFO:root:2019-05-10 22:50:55, Epoch : 1, Step : 5536, Training Loss : 0.30636, Training Acc : 0.889, Run Time : 0.51
INFO:root:2019-05-10 22:51:11, Epoch : 1, Step : 5537, Training Loss : 0.48055, Training Acc : 0.750, Run Time : 16.55
INFO:root:2019-05-10 22:51:11, Epoch : 1, Step : 5538, Training Loss : 0.43332, Training Acc : 0.772, Run Time : 0.27
INFO:root:2019-05-10 22:51:12, Epoch : 1, Step : 5539, Training Loss : 0.45232, Training Acc : 0.778, Run Time : 0.22
INFO:root:2019-05-10 22:51:12, Epoch : 1, Step : 5540, Training Loss : 0.67184, Training Acc : 0.683, Run Time : 0.45
INFO:root:2019-05-10 22:51:13, Epoch : 1, Step : 5541, Training Loss : 0.48966, Training Acc : 0.794, Run Time : 0.37
INFO:root:2019-05-10 22:51:30, Epoch : 1, Step : 5542, Training Loss : 0.37810, Training Acc : 0.811, Run Time : 17.76
INFO:root:2019-05-10 22:51:31, Epoch : 1, Step : 5543, Training Loss : 0.37556, Training Acc : 0.844, Run Time : 0.52
INFO:root:2019-05-10 22:51:31, Epoch : 1, Step : 5544, Training Loss : 0.52105, Training Acc : 0.728, Run Time : 0.36
INFO:root:2019-05-10 22:51:32, Epoch : 1, Step : 5545, Training Loss : 0.44072, Training Acc : 0.828, Run Time : 0.41
INFO:root:2019-05-10 22:51:32, Epoch : 1, Step : 5546, Training Loss : 0.36139, Training Acc : 0.789, Run Time : 0.69
INFO:root:2019-05-10 22:51:47, Epoch : 1, Step : 5547, Training Loss : 0.54419, Training Acc : 0.728, Run Time : 14.32
INFO:root:2019-05-10 22:51:47, Epoch : 1, Step : 5548, Training Loss : 0.32632, Training Acc : 0.889, Run Time : 0.25
INFO:root:2019-05-10 22:51:47, Epoch : 1, Step : 5549, Training Loss : 0.35034, Training Acc : 0.822, Run Time : 0.44
INFO:root:2019-05-10 22:51:48, Epoch : 1, Step : 5550, Training Loss : 0.46433, Training Acc : 0.761, Run Time : 0.46
INFO:root:2019-05-10 22:51:48, Epoch : 1, Step : 5551, Training Loss : 0.30394, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-10 22:51:57, Epoch : 1, Step : 5552, Training Loss : 0.25758, Training Acc : 0.889, Run Time : 8.79
INFO:root:2019-05-10 22:51:58, Epoch : 1, Step : 5553, Training Loss : 0.27011, Training Acc : 0.856, Run Time : 0.64
INFO:root:2019-05-10 22:51:58, Epoch : 1, Step : 5554, Training Loss : 0.27146, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-10 22:51:59, Epoch : 1, Step : 5555, Training Loss : 0.25049, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 22:52:08, Epoch : 1, Step : 5556, Training Loss : 0.22038, Training Acc : 0.911, Run Time : 9.72
INFO:root:2019-05-10 22:52:09, Epoch : 1, Step : 5557, Training Loss : 0.20996, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-10 22:52:09, Epoch : 1, Step : 5558, Training Loss : 0.25634, Training Acc : 0.883, Run Time : 0.50
INFO:root:2019-05-10 22:52:10, Epoch : 1, Step : 5559, Training Loss : 0.29718, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-10 22:52:20, Epoch : 1, Step : 5560, Training Loss : 0.31604, Training Acc : 0.883, Run Time : 10.56
INFO:root:2019-05-10 22:52:21, Epoch : 1, Step : 5561, Training Loss : 0.20430, Training Acc : 0.911, Run Time : 0.80
INFO:root:2019-05-10 22:52:22, Epoch : 1, Step : 5562, Training Loss : 0.25400, Training Acc : 0.906, Run Time : 0.48
INFO:root:2019-05-10 22:52:22, Epoch : 1, Step : 5563, Training Loss : 0.32482, Training Acc : 0.872, Run Time : 0.59
INFO:root:2019-05-10 22:52:23, Epoch : 1, Step : 5564, Training Loss : 0.28313, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 22:52:34, Epoch : 1, Step : 5565, Training Loss : 0.29714, Training Acc : 0.856, Run Time : 11.32
INFO:root:2019-05-10 22:52:34, Epoch : 1, Step : 5566, Training Loss : 0.23527, Training Acc : 0.911, Run Time : 0.33
INFO:root:2019-05-10 22:52:35, Epoch : 1, Step : 5567, Training Loss : 0.23876, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-10 22:52:35, Epoch : 1, Step : 5568, Training Loss : 0.24312, Training Acc : 0.911, Run Time : 0.44
INFO:root:2019-05-10 22:52:36, Epoch : 1, Step : 5569, Training Loss : 0.25886, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-10 22:52:46, Epoch : 1, Step : 5570, Training Loss : 0.39066, Training Acc : 0.811, Run Time : 10.59
INFO:root:2019-05-10 22:52:47, Epoch : 1, Step : 5571, Training Loss : 0.27997, Training Acc : 0.850, Run Time : 0.51
INFO:root:2019-05-10 22:52:47, Epoch : 1, Step : 5572, Training Loss : 0.37494, Training Acc : 0.828, Run Time : 0.45
INFO:root:2019-05-10 22:52:48, Epoch : 1, Step : 5573, Training Loss : 0.40502, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-10 22:52:50, Epoch : 1, Step : 5574, Training Loss : 0.28585, Training Acc : 0.872, Run Time : 2.36
INFO:root:2019-05-10 22:52:57, Epoch : 1, Step : 5575, Training Loss : 0.34793, Training Acc : 0.822, Run Time : 6.94
INFO:root:2019-05-10 22:52:58, Epoch : 1, Step : 5576, Training Loss : 0.36460, Training Acc : 0.856, Run Time : 1.01
INFO:root:2019-05-10 22:52:58, Epoch : 1, Step : 5577, Training Loss : 0.29957, Training Acc : 0.844, Run Time : 0.46
INFO:root:2019-05-10 22:53:05, Epoch : 1, Step : 5578, Training Loss : 0.28161, Training Acc : 0.867, Run Time : 6.81
INFO:root:2019-05-10 22:53:06, Epoch : 1, Step : 5579, Training Loss : 0.37871, Training Acc : 0.822, Run Time : 0.65
INFO:root:2019-05-10 22:53:07, Epoch : 1, Step : 5580, Training Loss : 0.34019, Training Acc : 0.844, Run Time : 0.97
INFO:root:2019-05-10 22:53:11, Epoch : 1, Step : 5581, Training Loss : 0.30093, Training Acc : 0.856, Run Time : 3.66
INFO:root:2019-05-10 22:53:11, Epoch : 1, Step : 5582, Training Loss : 0.27303, Training Acc : 0.856, Run Time : 0.77
INFO:root:2019-05-10 22:53:12, Epoch : 1, Step : 5583, Training Loss : 0.23826, Training Acc : 0.894, Run Time : 0.50
INFO:root:2019-05-10 22:53:25, Epoch : 1, Step : 5584, Training Loss : 0.30983, Training Acc : 0.850, Run Time : 12.70
INFO:root:2019-05-10 22:53:25, Epoch : 1, Step : 5585, Training Loss : 0.29814, Training Acc : 0.872, Run Time : 0.45
INFO:root:2019-05-10 22:53:25, Epoch : 1, Step : 5586, Training Loss : 0.28814, Training Acc : 0.856, Run Time : 0.38
INFO:root:2019-05-10 22:53:26, Epoch : 1, Step : 5587, Training Loss : 0.25670, Training Acc : 0.900, Run Time : 0.91
INFO:root:2019-05-10 22:53:35, Epoch : 1, Step : 5588, Training Loss : 0.26719, Training Acc : 0.878, Run Time : 8.75
INFO:root:2019-05-10 22:53:35, Epoch : 1, Step : 5589, Training Loss : 0.38609, Training Acc : 0.811, Run Time : 0.42
INFO:root:2019-05-10 22:53:36, Epoch : 1, Step : 5590, Training Loss : 0.51524, Training Acc : 0.772, Run Time : 0.45
INFO:root:2019-05-10 22:53:36, Epoch : 1, Step : 5591, Training Loss : 0.36947, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-10 22:53:45, Epoch : 1, Step : 5592, Training Loss : 0.22176, Training Acc : 0.917, Run Time : 8.19
INFO:root:2019-05-10 22:53:45, Epoch : 1, Step : 5593, Training Loss : 0.30986, Training Acc : 0.861, Run Time : 0.45
INFO:root:2019-05-10 22:53:45, Epoch : 1, Step : 5594, Training Loss : 0.28785, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-10 22:53:46, Epoch : 1, Step : 5595, Training Loss : 0.37716, Training Acc : 0.839, Run Time : 0.45
INFO:root:2019-05-10 22:53:47, Epoch : 1, Step : 5596, Training Loss : 0.31207, Training Acc : 0.889, Run Time : 0.92
INFO:root:2019-05-10 22:53:56, Epoch : 1, Step : 5597, Training Loss : 0.29174, Training Acc : 0.856, Run Time : 8.91
INFO:root:2019-05-10 22:53:56, Epoch : 1, Step : 5598, Training Loss : 0.23165, Training Acc : 0.883, Run Time : 0.28
INFO:root:2019-05-10 22:53:58, Epoch : 1, Step : 5599, Training Loss : 0.36038, Training Acc : 0.878, Run Time : 1.51
INFO:root:2019-05-10 22:54:04, Epoch : 1, Step : 5600, Training Loss : 0.35715, Training Acc : 0.828, Run Time : 6.67
INFO:root:2019-05-10 22:54:16, Epoch : 1, Step : 5601, Training Loss : 0.36635, Training Acc : 0.844, Run Time : 11.87
INFO:root:2019-05-10 22:54:16, Epoch : 1, Step : 5602, Training Loss : 0.44336, Training Acc : 0.806, Run Time : 0.32
INFO:root:2019-05-10 22:54:17, Epoch : 1, Step : 5603, Training Loss : 0.29969, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-10 22:54:17, Epoch : 1, Step : 5604, Training Loss : 0.43431, Training Acc : 0.750, Run Time : 0.52
INFO:root:2019-05-10 22:54:23, Epoch : 1, Step : 5605, Training Loss : 0.26295, Training Acc : 0.861, Run Time : 5.33
INFO:root:2019-05-10 22:54:24, Epoch : 1, Step : 5606, Training Loss : 0.20989, Training Acc : 0.911, Run Time : 1.13
INFO:root:2019-05-10 22:54:24, Epoch : 1, Step : 5607, Training Loss : 0.53855, Training Acc : 0.789, Run Time : 0.49
INFO:root:2019-05-10 22:54:35, Epoch : 1, Step : 5608, Training Loss : 0.73587, Training Acc : 0.667, Run Time : 10.48
INFO:root:2019-05-10 22:54:35, Epoch : 1, Step : 5609, Training Loss : 0.76798, Training Acc : 0.678, Run Time : 0.45
INFO:root:2019-05-10 22:54:36, Epoch : 1, Step : 5610, Training Loss : 0.70127, Training Acc : 0.644, Run Time : 0.46
INFO:root:2019-05-10 22:54:36, Epoch : 1, Step : 5611, Training Loss : 1.13137, Training Acc : 0.489, Run Time : 0.44
INFO:root:2019-05-10 22:54:46, Epoch : 1, Step : 5612, Training Loss : 0.64197, Training Acc : 0.667, Run Time : 9.55
INFO:root:2019-05-10 22:54:46, Epoch : 1, Step : 5613, Training Loss : 0.50063, Training Acc : 0.689, Run Time : 0.35
INFO:root:2019-05-10 22:54:47, Epoch : 1, Step : 5614, Training Loss : 0.60279, Training Acc : 0.733, Run Time : 0.82
INFO:root:2019-05-10 22:54:47, Epoch : 1, Step : 5615, Training Loss : 0.43678, Training Acc : 0.794, Run Time : 0.25
INFO:root:2019-05-10 22:54:48, Epoch : 1, Step : 5616, Training Loss : 0.53948, Training Acc : 0.756, Run Time : 0.46
INFO:root:2019-05-10 22:54:56, Epoch : 1, Step : 5617, Training Loss : 0.67662, Training Acc : 0.672, Run Time : 8.67
INFO:root:2019-05-10 22:54:57, Epoch : 1, Step : 5618, Training Loss : 0.69981, Training Acc : 0.706, Run Time : 0.51
INFO:root:2019-05-10 22:55:03, Epoch : 1, Step : 5619, Training Loss : 0.66173, Training Acc : 0.678, Run Time : 6.22
INFO:root:2019-05-10 22:55:13, Epoch : 1, Step : 5620, Training Loss : 0.63871, Training Acc : 0.689, Run Time : 9.92
INFO:root:2019-05-10 22:55:13, Epoch : 1, Step : 5621, Training Loss : 0.49011, Training Acc : 0.839, Run Time : 0.31
INFO:root:2019-05-10 22:55:14, Epoch : 1, Step : 5622, Training Loss : 0.49610, Training Acc : 0.783, Run Time : 0.44
INFO:root:2019-05-10 22:55:14, Epoch : 1, Step : 5623, Training Loss : 0.50949, Training Acc : 0.711, Run Time : 0.47
INFO:root:2019-05-10 22:55:15, Epoch : 1, Step : 5624, Training Loss : 0.39636, Training Acc : 0.806, Run Time : 0.48
INFO:root:2019-05-10 22:55:32, Epoch : 1, Step : 5625, Training Loss : 0.50104, Training Acc : 0.733, Run Time : 17.60
INFO:root:2019-05-10 22:55:32, Epoch : 1, Step : 5626, Training Loss : 0.52074, Training Acc : 0.750, Run Time : 0.32
INFO:root:2019-05-10 22:55:33, Epoch : 1, Step : 5627, Training Loss : 0.36333, Training Acc : 0.828, Run Time : 0.22
INFO:root:2019-05-10 22:55:33, Epoch : 1, Step : 5628, Training Loss : 0.67054, Training Acc : 0.667, Run Time : 0.52
INFO:root:2019-05-10 22:55:34, Epoch : 1, Step : 5629, Training Loss : 0.65360, Training Acc : 0.739, Run Time : 0.47
INFO:root:2019-05-10 22:55:46, Epoch : 1, Step : 5630, Training Loss : 0.59615, Training Acc : 0.700, Run Time : 12.30
INFO:root:2019-05-10 22:55:46, Epoch : 1, Step : 5631, Training Loss : 0.58969, Training Acc : 0.706, Run Time : 0.35
INFO:root:2019-05-10 22:55:47, Epoch : 1, Step : 5632, Training Loss : 0.47779, Training Acc : 0.783, Run Time : 0.45
INFO:root:2019-05-10 22:55:47, Epoch : 1, Step : 5633, Training Loss : 0.38455, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 22:55:48, Epoch : 1, Step : 5634, Training Loss : 0.54623, Training Acc : 0.728, Run Time : 0.47
INFO:root:2019-05-10 22:55:52, Epoch : 1, Step : 5635, Training Loss : 0.48130, Training Acc : 0.800, Run Time : 4.01
INFO:root:2019-05-10 22:55:52, Epoch : 1, Step : 5636, Training Loss : 0.65134, Training Acc : 0.689, Run Time : 0.44
INFO:root:2019-05-10 22:56:04, Epoch : 1, Step : 5637, Training Loss : 0.35999, Training Acc : 0.850, Run Time : 11.80
INFO:root:2019-05-10 22:56:04, Epoch : 1, Step : 5638, Training Loss : 0.42100, Training Acc : 0.806, Run Time : 0.45
INFO:root:2019-05-10 22:56:05, Epoch : 1, Step : 5639, Training Loss : 0.33151, Training Acc : 0.867, Run Time : 0.45
INFO:root:2019-05-10 22:56:05, Epoch : 1, Step : 5640, Training Loss : 0.39140, Training Acc : 0.844, Run Time : 0.46
INFO:root:2019-05-10 22:56:06, Epoch : 1, Step : 5641, Training Loss : 0.40311, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-10 22:56:15, Epoch : 1, Step : 5642, Training Loss : 0.39266, Training Acc : 0.828, Run Time : 9.28
INFO:root:2019-05-10 22:56:16, Epoch : 1, Step : 5643, Training Loss : 0.39637, Training Acc : 0.822, Run Time : 0.45
INFO:root:2019-05-10 22:56:16, Epoch : 1, Step : 5644, Training Loss : 0.42763, Training Acc : 0.789, Run Time : 0.47
INFO:root:2019-05-10 22:56:18, Epoch : 1, Step : 5645, Training Loss : 0.46533, Training Acc : 0.761, Run Time : 1.95
INFO:root:2019-05-10 22:56:27, Epoch : 1, Step : 5646, Training Loss : 0.39440, Training Acc : 0.861, Run Time : 8.71
INFO:root:2019-05-10 22:56:27, Epoch : 1, Step : 5647, Training Loss : 0.34936, Training Acc : 0.856, Run Time : 0.53
INFO:root:2019-05-10 22:56:28, Epoch : 1, Step : 5648, Training Loss : 0.51748, Training Acc : 0.733, Run Time : 0.45
INFO:root:2019-05-10 22:56:28, Epoch : 1, Step : 5649, Training Loss : 0.20967, Training Acc : 0.961, Run Time : 0.59
INFO:root:2019-05-10 22:56:29, Epoch : 1, Step : 5650, Training Loss : 0.32908, Training Acc : 0.878, Run Time : 1.21
INFO:root:2019-05-10 22:56:36, Epoch : 1, Step : 5651, Training Loss : 0.47584, Training Acc : 0.750, Run Time : 6.26
INFO:root:2019-05-10 22:56:38, Epoch : 1, Step : 5652, Training Loss : 0.44018, Training Acc : 0.789, Run Time : 2.29
INFO:root:2019-05-10 22:56:39, Epoch : 1, Step : 5653, Training Loss : 0.39336, Training Acc : 0.806, Run Time : 0.49
INFO:root:2019-05-10 22:56:39, Epoch : 1, Step : 5654, Training Loss : 0.29549, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-10 22:56:45, Epoch : 1, Step : 5655, Training Loss : 0.26084, Training Acc : 0.878, Run Time : 5.61
INFO:root:2019-05-10 22:56:53, Epoch : 1, Step : 5656, Training Loss : 0.35250, Training Acc : 0.839, Run Time : 8.44
INFO:root:2019-05-10 22:56:54, Epoch : 1, Step : 5657, Training Loss : 0.32176, Training Acc : 0.878, Run Time : 1.07
INFO:root:2019-05-10 22:56:55, Epoch : 1, Step : 5658, Training Loss : 0.34245, Training Acc : 0.878, Run Time : 0.54
INFO:root:2019-05-10 22:56:55, Epoch : 1, Step : 5659, Training Loss : 0.42412, Training Acc : 0.833, Run Time : 0.50
INFO:root:2019-05-10 22:56:56, Epoch : 1, Step : 5660, Training Loss : 0.34445, Training Acc : 0.867, Run Time : 0.83
INFO:root:2019-05-10 22:57:06, Epoch : 1, Step : 5661, Training Loss : 0.30542, Training Acc : 0.856, Run Time : 9.98
INFO:root:2019-05-10 22:57:06, Epoch : 1, Step : 5662, Training Loss : 0.24869, Training Acc : 0.922, Run Time : 0.33
INFO:root:2019-05-10 22:57:07, Epoch : 1, Step : 5663, Training Loss : 0.31895, Training Acc : 0.833, Run Time : 0.58
INFO:root:2019-05-10 22:57:07, Epoch : 1, Step : 5664, Training Loss : 0.35010, Training Acc : 0.833, Run Time : 0.46
INFO:root:2019-05-10 22:57:08, Epoch : 1, Step : 5665, Training Loss : 0.21228, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-10 22:57:12, Epoch : 1, Step : 5666, Training Loss : 0.27041, Training Acc : 0.867, Run Time : 3.96
INFO:root:2019-05-10 22:57:12, Epoch : 1, Step : 5667, Training Loss : 0.37974, Training Acc : 0.800, Run Time : 0.37
INFO:root:2019-05-10 22:57:25, Epoch : 1, Step : 5668, Training Loss : 0.19363, Training Acc : 0.922, Run Time : 12.85
INFO:root:2019-05-10 22:57:25, Epoch : 1, Step : 5669, Training Loss : 0.26450, Training Acc : 0.894, Run Time : 0.31
INFO:root:2019-05-10 22:57:26, Epoch : 1, Step : 5670, Training Loss : 0.31662, Training Acc : 0.833, Run Time : 0.35
INFO:root:2019-05-10 22:57:26, Epoch : 1, Step : 5671, Training Loss : 0.33360, Training Acc : 0.817, Run Time : 0.48
INFO:root:2019-05-10 22:57:34, Epoch : 1, Step : 5672, Training Loss : 0.32855, Training Acc : 0.878, Run Time : 8.03
INFO:root:2019-05-10 22:57:35, Epoch : 1, Step : 5673, Training Loss : 0.24246, Training Acc : 0.906, Run Time : 0.68
INFO:root:2019-05-10 22:57:35, Epoch : 1, Step : 5674, Training Loss : 0.29965, Training Acc : 0.867, Run Time : 0.49
INFO:root:2019-05-10 22:57:36, Epoch : 1, Step : 5675, Training Loss : 0.34300, Training Acc : 0.817, Run Time : 0.45
INFO:root:2019-05-10 22:57:36, Epoch : 1, Step : 5676, Training Loss : 0.17061, Training Acc : 0.956, Run Time : 0.49
INFO:root:2019-05-10 22:57:45, Epoch : 1, Step : 5677, Training Loss : 0.19657, Training Acc : 0.928, Run Time : 8.55
INFO:root:2019-05-10 22:57:45, Epoch : 1, Step : 5678, Training Loss : 0.39109, Training Acc : 0.822, Run Time : 0.47
INFO:root:2019-05-10 22:57:46, Epoch : 1, Step : 5679, Training Loss : 0.44115, Training Acc : 0.806, Run Time : 0.49
INFO:root:2019-05-10 22:57:46, Epoch : 1, Step : 5680, Training Loss : 0.13038, Training Acc : 0.967, Run Time : 0.45
INFO:root:2019-05-10 22:57:55, Epoch : 1, Step : 5681, Training Loss : 0.32566, Training Acc : 0.917, Run Time : 9.00
INFO:root:2019-05-10 22:57:56, Epoch : 1, Step : 5682, Training Loss : 0.19471, Training Acc : 0.944, Run Time : 0.40
INFO:root:2019-05-10 22:57:56, Epoch : 1, Step : 5683, Training Loss : 0.29229, Training Acc : 0.889, Run Time : 0.50
INFO:root:2019-05-10 22:57:56, Epoch : 1, Step : 5684, Training Loss : 0.19788, Training Acc : 0.933, Run Time : 0.28
INFO:root:2019-05-10 22:58:04, Epoch : 1, Step : 5685, Training Loss : 0.33002, Training Acc : 0.894, Run Time : 7.72
INFO:root:2019-05-10 22:58:05, Epoch : 1, Step : 5686, Training Loss : 0.42296, Training Acc : 0.867, Run Time : 0.48
INFO:root:2019-05-10 22:58:06, Epoch : 1, Step : 5687, Training Loss : 0.26567, Training Acc : 0.922, Run Time : 1.05
INFO:root:2019-05-10 22:58:07, Epoch : 1, Step : 5688, Training Loss : 0.29543, Training Acc : 0.867, Run Time : 1.52
INFO:root:2019-05-10 22:58:16, Epoch : 1, Step : 5689, Training Loss : 0.36407, Training Acc : 0.850, Run Time : 8.88
INFO:root:2019-05-10 22:58:17, Epoch : 1, Step : 5690, Training Loss : 0.33220, Training Acc : 0.889, Run Time : 0.81
INFO:root:2019-05-10 22:58:18, Epoch : 1, Step : 5691, Training Loss : 0.28850, Training Acc : 0.900, Run Time : 0.89
INFO:root:2019-05-10 22:58:19, Epoch : 1, Step : 5692, Training Loss : 0.28125, Training Acc : 0.883, Run Time : 1.19
INFO:root:2019-05-10 22:58:20, Epoch : 1, Step : 5693, Training Loss : 0.24999, Training Acc : 0.911, Run Time : 0.70
INFO:root:2019-05-10 22:58:24, Epoch : 1, Step : 5694, Training Loss : 0.27719, Training Acc : 0.900, Run Time : 4.79
INFO:root:2019-05-10 22:58:25, Epoch : 1, Step : 5695, Training Loss : 0.32194, Training Acc : 0.872, Run Time : 0.44
INFO:root:2019-05-10 22:58:34, Epoch : 1, Step : 5696, Training Loss : 0.39747, Training Acc : 0.861, Run Time : 8.81
INFO:root:2019-05-10 22:58:34, Epoch : 1, Step : 5697, Training Loss : 0.37912, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-10 22:58:35, Epoch : 1, Step : 5698, Training Loss : 0.28453, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-10 22:58:35, Epoch : 1, Step : 5699, Training Loss : 0.18800, Training Acc : 0.944, Run Time : 0.53
INFO:root:2019-05-10 22:58:41, Epoch : 1, Step : 5700, Training Loss : 0.29462, Training Acc : 0.844, Run Time : 5.45
INFO:root:2019-05-10 22:58:41, Epoch : 1, Step : 5701, Training Loss : 0.27997, Training Acc : 0.883, Run Time : 0.90
INFO:root:2019-05-10 22:58:42, Epoch : 1, Step : 5702, Training Loss : 0.39415, Training Acc : 0.789, Run Time : 0.58
INFO:root:2019-05-10 22:58:51, Epoch : 1, Step : 5703, Training Loss : 0.29196, Training Acc : 0.872, Run Time : 9.12
INFO:root:2019-05-10 22:58:52, Epoch : 1, Step : 5704, Training Loss : 0.23938, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 22:58:52, Epoch : 1, Step : 5705, Training Loss : 0.27492, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-10 22:58:53, Epoch : 1, Step : 5706, Training Loss : 0.25293, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-10 22:58:57, Epoch : 1, Step : 5707, Training Loss : 0.23532, Training Acc : 0.928, Run Time : 4.04
INFO:root:2019-05-10 22:58:57, Epoch : 1, Step : 5708, Training Loss : 0.21104, Training Acc : 0.933, Run Time : 0.80
INFO:root:2019-05-10 22:59:01, Epoch : 1, Step : 5709, Training Loss : 0.23029, Training Acc : 0.922, Run Time : 3.49
INFO:root:2019-05-10 22:59:05, Epoch : 1, Step : 5710, Training Loss : 0.15602, Training Acc : 0.961, Run Time : 4.14
INFO:root:2019-05-10 22:59:05, Epoch : 1, Step : 5711, Training Loss : 0.18757, Training Acc : 0.939, Run Time : 0.39
INFO:root:2019-05-10 22:59:06, Epoch : 1, Step : 5712, Training Loss : 0.17224, Training Acc : 0.944, Run Time : 0.92
INFO:root:2019-05-10 22:59:17, Epoch : 1, Step : 5713, Training Loss : 0.24946, Training Acc : 0.894, Run Time : 11.02
INFO:root:2019-05-10 22:59:18, Epoch : 1, Step : 5714, Training Loss : 0.19419, Training Acc : 0.922, Run Time : 0.25
INFO:root:2019-05-10 22:59:18, Epoch : 1, Step : 5715, Training Loss : 0.20779, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-10 22:59:18, Epoch : 1, Step : 5716, Training Loss : 0.24962, Training Acc : 0.911, Run Time : 0.43
INFO:root:2019-05-10 22:59:19, Epoch : 1, Step : 5717, Training Loss : 0.26411, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-10 22:59:28, Epoch : 1, Step : 5718, Training Loss : 0.25955, Training Acc : 0.911, Run Time : 9.53
INFO:root:2019-05-10 22:59:29, Epoch : 1, Step : 5719, Training Loss : 0.23669, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-10 22:59:29, Epoch : 1, Step : 5720, Training Loss : 0.17596, Training Acc : 0.933, Run Time : 0.47
INFO:root:2019-05-10 22:59:30, Epoch : 1, Step : 5721, Training Loss : 0.21882, Training Acc : 0.933, Run Time : 0.45
INFO:root:2019-05-10 22:59:42, Epoch : 1, Step : 5722, Training Loss : 0.17870, Training Acc : 0.944, Run Time : 12.16
INFO:root:2019-05-10 22:59:42, Epoch : 1, Step : 5723, Training Loss : 0.21395, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-10 22:59:43, Epoch : 1, Step : 5724, Training Loss : 0.13991, Training Acc : 0.956, Run Time : 0.45
INFO:root:2019-05-10 22:59:43, Epoch : 1, Step : 5725, Training Loss : 0.18382, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-10 22:59:44, Epoch : 1, Step : 5726, Training Loss : 0.16726, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-10 22:59:52, Epoch : 1, Step : 5727, Training Loss : 0.23628, Training Acc : 0.911, Run Time : 8.52
INFO:root:2019-05-10 22:59:53, Epoch : 1, Step : 5728, Training Loss : 0.23116, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-10 22:59:54, Epoch : 1, Step : 5729, Training Loss : 0.15758, Training Acc : 0.950, Run Time : 0.83
INFO:root:2019-05-10 22:59:54, Epoch : 1, Step : 5730, Training Loss : 0.26940, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-10 23:00:06, Epoch : 1, Step : 5731, Training Loss : 0.31808, Training Acc : 0.867, Run Time : 12.08
INFO:root:2019-05-10 23:00:07, Epoch : 1, Step : 5732, Training Loss : 0.25454, Training Acc : 0.911, Run Time : 0.36
INFO:root:2019-05-10 23:00:07, Epoch : 1, Step : 5733, Training Loss : 0.29323, Training Acc : 0.906, Run Time : 0.44
INFO:root:2019-05-10 23:00:07, Epoch : 1, Step : 5734, Training Loss : 0.17207, Training Acc : 0.956, Run Time : 0.44
INFO:root:2019-05-10 23:00:08, Epoch : 1, Step : 5735, Training Loss : 0.32350, Training Acc : 0.861, Run Time : 0.45
INFO:root:2019-05-10 23:00:15, Epoch : 1, Step : 5736, Training Loss : 0.23408, Training Acc : 0.894, Run Time : 7.06
INFO:root:2019-05-10 23:00:15, Epoch : 1, Step : 5737, Training Loss : 0.21913, Training Acc : 0.911, Run Time : 0.49
INFO:root:2019-05-10 23:00:17, Epoch : 1, Step : 5738, Training Loss : 0.27307, Training Acc : 0.889, Run Time : 1.43
INFO:root:2019-05-10 23:00:24, Epoch : 1, Step : 5739, Training Loss : 0.20500, Training Acc : 0.922, Run Time : 6.63
INFO:root:2019-05-10 23:00:25, Epoch : 1, Step : 5740, Training Loss : 0.32063, Training Acc : 0.850, Run Time : 0.97
INFO:root:2019-05-10 23:00:25, Epoch : 1, Step : 5741, Training Loss : 0.28355, Training Acc : 0.900, Run Time : 0.48
INFO:root:2019-05-10 23:00:26, Epoch : 1, Step : 5742, Training Loss : 0.33693, Training Acc : 0.867, Run Time : 1.10
INFO:root:2019-05-10 23:00:32, Epoch : 1, Step : 5743, Training Loss : 0.27802, Training Acc : 0.889, Run Time : 5.94
INFO:root:2019-05-10 23:00:32, Epoch : 1, Step : 5744, Training Loss : 0.39764, Training Acc : 0.811, Run Time : 0.44
INFO:root:2019-05-10 23:00:33, Epoch : 1, Step : 5745, Training Loss : 0.40079, Training Acc : 0.850, Run Time : 0.54
INFO:root:2019-05-10 23:00:42, Epoch : 1, Step : 5746, Training Loss : 0.49731, Training Acc : 0.767, Run Time : 9.11
INFO:root:2019-05-10 23:00:43, Epoch : 1, Step : 5747, Training Loss : 0.58917, Training Acc : 0.783, Run Time : 0.55
INFO:root:2019-05-10 23:00:43, Epoch : 1, Step : 5748, Training Loss : 0.34632, Training Acc : 0.856, Run Time : 0.44
INFO:root:2019-05-10 23:00:44, Epoch : 1, Step : 5749, Training Loss : 0.29666, Training Acc : 0.850, Run Time : 0.45
INFO:root:2019-05-10 23:00:46, Epoch : 1, Step : 5750, Training Loss : 0.33444, Training Acc : 0.861, Run Time : 2.30
INFO:root:2019-05-10 23:00:52, Epoch : 1, Step : 5751, Training Loss : 0.33405, Training Acc : 0.867, Run Time : 6.14
INFO:root:2019-05-10 23:00:52, Epoch : 1, Step : 5752, Training Loss : 0.31743, Training Acc : 0.850, Run Time : 0.44
INFO:root:2019-05-10 23:00:53, Epoch : 1, Step : 5753, Training Loss : 0.35788, Training Acc : 0.828, Run Time : 0.35
INFO:root:2019-05-10 23:01:01, Epoch : 1, Step : 5754, Training Loss : 0.40701, Training Acc : 0.833, Run Time : 8.49
INFO:root:2019-05-10 23:01:02, Epoch : 1, Step : 5755, Training Loss : 0.39837, Training Acc : 0.828, Run Time : 0.47
INFO:root:2019-05-10 23:01:02, Epoch : 1, Step : 5756, Training Loss : 0.35348, Training Acc : 0.833, Run Time : 0.45
INFO:root:2019-05-10 23:01:03, Epoch : 1, Step : 5757, Training Loss : 0.22064, Training Acc : 0.939, Run Time : 0.73
INFO:root:2019-05-10 23:01:09, Epoch : 1, Step : 5758, Training Loss : 0.29060, Training Acc : 0.878, Run Time : 6.44
INFO:root:2019-05-10 23:01:10, Epoch : 1, Step : 5759, Training Loss : 0.18762, Training Acc : 0.928, Run Time : 0.64
INFO:root:2019-05-10 23:01:11, Epoch : 1, Step : 5760, Training Loss : 0.32720, Training Acc : 0.867, Run Time : 0.57
INFO:root:2019-05-10 23:01:14, Epoch : 1, Step : 5761, Training Loss : 0.34496, Training Acc : 0.833, Run Time : 3.85
INFO:root:2019-05-10 23:01:16, Epoch : 1, Step : 5762, Training Loss : 0.16957, Training Acc : 0.967, Run Time : 1.32
INFO:root:2019-05-10 23:01:24, Epoch : 1, Step : 5763, Training Loss : 0.19920, Training Acc : 0.911, Run Time : 7.99
INFO:root:2019-05-10 23:01:24, Epoch : 1, Step : 5764, Training Loss : 0.14275, Training Acc : 0.961, Run Time : 0.46
INFO:root:2019-05-10 23:01:25, Epoch : 1, Step : 5765, Training Loss : 0.24174, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 23:01:25, Epoch : 1, Step : 5766, Training Loss : 0.15319, Training Acc : 0.950, Run Time : 0.58
INFO:root:2019-05-10 23:01:33, Epoch : 1, Step : 5767, Training Loss : 0.35722, Training Acc : 0.850, Run Time : 8.25
INFO:root:2019-05-10 23:01:34, Epoch : 1, Step : 5768, Training Loss : 0.31319, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-10 23:01:34, Epoch : 1, Step : 5769, Training Loss : 0.39252, Training Acc : 0.822, Run Time : 0.44
INFO:root:2019-05-10 23:01:36, Epoch : 1, Step : 5770, Training Loss : 0.20546, Training Acc : 0.906, Run Time : 1.43
INFO:root:2019-05-10 23:01:43, Epoch : 1, Step : 5771, Training Loss : 0.27980, Training Acc : 0.872, Run Time : 7.40
INFO:root:2019-05-10 23:01:44, Epoch : 1, Step : 5772, Training Loss : 0.32128, Training Acc : 0.878, Run Time : 0.85
INFO:root:2019-05-10 23:01:45, Epoch : 1, Step : 5773, Training Loss : 0.28271, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-10 23:01:45, Epoch : 1, Step : 5774, Training Loss : 0.30604, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-10 23:01:57, Epoch : 1, Step : 5775, Training Loss : 0.43713, Training Acc : 0.822, Run Time : 11.77
INFO:root:2019-05-10 23:01:57, Epoch : 1, Step : 5776, Training Loss : 0.44403, Training Acc : 0.817, Run Time : 0.34
INFO:root:2019-05-10 23:01:58, Epoch : 1, Step : 5777, Training Loss : 0.38885, Training Acc : 0.833, Run Time : 0.40
INFO:root:2019-05-10 23:01:58, Epoch : 1, Step : 5778, Training Loss : 0.33047, Training Acc : 0.844, Run Time : 0.50
INFO:root:2019-05-10 23:01:58, Epoch : 1, Step : 5779, Training Loss : 0.39931, Training Acc : 0.839, Run Time : 0.40
INFO:root:2019-05-10 23:02:10, Epoch : 1, Step : 5780, Training Loss : 0.31600, Training Acc : 0.872, Run Time : 11.94
INFO:root:2019-05-10 23:02:11, Epoch : 1, Step : 5781, Training Loss : 0.31190, Training Acc : 0.861, Run Time : 0.25
INFO:root:2019-05-10 23:02:11, Epoch : 1, Step : 5782, Training Loss : 0.31750, Training Acc : 0.861, Run Time : 0.44
INFO:root:2019-05-10 23:02:12, Epoch : 1, Step : 5783, Training Loss : 0.30030, Training Acc : 0.856, Run Time : 0.48
INFO:root:2019-05-10 23:02:16, Epoch : 1, Step : 5784, Training Loss : 0.26576, Training Acc : 0.894, Run Time : 4.74
INFO:root:2019-05-10 23:02:17, Epoch : 1, Step : 5785, Training Loss : 0.28730, Training Acc : 0.900, Run Time : 0.87
INFO:root:2019-05-10 23:02:18, Epoch : 1, Step : 5786, Training Loss : 0.24412, Training Acc : 0.933, Run Time : 0.55
INFO:root:2019-05-10 23:02:25, Epoch : 1, Step : 5787, Training Loss : 0.26217, Training Acc : 0.933, Run Time : 6.92
INFO:root:2019-05-10 23:02:25, Epoch : 1, Step : 5788, Training Loss : 0.18605, Training Acc : 0.967, Run Time : 0.74
INFO:root:2019-05-10 23:02:26, Epoch : 1, Step : 5789, Training Loss : 0.15857, Training Acc : 0.967, Run Time : 0.76
INFO:root:2019-05-10 23:02:34, Epoch : 1, Step : 5790, Training Loss : 0.19416, Training Acc : 0.956, Run Time : 7.88
INFO:root:2019-05-10 23:02:34, Epoch : 1, Step : 5791, Training Loss : 0.25836, Training Acc : 0.933, Run Time : 0.36
INFO:root:2019-05-10 23:02:35, Epoch : 1, Step : 5792, Training Loss : 0.14039, Training Acc : 0.972, Run Time : 0.63
INFO:root:2019-05-10 23:02:36, Epoch : 1, Step : 5793, Training Loss : 0.24881, Training Acc : 0.922, Run Time : 0.85
INFO:root:2019-05-10 23:02:36, Epoch : 1, Step : 5794, Training Loss : 0.24295, Training Acc : 0.922, Run Time : 0.50
INFO:root:2019-05-10 23:02:46, Epoch : 1, Step : 5795, Training Loss : 0.18296, Training Acc : 0.950, Run Time : 9.60
INFO:root:2019-05-10 23:02:46, Epoch : 1, Step : 5796, Training Loss : 0.22879, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-10 23:02:47, Epoch : 1, Step : 5797, Training Loss : 0.38939, Training Acc : 0.850, Run Time : 0.45
INFO:root:2019-05-10 23:02:47, Epoch : 1, Step : 5798, Training Loss : 0.26222, Training Acc : 0.917, Run Time : 0.20
INFO:root:2019-05-10 23:02:56, Epoch : 1, Step : 5799, Training Loss : 0.43785, Training Acc : 0.811, Run Time : 8.77
INFO:root:2019-05-10 23:02:56, Epoch : 1, Step : 5800, Training Loss : 0.47815, Training Acc : 0.789, Run Time : 0.65
INFO:root:2019-05-10 23:03:04, Epoch : 1, Step : 5801, Training Loss : 0.51785, Training Acc : 0.744, Run Time : 7.47
INFO:root:2019-05-10 23:03:04, Epoch : 1, Step : 5802, Training Loss : 0.44166, Training Acc : 0.789, Run Time : 0.52
INFO:root:2019-05-10 23:03:05, Epoch : 1, Step : 5803, Training Loss : 0.30339, Training Acc : 0.839, Run Time : 0.41
INFO:root:2019-05-10 23:03:05, Epoch : 1, Step : 5804, Training Loss : 0.34943, Training Acc : 0.844, Run Time : 0.47
INFO:root:2019-05-10 23:03:06, Epoch : 1, Step : 5805, Training Loss : 0.27604, Training Acc : 0.889, Run Time : 0.49
INFO:root:2019-05-10 23:03:15, Epoch : 1, Step : 5806, Training Loss : 0.23865, Training Acc : 0.894, Run Time : 9.13
INFO:root:2019-05-10 23:03:15, Epoch : 1, Step : 5807, Training Loss : 0.16197, Training Acc : 0.950, Run Time : 0.44
INFO:root:2019-05-10 23:03:16, Epoch : 1, Step : 5808, Training Loss : 0.14663, Training Acc : 0.961, Run Time : 0.45
INFO:root:2019-05-10 23:03:25, Epoch : 1, Step : 5809, Training Loss : 0.15353, Training Acc : 0.944, Run Time : 8.85
INFO:root:2019-05-10 23:03:25, Epoch : 1, Step : 5810, Training Loss : 0.15468, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-10 23:03:26, Epoch : 1, Step : 5811, Training Loss : 0.10170, Training Acc : 0.972, Run Time : 0.43
INFO:root:2019-05-10 23:03:26, Epoch : 1, Step : 5812, Training Loss : 0.12916, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 23:03:28, Epoch : 1, Step : 5813, Training Loss : 0.15109, Training Acc : 0.956, Run Time : 1.64
INFO:root:2019-05-10 23:03:34, Epoch : 1, Step : 5814, Training Loss : 0.12562, Training Acc : 0.956, Run Time : 6.10
INFO:root:2019-05-10 23:03:34, Epoch : 1, Step : 5815, Training Loss : 0.14835, Training Acc : 0.944, Run Time : 0.44
INFO:root:2019-05-10 23:03:44, Epoch : 1, Step : 5816, Training Loss : 0.15980, Training Acc : 0.906, Run Time : 9.34
INFO:root:2019-05-10 23:03:44, Epoch : 1, Step : 5817, Training Loss : 0.15604, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-10 23:03:45, Epoch : 1, Step : 5818, Training Loss : 0.19935, Training Acc : 0.917, Run Time : 0.49
INFO:root:2019-05-10 23:03:45, Epoch : 1, Step : 5819, Training Loss : 0.15649, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-10 23:03:45, Epoch : 1, Step : 5820, Training Loss : 0.17095, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-10 23:03:58, Epoch : 1, Step : 5821, Training Loss : 0.18927, Training Acc : 0.928, Run Time : 12.37
INFO:root:2019-05-10 23:03:58, Epoch : 1, Step : 5822, Training Loss : 0.16228, Training Acc : 0.928, Run Time : 0.22
INFO:root:2019-05-10 23:03:58, Epoch : 1, Step : 5823, Training Loss : 0.18451, Training Acc : 0.939, Run Time : 0.22
INFO:root:2019-05-10 23:03:59, Epoch : 1, Step : 5824, Training Loss : 0.15819, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-10 23:03:59, Epoch : 1, Step : 5825, Training Loss : 0.13417, Training Acc : 0.950, Run Time : 0.44
INFO:root:2019-05-10 23:04:10, Epoch : 1, Step : 5826, Training Loss : 0.13780, Training Acc : 0.956, Run Time : 11.26
INFO:root:2019-05-10 23:04:11, Epoch : 1, Step : 5827, Training Loss : 0.16482, Training Acc : 0.922, Run Time : 0.63
INFO:root:2019-05-10 23:04:12, Epoch : 1, Step : 5828, Training Loss : 0.14018, Training Acc : 0.956, Run Time : 0.63
INFO:root:2019-05-10 23:04:12, Epoch : 1, Step : 5829, Training Loss : 0.13236, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-10 23:04:14, Epoch : 1, Step : 5830, Training Loss : 0.13422, Training Acc : 0.944, Run Time : 1.78
INFO:root:2019-05-10 23:04:16, Epoch : 1, Step : 5831, Training Loss : 0.18363, Training Acc : 0.900, Run Time : 2.13
INFO:root:2019-05-10 23:04:26, Epoch : 1, Step : 5832, Training Loss : 0.17462, Training Acc : 0.933, Run Time : 10.24
INFO:root:2019-05-10 23:04:26, Epoch : 1, Step : 5833, Training Loss : 0.22096, Training Acc : 0.917, Run Time : 0.23
INFO:root:2019-05-10 23:04:27, Epoch : 1, Step : 5834, Training Loss : 0.17631, Training Acc : 0.944, Run Time : 0.49
INFO:root:2019-05-10 23:04:27, Epoch : 1, Step : 5835, Training Loss : 0.13852, Training Acc : 0.933, Run Time : 0.47
INFO:root:2019-05-10 23:04:34, Epoch : 1, Step : 5836, Training Loss : 0.13154, Training Acc : 0.933, Run Time : 6.92
INFO:root:2019-05-10 23:04:35, Epoch : 1, Step : 5837, Training Loss : 0.17699, Training Acc : 0.911, Run Time : 0.43
INFO:root:2019-05-10 23:04:35, Epoch : 1, Step : 5838, Training Loss : 0.19329, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-10 23:04:37, Epoch : 1, Step : 5839, Training Loss : 0.34032, Training Acc : 0.894, Run Time : 1.84
INFO:root:2019-05-10 23:04:44, Epoch : 1, Step : 5840, Training Loss : 0.20546, Training Acc : 0.900, Run Time : 7.13
INFO:root:2019-05-10 23:04:45, Epoch : 1, Step : 5841, Training Loss : 0.19431, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-10 23:04:45, Epoch : 1, Step : 5842, Training Loss : 0.16571, Training Acc : 0.928, Run Time : 0.63
INFO:root:2019-05-10 23:04:54, Epoch : 1, Step : 5843, Training Loss : 0.29802, Training Acc : 0.850, Run Time : 8.53
INFO:root:2019-05-10 23:04:54, Epoch : 1, Step : 5844, Training Loss : 0.33612, Training Acc : 0.839, Run Time : 0.49
INFO:root:2019-05-10 23:04:55, Epoch : 1, Step : 5845, Training Loss : 0.34918, Training Acc : 0.828, Run Time : 0.46
INFO:root:2019-05-10 23:04:55, Epoch : 1, Step : 5846, Training Loss : 0.30724, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-10 23:04:56, Epoch : 1, Step : 5847, Training Loss : 0.36749, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-10 23:05:05, Epoch : 1, Step : 5848, Training Loss : 0.28464, Training Acc : 0.900, Run Time : 9.48
INFO:root:2019-05-10 23:05:06, Epoch : 1, Step : 5849, Training Loss : 0.15639, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-10 23:05:06, Epoch : 1, Step : 5850, Training Loss : 0.19317, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 23:05:06, Epoch : 1, Step : 5851, Training Loss : 0.22923, Training Acc : 0.900, Run Time : 0.48
INFO:root:2019-05-10 23:05:13, Epoch : 1, Step : 5852, Training Loss : 0.22661, Training Acc : 0.900, Run Time : 6.14
INFO:root:2019-05-10 23:05:13, Epoch : 1, Step : 5853, Training Loss : 0.18234, Training Acc : 0.933, Run Time : 0.43
INFO:root:2019-05-10 23:05:14, Epoch : 1, Step : 5854, Training Loss : 0.30744, Training Acc : 0.883, Run Time : 0.90
INFO:root:2019-05-10 23:05:21, Epoch : 1, Step : 5855, Training Loss : 0.20089, Training Acc : 0.906, Run Time : 6.79
INFO:root:2019-05-10 23:05:22, Epoch : 1, Step : 5856, Training Loss : 0.17577, Training Acc : 0.939, Run Time : 0.83
INFO:root:2019-05-10 23:05:22, Epoch : 1, Step : 5857, Training Loss : 0.13173, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 23:05:24, Epoch : 1, Step : 5858, Training Loss : 0.25250, Training Acc : 0.894, Run Time : 1.84
INFO:root:2019-05-10 23:05:32, Epoch : 1, Step : 5859, Training Loss : 0.17522, Training Acc : 0.928, Run Time : 8.06
INFO:root:2019-05-10 23:05:32, Epoch : 1, Step : 5860, Training Loss : 0.16691, Training Acc : 0.933, Run Time : 0.56
INFO:root:2019-05-10 23:05:33, Epoch : 1, Step : 5861, Training Loss : 0.16884, Training Acc : 0.922, Run Time : 0.43
INFO:root:2019-05-10 23:05:35, Epoch : 1, Step : 5862, Training Loss : 0.12646, Training Acc : 0.961, Run Time : 1.78
INFO:root:2019-05-10 23:05:35, Epoch : 1, Step : 5863, Training Loss : 0.16809, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-10 23:05:45, Epoch : 1, Step : 5864, Training Loss : 0.22927, Training Acc : 0.911, Run Time : 9.75
INFO:root:2019-05-10 23:05:45, Epoch : 1, Step : 5865, Training Loss : 0.23161, Training Acc : 0.928, Run Time : 0.59
INFO:root:2019-05-10 23:05:46, Epoch : 1, Step : 5866, Training Loss : 0.12530, Training Acc : 0.956, Run Time : 0.48
INFO:root:2019-05-10 23:05:46, Epoch : 1, Step : 5867, Training Loss : 0.17599, Training Acc : 0.928, Run Time : 0.49
INFO:root:2019-05-10 23:05:54, Epoch : 1, Step : 5868, Training Loss : 0.15431, Training Acc : 0.928, Run Time : 7.81
INFO:root:2019-05-10 23:05:55, Epoch : 1, Step : 5869, Training Loss : 0.18639, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-10 23:05:55, Epoch : 1, Step : 5870, Training Loss : 0.14690, Training Acc : 0.933, Run Time : 0.68
INFO:root:2019-05-10 23:05:56, Epoch : 1, Step : 5871, Training Loss : 0.16084, Training Acc : 0.928, Run Time : 0.70
INFO:root:2019-05-10 23:06:03, Epoch : 1, Step : 5872, Training Loss : 0.22403, Training Acc : 0.878, Run Time : 7.40
INFO:root:2019-05-10 23:06:04, Epoch : 1, Step : 5873, Training Loss : 0.18112, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-10 23:06:06, Epoch : 1, Step : 5874, Training Loss : 0.12293, Training Acc : 0.950, Run Time : 1.74
INFO:root:2019-05-10 23:06:06, Epoch : 1, Step : 5875, Training Loss : 0.16500, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-10 23:06:15, Epoch : 1, Step : 5876, Training Loss : 0.18409, Training Acc : 0.906, Run Time : 9.32
INFO:root:2019-05-10 23:06:16, Epoch : 1, Step : 5877, Training Loss : 0.11591, Training Acc : 0.961, Run Time : 0.57
INFO:root:2019-05-10 23:06:16, Epoch : 1, Step : 5878, Training Loss : 0.14631, Training Acc : 0.956, Run Time : 0.42
INFO:root:2019-05-10 23:06:20, Epoch : 1, Step : 5879, Training Loss : 0.19898, Training Acc : 0.922, Run Time : 3.76
INFO:root:2019-05-10 23:06:21, Epoch : 1, Step : 5880, Training Loss : 0.12896, Training Acc : 0.956, Run Time : 0.94
INFO:root:2019-05-10 23:06:22, Epoch : 1, Step : 5881, Training Loss : 0.18108, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-10 23:06:31, Epoch : 1, Step : 5882, Training Loss : 0.15556, Training Acc : 0.928, Run Time : 8.95
INFO:root:2019-05-10 23:06:31, Epoch : 1, Step : 5883, Training Loss : 0.14752, Training Acc : 0.956, Run Time : 0.58
INFO:root:2019-05-10 23:06:32, Epoch : 1, Step : 5884, Training Loss : 0.18172, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 23:06:32, Epoch : 1, Step : 5885, Training Loss : 0.23961, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 23:06:42, Epoch : 1, Step : 5886, Training Loss : 0.14727, Training Acc : 0.944, Run Time : 9.66
INFO:root:2019-05-10 23:06:42, Epoch : 1, Step : 5887, Training Loss : 0.18023, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 23:06:43, Epoch : 1, Step : 5888, Training Loss : 0.12206, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-10 23:06:43, Epoch : 1, Step : 5889, Training Loss : 0.12807, Training Acc : 0.967, Run Time : 0.46
INFO:root:2019-05-10 23:06:46, Epoch : 1, Step : 5890, Training Loss : 0.10126, Training Acc : 0.983, Run Time : 2.53
INFO:root:2019-05-10 23:06:57, Epoch : 1, Step : 5891, Training Loss : 0.14815, Training Acc : 0.933, Run Time : 11.09
INFO:root:2019-05-10 23:06:57, Epoch : 1, Step : 5892, Training Loss : 0.12836, Training Acc : 0.967, Run Time : 0.28
INFO:root:2019-05-10 23:06:57, Epoch : 1, Step : 5893, Training Loss : 0.14543, Training Acc : 0.939, Run Time : 0.37
INFO:root:2019-05-10 23:06:58, Epoch : 1, Step : 5894, Training Loss : 0.10640, Training Acc : 0.972, Run Time : 0.46
INFO:root:2019-05-10 23:07:05, Epoch : 1, Step : 5895, Training Loss : 0.10914, Training Acc : 0.956, Run Time : 6.81
INFO:root:2019-05-10 23:07:12, Epoch : 1, Step : 5896, Training Loss : 0.12101, Training Acc : 0.961, Run Time : 7.35
INFO:root:2019-05-10 23:07:12, Epoch : 1, Step : 5897, Training Loss : 0.14605, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-10 23:07:13, Epoch : 1, Step : 5898, Training Loss : 0.12376, Training Acc : 0.950, Run Time : 0.66
INFO:root:2019-05-10 23:07:14, Epoch : 1, Step : 5899, Training Loss : 0.10751, Training Acc : 0.967, Run Time : 0.45
INFO:root:2019-05-10 23:07:23, Epoch : 1, Step : 5900, Training Loss : 0.11197, Training Acc : 0.972, Run Time : 9.40
INFO:root:2019-05-10 23:07:25, Epoch : 1, Step : 5901, Training Loss : 0.12753, Training Acc : 0.967, Run Time : 1.73
INFO:root:2019-05-10 23:07:32, Epoch : 1, Step : 5902, Training Loss : 0.15554, Training Acc : 0.944, Run Time : 7.20
INFO:root:2019-05-10 23:07:32, Epoch : 1, Step : 5903, Training Loss : 0.12103, Training Acc : 0.956, Run Time : 0.42
INFO:root:2019-05-10 23:07:33, Epoch : 1, Step : 5904, Training Loss : 0.14802, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-10 23:07:33, Epoch : 1, Step : 5905, Training Loss : 0.14265, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-10 23:07:34, Epoch : 1, Step : 5906, Training Loss : 0.14112, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 23:07:43, Epoch : 1, Step : 5907, Training Loss : 0.13409, Training Acc : 0.956, Run Time : 9.14
INFO:root:2019-05-10 23:07:43, Epoch : 1, Step : 5908, Training Loss : 0.12191, Training Acc : 0.967, Run Time : 0.50
INFO:root:2019-05-10 23:07:44, Epoch : 1, Step : 5909, Training Loss : 0.24228, Training Acc : 0.906, Run Time : 0.85
INFO:root:2019-05-10 23:07:45, Epoch : 1, Step : 5910, Training Loss : 0.49477, Training Acc : 0.828, Run Time : 0.47
INFO:root:2019-05-10 23:08:02, Epoch : 1, Step : 5911, Training Loss : 0.71744, Training Acc : 0.761, Run Time : 16.91
INFO:root:2019-05-10 23:08:02, Epoch : 1, Step : 5912, Training Loss : 0.80850, Training Acc : 0.744, Run Time : 0.33
INFO:root:2019-05-10 23:08:02, Epoch : 1, Step : 5913, Training Loss : 0.76505, Training Acc : 0.717, Run Time : 0.45
INFO:root:2019-05-10 23:08:04, Epoch : 1, Step : 5914, Training Loss : 0.60485, Training Acc : 0.794, Run Time : 1.44
INFO:root:2019-05-10 23:08:04, Epoch : 1, Step : 5915, Training Loss : 0.78761, Training Acc : 0.761, Run Time : 0.48
INFO:root:2019-05-10 23:08:12, Epoch : 1, Step : 5916, Training Loss : 0.54293, Training Acc : 0.811, Run Time : 7.73
INFO:root:2019-05-10 23:08:12, Epoch : 1, Step : 5917, Training Loss : 0.53094, Training Acc : 0.789, Run Time : 0.48
INFO:root:2019-05-10 23:08:13, Epoch : 1, Step : 5918, Training Loss : 0.54978, Training Acc : 0.806, Run Time : 0.77
INFO:root:2019-05-10 23:08:14, Epoch : 1, Step : 5919, Training Loss : 0.42789, Training Acc : 0.817, Run Time : 0.39
INFO:root:2019-05-10 23:08:30, Epoch : 1, Step : 5920, Training Loss : 0.32275, Training Acc : 0.894, Run Time : 16.85
INFO:root:2019-05-10 23:08:31, Epoch : 1, Step : 5921, Training Loss : 0.52961, Training Acc : 0.800, Run Time : 0.24
INFO:root:2019-05-10 23:08:31, Epoch : 1, Step : 5922, Training Loss : 0.56302, Training Acc : 0.767, Run Time : 0.43
INFO:root:2019-05-10 23:08:32, Epoch : 1, Step : 5923, Training Loss : 0.57801, Training Acc : 0.783, Run Time : 0.53
INFO:root:2019-05-10 23:08:32, Epoch : 1, Step : 5924, Training Loss : 0.33352, Training Acc : 0.839, Run Time : 0.59
INFO:root:2019-05-10 23:08:46, Epoch : 1, Step : 5925, Training Loss : 0.36033, Training Acc : 0.833, Run Time : 13.55
INFO:root:2019-05-10 23:08:46, Epoch : 1, Step : 5926, Training Loss : 0.37466, Training Acc : 0.833, Run Time : 0.24
INFO:root:2019-05-10 23:08:46, Epoch : 1, Step : 5927, Training Loss : 0.39483, Training Acc : 0.806, Run Time : 0.44
INFO:root:2019-05-10 23:08:48, Epoch : 1, Step : 5928, Training Loss : 0.41770, Training Acc : 0.800, Run Time : 1.74
INFO:root:2019-05-10 23:08:51, Epoch : 1, Step : 5929, Training Loss : 0.48946, Training Acc : 0.761, Run Time : 3.17
INFO:root:2019-05-10 23:08:52, Epoch : 1, Step : 5930, Training Loss : 0.33223, Training Acc : 0.850, Run Time : 0.53
INFO:root:2019-05-10 23:08:52, Epoch : 1, Step : 5931, Training Loss : 0.34994, Training Acc : 0.828, Run Time : 0.48
INFO:root:2019-05-10 23:09:01, Epoch : 1, Step : 5932, Training Loss : 0.44630, Training Acc : 0.789, Run Time : 8.62
INFO:root:2019-05-10 23:09:01, Epoch : 1, Step : 5933, Training Loss : 0.44635, Training Acc : 0.783, Run Time : 0.50
INFO:root:2019-05-10 23:09:02, Epoch : 1, Step : 5934, Training Loss : 0.37906, Training Acc : 0.839, Run Time : 0.46
INFO:root:2019-05-10 23:09:02, Epoch : 1, Step : 5935, Training Loss : 0.36783, Training Acc : 0.828, Run Time : 0.45
INFO:root:2019-05-10 23:09:14, Epoch : 1, Step : 5936, Training Loss : 0.30792, Training Acc : 0.844, Run Time : 11.86
INFO:root:2019-05-10 23:09:15, Epoch : 1, Step : 5937, Training Loss : 0.34181, Training Acc : 0.833, Run Time : 0.33
INFO:root:2019-05-10 23:09:15, Epoch : 1, Step : 5938, Training Loss : 0.53237, Training Acc : 0.817, Run Time : 0.47
INFO:root:2019-05-10 23:09:16, Epoch : 1, Step : 5939, Training Loss : 0.45891, Training Acc : 0.828, Run Time : 0.61
INFO:root:2019-05-10 23:09:16, Epoch : 1, Step : 5940, Training Loss : 0.72803, Training Acc : 0.756, Run Time : 0.49
INFO:root:2019-05-10 23:09:31, Epoch : 1, Step : 5941, Training Loss : 0.69659, Training Acc : 0.772, Run Time : 15.08
INFO:root:2019-05-10 23:09:32, Epoch : 1, Step : 5942, Training Loss : 0.58076, Training Acc : 0.783, Run Time : 0.36
INFO:root:2019-05-10 23:09:32, Epoch : 1, Step : 5943, Training Loss : 0.49157, Training Acc : 0.833, Run Time : 0.36
INFO:root:2019-05-10 23:09:32, Epoch : 1, Step : 5944, Training Loss : 0.34446, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-10 23:09:33, Epoch : 1, Step : 5945, Training Loss : 0.25138, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-10 23:09:49, Epoch : 1, Step : 5946, Training Loss : 0.41824, Training Acc : 0.844, Run Time : 16.05
INFO:root:2019-05-10 23:09:49, Epoch : 1, Step : 5947, Training Loss : 0.25979, Training Acc : 0.872, Run Time : 0.28
INFO:root:2019-05-10 23:09:50, Epoch : 1, Step : 5948, Training Loss : 0.10196, Training Acc : 0.961, Run Time : 0.45
INFO:root:2019-05-10 23:09:53, Epoch : 1, Step : 5949, Training Loss : 0.13432, Training Acc : 0.944, Run Time : 2.94
INFO:root:2019-05-10 23:09:53, Epoch : 1, Step : 5950, Training Loss : 0.17773, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-10 23:09:59, Epoch : 1, Step : 5951, Training Loss : 0.07477, Training Acc : 0.978, Run Time : 5.98
INFO:root:2019-05-10 23:10:00, Epoch : 1, Step : 5952, Training Loss : 0.21348, Training Acc : 0.911, Run Time : 0.65
INFO:root:2019-05-10 23:10:00, Epoch : 1, Step : 5953, Training Loss : 0.17267, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-10 23:10:01, Epoch : 1, Step : 5954, Training Loss : 0.13179, Training Acc : 0.961, Run Time : 0.46
INFO:root:2019-05-10 23:10:08, Epoch : 1, Step : 5955, Training Loss : 0.18240, Training Acc : 0.917, Run Time : 7.46
INFO:root:2019-05-10 23:10:09, Epoch : 1, Step : 5956, Training Loss : 0.10827, Training Acc : 0.967, Run Time : 0.45
INFO:root:2019-05-10 23:10:09, Epoch : 1, Step : 5957, Training Loss : 0.14471, Training Acc : 0.922, Run Time : 0.61
INFO:root:2019-05-10 23:10:10, Epoch : 1, Step : 5958, Training Loss : 0.13963, Training Acc : 0.939, Run Time : 0.50
INFO:root:2019-05-10 23:10:19, Epoch : 1, Step : 5959, Training Loss : 0.10354, Training Acc : 0.956, Run Time : 9.43
INFO:root:2019-05-10 23:10:20, Epoch : 1, Step : 5960, Training Loss : 0.13059, Training Acc : 0.961, Run Time : 0.59
INFO:root:2019-05-10 23:10:20, Epoch : 1, Step : 5961, Training Loss : 0.13968, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-10 23:10:31, Epoch : 1, Step : 5962, Training Loss : 0.18869, Training Acc : 0.928, Run Time : 10.50
INFO:root:2019-05-10 23:10:32, Epoch : 1, Step : 5963, Training Loss : 0.15202, Training Acc : 0.939, Run Time : 1.15
INFO:root:2019-05-10 23:10:32, Epoch : 1, Step : 5964, Training Loss : 0.16250, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-10 23:10:33, Epoch : 1, Step : 5965, Training Loss : 0.13219, Training Acc : 0.933, Run Time : 0.45
INFO:root:2019-05-10 23:10:34, Epoch : 1, Step : 5966, Training Loss : 0.13369, Training Acc : 0.928, Run Time : 1.67
INFO:root:2019-05-10 23:10:36, Epoch : 1, Step : 5967, Training Loss : 0.12521, Training Acc : 0.922, Run Time : 1.28
INFO:root:2019-05-10 23:10:43, Epoch : 1, Step : 5968, Training Loss : 0.07965, Training Acc : 0.972, Run Time : 6.97
INFO:root:2019-05-10 23:10:43, Epoch : 1, Step : 5969, Training Loss : 0.10319, Training Acc : 0.967, Run Time : 0.48
INFO:root:2019-05-10 23:10:44, Epoch : 1, Step : 5970, Training Loss : 0.14307, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-10 23:10:46, Epoch : 1, Step : 5971, Training Loss : 0.14179, Training Acc : 0.911, Run Time : 2.09
INFO:root:2019-05-10 23:10:53, Epoch : 1, Step : 5972, Training Loss : 0.17878, Training Acc : 0.922, Run Time : 7.53
INFO:root:2019-05-10 23:10:54, Epoch : 1, Step : 5973, Training Loss : 0.16657, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-10 23:10:54, Epoch : 1, Step : 5974, Training Loss : 0.14403, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 23:11:04, Epoch : 1, Step : 5975, Training Loss : 0.07418, Training Acc : 0.967, Run Time : 9.99
INFO:root:2019-05-10 23:11:05, Epoch : 1, Step : 5976, Training Loss : 0.15236, Training Acc : 0.933, Run Time : 0.59
INFO:root:2019-05-10 23:11:05, Epoch : 1, Step : 5977, Training Loss : 0.10483, Training Acc : 0.972, Run Time : 0.48
INFO:root:2019-05-10 23:11:06, Epoch : 1, Step : 5978, Training Loss : 0.05645, Training Acc : 0.983, Run Time : 0.44
INFO:root:2019-05-10 23:11:06, Epoch : 1, Step : 5979, Training Loss : 0.07581, Training Acc : 0.967, Run Time : 0.45
INFO:root:2019-05-10 23:11:17, Epoch : 1, Step : 5980, Training Loss : 0.12241, Training Acc : 0.944, Run Time : 10.71
INFO:root:2019-05-10 23:11:17, Epoch : 1, Step : 5981, Training Loss : 0.04568, Training Acc : 0.989, Run Time : 0.36
INFO:root:2019-05-10 23:11:18, Epoch : 1, Step : 5982, Training Loss : 0.08817, Training Acc : 0.967, Run Time : 0.47
INFO:root:2019-05-10 23:11:18, Epoch : 1, Step : 5983, Training Loss : 0.08906, Training Acc : 0.961, Run Time : 0.43
INFO:root:2019-05-10 23:11:21, Epoch : 1, Step : 5984, Training Loss : 0.05867, Training Acc : 0.983, Run Time : 3.50
INFO:root:2019-05-10 23:11:22, Epoch : 1, Step : 5985, Training Loss : 0.08922, Training Acc : 0.961, Run Time : 0.63
INFO:root:2019-05-10 23:11:33, Epoch : 1, Step : 5986, Training Loss : 0.10121, Training Acc : 0.956, Run Time : 10.67
INFO:root:2019-05-10 23:11:33, Epoch : 1, Step : 5987, Training Loss : 0.10764, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 23:11:34, Epoch : 1, Step : 5988, Training Loss : 0.09485, Training Acc : 0.961, Run Time : 0.69
INFO:root:2019-05-10 23:11:34, Epoch : 1, Step : 5989, Training Loss : 0.06472, Training Acc : 0.989, Run Time : 0.30
INFO:root:2019-05-10 23:11:35, Epoch : 1, Step : 5990, Training Loss : 0.17598, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-10 23:11:43, Epoch : 1, Step : 5991, Training Loss : 0.08988, Training Acc : 0.961, Run Time : 8.22
INFO:root:2019-05-10 23:11:43, Epoch : 1, Step : 5992, Training Loss : 0.08404, Training Acc : 0.983, Run Time : 0.43
INFO:root:2019-05-10 23:11:44, Epoch : 1, Step : 5993, Training Loss : 0.11468, Training Acc : 0.956, Run Time : 0.63
INFO:root:2019-05-10 23:11:44, Epoch : 1, Step : 5994, Training Loss : 0.11283, Training Acc : 0.956, Run Time : 0.43
INFO:root:2019-05-10 23:11:54, Epoch : 1, Step : 5995, Training Loss : 0.10607, Training Acc : 0.961, Run Time : 9.55
INFO:root:2019-05-10 23:11:54, Epoch : 1, Step : 5996, Training Loss : 0.12962, Training Acc : 0.933, Run Time : 0.39
INFO:root:2019-05-10 23:11:55, Epoch : 1, Step : 5997, Training Loss : 0.06981, Training Acc : 0.978, Run Time : 0.48
INFO:root:2019-05-10 23:11:55, Epoch : 1, Step : 5998, Training Loss : 0.11277, Training Acc : 0.961, Run Time : 0.46
INFO:root:2019-05-10 23:12:09, Epoch : 1, Step : 5999, Training Loss : 0.09988, Training Acc : 0.961, Run Time : 13.84
INFO:root:2019-05-10 23:12:09, Epoch : 1, Step : 6000, Training Loss : 0.07434, Training Acc : 0.989, Run Time : 0.24
INFO:root:2019-05-10 23:12:10, Epoch : 1, Step : 6001, Training Loss : 0.53717, Training Acc : 0.817, Run Time : 0.91
INFO:root:2019-05-10 23:12:11, Epoch : 1, Step : 6002, Training Loss : 0.47031, Training Acc : 0.800, Run Time : 0.47
INFO:root:2019-05-10 23:12:11, Epoch : 1, Step : 6003, Training Loss : 0.35543, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-10 23:12:23, Epoch : 1, Step : 6004, Training Loss : 0.57842, Training Acc : 0.761, Run Time : 12.11
INFO:root:2019-05-10 23:12:24, Epoch : 1, Step : 6005, Training Loss : 0.66239, Training Acc : 0.767, Run Time : 0.72
INFO:root:2019-05-10 23:12:25, Epoch : 1, Step : 6006, Training Loss : 0.61340, Training Acc : 0.744, Run Time : 0.47
INFO:root:2019-05-10 23:12:32, Epoch : 1, Step : 6007, Training Loss : 0.33375, Training Acc : 0.872, Run Time : 7.79
INFO:root:2019-05-10 23:12:33, Epoch : 1, Step : 6008, Training Loss : 0.61923, Training Acc : 0.850, Run Time : 1.07
INFO:root:2019-05-10 23:12:34, Epoch : 1, Step : 6009, Training Loss : 0.42993, Training Acc : 0.833, Run Time : 0.45
INFO:root:2019-05-10 23:12:48, Epoch : 1, Step : 6010, Training Loss : 0.52919, Training Acc : 0.844, Run Time : 14.31
INFO:root:2019-05-10 23:12:49, Epoch : 1, Step : 6011, Training Loss : 0.60264, Training Acc : 0.844, Run Time : 0.99
INFO:root:2019-05-10 23:12:50, Epoch : 1, Step : 6012, Training Loss : 0.31010, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-10 23:12:50, Epoch : 1, Step : 6013, Training Loss : 0.24374, Training Acc : 0.900, Run Time : 0.44
INFO:root:2019-05-10 23:12:51, Epoch : 1, Step : 6014, Training Loss : 0.27325, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 23:13:04, Epoch : 1, Step : 6015, Training Loss : 0.30206, Training Acc : 0.856, Run Time : 13.74
INFO:root:2019-05-10 23:13:05, Epoch : 1, Step : 6016, Training Loss : 0.35949, Training Acc : 0.889, Run Time : 0.83
INFO:root:2019-05-10 23:13:06, Epoch : 1, Step : 6017, Training Loss : 0.19352, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-10 23:13:06, Epoch : 1, Step : 6018, Training Loss : 0.10908, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-10 23:13:16, Epoch : 1, Step : 6019, Training Loss : 0.21789, Training Acc : 0.900, Run Time : 10.41
INFO:root:2019-05-10 23:13:17, Epoch : 1, Step : 6020, Training Loss : 0.18891, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 23:13:17, Epoch : 1, Step : 6021, Training Loss : 0.25238, Training Acc : 0.900, Run Time : 0.40
INFO:root:2019-05-10 23:13:18, Epoch : 1, Step : 6022, Training Loss : 0.25514, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 23:13:18, Epoch : 1, Step : 6023, Training Loss : 0.17471, Training Acc : 0.939, Run Time : 0.58
INFO:root:2019-05-10 23:13:26, Epoch : 1, Step : 6024, Training Loss : 0.12599, Training Acc : 0.956, Run Time : 7.16
INFO:root:2019-05-10 23:13:26, Epoch : 1, Step : 6025, Training Loss : 0.07318, Training Acc : 0.983, Run Time : 0.47
INFO:root:2019-05-10 23:13:33, Epoch : 1, Step : 6026, Training Loss : 0.28968, Training Acc : 0.917, Run Time : 6.84
INFO:root:2019-05-10 23:13:33, Epoch : 1, Step : 6027, Training Loss : 0.21519, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-10 23:13:34, Epoch : 1, Step : 6028, Training Loss : 0.11195, Training Acc : 0.967, Run Time : 0.60
INFO:root:2019-05-10 23:13:34, Epoch : 1, Step : 6029, Training Loss : 0.24389, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 23:13:47, Epoch : 1, Step : 6030, Training Loss : 0.13041, Training Acc : 0.961, Run Time : 12.99
INFO:root:2019-05-10 23:13:48, Epoch : 1, Step : 6031, Training Loss : 0.27394, Training Acc : 0.900, Run Time : 0.32
INFO:root:2019-05-10 23:13:48, Epoch : 1, Step : 6032, Training Loss : 0.25325, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-10 23:13:48, Epoch : 1, Step : 6033, Training Loss : 0.13333, Training Acc : 0.972, Run Time : 0.40
INFO:root:2019-05-10 23:14:01, Epoch : 1, Step : 6034, Training Loss : 0.08792, Training Acc : 0.967, Run Time : 12.76
INFO:root:2019-05-10 23:14:02, Epoch : 1, Step : 6035, Training Loss : 0.24612, Training Acc : 0.889, Run Time : 0.61
INFO:root:2019-05-10 23:14:02, Epoch : 1, Step : 6036, Training Loss : 0.14889, Training Acc : 0.939, Run Time : 0.47
INFO:root:2019-05-10 23:14:03, Epoch : 1, Step : 6037, Training Loss : 0.17815, Training Acc : 0.933, Run Time : 0.49
INFO:root:2019-05-10 23:14:03, Epoch : 1, Step : 6038, Training Loss : 0.19819, Training Acc : 0.933, Run Time : 0.47
INFO:root:2019-05-10 23:14:12, Epoch : 1, Step : 6039, Training Loss : 0.37498, Training Acc : 0.856, Run Time : 8.69
INFO:root:2019-05-10 23:14:12, Epoch : 1, Step : 6040, Training Loss : 0.23831, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-10 23:14:14, Epoch : 1, Step : 6041, Training Loss : 0.16847, Training Acc : 0.933, Run Time : 1.42
INFO:root:2019-05-10 23:14:14, Epoch : 1, Step : 6042, Training Loss : 0.25109, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-10 23:14:28, Epoch : 1, Step : 6043, Training Loss : 0.39800, Training Acc : 0.878, Run Time : 13.53
INFO:root:2019-05-10 23:14:30, Epoch : 1, Step : 6044, Training Loss : 0.30380, Training Acc : 0.906, Run Time : 1.77
INFO:root:2019-05-10 23:14:30, Epoch : 1, Step : 6045, Training Loss : 0.30136, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-10 23:14:31, Epoch : 1, Step : 6046, Training Loss : 0.11491, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-10 23:14:31, Epoch : 1, Step : 6047, Training Loss : 0.17461, Training Acc : 0.917, Run Time : 0.49
INFO:root:2019-05-10 23:14:40, Epoch : 1, Step : 6048, Training Loss : 0.17544, Training Acc : 0.939, Run Time : 9.25
INFO:root:2019-05-10 23:14:41, Epoch : 1, Step : 6049, Training Loss : 0.11674, Training Acc : 0.978, Run Time : 0.72
INFO:root:2019-05-10 23:14:41, Epoch : 1, Step : 6050, Training Loss : 0.12118, Training Acc : 0.956, Run Time : 0.48
INFO:root:2019-05-10 23:14:43, Epoch : 1, Step : 6051, Training Loss : 0.09310, Training Acc : 0.967, Run Time : 1.35
INFO:root:2019-05-10 23:14:45, Epoch : 1, Step : 6052, Training Loss : 0.18530, Training Acc : 0.911, Run Time : 2.30
INFO:root:2019-05-10 23:14:55, Epoch : 1, Step : 6053, Training Loss : 0.21114, Training Acc : 0.933, Run Time : 9.80
INFO:root:2019-05-10 23:14:55, Epoch : 1, Step : 6054, Training Loss : 0.18213, Training Acc : 0.944, Run Time : 0.40
INFO:root:2019-05-10 23:14:56, Epoch : 1, Step : 6055, Training Loss : 0.25683, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 23:14:56, Epoch : 1, Step : 6056, Training Loss : 0.40285, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-10 23:15:03, Epoch : 1, Step : 6057, Training Loss : 0.18027, Training Acc : 0.933, Run Time : 6.42
INFO:root:2019-05-10 23:15:03, Epoch : 1, Step : 6058, Training Loss : 0.28243, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-10 23:15:04, Epoch : 1, Step : 6059, Training Loss : 0.31645, Training Acc : 0.894, Run Time : 1.16
INFO:root:2019-05-10 23:15:21, Epoch : 1, Step : 6060, Training Loss : 0.23134, Training Acc : 0.928, Run Time : 16.34
INFO:root:2019-05-10 23:15:22, Epoch : 1, Step : 6061, Training Loss : 0.12447, Training Acc : 0.933, Run Time : 0.92
INFO:root:2019-05-10 23:15:27, Epoch : 1, Step : 6062, Training Loss : 0.16956, Training Acc : 0.928, Run Time : 5.69
INFO:root:2019-05-10 23:15:31, Epoch : 1, Step : 6063, Training Loss : 0.05809, Training Acc : 0.989, Run Time : 3.36
INFO:root:2019-05-10 23:15:31, Epoch : 1, Step : 6064, Training Loss : 0.13326, Training Acc : 0.967, Run Time : 0.27
INFO:root:2019-05-10 23:15:31, Epoch : 1, Step : 6065, Training Loss : 0.08450, Training Acc : 0.978, Run Time : 0.46
INFO:root:2019-05-10 23:15:32, Epoch : 1, Step : 6066, Training Loss : 0.04376, Training Acc : 0.994, Run Time : 0.45
INFO:root:2019-05-10 23:15:32, Epoch : 1, Step : 6067, Training Loss : 0.22585, Training Acc : 0.906, Run Time : 0.50
INFO:root:2019-05-10 23:15:52, Epoch : 1, Step : 6068, Training Loss : 0.26271, Training Acc : 0.889, Run Time : 19.28
INFO:root:2019-05-10 23:15:54, Epoch : 1, Step : 6069, Training Loss : 0.20465, Training Acc : 0.933, Run Time : 1.99
INFO:root:2019-05-10 23:15:54, Epoch : 1, Step : 6070, Training Loss : 0.13880, Training Acc : 0.950, Run Time : 0.50
INFO:root:2019-05-10 23:15:55, Epoch : 1, Step : 6071, Training Loss : 0.26831, Training Acc : 0.906, Run Time : 0.45
INFO:root:2019-05-10 23:16:06, Epoch : 1, Step : 6072, Training Loss : 0.10615, Training Acc : 0.961, Run Time : 11.14
INFO:root:2019-05-10 23:16:06, Epoch : 1, Step : 6073, Training Loss : 0.17147, Training Acc : 0.928, Run Time : 0.49
INFO:root:2019-05-10 23:16:07, Epoch : 1, Step : 6074, Training Loss : 0.07933, Training Acc : 0.978, Run Time : 1.05
INFO:root:2019-05-10 23:16:13, Epoch : 1, Step : 6075, Training Loss : 0.14128, Training Acc : 0.967, Run Time : 5.67
INFO:root:2019-05-10 23:16:13, Epoch : 1, Step : 6076, Training Loss : 0.22107, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-10 23:16:14, Epoch : 1, Step : 6077, Training Loss : 0.28700, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-10 23:16:14, Epoch : 1, Step : 6078, Training Loss : 0.09069, Training Acc : 0.967, Run Time : 0.46
INFO:root:2019-05-10 23:16:16, Epoch : 1, Step : 6079, Training Loss : 0.35781, Training Acc : 0.889, Run Time : 1.75
INFO:root:2019-05-10 23:16:24, Epoch : 1, Step : 6080, Training Loss : 0.31339, Training Acc : 0.889, Run Time : 7.64
INFO:root:2019-05-10 23:16:24, Epoch : 1, Step : 6081, Training Loss : 0.26260, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 23:16:25, Epoch : 1, Step : 6082, Training Loss : 0.18367, Training Acc : 0.933, Run Time : 0.84
INFO:root:2019-05-10 23:16:26, Epoch : 1, Step : 6083, Training Loss : 0.13524, Training Acc : 0.939, Run Time : 1.29
INFO:root:2019-05-10 23:16:37, Epoch : 1, Step : 6084, Training Loss : 0.13526, Training Acc : 0.961, Run Time : 11.20
INFO:root:2019-05-10 23:16:38, Epoch : 1, Step : 6085, Training Loss : 0.16480, Training Acc : 0.939, Run Time : 0.70
INFO:root:2019-05-10 23:16:39, Epoch : 1, Step : 6086, Training Loss : 0.25952, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-10 23:16:39, Epoch : 1, Step : 6087, Training Loss : 0.23873, Training Acc : 0.906, Run Time : 0.45
INFO:root:2019-05-10 23:16:40, Epoch : 1, Step : 6088, Training Loss : 0.19124, Training Acc : 0.928, Run Time : 0.94
INFO:root:2019-05-10 23:16:43, Epoch : 1, Step : 6089, Training Loss : 0.15876, Training Acc : 0.917, Run Time : 2.90
INFO:root:2019-05-10 23:17:02, Epoch : 1, Step : 6090, Training Loss : 0.10560, Training Acc : 0.961, Run Time : 18.99
INFO:root:2019-05-10 23:17:02, Epoch : 1, Step : 6091, Training Loss : 0.17300, Training Acc : 0.939, Run Time : 0.54
INFO:root:2019-05-10 23:17:03, Epoch : 1, Step : 6092, Training Loss : 0.26526, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-10 23:17:03, Epoch : 1, Step : 6093, Training Loss : 0.15862, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 23:17:04, Epoch : 1, Step : 6094, Training Loss : 0.24673, Training Acc : 0.867, Run Time : 0.63
INFO:root:2019-05-10 23:17:23, Epoch : 1, Step : 6095, Training Loss : 0.32343, Training Acc : 0.906, Run Time : 19.00
INFO:root:2019-05-10 23:17:23, Epoch : 1, Step : 6096, Training Loss : 0.20177, Training Acc : 0.917, Run Time : 0.32
INFO:root:2019-05-10 23:17:24, Epoch : 1, Step : 6097, Training Loss : 0.35331, Training Acc : 0.833, Run Time : 0.42
INFO:root:2019-05-10 23:17:24, Epoch : 1, Step : 6098, Training Loss : 0.17064, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-10 23:17:25, Epoch : 1, Step : 6099, Training Loss : 0.09972, Training Acc : 0.972, Run Time : 0.49
INFO:root:2019-05-10 23:17:40, Epoch : 1, Step : 6100, Training Loss : 0.15309, Training Acc : 0.950, Run Time : 15.60
INFO:root:2019-05-10 23:17:42, Epoch : 1, Step : 6101, Training Loss : 0.20811, Training Acc : 0.917, Run Time : 2.03
INFO:root:2019-05-10 23:17:43, Epoch : 1, Step : 6102, Training Loss : 0.13462, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 23:17:43, Epoch : 1, Step : 6103, Training Loss : 0.22808, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 23:17:44, Epoch : 1, Step : 6104, Training Loss : 0.17842, Training Acc : 0.922, Run Time : 0.51
INFO:root:2019-05-10 23:17:51, Epoch : 1, Step : 6105, Training Loss : 0.19389, Training Acc : 0.933, Run Time : 7.10
INFO:root:2019-05-10 23:17:51, Epoch : 1, Step : 6106, Training Loss : 0.21062, Training Acc : 0.906, Run Time : 0.43
INFO:root:2019-05-10 23:17:53, Epoch : 1, Step : 6107, Training Loss : 0.25961, Training Acc : 0.900, Run Time : 1.55
INFO:root:2019-05-10 23:17:53, Epoch : 1, Step : 6108, Training Loss : 0.29108, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-10 23:18:03, Epoch : 1, Step : 6109, Training Loss : 0.22854, Training Acc : 0.900, Run Time : 10.01
INFO:root:2019-05-10 23:18:04, Epoch : 1, Step : 6110, Training Loss : 0.13029, Training Acc : 0.944, Run Time : 0.36
INFO:root:2019-05-10 23:18:04, Epoch : 1, Step : 6111, Training Loss : 0.12303, Training Acc : 0.961, Run Time : 0.52
INFO:root:2019-05-10 23:18:05, Epoch : 1, Step : 6112, Training Loss : 0.18897, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-10 23:18:15, Epoch : 1, Step : 6113, Training Loss : 0.22137, Training Acc : 0.894, Run Time : 10.21
INFO:root:2019-05-10 23:18:15, Epoch : 1, Step : 6114, Training Loss : 0.17815, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-10 23:18:16, Epoch : 1, Step : 6115, Training Loss : 0.26536, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-10 23:18:16, Epoch : 1, Step : 6116, Training Loss : 0.61813, Training Acc : 0.744, Run Time : 0.49
INFO:root:2019-05-10 23:18:27, Epoch : 1, Step : 6117, Training Loss : 0.27236, Training Acc : 0.906, Run Time : 11.21
INFO:root:2019-05-10 23:18:28, Epoch : 1, Step : 6118, Training Loss : 0.22647, Training Acc : 0.917, Run Time : 0.32
INFO:root:2019-05-10 23:18:28, Epoch : 1, Step : 6119, Training Loss : 0.25311, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 23:18:29, Epoch : 1, Step : 6120, Training Loss : 0.13416, Training Acc : 0.967, Run Time : 0.57
INFO:root:2019-05-10 23:18:30, Epoch : 1, Step : 6121, Training Loss : 0.18276, Training Acc : 0.939, Run Time : 1.30
INFO:root:2019-05-10 23:18:33, Epoch : 1, Step : 6122, Training Loss : 0.19316, Training Acc : 0.928, Run Time : 3.19
INFO:root:2019-05-10 23:18:34, Epoch : 1, Step : 6123, Training Loss : 0.21303, Training Acc : 0.917, Run Time : 0.79
INFO:root:2019-05-10 23:18:45, Epoch : 1, Step : 6124, Training Loss : 0.14401, Training Acc : 0.950, Run Time : 11.41
INFO:root:2019-05-10 23:18:46, Epoch : 1, Step : 6125, Training Loss : 0.36620, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-10 23:18:53, Epoch : 1, Step : 6126, Training Loss : 0.09092, Training Acc : 0.978, Run Time : 6.81
INFO:root:2019-05-10 23:18:53, Epoch : 1, Step : 6127, Training Loss : 0.23602, Training Acc : 0.928, Run Time : 0.32
INFO:root:2019-05-10 23:18:53, Epoch : 1, Step : 6128, Training Loss : 0.19883, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-10 23:18:59, Epoch : 1, Step : 6129, Training Loss : 0.20161, Training Acc : 0.922, Run Time : 5.57
INFO:root:2019-05-10 23:19:00, Epoch : 1, Step : 6130, Training Loss : 0.29248, Training Acc : 0.894, Run Time : 0.50
INFO:root:2019-05-10 23:19:00, Epoch : 1, Step : 6131, Training Loss : 0.27293, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-10 23:19:02, Epoch : 1, Step : 6132, Training Loss : 0.29599, Training Acc : 0.878, Run Time : 1.61
INFO:root:2019-05-10 23:19:14, Epoch : 1, Step : 6133, Training Loss : 0.14958, Training Acc : 0.950, Run Time : 12.65
INFO:root:2019-05-10 23:19:15, Epoch : 1, Step : 6134, Training Loss : 0.11808, Training Acc : 0.950, Run Time : 0.64
INFO:root:2019-05-10 23:19:15, Epoch : 1, Step : 6135, Training Loss : 0.24344, Training Acc : 0.906, Run Time : 0.62
INFO:root:2019-05-10 23:19:23, Epoch : 1, Step : 6136, Training Loss : 0.07937, Training Acc : 0.967, Run Time : 7.32
INFO:root:2019-05-10 23:19:25, Epoch : 1, Step : 6137, Training Loss : 0.17863, Training Acc : 0.933, Run Time : 2.39
INFO:root:2019-05-10 23:19:26, Epoch : 1, Step : 6138, Training Loss : 0.19954, Training Acc : 0.906, Run Time : 0.49
INFO:root:2019-05-10 23:19:26, Epoch : 1, Step : 6139, Training Loss : 0.11226, Training Acc : 0.961, Run Time : 0.43
INFO:root:2019-05-10 23:19:27, Epoch : 1, Step : 6140, Training Loss : 0.18712, Training Acc : 0.939, Run Time : 0.56
INFO:root:2019-05-10 23:19:30, Epoch : 1, Step : 6141, Training Loss : 0.13518, Training Acc : 0.944, Run Time : 3.22
INFO:root:2019-05-10 23:19:31, Epoch : 1, Step : 6142, Training Loss : 0.17024, Training Acc : 0.939, Run Time : 1.01
INFO:root:2019-05-10 23:19:36, Epoch : 1, Step : 6143, Training Loss : 0.10397, Training Acc : 0.961, Run Time : 4.75
INFO:root:2019-05-10 23:19:41, Epoch : 1, Step : 6144, Training Loss : 0.13316, Training Acc : 0.950, Run Time : 5.79
INFO:root:2019-05-10 23:19:42, Epoch : 1, Step : 6145, Training Loss : 0.14556, Training Acc : 0.944, Run Time : 0.82
INFO:root:2019-05-10 23:19:43, Epoch : 1, Step : 6146, Training Loss : 0.20919, Training Acc : 0.933, Run Time : 0.45
INFO:root:2019-05-10 23:20:00, Epoch : 1, Step : 6147, Training Loss : 0.13567, Training Acc : 0.956, Run Time : 17.17
INFO:root:2019-05-10 23:20:00, Epoch : 1, Step : 6148, Training Loss : 0.18829, Training Acc : 0.933, Run Time : 0.24
INFO:root:2019-05-10 23:20:01, Epoch : 1, Step : 6149, Training Loss : 0.41267, Training Acc : 0.817, Run Time : 0.45
INFO:root:2019-05-10 23:20:01, Epoch : 1, Step : 6150, Training Loss : 0.36251, Training Acc : 0.844, Run Time : 0.45
INFO:root:2019-05-10 23:20:01, Epoch : 1, Step : 6151, Training Loss : 0.26445, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-10 23:20:06, Epoch : 1, Step : 6152, Training Loss : 0.18940, Training Acc : 0.922, Run Time : 4.57
INFO:root:2019-05-10 23:20:06, Epoch : 1, Step : 6153, Training Loss : 0.35496, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 23:20:23, Epoch : 1, Step : 6154, Training Loss : 0.10436, Training Acc : 0.972, Run Time : 16.35
INFO:root:2019-05-10 23:20:23, Epoch : 1, Step : 6155, Training Loss : 0.12552, Training Acc : 0.972, Run Time : 0.29
INFO:root:2019-05-10 23:20:24, Epoch : 1, Step : 6156, Training Loss : 0.30068, Training Acc : 0.872, Run Time : 0.45
INFO:root:2019-05-10 23:20:24, Epoch : 1, Step : 6157, Training Loss : 0.18023, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-10 23:20:25, Epoch : 1, Step : 6158, Training Loss : 0.09579, Training Acc : 0.972, Run Time : 0.51
INFO:root:2019-05-10 23:20:37, Epoch : 1, Step : 6159, Training Loss : 0.26433, Training Acc : 0.906, Run Time : 12.22
INFO:root:2019-05-10 23:20:37, Epoch : 1, Step : 6160, Training Loss : 0.26986, Training Acc : 0.917, Run Time : 0.51
INFO:root:2019-05-10 23:20:39, Epoch : 1, Step : 6161, Training Loss : 0.37635, Training Acc : 0.822, Run Time : 1.28
INFO:root:2019-05-10 23:20:45, Epoch : 1, Step : 6162, Training Loss : 0.30586, Training Acc : 0.911, Run Time : 6.07
INFO:root:2019-05-10 23:20:46, Epoch : 1, Step : 6163, Training Loss : 0.30477, Training Acc : 0.872, Run Time : 1.50
INFO:root:2019-05-10 23:20:55, Epoch : 1, Step : 6164, Training Loss : 0.26169, Training Acc : 0.894, Run Time : 8.81
INFO:root:2019-05-10 23:20:55, Epoch : 1, Step : 6165, Training Loss : 0.18243, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-10 23:20:56, Epoch : 1, Step : 6166, Training Loss : 0.37362, Training Acc : 0.883, Run Time : 0.60
INFO:root:2019-05-10 23:20:56, Epoch : 1, Step : 6167, Training Loss : 0.15491, Training Acc : 0.950, Run Time : 0.30
INFO:root:2019-05-10 23:21:05, Epoch : 1, Step : 6168, Training Loss : 0.23754, Training Acc : 0.894, Run Time : 9.09
INFO:root:2019-05-10 23:21:06, Epoch : 1, Step : 6169, Training Loss : 0.15824, Training Acc : 0.939, Run Time : 0.36
INFO:root:2019-05-10 23:21:06, Epoch : 1, Step : 6170, Training Loss : 0.23240, Training Acc : 0.906, Run Time : 0.44
INFO:root:2019-05-10 23:21:14, Epoch : 1, Step : 6171, Training Loss : 0.22623, Training Acc : 0.894, Run Time : 7.27
INFO:root:2019-05-10 23:21:14, Epoch : 1, Step : 6172, Training Loss : 0.15196, Training Acc : 0.950, Run Time : 0.44
INFO:root:2019-05-10 23:21:14, Epoch : 1, Step : 6173, Training Loss : 0.20186, Training Acc : 0.906, Run Time : 0.48
INFO:root:2019-05-10 23:21:15, Epoch : 1, Step : 6174, Training Loss : 0.16267, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 23:21:16, Epoch : 1, Step : 6175, Training Loss : 0.16226, Training Acc : 0.944, Run Time : 0.73
INFO:root:2019-05-10 23:21:27, Epoch : 1, Step : 6176, Training Loss : 0.27721, Training Acc : 0.894, Run Time : 11.14
INFO:root:2019-05-10 23:21:27, Epoch : 1, Step : 6177, Training Loss : 0.32648, Training Acc : 0.872, Run Time : 0.37
INFO:root:2019-05-10 23:21:28, Epoch : 1, Step : 6178, Training Loss : 0.20459, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-10 23:21:28, Epoch : 1, Step : 6179, Training Loss : 0.08687, Training Acc : 0.983, Run Time : 0.55
INFO:root:2019-05-10 23:21:29, Epoch : 1, Step : 6180, Training Loss : 0.08569, Training Acc : 0.961, Run Time : 1.15
INFO:root:2019-05-10 23:21:39, Epoch : 1, Step : 6181, Training Loss : 0.22439, Training Acc : 0.906, Run Time : 10.12
INFO:root:2019-05-10 23:21:40, Epoch : 1, Step : 6182, Training Loss : 0.21974, Training Acc : 0.917, Run Time : 0.52
INFO:root:2019-05-10 23:21:40, Epoch : 1, Step : 6183, Training Loss : 0.34376, Training Acc : 0.906, Run Time : 0.50
INFO:root:2019-05-10 23:21:41, Epoch : 1, Step : 6184, Training Loss : 0.68274, Training Acc : 0.728, Run Time : 0.45
INFO:root:2019-05-10 23:21:48, Epoch : 1, Step : 6185, Training Loss : 0.20775, Training Acc : 0.922, Run Time : 6.93
INFO:root:2019-05-10 23:21:48, Epoch : 1, Step : 6186, Training Loss : 0.17238, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-10 23:21:50, Epoch : 1, Step : 6187, Training Loss : 0.19511, Training Acc : 0.906, Run Time : 1.83
INFO:root:2019-05-10 23:21:51, Epoch : 1, Step : 6188, Training Loss : 0.16297, Training Acc : 0.922, Run Time : 1.28
INFO:root:2019-05-10 23:22:03, Epoch : 1, Step : 6189, Training Loss : 0.19350, Training Acc : 0.933, Run Time : 11.14
INFO:root:2019-05-10 23:22:03, Epoch : 1, Step : 6190, Training Loss : 0.23745, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-10 23:22:03, Epoch : 1, Step : 6191, Training Loss : 0.12532, Training Acc : 0.972, Run Time : 0.41
INFO:root:2019-05-10 23:22:04, Epoch : 1, Step : 6192, Training Loss : 0.14196, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-10 23:22:04, Epoch : 1, Step : 6193, Training Loss : 0.13400, Training Acc : 0.956, Run Time : 0.54
INFO:root:2019-05-10 23:22:18, Epoch : 1, Step : 6194, Training Loss : 0.16104, Training Acc : 0.917, Run Time : 14.00
INFO:root:2019-05-10 23:22:19, Epoch : 1, Step : 6195, Training Loss : 0.14866, Training Acc : 0.928, Run Time : 0.44
INFO:root:2019-05-10 23:22:19, Epoch : 1, Step : 6196, Training Loss : 0.12756, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-10 23:22:20, Epoch : 1, Step : 6197, Training Loss : 0.10874, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-10 23:22:20, Epoch : 1, Step : 6198, Training Loss : 0.23866, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 23:22:24, Epoch : 1, Step : 6199, Training Loss : 0.45183, Training Acc : 0.822, Run Time : 4.36
INFO:root:2019-05-10 23:22:29, Epoch : 1, Step : 6200, Training Loss : 0.26983, Training Acc : 0.894, Run Time : 4.96
INFO:root:2019-05-10 23:22:32, Epoch : 1, Step : 6201, Training Loss : 0.57003, Training Acc : 0.817, Run Time : 2.26
INFO:root:2019-05-10 23:22:32, Epoch : 1, Step : 6202, Training Loss : 0.80396, Training Acc : 0.683, Run Time : 0.45
INFO:root:2019-05-10 23:22:34, Epoch : 1, Step : 6203, Training Loss : 0.77392, Training Acc : 0.722, Run Time : 1.94
INFO:root:2019-05-10 23:22:47, Epoch : 1, Step : 6204, Training Loss : 0.92491, Training Acc : 0.678, Run Time : 13.28
INFO:root:2019-05-10 23:22:48, Epoch : 1, Step : 6205, Training Loss : 0.89040, Training Acc : 0.639, Run Time : 0.24
INFO:root:2019-05-10 23:22:48, Epoch : 1, Step : 6206, Training Loss : 0.65337, Training Acc : 0.739, Run Time : 0.45
INFO:root:2019-05-10 23:22:48, Epoch : 1, Step : 6207, Training Loss : 0.63567, Training Acc : 0.717, Run Time : 0.41
INFO:root:2019-05-10 23:22:50, Epoch : 1, Step : 6208, Training Loss : 0.47158, Training Acc : 0.728, Run Time : 1.48
INFO:root:2019-05-10 23:22:57, Epoch : 1, Step : 6209, Training Loss : 0.40060, Training Acc : 0.767, Run Time : 7.20
INFO:root:2019-05-10 23:22:58, Epoch : 1, Step : 6210, Training Loss : 0.36949, Training Acc : 0.794, Run Time : 0.66
INFO:root:2019-05-10 23:23:05, Epoch : 1, Step : 6211, Training Loss : 0.31042, Training Acc : 0.856, Run Time : 7.32
INFO:root:2019-05-10 23:23:05, Epoch : 1, Step : 6212, Training Loss : 0.34560, Training Acc : 0.833, Run Time : 0.31
INFO:root:2019-05-10 23:23:06, Epoch : 1, Step : 6213, Training Loss : 0.33391, Training Acc : 0.833, Run Time : 0.41
INFO:root:2019-05-10 23:23:11, Epoch : 1, Step : 6214, Training Loss : 0.25023, Training Acc : 0.872, Run Time : 5.06
INFO:root:2019-05-10 23:23:12, Epoch : 1, Step : 6215, Training Loss : 0.39430, Training Acc : 0.844, Run Time : 0.61
INFO:root:2019-05-10 23:23:12, Epoch : 1, Step : 6216, Training Loss : 0.37415, Training Acc : 0.794, Run Time : 0.24
INFO:root:2019-05-10 23:23:12, Epoch : 1, Step : 6217, Training Loss : 0.38788, Training Acc : 0.833, Run Time : 0.21
INFO:root:2019-05-10 23:23:20, Epoch : 1, Step : 6218, Training Loss : 0.52417, Training Acc : 0.728, Run Time : 8.38
INFO:root:2019-05-10 23:23:21, Epoch : 1, Step : 6219, Training Loss : 0.31165, Training Acc : 0.867, Run Time : 0.39
INFO:root:2019-05-10 23:23:21, Epoch : 1, Step : 6220, Training Loss : 0.55312, Training Acc : 0.767, Run Time : 0.48
INFO:root:2019-05-10 23:23:22, Epoch : 1, Step : 6221, Training Loss : 0.43342, Training Acc : 0.778, Run Time : 0.46
INFO:root:2019-05-10 23:23:29, Epoch : 1, Step : 6222, Training Loss : 0.37790, Training Acc : 0.789, Run Time : 6.94
INFO:root:2019-05-10 23:23:29, Epoch : 1, Step : 6223, Training Loss : 0.42094, Training Acc : 0.844, Run Time : 0.80
INFO:root:2019-05-10 23:23:30, Epoch : 1, Step : 6224, Training Loss : 0.39581, Training Acc : 0.772, Run Time : 0.43
INFO:root:2019-05-10 23:23:31, Epoch : 1, Step : 6225, Training Loss : 0.35649, Training Acc : 0.794, Run Time : 0.76
INFO:root:2019-05-10 23:23:37, Epoch : 1, Step : 6226, Training Loss : 0.31077, Training Acc : 0.844, Run Time : 6.17
INFO:root:2019-05-10 23:23:38, Epoch : 1, Step : 6227, Training Loss : 0.29768, Training Acc : 0.878, Run Time : 1.07
INFO:root:2019-05-10 23:23:49, Epoch : 1, Step : 6228, Training Loss : 0.31584, Training Acc : 0.828, Run Time : 11.60
INFO:root:2019-05-10 23:23:50, Epoch : 1, Step : 6229, Training Loss : 0.26171, Training Acc : 0.878, Run Time : 0.40
INFO:root:2019-05-10 23:23:50, Epoch : 1, Step : 6230, Training Loss : 0.22872, Training Acc : 0.900, Run Time : 0.43
INFO:root:2019-05-10 23:23:51, Epoch : 1, Step : 6231, Training Loss : 0.22728, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-10 23:23:51, Epoch : 1, Step : 6232, Training Loss : 0.17344, Training Acc : 0.944, Run Time : 0.52
INFO:root:2019-05-10 23:23:58, Epoch : 1, Step : 6233, Training Loss : 0.24964, Training Acc : 0.906, Run Time : 6.88
INFO:root:2019-05-10 23:23:59, Epoch : 1, Step : 6234, Training Loss : 0.31354, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-10 23:24:05, Epoch : 1, Step : 6235, Training Loss : 0.20840, Training Acc : 0.922, Run Time : 6.09
INFO:root:2019-05-10 23:24:05, Epoch : 1, Step : 6236, Training Loss : 0.19941, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-10 23:24:06, Epoch : 1, Step : 6237, Training Loss : 0.30535, Training Acc : 0.861, Run Time : 0.55
INFO:root:2019-05-10 23:24:06, Epoch : 1, Step : 6238, Training Loss : 0.21072, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 23:24:15, Epoch : 1, Step : 6239, Training Loss : 0.26734, Training Acc : 0.894, Run Time : 8.51
INFO:root:2019-05-10 23:24:15, Epoch : 1, Step : 6240, Training Loss : 0.19779, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-10 23:24:16, Epoch : 1, Step : 6241, Training Loss : 0.26108, Training Acc : 0.894, Run Time : 0.60
INFO:root:2019-05-10 23:24:16, Epoch : 1, Step : 6242, Training Loss : 0.18130, Training Acc : 0.944, Run Time : 0.42
INFO:root:2019-05-10 23:24:25, Epoch : 1, Step : 6243, Training Loss : 0.24864, Training Acc : 0.894, Run Time : 9.15
INFO:root:2019-05-10 23:24:26, Epoch : 1, Step : 6244, Training Loss : 0.30846, Training Acc : 0.878, Run Time : 0.42
INFO:root:2019-05-10 23:24:26, Epoch : 1, Step : 6245, Training Loss : 0.25537, Training Acc : 0.889, Run Time : 0.49
INFO:root:2019-05-10 23:24:28, Epoch : 1, Step : 6246, Training Loss : 0.22959, Training Acc : 0.906, Run Time : 2.15
INFO:root:2019-05-10 23:24:49, Epoch : 1, Step : 6247, Training Loss : 0.23978, Training Acc : 0.917, Run Time : 20.63
INFO:root:2019-05-10 23:24:50, Epoch : 1, Step : 6248, Training Loss : 0.16056, Training Acc : 0.933, Run Time : 0.96
INFO:root:2019-05-10 23:24:50, Epoch : 1, Step : 6249, Training Loss : 0.21832, Training Acc : 0.894, Run Time : 0.41
INFO:root:2019-05-10 23:24:51, Epoch : 1, Step : 6250, Training Loss : 0.23630, Training Acc : 0.922, Run Time : 0.95
INFO:root:2019-05-10 23:25:02, Epoch : 1, Step : 6251, Training Loss : 0.21521, Training Acc : 0.928, Run Time : 10.46
INFO:root:2019-05-10 23:25:02, Epoch : 1, Step : 6252, Training Loss : 0.19554, Training Acc : 0.933, Run Time : 0.70
INFO:root:2019-05-10 23:25:03, Epoch : 1, Step : 6253, Training Loss : 0.14931, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-10 23:25:03, Epoch : 1, Step : 6254, Training Loss : 0.27922, Training Acc : 0.878, Run Time : 0.46
INFO:root:2019-05-10 23:25:04, Epoch : 1, Step : 6255, Training Loss : 0.23421, Training Acc : 0.911, Run Time : 0.83
INFO:root:2019-05-10 23:25:07, Epoch : 1, Step : 6256, Training Loss : 0.23140, Training Acc : 0.906, Run Time : 2.41
INFO:root:2019-05-10 23:25:11, Epoch : 1, Step : 6257, Training Loss : 0.24861, Training Acc : 0.906, Run Time : 4.89
INFO:root:2019-05-10 23:25:12, Epoch : 1, Step : 6258, Training Loss : 0.22973, Training Acc : 0.922, Run Time : 0.43
INFO:root:2019-05-10 23:25:16, Epoch : 1, Step : 6259, Training Loss : 0.19888, Training Acc : 0.928, Run Time : 3.69
INFO:root:2019-05-10 23:25:16, Epoch : 1, Step : 6260, Training Loss : 0.21457, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-10 23:25:25, Epoch : 1, Step : 6261, Training Loss : 0.20670, Training Acc : 0.939, Run Time : 8.62
INFO:root:2019-05-10 23:25:25, Epoch : 1, Step : 6262, Training Loss : 0.20160, Training Acc : 0.917, Run Time : 0.55
INFO:root:2019-05-10 23:25:26, Epoch : 1, Step : 6263, Training Loss : 0.32745, Training Acc : 0.872, Run Time : 0.51
INFO:root:2019-05-10 23:25:26, Epoch : 1, Step : 6264, Training Loss : 1.23412, Training Acc : 0.472, Run Time : 0.46
INFO:root:2019-05-10 23:25:35, Epoch : 1, Step : 6265, Training Loss : 0.48960, Training Acc : 0.728, Run Time : 9.17
INFO:root:2019-05-10 23:25:36, Epoch : 1, Step : 6266, Training Loss : 0.23238, Training Acc : 0.911, Run Time : 0.32
INFO:root:2019-05-10 23:25:36, Epoch : 1, Step : 6267, Training Loss : 0.36694, Training Acc : 0.817, Run Time : 0.61
INFO:root:2019-05-10 23:25:37, Epoch : 1, Step : 6268, Training Loss : 0.23050, Training Acc : 0.906, Run Time : 1.15
INFO:root:2019-05-10 23:25:45, Epoch : 1, Step : 6269, Training Loss : 0.24290, Training Acc : 0.917, Run Time : 7.50
INFO:root:2019-05-10 23:25:45, Epoch : 1, Step : 6270, Training Loss : 0.23725, Training Acc : 0.911, Run Time : 0.39
INFO:root:2019-05-10 23:25:46, Epoch : 1, Step : 6271, Training Loss : 0.24392, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-10 23:25:46, Epoch : 1, Step : 6272, Training Loss : 0.21861, Training Acc : 0.900, Run Time : 0.48
INFO:root:2019-05-10 23:25:56, Epoch : 1, Step : 6273, Training Loss : 0.27050, Training Acc : 0.922, Run Time : 9.84
INFO:root:2019-05-10 23:25:56, Epoch : 1, Step : 6274, Training Loss : 0.18883, Training Acc : 0.922, Run Time : 0.43
INFO:root:2019-05-10 23:25:57, Epoch : 1, Step : 6275, Training Loss : 0.28627, Training Acc : 0.850, Run Time : 0.51
INFO:root:2019-05-10 23:25:57, Epoch : 1, Step : 6276, Training Loss : 0.24998, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 23:25:59, Epoch : 1, Step : 6277, Training Loss : 0.18371, Training Acc : 0.956, Run Time : 1.30
INFO:root:2019-05-10 23:26:08, Epoch : 1, Step : 6278, Training Loss : 0.22577, Training Acc : 0.894, Run Time : 8.94
INFO:root:2019-05-10 23:26:08, Epoch : 1, Step : 6279, Training Loss : 0.37711, Training Acc : 0.883, Run Time : 0.53
INFO:root:2019-05-10 23:26:09, Epoch : 1, Step : 6280, Training Loss : 0.28661, Training Acc : 0.894, Run Time : 0.50
INFO:root:2019-05-10 23:26:10, Epoch : 1, Step : 6281, Training Loss : 0.27463, Training Acc : 0.900, Run Time : 0.81
INFO:root:2019-05-10 23:26:12, Epoch : 1, Step : 6282, Training Loss : 0.24818, Training Acc : 0.894, Run Time : 2.74
INFO:root:2019-05-10 23:26:15, Epoch : 1, Step : 6283, Training Loss : 0.23144, Training Acc : 0.917, Run Time : 2.96
INFO:root:2019-05-10 23:26:27, Epoch : 1, Step : 6284, Training Loss : 0.18507, Training Acc : 0.956, Run Time : 11.46
INFO:root:2019-05-10 23:26:27, Epoch : 1, Step : 6285, Training Loss : 0.22100, Training Acc : 0.911, Run Time : 0.39
INFO:root:2019-05-10 23:26:28, Epoch : 1, Step : 6286, Training Loss : 0.20505, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 23:26:28, Epoch : 1, Step : 6287, Training Loss : 0.26851, Training Acc : 0.889, Run Time : 0.44
INFO:root:2019-05-10 23:26:38, Epoch : 1, Step : 6288, Training Loss : 0.25896, Training Acc : 0.917, Run Time : 9.80
INFO:root:2019-05-10 23:26:39, Epoch : 1, Step : 6289, Training Loss : 0.45945, Training Acc : 0.772, Run Time : 0.78
INFO:root:2019-05-10 23:26:44, Epoch : 1, Step : 6290, Training Loss : 0.30167, Training Acc : 0.867, Run Time : 4.89
INFO:root:2019-05-10 23:26:44, Epoch : 1, Step : 6291, Training Loss : 0.32274, Training Acc : 0.828, Run Time : 0.41
INFO:root:2019-05-10 23:26:44, Epoch : 1, Step : 6292, Training Loss : 0.22088, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-10 23:26:45, Epoch : 1, Step : 6293, Training Loss : 0.18743, Training Acc : 0.956, Run Time : 0.42
INFO:root:2019-05-10 23:26:49, Epoch : 1, Step : 6294, Training Loss : 0.20307, Training Acc : 0.917, Run Time : 4.67
INFO:root:2019-05-10 23:26:50, Epoch : 1, Step : 6295, Training Loss : 0.25883, Training Acc : 0.878, Run Time : 0.73
INFO:root:2019-05-10 23:26:51, Epoch : 1, Step : 6296, Training Loss : 0.28582, Training Acc : 0.856, Run Time : 0.45
INFO:root:2019-05-10 23:27:00, Epoch : 1, Step : 6297, Training Loss : 0.27508, Training Acc : 0.894, Run Time : 9.41
INFO:root:2019-05-10 23:27:00, Epoch : 1, Step : 6298, Training Loss : 0.28340, Training Acc : 0.872, Run Time : 0.42
INFO:root:2019-05-10 23:27:01, Epoch : 1, Step : 6299, Training Loss : 0.48389, Training Acc : 0.767, Run Time : 0.40
INFO:root:2019-05-10 23:27:01, Epoch : 1, Step : 6300, Training Loss : 0.30361, Training Acc : 0.889, Run Time : 0.54
INFO:root:2019-05-10 23:27:08, Epoch : 1, Step : 6301, Training Loss : 0.27522, Training Acc : 0.878, Run Time : 6.90
INFO:root:2019-05-10 23:27:09, Epoch : 1, Step : 6302, Training Loss : 0.30417, Training Acc : 0.900, Run Time : 0.66
INFO:root:2019-05-10 23:27:10, Epoch : 1, Step : 6303, Training Loss : 0.28512, Training Acc : 0.894, Run Time : 0.68
INFO:root:2019-05-10 23:27:12, Epoch : 1, Step : 6304, Training Loss : 0.25306, Training Acc : 0.906, Run Time : 1.92
INFO:root:2019-05-10 23:27:15, Epoch : 1, Step : 6305, Training Loss : 0.28627, Training Acc : 0.878, Run Time : 3.37
INFO:root:2019-05-10 23:27:16, Epoch : 1, Step : 6306, Training Loss : 0.27856, Training Acc : 0.889, Run Time : 1.51
INFO:root:2019-05-10 23:27:29, Epoch : 1, Step : 6307, Training Loss : 0.32285, Training Acc : 0.872, Run Time : 12.08
INFO:root:2019-05-10 23:27:29, Epoch : 1, Step : 6308, Training Loss : 0.20659, Training Acc : 0.928, Run Time : 0.37
INFO:root:2019-05-10 23:27:29, Epoch : 1, Step : 6309, Training Loss : 0.29120, Training Acc : 0.894, Run Time : 0.37
INFO:root:2019-05-10 23:27:30, Epoch : 1, Step : 6310, Training Loss : 0.25527, Training Acc : 0.911, Run Time : 0.50
INFO:root:2019-05-10 23:27:30, Epoch : 1, Step : 6311, Training Loss : 0.19475, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 23:27:46, Epoch : 1, Step : 6312, Training Loss : 0.36557, Training Acc : 0.867, Run Time : 15.81
INFO:root:2019-05-10 23:27:46, Epoch : 1, Step : 6313, Training Loss : 0.24539, Training Acc : 0.917, Run Time : 0.25
INFO:root:2019-05-10 23:27:47, Epoch : 1, Step : 6314, Training Loss : 0.21859, Training Acc : 0.922, Run Time : 0.63
INFO:root:2019-05-10 23:27:47, Epoch : 1, Step : 6315, Training Loss : 0.18467, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 23:27:48, Epoch : 1, Step : 6316, Training Loss : 0.24790, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-10 23:27:56, Epoch : 1, Step : 6317, Training Loss : 0.27184, Training Acc : 0.872, Run Time : 8.08
INFO:root:2019-05-10 23:27:57, Epoch : 1, Step : 6318, Training Loss : 0.31419, Training Acc : 0.906, Run Time : 1.10
INFO:root:2019-05-10 23:27:58, Epoch : 1, Step : 6319, Training Loss : 0.26002, Training Acc : 0.906, Run Time : 1.32
INFO:root:2019-05-10 23:28:00, Epoch : 1, Step : 6320, Training Loss : 0.22737, Training Acc : 0.911, Run Time : 1.65
INFO:root:2019-05-10 23:28:02, Epoch : 1, Step : 6321, Training Loss : 0.36100, Training Acc : 0.889, Run Time : 1.81
INFO:root:2019-05-10 23:28:02, Epoch : 1, Step : 6322, Training Loss : 0.26915, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-10 23:28:16, Epoch : 1, Step : 6323, Training Loss : 0.21554, Training Acc : 0.928, Run Time : 13.32
INFO:root:2019-05-10 23:28:16, Epoch : 1, Step : 6324, Training Loss : 0.33771, Training Acc : 0.867, Run Time : 0.24
INFO:root:2019-05-10 23:28:16, Epoch : 1, Step : 6325, Training Loss : 0.20045, Training Acc : 0.922, Run Time : 0.44
INFO:root:2019-05-10 23:28:18, Epoch : 1, Step : 6326, Training Loss : 0.19665, Training Acc : 0.922, Run Time : 1.95
INFO:root:2019-05-10 23:28:19, Epoch : 1, Step : 6327, Training Loss : 0.32117, Training Acc : 0.911, Run Time : 0.57
INFO:root:2019-05-10 23:28:24, Epoch : 1, Step : 6328, Training Loss : 0.26166, Training Acc : 0.889, Run Time : 5.55
INFO:root:2019-05-10 23:28:25, Epoch : 1, Step : 6329, Training Loss : 0.28215, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-10 23:28:51, Epoch : 1, Step : 6330, Training Loss : 0.37971, Training Acc : 0.861, Run Time : 26.36
INFO:root:2019-05-10 23:28:52, Epoch : 1, Step : 6331, Training Loss : 0.25381, Training Acc : 0.889, Run Time : 0.76
INFO:root:2019-05-10 23:28:52, Epoch : 1, Step : 6332, Training Loss : 0.29345, Training Acc : 0.878, Run Time : 0.54
INFO:root:2019-05-10 23:28:53, Epoch : 1, Step : 6333, Training Loss : 0.31577, Training Acc : 0.889, Run Time : 0.36
INFO:root:2019-05-10 23:28:53, Epoch : 1, Step : 6334, Training Loss : 0.26898, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-10 23:29:12, Epoch : 1, Step : 6335, Training Loss : 0.27048, Training Acc : 0.906, Run Time : 18.88
INFO:root:2019-05-10 23:29:12, Epoch : 1, Step : 6336, Training Loss : 0.26917, Training Acc : 0.906, Run Time : 0.23
INFO:root:2019-05-10 23:29:13, Epoch : 1, Step : 6337, Training Loss : 0.33358, Training Acc : 0.828, Run Time : 0.33
INFO:root:2019-05-10 23:29:13, Epoch : 1, Step : 6338, Training Loss : 0.24906, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-10 23:29:13, Epoch : 1, Step : 6339, Training Loss : 0.19933, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-10 23:29:23, Epoch : 1, Step : 6340, Training Loss : 0.37878, Training Acc : 0.839, Run Time : 9.68
INFO:root:2019-05-10 23:29:24, Epoch : 1, Step : 6341, Training Loss : 0.27117, Training Acc : 0.900, Run Time : 0.43
INFO:root:2019-05-10 23:29:24, Epoch : 1, Step : 6342, Training Loss : 0.34872, Training Acc : 0.833, Run Time : 0.46
INFO:root:2019-05-10 23:29:24, Epoch : 1, Step : 6343, Training Loss : 0.23338, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-10 23:29:26, Epoch : 1, Step : 6344, Training Loss : 0.23359, Training Acc : 0.922, Run Time : 1.83
INFO:root:2019-05-10 23:29:45, Epoch : 1, Step : 6345, Training Loss : 0.26076, Training Acc : 0.872, Run Time : 18.87
INFO:root:2019-05-10 23:29:46, Epoch : 1, Step : 6346, Training Loss : 0.21773, Training Acc : 0.906, Run Time : 0.67
INFO:root:2019-05-10 23:29:46, Epoch : 1, Step : 6347, Training Loss : 0.14675, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-10 23:29:52, Epoch : 1, Step : 6348, Training Loss : 0.14966, Training Acc : 0.956, Run Time : 5.77
INFO:root:2019-05-10 23:29:52, Epoch : 1, Step : 6349, Training Loss : 0.22654, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-10 23:29:53, Epoch : 1, Step : 6350, Training Loss : 0.26813, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-10 23:29:53, Epoch : 1, Step : 6351, Training Loss : 0.15729, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 23:30:00, Epoch : 1, Step : 6352, Training Loss : 0.13497, Training Acc : 0.956, Run Time : 6.34
INFO:root:2019-05-10 23:30:01, Epoch : 1, Step : 6353, Training Loss : 0.15577, Training Acc : 0.950, Run Time : 0.80
INFO:root:2019-05-10 23:30:01, Epoch : 1, Step : 6354, Training Loss : 0.14080, Training Acc : 0.956, Run Time : 0.45
INFO:root:2019-05-10 23:30:03, Epoch : 1, Step : 6355, Training Loss : 0.16397, Training Acc : 0.944, Run Time : 1.76
INFO:root:2019-05-10 23:30:10, Epoch : 1, Step : 6356, Training Loss : 0.14461, Training Acc : 0.961, Run Time : 7.27
INFO:root:2019-05-10 23:30:11, Epoch : 1, Step : 6357, Training Loss : 0.19382, Training Acc : 0.939, Run Time : 0.57
INFO:root:2019-05-10 23:30:11, Epoch : 1, Step : 6358, Training Loss : 0.12057, Training Acc : 0.972, Run Time : 0.82
INFO:root:2019-05-10 23:30:12, Epoch : 1, Step : 6359, Training Loss : 0.18015, Training Acc : 0.922, Run Time : 1.00
INFO:root:2019-05-10 23:30:13, Epoch : 1, Step : 6360, Training Loss : 0.16526, Training Acc : 0.956, Run Time : 0.88
INFO:root:2019-05-10 23:30:23, Epoch : 1, Step : 6361, Training Loss : 0.21133, Training Acc : 0.922, Run Time : 9.54
INFO:root:2019-05-10 23:30:23, Epoch : 1, Step : 6362, Training Loss : 0.17056, Training Acc : 0.944, Run Time : 0.51
INFO:root:2019-05-10 23:30:24, Epoch : 1, Step : 6363, Training Loss : 0.16232, Training Acc : 0.922, Run Time : 0.45
INFO:root:2019-05-10 23:30:24, Epoch : 1, Step : 6364, Training Loss : 0.25736, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 23:30:42, Epoch : 1, Step : 6365, Training Loss : 0.28690, Training Acc : 0.883, Run Time : 18.07
INFO:root:2019-05-10 23:30:49, Epoch : 1, Step : 6366, Training Loss : 0.16446, Training Acc : 0.944, Run Time : 6.27
INFO:root:2019-05-10 23:30:50, Epoch : 1, Step : 6367, Training Loss : 0.19623, Training Acc : 0.906, Run Time : 1.03
INFO:root:2019-05-10 23:30:50, Epoch : 1, Step : 6368, Training Loss : 0.21952, Training Acc : 0.900, Run Time : 0.43
INFO:root:2019-05-10 23:30:51, Epoch : 1, Step : 6369, Training Loss : 0.17376, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-10 23:30:51, Epoch : 1, Step : 6370, Training Loss : 0.17646, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-10 23:30:56, Epoch : 1, Step : 6371, Training Loss : 0.21871, Training Acc : 0.883, Run Time : 5.00
INFO:root:2019-05-10 23:30:56, Epoch : 1, Step : 6372, Training Loss : 0.19584, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-10 23:31:07, Epoch : 1, Step : 6373, Training Loss : 0.14792, Training Acc : 0.950, Run Time : 10.37
INFO:root:2019-05-10 23:31:08, Epoch : 1, Step : 6374, Training Loss : 0.20110, Training Acc : 0.922, Run Time : 0.76
INFO:root:2019-05-10 23:31:08, Epoch : 1, Step : 6375, Training Loss : 0.12613, Training Acc : 0.967, Run Time : 0.43
INFO:root:2019-05-10 23:31:08, Epoch : 1, Step : 6376, Training Loss : 0.13661, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 23:31:09, Epoch : 1, Step : 6377, Training Loss : 0.10009, Training Acc : 0.983, Run Time : 0.45
INFO:root:2019-05-10 23:31:12, Epoch : 1, Step : 6378, Training Loss : 0.12440, Training Acc : 0.961, Run Time : 3.40
INFO:root:2019-05-10 23:31:19, Epoch : 1, Step : 6379, Training Loss : 0.19746, Training Acc : 0.922, Run Time : 7.06
INFO:root:2019-05-10 23:31:20, Epoch : 1, Step : 6380, Training Loss : 0.16173, Training Acc : 0.933, Run Time : 0.58
INFO:root:2019-05-10 23:31:20, Epoch : 1, Step : 6381, Training Loss : 0.12882, Training Acc : 0.956, Run Time : 0.48
INFO:root:2019-05-10 23:31:27, Epoch : 1, Step : 6382, Training Loss : 0.11749, Training Acc : 0.961, Run Time : 6.95
INFO:root:2019-05-10 23:31:28, Epoch : 1, Step : 6383, Training Loss : 0.17110, Training Acc : 0.917, Run Time : 0.71
INFO:root:2019-05-10 23:31:29, Epoch : 1, Step : 6384, Training Loss : 0.15122, Training Acc : 0.917, Run Time : 0.71
INFO:root:2019-05-10 23:31:29, Epoch : 1, Step : 6385, Training Loss : 0.14500, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-10 23:31:33, Epoch : 1, Step : 6386, Training Loss : 0.11727, Training Acc : 0.972, Run Time : 3.52
INFO:root:2019-05-10 23:31:33, Epoch : 1, Step : 6387, Training Loss : 0.13224, Training Acc : 0.939, Run Time : 0.47
INFO:root:2019-05-10 23:31:45, Epoch : 1, Step : 6388, Training Loss : 0.13031, Training Acc : 0.983, Run Time : 11.89
INFO:root:2019-05-10 23:31:46, Epoch : 1, Step : 6389, Training Loss : 0.14120, Training Acc : 0.956, Run Time : 0.35
INFO:root:2019-05-10 23:31:46, Epoch : 1, Step : 6390, Training Loss : 0.15091, Training Acc : 0.956, Run Time : 0.77
INFO:root:2019-05-10 23:31:51, Epoch : 1, Step : 6391, Training Loss : 0.14248, Training Acc : 0.950, Run Time : 4.71
INFO:root:2019-05-10 23:31:52, Epoch : 1, Step : 6392, Training Loss : 0.12851, Training Acc : 0.956, Run Time : 0.79
INFO:root:2019-05-10 23:31:52, Epoch : 1, Step : 6393, Training Loss : 0.15974, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-10 23:31:53, Epoch : 1, Step : 6394, Training Loss : 0.19386, Training Acc : 0.911, Run Time : 1.08
INFO:root:2019-05-10 23:31:58, Epoch : 1, Step : 6395, Training Loss : 0.17480, Training Acc : 0.933, Run Time : 4.51
INFO:root:2019-05-10 23:31:58, Epoch : 1, Step : 6396, Training Loss : 0.19129, Training Acc : 0.889, Run Time : 0.67
INFO:root:2019-05-10 23:32:00, Epoch : 1, Step : 6397, Training Loss : 0.21809, Training Acc : 0.917, Run Time : 1.07
INFO:root:2019-05-10 23:32:03, Epoch : 1, Step : 6398, Training Loss : 0.29124, Training Acc : 0.906, Run Time : 3.29
INFO:root:2019-05-10 23:32:04, Epoch : 1, Step : 6399, Training Loss : 0.33376, Training Acc : 0.889, Run Time : 1.34
INFO:root:2019-05-10 23:32:13, Epoch : 1, Step : 6400, Training Loss : 0.41561, Training Acc : 0.844, Run Time : 8.79
INFO:root:2019-05-10 23:32:14, Epoch : 1, Step : 6401, Training Loss : 0.64546, Training Acc : 0.767, Run Time : 0.80
INFO:root:2019-05-10 23:32:14, Epoch : 1, Step : 6402, Training Loss : 0.64958, Training Acc : 0.756, Run Time : 0.49
INFO:root:2019-05-10 23:32:20, Epoch : 1, Step : 6403, Training Loss : 0.63173, Training Acc : 0.744, Run Time : 5.71
INFO:root:2019-05-10 23:32:20, Epoch : 1, Step : 6404, Training Loss : 0.96930, Training Acc : 0.661, Run Time : 0.52
INFO:root:2019-05-10 23:32:21, Epoch : 1, Step : 6405, Training Loss : 1.02987, Training Acc : 0.650, Run Time : 0.43
INFO:root:2019-05-10 23:32:21, Epoch : 1, Step : 6406, Training Loss : 1.01048, Training Acc : 0.689, Run Time : 0.45
INFO:root:2019-05-10 23:32:33, Epoch : 1, Step : 6407, Training Loss : 0.91314, Training Acc : 0.689, Run Time : 11.48
INFO:root:2019-05-10 23:32:33, Epoch : 1, Step : 6408, Training Loss : 0.69693, Training Acc : 0.728, Run Time : 0.30
INFO:root:2019-05-10 23:32:34, Epoch : 1, Step : 6409, Training Loss : 0.46145, Training Acc : 0.794, Run Time : 0.43
INFO:root:2019-05-10 23:32:35, Epoch : 1, Step : 6410, Training Loss : 0.37536, Training Acc : 0.828, Run Time : 1.55
INFO:root:2019-05-10 23:32:36, Epoch : 1, Step : 6411, Training Loss : 0.38556, Training Acc : 0.822, Run Time : 0.80
INFO:root:2019-05-10 23:32:46, Epoch : 1, Step : 6412, Training Loss : 0.27645, Training Acc : 0.867, Run Time : 10.26
INFO:root:2019-05-10 23:32:47, Epoch : 1, Step : 6413, Training Loss : 0.41345, Training Acc : 0.811, Run Time : 0.59
INFO:root:2019-05-10 23:32:47, Epoch : 1, Step : 6414, Training Loss : 0.43243, Training Acc : 0.772, Run Time : 0.39
INFO:root:2019-05-10 23:32:48, Epoch : 1, Step : 6415, Training Loss : 0.32047, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 23:32:48, Epoch : 1, Step : 6416, Training Loss : 0.26605, Training Acc : 0.906, Run Time : 0.45
INFO:root:2019-05-10 23:32:52, Epoch : 1, Step : 6417, Training Loss : 0.32515, Training Acc : 0.906, Run Time : 3.98
INFO:root:2019-05-10 23:32:52, Epoch : 1, Step : 6418, Training Loss : 0.39374, Training Acc : 0.811, Run Time : 0.34
INFO:root:2019-05-10 23:33:05, Epoch : 1, Step : 6419, Training Loss : 0.59892, Training Acc : 0.728, Run Time : 12.73
INFO:root:2019-05-10 23:33:05, Epoch : 1, Step : 6420, Training Loss : 0.57776, Training Acc : 0.767, Run Time : 0.32
INFO:root:2019-05-10 23:33:06, Epoch : 1, Step : 6421, Training Loss : 0.44689, Training Acc : 0.817, Run Time : 0.42
INFO:root:2019-05-10 23:33:06, Epoch : 1, Step : 6422, Training Loss : 0.40890, Training Acc : 0.817, Run Time : 0.58
INFO:root:2019-05-10 23:33:18, Epoch : 1, Step : 6423, Training Loss : 0.41198, Training Acc : 0.839, Run Time : 11.16
INFO:root:2019-05-10 23:33:18, Epoch : 1, Step : 6424, Training Loss : 0.45743, Training Acc : 0.844, Run Time : 0.53
INFO:root:2019-05-10 23:33:19, Epoch : 1, Step : 6425, Training Loss : 0.37797, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-10 23:33:19, Epoch : 1, Step : 6426, Training Loss : 0.48307, Training Acc : 0.800, Run Time : 0.56
INFO:root:2019-05-10 23:33:20, Epoch : 1, Step : 6427, Training Loss : 0.70095, Training Acc : 0.783, Run Time : 0.44
INFO:root:2019-05-10 23:33:27, Epoch : 1, Step : 6428, Training Loss : 0.91991, Training Acc : 0.683, Run Time : 7.11
INFO:root:2019-05-10 23:33:28, Epoch : 1, Step : 6429, Training Loss : 0.64706, Training Acc : 0.722, Run Time : 1.11
INFO:root:2019-05-10 23:33:29, Epoch : 1, Step : 6430, Training Loss : 0.37054, Training Acc : 0.856, Run Time : 0.80
INFO:root:2019-05-10 23:33:29, Epoch : 1, Step : 6431, Training Loss : 0.38513, Training Acc : 0.867, Run Time : 0.48
INFO:root:2019-05-10 23:33:36, Epoch : 1, Step : 6432, Training Loss : 0.19545, Training Acc : 0.917, Run Time : 6.98
INFO:root:2019-05-10 23:33:37, Epoch : 1, Step : 6433, Training Loss : 0.28409, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-10 23:33:47, Epoch : 1, Step : 6434, Training Loss : 0.50251, Training Acc : 0.789, Run Time : 10.52
INFO:root:2019-05-10 23:33:47, Epoch : 1, Step : 6435, Training Loss : 0.53131, Training Acc : 0.772, Run Time : 0.43
INFO:root:2019-05-10 23:33:48, Epoch : 1, Step : 6436, Training Loss : 0.46233, Training Acc : 0.844, Run Time : 0.39
INFO:root:2019-05-10 23:33:48, Epoch : 1, Step : 6437, Training Loss : 0.40018, Training Acc : 0.856, Run Time : 0.43
INFO:root:2019-05-10 23:33:50, Epoch : 1, Step : 6438, Training Loss : 0.46057, Training Acc : 0.833, Run Time : 1.31
INFO:root:2019-05-10 23:33:53, Epoch : 1, Step : 6439, Training Loss : 0.40943, Training Acc : 0.828, Run Time : 3.45
INFO:root:2019-05-10 23:33:54, Epoch : 1, Step : 6440, Training Loss : 0.53614, Training Acc : 0.789, Run Time : 0.47
INFO:root:2019-05-10 23:34:08, Epoch : 1, Step : 6441, Training Loss : 0.39936, Training Acc : 0.839, Run Time : 14.02
INFO:root:2019-05-10 23:34:08, Epoch : 1, Step : 6442, Training Loss : 0.22562, Training Acc : 0.894, Run Time : 0.24
INFO:root:2019-05-10 23:34:08, Epoch : 1, Step : 6443, Training Loss : 0.31247, Training Acc : 0.900, Run Time : 0.38
INFO:root:2019-05-10 23:34:09, Epoch : 1, Step : 6444, Training Loss : 0.32788, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-10 23:34:09, Epoch : 1, Step : 6445, Training Loss : 0.48726, Training Acc : 0.778, Run Time : 0.47
INFO:root:2019-05-10 23:34:17, Epoch : 1, Step : 6446, Training Loss : 0.24484, Training Acc : 0.900, Run Time : 8.32
INFO:root:2019-05-10 23:34:18, Epoch : 1, Step : 6447, Training Loss : 0.40463, Training Acc : 0.872, Run Time : 0.64
INFO:root:2019-05-10 23:34:19, Epoch : 1, Step : 6448, Training Loss : 0.29821, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-10 23:34:19, Epoch : 1, Step : 6449, Training Loss : 0.23216, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-10 23:34:30, Epoch : 1, Step : 6450, Training Loss : 0.18495, Training Acc : 0.939, Run Time : 11.06
INFO:root:2019-05-10 23:34:31, Epoch : 1, Step : 6451, Training Loss : 0.18665, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-10 23:34:31, Epoch : 1, Step : 6452, Training Loss : 0.22956, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-10 23:34:31, Epoch : 1, Step : 6453, Training Loss : 0.14695, Training Acc : 0.950, Run Time : 0.42
INFO:root:2019-05-10 23:34:32, Epoch : 1, Step : 6454, Training Loss : 0.35913, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 23:34:39, Epoch : 1, Step : 6455, Training Loss : 0.61041, Training Acc : 0.800, Run Time : 7.33
INFO:root:2019-05-10 23:34:40, Epoch : 1, Step : 6456, Training Loss : 0.27215, Training Acc : 0.883, Run Time : 0.43
INFO:root:2019-05-10 23:34:41, Epoch : 1, Step : 6457, Training Loss : 0.43236, Training Acc : 0.822, Run Time : 1.84
INFO:root:2019-05-10 23:34:42, Epoch : 1, Step : 6458, Training Loss : 0.20344, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-10 23:34:50, Epoch : 1, Step : 6459, Training Loss : 0.43826, Training Acc : 0.850, Run Time : 8.63
INFO:root:2019-05-10 23:34:51, Epoch : 1, Step : 6460, Training Loss : 0.20049, Training Acc : 0.922, Run Time : 0.57
INFO:root:2019-05-10 23:34:51, Epoch : 1, Step : 6461, Training Loss : 0.13497, Training Acc : 0.967, Run Time : 0.43
INFO:root:2019-05-10 23:34:52, Epoch : 1, Step : 6462, Training Loss : 0.18258, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-10 23:35:02, Epoch : 1, Step : 6463, Training Loss : 0.27542, Training Acc : 0.894, Run Time : 10.31
INFO:root:2019-05-10 23:35:03, Epoch : 1, Step : 6464, Training Loss : 0.36863, Training Acc : 0.839, Run Time : 0.70
INFO:root:2019-05-10 23:35:03, Epoch : 1, Step : 6465, Training Loss : 0.21930, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-10 23:35:04, Epoch : 1, Step : 6466, Training Loss : 0.21677, Training Acc : 0.928, Run Time : 0.54
INFO:root:2019-05-10 23:35:11, Epoch : 1, Step : 6467, Training Loss : 0.46498, Training Acc : 0.833, Run Time : 6.79
INFO:root:2019-05-10 23:35:11, Epoch : 1, Step : 6468, Training Loss : 0.37367, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-10 23:35:12, Epoch : 1, Step : 6469, Training Loss : 0.37557, Training Acc : 0.889, Run Time : 0.50
INFO:root:2019-05-10 23:35:14, Epoch : 1, Step : 6470, Training Loss : 0.33610, Training Acc : 0.867, Run Time : 1.83
INFO:root:2019-05-10 23:35:26, Epoch : 1, Step : 6471, Training Loss : 0.15675, Training Acc : 0.967, Run Time : 12.37
INFO:root:2019-05-10 23:35:26, Epoch : 1, Step : 6472, Training Loss : 0.14679, Training Acc : 0.961, Run Time : 0.49
INFO:root:2019-05-10 23:35:27, Epoch : 1, Step : 6473, Training Loss : 0.47896, Training Acc : 0.828, Run Time : 0.32
INFO:root:2019-05-10 23:35:30, Epoch : 1, Step : 6474, Training Loss : 0.44381, Training Acc : 0.867, Run Time : 2.77
INFO:root:2019-05-10 23:35:30, Epoch : 1, Step : 6475, Training Loss : 0.42890, Training Acc : 0.861, Run Time : 0.49
INFO:root:2019-05-10 23:35:32, Epoch : 1, Step : 6476, Training Loss : 0.23110, Training Acc : 0.911, Run Time : 1.69
INFO:root:2019-05-10 23:35:34, Epoch : 1, Step : 6477, Training Loss : 0.32149, Training Acc : 0.883, Run Time : 1.98
INFO:root:2019-05-10 23:35:43, Epoch : 1, Step : 6478, Training Loss : 0.22804, Training Acc : 0.917, Run Time : 9.66
INFO:root:2019-05-10 23:35:44, Epoch : 1, Step : 6479, Training Loss : 0.24600, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 23:35:44, Epoch : 1, Step : 6480, Training Loss : 0.35020, Training Acc : 0.900, Run Time : 0.44
INFO:root:2019-05-10 23:35:45, Epoch : 1, Step : 6481, Training Loss : 0.20663, Training Acc : 0.922, Run Time : 0.77
INFO:root:2019-05-10 23:35:50, Epoch : 1, Step : 6482, Training Loss : 0.26203, Training Acc : 0.928, Run Time : 5.16
INFO:root:2019-05-10 23:35:57, Epoch : 1, Step : 6483, Training Loss : 0.22655, Training Acc : 0.922, Run Time : 6.80
INFO:root:2019-05-10 23:35:58, Epoch : 1, Step : 6484, Training Loss : 0.15761, Training Acc : 0.983, Run Time : 0.68
INFO:root:2019-05-10 23:35:58, Epoch : 1, Step : 6485, Training Loss : 0.13082, Training Acc : 0.972, Run Time : 0.47
INFO:root:2019-05-10 23:35:59, Epoch : 1, Step : 6486, Training Loss : 0.19273, Training Acc : 0.933, Run Time : 0.50
INFO:root:2019-05-10 23:35:59, Epoch : 1, Step : 6487, Training Loss : 0.16677, Training Acc : 0.944, Run Time : 0.86
INFO:root:2019-05-10 23:36:05, Epoch : 1, Step : 6488, Training Loss : 0.24547, Training Acc : 0.911, Run Time : 5.94
INFO:root:2019-05-10 23:36:06, Epoch : 1, Step : 6489, Training Loss : 0.20374, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-10 23:36:14, Epoch : 1, Step : 6490, Training Loss : 0.21967, Training Acc : 0.917, Run Time : 7.63
INFO:root:2019-05-10 23:36:14, Epoch : 1, Step : 6491, Training Loss : 0.28046, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-10 23:36:14, Epoch : 1, Step : 6492, Training Loss : 0.30989, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 23:36:15, Epoch : 1, Step : 6493, Training Loss : 0.41126, Training Acc : 0.811, Run Time : 0.40
INFO:root:2019-05-10 23:36:21, Epoch : 1, Step : 6494, Training Loss : 0.45207, Training Acc : 0.794, Run Time : 6.61
INFO:root:2019-05-10 23:36:22, Epoch : 1, Step : 6495, Training Loss : 0.53095, Training Acc : 0.744, Run Time : 0.43
INFO:root:2019-05-10 23:36:24, Epoch : 1, Step : 6496, Training Loss : 0.44583, Training Acc : 0.833, Run Time : 2.23
INFO:root:2019-05-10 23:36:25, Epoch : 1, Step : 6497, Training Loss : 0.22141, Training Acc : 0.922, Run Time : 0.58
INFO:root:2019-05-10 23:36:39, Epoch : 1, Step : 6498, Training Loss : 0.29312, Training Acc : 0.900, Run Time : 14.12
INFO:root:2019-05-10 23:36:39, Epoch : 1, Step : 6499, Training Loss : 0.21181, Training Acc : 0.911, Run Time : 0.32
INFO:root:2019-05-10 23:36:40, Epoch : 1, Step : 6500, Training Loss : 0.42907, Training Acc : 0.817, Run Time : 0.45
INFO:root:2019-05-10 23:36:42, Epoch : 1, Step : 6501, Training Loss : 0.33336, Training Acc : 0.850, Run Time : 2.43
INFO:root:2019-05-10 23:36:42, Epoch : 1, Step : 6502, Training Loss : 0.42910, Training Acc : 0.811, Run Time : 0.48
INFO:root:2019-05-10 23:36:48, Epoch : 1, Step : 6503, Training Loss : 0.20896, Training Acc : 0.911, Run Time : 5.08
INFO:root:2019-05-10 23:36:52, Epoch : 1, Step : 6504, Training Loss : 0.31244, Training Acc : 0.883, Run Time : 4.90
INFO:root:2019-05-10 23:36:53, Epoch : 1, Step : 6505, Training Loss : 0.23870, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 23:36:53, Epoch : 1, Step : 6506, Training Loss : 0.21887, Training Acc : 0.956, Run Time : 0.46
INFO:root:2019-05-10 23:36:54, Epoch : 1, Step : 6507, Training Loss : 0.40258, Training Acc : 0.817, Run Time : 0.96
INFO:root:2019-05-10 23:37:03, Epoch : 1, Step : 6508, Training Loss : 0.47647, Training Acc : 0.761, Run Time : 8.63
INFO:root:2019-05-10 23:37:03, Epoch : 1, Step : 6509, Training Loss : 0.44348, Training Acc : 0.806, Run Time : 0.48
INFO:root:2019-05-10 23:37:04, Epoch : 1, Step : 6510, Training Loss : 0.53958, Training Acc : 0.711, Run Time : 0.42
INFO:root:2019-05-10 23:37:05, Epoch : 1, Step : 6511, Training Loss : 0.56308, Training Acc : 0.761, Run Time : 0.89
INFO:root:2019-05-10 23:37:08, Epoch : 1, Step : 6512, Training Loss : 0.28564, Training Acc : 0.872, Run Time : 2.98
INFO:root:2019-05-10 23:37:08, Epoch : 1, Step : 6513, Training Loss : 0.31967, Training Acc : 0.822, Run Time : 0.77
INFO:root:2019-05-10 23:37:15, Epoch : 1, Step : 6514, Training Loss : 0.43687, Training Acc : 0.800, Run Time : 6.40
INFO:root:2019-05-10 23:37:16, Epoch : 1, Step : 6515, Training Loss : 0.56422, Training Acc : 0.728, Run Time : 1.05
INFO:root:2019-05-10 23:37:16, Epoch : 1, Step : 6516, Training Loss : 0.64574, Training Acc : 0.711, Run Time : 0.45
INFO:root:2019-05-10 23:37:24, Epoch : 1, Step : 6517, Training Loss : 0.53994, Training Acc : 0.767, Run Time : 7.45
INFO:root:2019-05-10 23:37:24, Epoch : 1, Step : 6518, Training Loss : 0.43338, Training Acc : 0.833, Run Time : 0.43
INFO:root:2019-05-10 23:37:25, Epoch : 1, Step : 6519, Training Loss : 0.26609, Training Acc : 0.906, Run Time : 0.40
INFO:root:2019-05-10 23:37:25, Epoch : 1, Step : 6520, Training Loss : 0.18525, Training Acc : 0.922, Run Time : 0.67
INFO:root:2019-05-10 23:37:34, Epoch : 1, Step : 6521, Training Loss : 0.24106, Training Acc : 0.883, Run Time : 8.44
INFO:root:2019-05-10 23:37:34, Epoch : 1, Step : 6522, Training Loss : 0.20883, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-10 23:37:36, Epoch : 1, Step : 6523, Training Loss : 0.18155, Training Acc : 0.911, Run Time : 2.09
INFO:root:2019-05-10 23:37:48, Epoch : 1, Step : 6524, Training Loss : 0.16854, Training Acc : 0.950, Run Time : 11.31
INFO:root:2019-05-10 23:37:48, Epoch : 1, Step : 6525, Training Loss : 0.19443, Training Acc : 0.922, Run Time : 0.67
INFO:root:2019-05-10 23:37:49, Epoch : 1, Step : 6526, Training Loss : 0.18185, Training Acc : 0.917, Run Time : 0.39
INFO:root:2019-05-10 23:37:49, Epoch : 1, Step : 6527, Training Loss : 0.14918, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-10 23:37:58, Epoch : 1, Step : 6528, Training Loss : 0.20690, Training Acc : 0.917, Run Time : 8.76
INFO:root:2019-05-10 23:37:59, Epoch : 1, Step : 6529, Training Loss : 0.23654, Training Acc : 0.906, Run Time : 0.88
INFO:root:2019-05-10 23:37:59, Epoch : 1, Step : 6530, Training Loss : 0.22396, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-10 23:38:00, Epoch : 1, Step : 6531, Training Loss : 0.22463, Training Acc : 0.928, Run Time : 0.37
INFO:root:2019-05-10 23:38:00, Epoch : 1, Step : 6532, Training Loss : 0.21491, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-10 23:38:30, Epoch : 1, Step : 6533, Training Loss : 0.12943, Training Acc : 0.944, Run Time : 30.41
INFO:root:2019-05-10 23:38:32, Epoch : 1, Step : 6534, Training Loss : 0.16895, Training Acc : 0.922, Run Time : 1.61
INFO:root:2019-05-10 23:38:32, Epoch : 1, Step : 6535, Training Loss : 0.11513, Training Acc : 0.961, Run Time : 0.44
INFO:root:2019-05-10 23:38:33, Epoch : 1, Step : 6536, Training Loss : 0.10207, Training Acc : 0.972, Run Time : 0.47
INFO:root:2019-05-10 23:38:33, Epoch : 1, Step : 6537, Training Loss : 0.10895, Training Acc : 0.967, Run Time : 0.47
INFO:root:2019-05-10 23:38:39, Epoch : 1, Step : 6538, Training Loss : 0.08727, Training Acc : 0.989, Run Time : 5.79
INFO:root:2019-05-10 23:38:40, Epoch : 1, Step : 6539, Training Loss : 0.08637, Training Acc : 0.989, Run Time : 0.47
INFO:root:2019-05-10 23:38:49, Epoch : 1, Step : 6540, Training Loss : 0.11487, Training Acc : 0.967, Run Time : 9.22
INFO:root:2019-05-10 23:38:50, Epoch : 1, Step : 6541, Training Loss : 0.11381, Training Acc : 0.967, Run Time : 0.85
INFO:root:2019-05-10 23:38:50, Epoch : 1, Step : 6542, Training Loss : 0.09542, Training Acc : 0.972, Run Time : 0.43
INFO:root:2019-05-10 23:38:51, Epoch : 1, Step : 6543, Training Loss : 0.13623, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-10 23:38:58, Epoch : 1, Step : 6544, Training Loss : 0.18185, Training Acc : 0.933, Run Time : 7.30
INFO:root:2019-05-10 23:39:00, Epoch : 1, Step : 6545, Training Loss : 0.10266, Training Acc : 0.972, Run Time : 1.70
INFO:root:2019-05-10 23:39:00, Epoch : 1, Step : 6546, Training Loss : 0.13877, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-10 23:39:01, Epoch : 1, Step : 6547, Training Loss : 0.08223, Training Acc : 0.978, Run Time : 0.46
INFO:root:2019-05-10 23:39:01, Epoch : 1, Step : 6548, Training Loss : 0.09404, Training Acc : 0.978, Run Time : 0.71
INFO:root:2019-05-10 23:39:10, Epoch : 1, Step : 6549, Training Loss : 0.07483, Training Acc : 0.983, Run Time : 9.14
INFO:root:2019-05-10 23:39:11, Epoch : 1, Step : 6550, Training Loss : 0.08581, Training Acc : 0.972, Run Time : 0.84
INFO:root:2019-05-10 23:39:13, Epoch : 1, Step : 6551, Training Loss : 0.12229, Training Acc : 0.956, Run Time : 2.26
INFO:root:2019-05-10 23:39:16, Epoch : 1, Step : 6552, Training Loss : 0.07493, Training Acc : 0.994, Run Time : 2.21
INFO:root:2019-05-10 23:39:16, Epoch : 1, Step : 6553, Training Loss : 0.05787, Training Acc : 0.994, Run Time : 0.43
INFO:root:2019-05-10 23:39:16, Epoch : 1, Step : 6554, Training Loss : 0.10047, Training Acc : 0.989, Run Time : 0.32
INFO:root:2019-05-10 23:39:25, Epoch : 1, Step : 6555, Training Loss : 0.08322, Training Acc : 0.961, Run Time : 8.74
INFO:root:2019-05-10 23:39:26, Epoch : 1, Step : 6556, Training Loss : 0.08087, Training Acc : 0.983, Run Time : 0.40
INFO:root:2019-05-10 23:39:26, Epoch : 1, Step : 6557, Training Loss : 0.11962, Training Acc : 0.961, Run Time : 0.46
INFO:root:2019-05-10 23:39:27, Epoch : 1, Step : 6558, Training Loss : 0.11178, Training Acc : 0.961, Run Time : 1.33
INFO:root:2019-05-10 23:39:34, Epoch : 1, Step : 6559, Training Loss : 0.08342, Training Acc : 0.972, Run Time : 7.06
INFO:root:2019-05-10 23:39:35, Epoch : 1, Step : 6560, Training Loss : 0.09187, Training Acc : 0.967, Run Time : 0.40
INFO:root:2019-05-10 23:39:35, Epoch : 1, Step : 6561, Training Loss : 0.21116, Training Acc : 0.911, Run Time : 0.54
INFO:root:2019-05-10 23:39:36, Epoch : 1, Step : 6562, Training Loss : 0.20874, Training Acc : 0.933, Run Time : 0.59
INFO:root:2019-05-10 23:39:44, Epoch : 1, Step : 6563, Training Loss : 0.23029, Training Acc : 0.933, Run Time : 7.58
INFO:root:2019-05-10 23:39:44, Epoch : 1, Step : 6564, Training Loss : 0.26590, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-10 23:39:45, Epoch : 1, Step : 6565, Training Loss : 0.62512, Training Acc : 0.822, Run Time : 0.95
INFO:root:2019-05-10 23:39:46, Epoch : 1, Step : 6566, Training Loss : 0.52991, Training Acc : 0.861, Run Time : 1.47
INFO:root:2019-05-10 23:39:51, Epoch : 1, Step : 6567, Training Loss : 0.29748, Training Acc : 0.906, Run Time : 4.38
INFO:root:2019-05-10 23:39:51, Epoch : 1, Step : 6568, Training Loss : 0.28337, Training Acc : 0.878, Run Time : 0.43
INFO:root:2019-05-10 23:40:02, Epoch : 1, Step : 6569, Training Loss : 0.18907, Training Acc : 0.928, Run Time : 10.92
INFO:root:2019-05-10 23:40:02, Epoch : 1, Step : 6570, Training Loss : 0.11719, Training Acc : 0.956, Run Time : 0.23
INFO:root:2019-05-10 23:40:03, Epoch : 1, Step : 6571, Training Loss : 0.10228, Training Acc : 0.967, Run Time : 0.56
INFO:root:2019-05-10 23:40:03, Epoch : 1, Step : 6572, Training Loss : 0.22021, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-10 23:40:04, Epoch : 1, Step : 6573, Training Loss : 0.24917, Training Acc : 0.906, Run Time : 0.35
INFO:root:2019-05-10 23:40:11, Epoch : 1, Step : 6574, Training Loss : 0.15937, Training Acc : 0.922, Run Time : 7.47
INFO:root:2019-05-10 23:40:12, Epoch : 1, Step : 6575, Training Loss : 0.16439, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-10 23:40:13, Epoch : 1, Step : 6576, Training Loss : 0.17223, Training Acc : 0.911, Run Time : 1.11
INFO:root:2019-05-10 23:40:13, Epoch : 1, Step : 6577, Training Loss : 0.13218, Training Acc : 0.961, Run Time : 0.45
INFO:root:2019-05-10 23:40:20, Epoch : 1, Step : 6578, Training Loss : 0.08371, Training Acc : 0.983, Run Time : 7.19
INFO:root:2019-05-10 23:40:21, Epoch : 1, Step : 6579, Training Loss : 0.08409, Training Acc : 0.983, Run Time : 0.31
INFO:root:2019-05-10 23:40:23, Epoch : 1, Step : 6580, Training Loss : 0.15044, Training Acc : 0.922, Run Time : 2.32
INFO:root:2019-05-10 23:40:23, Epoch : 1, Step : 6581, Training Loss : 0.14198, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-10 23:40:44, Epoch : 1, Step : 6582, Training Loss : 0.30084, Training Acc : 0.850, Run Time : 20.17
INFO:root:2019-05-10 23:40:44, Epoch : 1, Step : 6583, Training Loss : 0.22920, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-10 23:40:44, Epoch : 1, Step : 6584, Training Loss : 0.14896, Training Acc : 0.950, Run Time : 0.42
INFO:root:2019-05-10 23:40:45, Epoch : 1, Step : 6585, Training Loss : 0.19484, Training Acc : 0.900, Run Time : 0.97
INFO:root:2019-05-10 23:40:50, Epoch : 1, Step : 6586, Training Loss : 0.11223, Training Acc : 0.961, Run Time : 4.78
INFO:root:2019-05-10 23:40:51, Epoch : 1, Step : 6587, Training Loss : 0.17148, Training Acc : 0.939, Run Time : 0.58
INFO:root:2019-05-10 23:40:51, Epoch : 1, Step : 6588, Training Loss : 0.09141, Training Acc : 0.961, Run Time : 0.53
INFO:root:2019-05-10 23:40:59, Epoch : 1, Step : 6589, Training Loss : 0.28329, Training Acc : 0.889, Run Time : 7.38
INFO:root:2019-05-10 23:40:59, Epoch : 1, Step : 6590, Training Loss : 0.22599, Training Acc : 0.922, Run Time : 0.43
INFO:root:2019-05-10 23:41:00, Epoch : 1, Step : 6591, Training Loss : 0.24942, Training Acc : 0.883, Run Time : 0.44
INFO:root:2019-05-10 23:41:00, Epoch : 1, Step : 6592, Training Loss : 0.19763, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-10 23:41:09, Epoch : 1, Step : 6593, Training Loss : 0.33802, Training Acc : 0.839, Run Time : 9.12
INFO:root:2019-05-10 23:41:10, Epoch : 1, Step : 6594, Training Loss : 0.38432, Training Acc : 0.861, Run Time : 0.58
INFO:root:2019-05-10 23:41:10, Epoch : 1, Step : 6595, Training Loss : 0.20924, Training Acc : 0.939, Run Time : 0.57
INFO:root:2019-05-10 23:41:11, Epoch : 1, Step : 6596, Training Loss : 0.20116, Training Acc : 0.933, Run Time : 0.51
INFO:root:2019-05-10 23:41:16, Epoch : 1, Step : 6597, Training Loss : 0.06715, Training Acc : 0.983, Run Time : 4.94
INFO:root:2019-05-10 23:41:16, Epoch : 1, Step : 6598, Training Loss : 0.10465, Training Acc : 0.972, Run Time : 0.43
INFO:root:2019-05-10 23:41:25, Epoch : 1, Step : 6599, Training Loss : 0.18433, Training Acc : 0.933, Run Time : 8.72
INFO:root:2019-05-10 23:41:25, Epoch : 1, Step : 6600, Training Loss : 0.25547, Training Acc : 0.900, Run Time : 0.45
INFO:root:2019-05-10 23:41:26, Epoch : 1, Step : 6601, Training Loss : 1.19152, Training Acc : 0.556, Run Time : 0.90
INFO:root:2019-05-10 23:41:33, Epoch : 1, Step : 6602, Training Loss : 1.54611, Training Acc : 0.483, Run Time : 6.49
INFO:root:2019-05-10 23:41:33, Epoch : 1, Step : 6603, Training Loss : 1.53116, Training Acc : 0.428, Run Time : 0.40
INFO:root:2019-05-10 23:41:34, Epoch : 1, Step : 6604, Training Loss : 0.82324, Training Acc : 0.606, Run Time : 0.42
INFO:root:2019-05-10 23:41:35, Epoch : 1, Step : 6605, Training Loss : 1.36994, Training Acc : 0.361, Run Time : 1.07
INFO:root:2019-05-10 23:41:39, Epoch : 1, Step : 6606, Training Loss : 0.94358, Training Acc : 0.478, Run Time : 4.49
INFO:root:2019-05-10 23:41:40, Epoch : 1, Step : 6607, Training Loss : 0.71740, Training Acc : 0.644, Run Time : 1.13
INFO:root:2019-05-10 23:41:41, Epoch : 1, Step : 6608, Training Loss : 0.92095, Training Acc : 0.583, Run Time : 0.72
INFO:root:2019-05-10 23:41:46, Epoch : 1, Step : 6609, Training Loss : 0.80561, Training Acc : 0.644, Run Time : 5.22
INFO:root:2019-05-10 23:41:48, Epoch : 1, Step : 6610, Training Loss : 0.88299, Training Acc : 0.611, Run Time : 2.13
INFO:root:2019-05-10 23:41:52, Epoch : 1, Step : 6611, Training Loss : 1.08679, Training Acc : 0.433, Run Time : 4.08
INFO:root:2019-05-10 23:41:53, Epoch : 1, Step : 6612, Training Loss : 0.80687, Training Acc : 0.633, Run Time : 0.43
INFO:root:2019-05-10 23:42:03, Epoch : 1, Step : 6613, Training Loss : 0.92865, Training Acc : 0.544, Run Time : 10.41
INFO:root:2019-05-10 23:42:04, Epoch : 1, Step : 6614, Training Loss : 0.81523, Training Acc : 0.550, Run Time : 0.46
INFO:root:2019-05-10 23:42:04, Epoch : 1, Step : 6615, Training Loss : 0.56964, Training Acc : 0.717, Run Time : 0.47
INFO:root:2019-05-10 23:42:05, Epoch : 1, Step : 6616, Training Loss : 0.51702, Training Acc : 0.700, Run Time : 0.47
INFO:root:2019-05-10 23:42:05, Epoch : 1, Step : 6617, Training Loss : 0.50783, Training Acc : 0.711, Run Time : 0.43
INFO:root:2019-05-10 23:42:16, Epoch : 1, Step : 6618, Training Loss : 0.48911, Training Acc : 0.778, Run Time : 10.55
INFO:root:2019-05-10 23:42:16, Epoch : 1, Step : 6619, Training Loss : 0.43441, Training Acc : 0.772, Run Time : 0.62
INFO:root:2019-05-10 23:42:30, Epoch : 1, Step : 6620, Training Loss : 0.51489, Training Acc : 0.772, Run Time : 13.87
INFO:root:2019-05-10 23:42:31, Epoch : 1, Step : 6621, Training Loss : 0.45086, Training Acc : 0.817, Run Time : 0.94
INFO:root:2019-05-10 23:42:31, Epoch : 1, Step : 6622, Training Loss : 0.49745, Training Acc : 0.783, Run Time : 0.44
INFO:root:2019-05-10 23:42:32, Epoch : 1, Step : 6623, Training Loss : 0.48959, Training Acc : 0.778, Run Time : 0.46
INFO:root:2019-05-10 23:42:32, Epoch : 1, Step : 6624, Training Loss : 0.62684, Training Acc : 0.644, Run Time : 0.47
INFO:root:2019-05-10 23:42:43, Epoch : 1, Step : 6625, Training Loss : 0.54100, Training Acc : 0.694, Run Time : 10.12
INFO:root:2019-05-10 23:42:43, Epoch : 1, Step : 6626, Training Loss : 0.47911, Training Acc : 0.783, Run Time : 0.43
INFO:root:2019-05-10 23:42:43, Epoch : 1, Step : 6627, Training Loss : 0.43862, Training Acc : 0.822, Run Time : 0.49
INFO:root:2019-05-10 23:42:44, Epoch : 1, Step : 6628, Training Loss : 0.34123, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-10 23:42:45, Epoch : 1, Step : 6629, Training Loss : 0.49457, Training Acc : 0.783, Run Time : 1.41
INFO:root:2019-05-10 23:42:55, Epoch : 1, Step : 6630, Training Loss : 0.47028, Training Acc : 0.778, Run Time : 9.77
INFO:root:2019-05-10 23:42:56, Epoch : 1, Step : 6631, Training Loss : 0.45823, Training Acc : 0.772, Run Time : 0.42
INFO:root:2019-05-10 23:42:56, Epoch : 1, Step : 6632, Training Loss : 0.40817, Training Acc : 0.794, Run Time : 0.50
INFO:root:2019-05-10 23:43:01, Epoch : 1, Step : 6633, Training Loss : 0.42552, Training Acc : 0.894, Run Time : 4.92
INFO:root:2019-05-10 23:43:01, Epoch : 1, Step : 6634, Training Loss : 0.45979, Training Acc : 0.761, Run Time : 0.46
INFO:root:2019-05-10 23:43:02, Epoch : 1, Step : 6635, Training Loss : 0.44184, Training Acc : 0.783, Run Time : 0.46
INFO:root:2019-05-10 23:43:07, Epoch : 1, Step : 6636, Training Loss : 0.30487, Training Acc : 0.911, Run Time : 5.45
INFO:root:2019-05-10 23:43:08, Epoch : 1, Step : 6637, Training Loss : 0.41470, Training Acc : 0.794, Run Time : 0.50
INFO:root:2019-05-10 23:43:09, Epoch : 1, Step : 6638, Training Loss : 0.53447, Training Acc : 0.750, Run Time : 0.72
INFO:root:2019-05-10 23:43:21, Epoch : 1, Step : 6639, Training Loss : 0.39719, Training Acc : 0.839, Run Time : 12.40
INFO:root:2019-05-10 23:43:22, Epoch : 1, Step : 6640, Training Loss : 0.25601, Training Acc : 0.972, Run Time : 1.10
INFO:root:2019-05-10 23:43:22, Epoch : 1, Step : 6641, Training Loss : 0.44211, Training Acc : 0.833, Run Time : 0.44
INFO:root:2019-05-10 23:43:23, Epoch : 1, Step : 6642, Training Loss : 0.34390, Training Acc : 0.894, Run Time : 0.64
INFO:root:2019-05-10 23:43:30, Epoch : 1, Step : 6643, Training Loss : 0.30947, Training Acc : 0.861, Run Time : 6.49
INFO:root:2019-05-10 23:43:30, Epoch : 1, Step : 6644, Training Loss : 0.42000, Training Acc : 0.822, Run Time : 0.68
INFO:root:2019-05-10 23:43:31, Epoch : 1, Step : 6645, Training Loss : 0.50426, Training Acc : 0.733, Run Time : 0.48
INFO:root:2019-05-10 23:43:31, Epoch : 1, Step : 6646, Training Loss : 0.40753, Training Acc : 0.844, Run Time : 0.51
INFO:root:2019-05-10 23:43:32, Epoch : 1, Step : 6647, Training Loss : 0.49434, Training Acc : 0.722, Run Time : 1.01
INFO:root:2019-05-10 23:43:43, Epoch : 1, Step : 6648, Training Loss : 0.34235, Training Acc : 0.839, Run Time : 10.97
INFO:root:2019-05-10 23:43:44, Epoch : 1, Step : 6649, Training Loss : 0.35328, Training Acc : 0.844, Run Time : 0.32
INFO:root:2019-05-10 23:43:44, Epoch : 1, Step : 6650, Training Loss : 0.34897, Training Acc : 0.856, Run Time : 0.38
INFO:root:2019-05-10 23:43:57, Epoch : 1, Step : 6651, Training Loss : 0.46770, Training Acc : 0.744, Run Time : 12.77
INFO:root:2019-05-10 23:43:57, Epoch : 1, Step : 6652, Training Loss : 0.39154, Training Acc : 0.800, Run Time : 0.48
INFO:root:2019-05-10 23:43:58, Epoch : 1, Step : 6653, Training Loss : 0.26347, Training Acc : 0.894, Run Time : 0.43
INFO:root:2019-05-10 23:43:58, Epoch : 1, Step : 6654, Training Loss : 0.33774, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-10 23:44:13, Epoch : 1, Step : 6655, Training Loss : 0.28678, Training Acc : 0.883, Run Time : 14.65
INFO:root:2019-05-10 23:44:14, Epoch : 1, Step : 6656, Training Loss : 0.28931, Training Acc : 0.911, Run Time : 0.80
INFO:root:2019-05-10 23:44:14, Epoch : 1, Step : 6657, Training Loss : 0.36290, Training Acc : 0.844, Run Time : 0.42
INFO:root:2019-05-10 23:44:15, Epoch : 1, Step : 6658, Training Loss : 0.23197, Training Acc : 0.950, Run Time : 0.55
INFO:root:2019-05-10 23:44:15, Epoch : 1, Step : 6659, Training Loss : 0.36785, Training Acc : 0.867, Run Time : 0.42
INFO:root:2019-05-10 23:44:23, Epoch : 1, Step : 6660, Training Loss : 0.35413, Training Acc : 0.861, Run Time : 7.78
INFO:root:2019-05-10 23:44:23, Epoch : 1, Step : 6661, Training Loss : 0.29515, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 23:44:24, Epoch : 1, Step : 6662, Training Loss : 0.33047, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-10 23:44:24, Epoch : 1, Step : 6663, Training Loss : 0.35396, Training Acc : 0.856, Run Time : 0.56
INFO:root:2019-05-10 23:44:40, Epoch : 1, Step : 6664, Training Loss : 0.32711, Training Acc : 0.883, Run Time : 15.50
INFO:root:2019-05-10 23:44:40, Epoch : 1, Step : 6665, Training Loss : 0.36353, Training Acc : 0.839, Run Time : 0.23
INFO:root:2019-05-10 23:44:40, Epoch : 1, Step : 6666, Training Loss : 0.25379, Training Acc : 0.906, Run Time : 0.21
INFO:root:2019-05-10 23:44:41, Epoch : 1, Step : 6667, Training Loss : 0.28866, Training Acc : 0.889, Run Time : 0.67
INFO:root:2019-05-10 23:44:41, Epoch : 1, Step : 6668, Training Loss : 0.65129, Training Acc : 0.694, Run Time : 0.29
INFO:root:2019-05-10 23:44:53, Epoch : 1, Step : 6669, Training Loss : 0.36329, Training Acc : 0.844, Run Time : 11.67
INFO:root:2019-05-10 23:44:53, Epoch : 1, Step : 6670, Training Loss : 0.37568, Training Acc : 0.833, Run Time : 0.31
INFO:root:2019-05-10 23:44:53, Epoch : 1, Step : 6671, Training Loss : 0.41016, Training Acc : 0.839, Run Time : 0.35
INFO:root:2019-05-10 23:44:54, Epoch : 1, Step : 6672, Training Loss : 0.40129, Training Acc : 0.822, Run Time : 0.39
INFO:root:2019-05-10 23:44:54, Epoch : 1, Step : 6673, Training Loss : 0.22695, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-10 23:45:07, Epoch : 1, Step : 6674, Training Loss : 0.22895, Training Acc : 0.933, Run Time : 12.66
INFO:root:2019-05-10 23:45:07, Epoch : 1, Step : 6675, Training Loss : 0.29701, Training Acc : 0.894, Run Time : 0.23
INFO:root:2019-05-10 23:45:07, Epoch : 1, Step : 6676, Training Loss : 0.36032, Training Acc : 0.839, Run Time : 0.22
INFO:root:2019-05-10 23:45:08, Epoch : 1, Step : 6677, Training Loss : 0.29029, Training Acc : 0.889, Run Time : 0.21
INFO:root:2019-05-10 23:45:08, Epoch : 1, Step : 6678, Training Loss : 0.29293, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-10 23:45:19, Epoch : 1, Step : 6679, Training Loss : 0.29199, Training Acc : 0.872, Run Time : 11.11
INFO:root:2019-05-10 23:45:20, Epoch : 1, Step : 6680, Training Loss : 0.21075, Training Acc : 0.928, Run Time : 0.58
INFO:root:2019-05-10 23:45:20, Epoch : 1, Step : 6681, Training Loss : 0.18112, Training Acc : 0.956, Run Time : 0.24
INFO:root:2019-05-10 23:45:20, Epoch : 1, Step : 6682, Training Loss : 0.12319, Training Acc : 1.000, Run Time : 0.24
INFO:root:2019-05-10 23:45:31, Epoch : 1, Step : 6683, Training Loss : 0.34426, Training Acc : 0.800, Run Time : 10.42
INFO:root:2019-05-10 23:45:32, Epoch : 1, Step : 6684, Training Loss : 0.21990, Training Acc : 0.939, Run Time : 1.00
INFO:root:2019-05-10 23:45:32, Epoch : 1, Step : 6685, Training Loss : 0.18956, Training Acc : 0.939, Run Time : 0.43
INFO:root:2019-05-10 23:45:36, Epoch : 1, Step : 6686, Training Loss : 0.22671, Training Acc : 0.928, Run Time : 3.67
INFO:root:2019-05-10 23:45:36, Epoch : 1, Step : 6687, Training Loss : 0.25870, Training Acc : 0.928, Run Time : 0.42
INFO:root:2019-05-10 23:45:39, Epoch : 1, Step : 6688, Training Loss : 0.20512, Training Acc : 0.933, Run Time : 2.40
INFO:root:2019-05-10 23:45:39, Epoch : 1, Step : 6689, Training Loss : 0.17892, Training Acc : 0.950, Run Time : 0.43
INFO:root:2019-05-10 23:45:52, Epoch : 1, Step : 6690, Training Loss : 0.36500, Training Acc : 0.828, Run Time : 12.55
INFO:root:2019-05-10 23:45:52, Epoch : 1, Step : 6691, Training Loss : 0.15300, Training Acc : 0.967, Run Time : 0.71
INFO:root:2019-05-10 23:45:53, Epoch : 1, Step : 6692, Training Loss : 0.15776, Training Acc : 0.967, Run Time : 0.56
INFO:root:2019-05-10 23:45:53, Epoch : 1, Step : 6693, Training Loss : 0.28330, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 23:45:54, Epoch : 1, Step : 6694, Training Loss : 0.16106, Training Acc : 0.956, Run Time : 1.06
INFO:root:2019-05-10 23:46:02, Epoch : 1, Step : 6695, Training Loss : 0.38421, Training Acc : 0.856, Run Time : 7.94
INFO:root:2019-05-10 23:46:03, Epoch : 1, Step : 6696, Training Loss : 0.20866, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 23:46:03, Epoch : 1, Step : 6697, Training Loss : 0.27997, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-10 23:46:04, Epoch : 1, Step : 6698, Training Loss : 0.24927, Training Acc : 0.889, Run Time : 0.77
INFO:root:2019-05-10 23:46:17, Epoch : 1, Step : 6699, Training Loss : 0.18189, Training Acc : 0.961, Run Time : 12.85
INFO:root:2019-05-10 23:46:17, Epoch : 1, Step : 6700, Training Loss : 0.30143, Training Acc : 0.872, Run Time : 0.25
INFO:root:2019-05-10 23:46:18, Epoch : 1, Step : 6701, Training Loss : 0.18717, Training Acc : 0.939, Run Time : 0.79
INFO:root:2019-05-10 23:46:18, Epoch : 1, Step : 6702, Training Loss : 0.13231, Training Acc : 0.967, Run Time : 0.48
INFO:root:2019-05-10 23:46:19, Epoch : 1, Step : 6703, Training Loss : 0.17943, Training Acc : 0.933, Run Time : 0.50
INFO:root:2019-05-10 23:46:25, Epoch : 1, Step : 6704, Training Loss : 0.25238, Training Acc : 0.883, Run Time : 6.47
INFO:root:2019-05-10 23:46:26, Epoch : 1, Step : 6705, Training Loss : 0.30530, Training Acc : 0.861, Run Time : 0.46
INFO:root:2019-05-10 23:46:34, Epoch : 1, Step : 6706, Training Loss : 0.12418, Training Acc : 0.956, Run Time : 7.93
INFO:root:2019-05-10 23:46:34, Epoch : 1, Step : 6707, Training Loss : 0.24081, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-10 23:46:35, Epoch : 1, Step : 6708, Training Loss : 0.26677, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 23:46:47, Epoch : 1, Step : 6709, Training Loss : 0.23830, Training Acc : 0.906, Run Time : 12.15
INFO:root:2019-05-10 23:46:47, Epoch : 1, Step : 6710, Training Loss : 0.23785, Training Acc : 0.928, Run Time : 0.25
INFO:root:2019-05-10 23:46:47, Epoch : 1, Step : 6711, Training Loss : 0.27555, Training Acc : 0.906, Run Time : 0.29
INFO:root:2019-05-10 23:46:48, Epoch : 1, Step : 6712, Training Loss : 0.34385, Training Acc : 0.867, Run Time : 0.91
INFO:root:2019-05-10 23:46:49, Epoch : 1, Step : 6713, Training Loss : 0.21328, Training Acc : 0.922, Run Time : 0.53
INFO:root:2019-05-10 23:46:54, Epoch : 1, Step : 6714, Training Loss : 0.30311, Training Acc : 0.856, Run Time : 4.98
INFO:root:2019-05-10 23:46:59, Epoch : 1, Step : 6715, Training Loss : 0.13102, Training Acc : 0.967, Run Time : 5.70
INFO:root:2019-05-10 23:47:01, Epoch : 1, Step : 6716, Training Loss : 0.42391, Training Acc : 0.800, Run Time : 1.41
INFO:root:2019-05-10 23:47:01, Epoch : 1, Step : 6717, Training Loss : 0.34493, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-10 23:47:10, Epoch : 1, Step : 6718, Training Loss : 0.31029, Training Acc : 0.850, Run Time : 8.71
INFO:root:2019-05-10 23:47:11, Epoch : 1, Step : 6719, Training Loss : 0.28034, Training Acc : 0.894, Run Time : 0.60
INFO:root:2019-05-10 23:47:11, Epoch : 1, Step : 6720, Training Loss : 0.23937, Training Acc : 0.872, Run Time : 0.39
INFO:root:2019-05-10 23:47:11, Epoch : 1, Step : 6721, Training Loss : 0.44212, Training Acc : 0.778, Run Time : 0.47
INFO:root:2019-05-10 23:47:20, Epoch : 1, Step : 6722, Training Loss : 0.31755, Training Acc : 0.861, Run Time : 8.26
INFO:root:2019-05-10 23:47:20, Epoch : 1, Step : 6723, Training Loss : 0.16934, Training Acc : 0.961, Run Time : 0.70
INFO:root:2019-05-10 23:47:21, Epoch : 1, Step : 6724, Training Loss : 0.15936, Training Acc : 0.967, Run Time : 0.60
INFO:root:2019-05-10 23:47:21, Epoch : 1, Step : 6725, Training Loss : 0.18388, Training Acc : 0.917, Run Time : 0.20
INFO:root:2019-05-10 23:47:31, Epoch : 1, Step : 6726, Training Loss : 0.18027, Training Acc : 0.933, Run Time : 9.64
INFO:root:2019-05-10 23:47:31, Epoch : 1, Step : 6727, Training Loss : 0.29721, Training Acc : 0.861, Run Time : 0.39
INFO:root:2019-05-10 23:47:32, Epoch : 1, Step : 6728, Training Loss : 0.23756, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-10 23:47:32, Epoch : 1, Step : 6729, Training Loss : 0.16259, Training Acc : 0.944, Run Time : 0.44
INFO:root:2019-05-10 23:47:45, Epoch : 1, Step : 6730, Training Loss : 0.19264, Training Acc : 0.928, Run Time : 12.67
INFO:root:2019-05-10 23:47:45, Epoch : 1, Step : 6731, Training Loss : 0.19008, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 23:47:46, Epoch : 1, Step : 6732, Training Loss : 0.22116, Training Acc : 0.911, Run Time : 0.43
INFO:root:2019-05-10 23:47:46, Epoch : 1, Step : 6733, Training Loss : 0.18984, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-10 23:47:50, Epoch : 1, Step : 6734, Training Loss : 0.14215, Training Acc : 0.956, Run Time : 3.53
INFO:root:2019-05-10 23:47:51, Epoch : 1, Step : 6735, Training Loss : 0.20813, Training Acc : 0.928, Run Time : 0.88
INFO:root:2019-05-10 23:47:51, Epoch : 1, Step : 6736, Training Loss : 0.24465, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-10 23:48:07, Epoch : 1, Step : 6737, Training Loss : 0.18617, Training Acc : 0.911, Run Time : 15.96
INFO:root:2019-05-10 23:48:08, Epoch : 1, Step : 6738, Training Loss : 0.37349, Training Acc : 0.867, Run Time : 0.66
INFO:root:2019-05-10 23:48:14, Epoch : 1, Step : 6739, Training Loss : 0.11384, Training Acc : 0.967, Run Time : 6.47
INFO:root:2019-05-10 23:48:14, Epoch : 1, Step : 6740, Training Loss : 0.18019, Training Acc : 0.922, Run Time : 0.28
INFO:root:2019-05-10 23:48:15, Epoch : 1, Step : 6741, Training Loss : 0.34573, Training Acc : 0.861, Run Time : 0.43
INFO:root:2019-05-10 23:48:16, Epoch : 1, Step : 6742, Training Loss : 0.39585, Training Acc : 0.789, Run Time : 0.85
INFO:root:2019-05-10 23:48:16, Epoch : 1, Step : 6743, Training Loss : 0.24659, Training Acc : 0.906, Run Time : 0.61
INFO:root:2019-05-10 23:48:24, Epoch : 1, Step : 6744, Training Loss : 0.22665, Training Acc : 0.894, Run Time : 7.86
INFO:root:2019-05-10 23:48:25, Epoch : 1, Step : 6745, Training Loss : 0.30060, Training Acc : 0.844, Run Time : 0.43
INFO:root:2019-05-10 23:48:26, Epoch : 1, Step : 6746, Training Loss : 0.38364, Training Acc : 0.828, Run Time : 1.11
INFO:root:2019-05-10 23:48:26, Epoch : 1, Step : 6747, Training Loss : 0.16766, Training Acc : 0.917, Run Time : 0.50
INFO:root:2019-05-10 23:48:36, Epoch : 1, Step : 6748, Training Loss : 0.37170, Training Acc : 0.822, Run Time : 9.31
INFO:root:2019-05-10 23:48:36, Epoch : 1, Step : 6749, Training Loss : 0.35330, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-10 23:48:36, Epoch : 1, Step : 6750, Training Loss : 0.10865, Training Acc : 0.978, Run Time : 0.41
INFO:root:2019-05-10 23:48:49, Epoch : 1, Step : 6751, Training Loss : 0.18888, Training Acc : 0.944, Run Time : 12.49
INFO:root:2019-05-10 23:48:50, Epoch : 1, Step : 6752, Training Loss : 0.18062, Training Acc : 0.944, Run Time : 0.61
INFO:root:2019-05-10 23:48:50, Epoch : 1, Step : 6753, Training Loss : 0.33347, Training Acc : 0.822, Run Time : 0.44
INFO:root:2019-05-10 23:48:50, Epoch : 1, Step : 6754, Training Loss : 0.21504, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-10 23:48:51, Epoch : 1, Step : 6755, Training Loss : 0.49954, Training Acc : 0.783, Run Time : 0.46
INFO:root:2019-05-10 23:48:59, Epoch : 1, Step : 6756, Training Loss : 0.30812, Training Acc : 0.850, Run Time : 8.35
INFO:root:2019-05-10 23:49:01, Epoch : 1, Step : 6757, Training Loss : 0.31173, Training Acc : 0.861, Run Time : 1.44
INFO:root:2019-05-10 23:49:01, Epoch : 1, Step : 6758, Training Loss : 0.28846, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-10 23:49:02, Epoch : 1, Step : 6759, Training Loss : 0.41429, Training Acc : 0.817, Run Time : 0.43
INFO:root:2019-05-10 23:49:18, Epoch : 1, Step : 6760, Training Loss : 0.21767, Training Acc : 0.922, Run Time : 16.63
INFO:root:2019-05-10 23:49:19, Epoch : 1, Step : 6761, Training Loss : 0.15152, Training Acc : 0.944, Run Time : 1.01
INFO:root:2019-05-10 23:49:20, Epoch : 1, Step : 6762, Training Loss : 0.22500, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-10 23:49:20, Epoch : 1, Step : 6763, Training Loss : 0.25766, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-10 23:49:21, Epoch : 1, Step : 6764, Training Loss : 0.47775, Training Acc : 0.817, Run Time : 0.47
INFO:root:2019-05-10 23:49:24, Epoch : 1, Step : 6765, Training Loss : 0.32254, Training Acc : 0.856, Run Time : 3.90
INFO:root:2019-05-10 23:49:25, Epoch : 1, Step : 6766, Training Loss : 0.41051, Training Acc : 0.817, Run Time : 0.46
INFO:root:2019-05-10 23:49:37, Epoch : 1, Step : 6767, Training Loss : 0.47821, Training Acc : 0.789, Run Time : 12.09
INFO:root:2019-05-10 23:49:37, Epoch : 1, Step : 6768, Training Loss : 0.18569, Training Acc : 0.900, Run Time : 0.27
INFO:root:2019-05-10 23:49:38, Epoch : 1, Step : 6769, Training Loss : 0.21080, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-10 23:49:38, Epoch : 1, Step : 6770, Training Loss : 0.30430, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-10 23:49:39, Epoch : 1, Step : 6771, Training Loss : 0.25557, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-10 23:49:48, Epoch : 1, Step : 6772, Training Loss : 0.15716, Training Acc : 0.956, Run Time : 8.92
INFO:root:2019-05-10 23:49:48, Epoch : 1, Step : 6773, Training Loss : 0.34207, Training Acc : 0.833, Run Time : 0.38
INFO:root:2019-05-10 23:49:48, Epoch : 1, Step : 6774, Training Loss : 0.18127, Training Acc : 0.906, Run Time : 0.49
INFO:root:2019-05-10 23:49:49, Epoch : 1, Step : 6775, Training Loss : 0.28420, Training Acc : 0.861, Run Time : 0.45
INFO:root:2019-05-10 23:49:56, Epoch : 1, Step : 6776, Training Loss : 0.21352, Training Acc : 0.911, Run Time : 7.07
INFO:root:2019-05-10 23:49:56, Epoch : 1, Step : 6777, Training Loss : 0.12242, Training Acc : 0.956, Run Time : 0.46
INFO:root:2019-05-10 23:49:59, Epoch : 1, Step : 6778, Training Loss : 0.16400, Training Acc : 0.944, Run Time : 2.18
INFO:root:2019-05-10 23:49:59, Epoch : 1, Step : 6779, Training Loss : 0.17067, Training Acc : 0.928, Run Time : 0.51
INFO:root:2019-05-10 23:50:05, Epoch : 1, Step : 6780, Training Loss : 0.21245, Training Acc : 0.906, Run Time : 5.43
INFO:root:2019-05-10 23:50:05, Epoch : 1, Step : 6781, Training Loss : 0.21531, Training Acc : 0.900, Run Time : 0.43
INFO:root:2019-05-10 23:50:13, Epoch : 1, Step : 6782, Training Loss : 0.10763, Training Acc : 0.961, Run Time : 7.68
INFO:root:2019-05-10 23:50:13, Epoch : 1, Step : 6783, Training Loss : 0.22129, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 23:50:17, Epoch : 1, Step : 6784, Training Loss : 0.21366, Training Acc : 0.906, Run Time : 3.60
INFO:root:2019-05-10 23:50:19, Epoch : 1, Step : 6785, Training Loss : 0.27981, Training Acc : 0.878, Run Time : 2.45
INFO:root:2019-05-10 23:50:22, Epoch : 1, Step : 6786, Training Loss : 0.55047, Training Acc : 0.783, Run Time : 3.21
INFO:root:2019-05-10 23:50:23, Epoch : 1, Step : 6787, Training Loss : 0.98812, Training Acc : 0.606, Run Time : 0.77
INFO:root:2019-05-10 23:50:30, Epoch : 1, Step : 6788, Training Loss : 0.88410, Training Acc : 0.617, Run Time : 7.25
INFO:root:2019-05-10 23:50:31, Epoch : 1, Step : 6789, Training Loss : 0.71023, Training Acc : 0.700, Run Time : 0.48
INFO:root:2019-05-10 23:50:32, Epoch : 1, Step : 6790, Training Loss : 0.70049, Training Acc : 0.678, Run Time : 1.59
INFO:root:2019-05-10 23:50:33, Epoch : 1, Step : 6791, Training Loss : 0.52963, Training Acc : 0.733, Run Time : 0.46
INFO:root:2019-05-10 23:50:39, Epoch : 1, Step : 6792, Training Loss : 0.30526, Training Acc : 0.856, Run Time : 6.52
INFO:root:2019-05-10 23:50:40, Epoch : 1, Step : 6793, Training Loss : 0.27667, Training Acc : 0.861, Run Time : 0.44
INFO:root:2019-05-10 23:50:42, Epoch : 1, Step : 6794, Training Loss : 0.25942, Training Acc : 0.861, Run Time : 1.98
INFO:root:2019-05-10 23:50:42, Epoch : 1, Step : 6795, Training Loss : 0.30064, Training Acc : 0.844, Run Time : 0.46
INFO:root:2019-05-10 23:51:01, Epoch : 1, Step : 6796, Training Loss : 0.46885, Training Acc : 0.794, Run Time : 18.96
INFO:root:2019-05-10 23:51:02, Epoch : 1, Step : 6797, Training Loss : 0.33634, Training Acc : 0.822, Run Time : 0.35
INFO:root:2019-05-10 23:51:02, Epoch : 1, Step : 6798, Training Loss : 0.23018, Training Acc : 0.922, Run Time : 0.44
INFO:root:2019-05-10 23:51:03, Epoch : 1, Step : 6799, Training Loss : 0.63987, Training Acc : 0.706, Run Time : 0.46
INFO:root:2019-05-10 23:51:03, Epoch : 1, Step : 6800, Training Loss : 0.54993, Training Acc : 0.739, Run Time : 0.46
INFO:root:2019-05-10 23:51:11, Epoch : 1, Step : 6801, Training Loss : 1.59979, Training Acc : 0.478, Run Time : 8.28
INFO:root:2019-05-10 23:51:12, Epoch : 1, Step : 6802, Training Loss : 1.05906, Training Acc : 0.506, Run Time : 0.44
INFO:root:2019-05-10 23:51:13, Epoch : 1, Step : 6803, Training Loss : 0.92055, Training Acc : 0.606, Run Time : 0.91
INFO:root:2019-05-10 23:51:20, Epoch : 1, Step : 6804, Training Loss : 0.89167, Training Acc : 0.617, Run Time : 7.68
INFO:root:2019-05-10 23:51:21, Epoch : 1, Step : 6805, Training Loss : 0.57863, Training Acc : 0.761, Run Time : 0.70
INFO:root:2019-05-10 23:51:22, Epoch : 1, Step : 6806, Training Loss : 0.42954, Training Acc : 0.828, Run Time : 0.60
INFO:root:2019-05-10 23:51:22, Epoch : 1, Step : 6807, Training Loss : 0.47639, Training Acc : 0.789, Run Time : 0.80
INFO:root:2019-05-10 23:51:23, Epoch : 1, Step : 6808, Training Loss : 0.31245, Training Acc : 0.883, Run Time : 0.78
INFO:root:2019-05-10 23:51:33, Epoch : 1, Step : 6809, Training Loss : 0.25062, Training Acc : 0.933, Run Time : 9.77
INFO:root:2019-05-10 23:51:34, Epoch : 1, Step : 6810, Training Loss : 0.19940, Training Acc : 0.950, Run Time : 0.55
INFO:root:2019-05-10 23:51:34, Epoch : 1, Step : 6811, Training Loss : 0.27254, Training Acc : 0.883, Run Time : 0.36
INFO:root:2019-05-10 23:51:34, Epoch : 1, Step : 6812, Training Loss : 0.22692, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-10 23:51:44, Epoch : 1, Step : 6813, Training Loss : 0.21944, Training Acc : 0.917, Run Time : 9.38
INFO:root:2019-05-10 23:51:44, Epoch : 1, Step : 6814, Training Loss : 0.22434, Training Acc : 0.928, Run Time : 0.44
INFO:root:2019-05-10 23:51:45, Epoch : 1, Step : 6815, Training Loss : 0.18595, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-10 23:51:45, Epoch : 1, Step : 6816, Training Loss : 0.19805, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-10 23:51:47, Epoch : 1, Step : 6817, Training Loss : 0.22028, Training Acc : 0.917, Run Time : 1.78
INFO:root:2019-05-10 23:51:53, Epoch : 1, Step : 6818, Training Loss : 0.16547, Training Acc : 0.928, Run Time : 6.17
INFO:root:2019-05-10 23:51:53, Epoch : 1, Step : 6819, Training Loss : 0.19028, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-10 23:51:54, Epoch : 1, Step : 6820, Training Loss : 0.14989, Training Acc : 0.928, Run Time : 0.49
INFO:root:2019-05-10 23:51:56, Epoch : 1, Step : 6821, Training Loss : 0.17033, Training Acc : 0.933, Run Time : 2.29
INFO:root:2019-05-10 23:52:09, Epoch : 1, Step : 6822, Training Loss : 0.16501, Training Acc : 0.922, Run Time : 13.08
INFO:root:2019-05-10 23:52:10, Epoch : 1, Step : 6823, Training Loss : 0.20680, Training Acc : 0.917, Run Time : 0.29
INFO:root:2019-05-10 23:52:10, Epoch : 1, Step : 6824, Training Loss : 0.16714, Training Acc : 0.933, Run Time : 0.45
INFO:root:2019-05-10 23:52:11, Epoch : 1, Step : 6825, Training Loss : 0.15027, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 23:52:11, Epoch : 1, Step : 6826, Training Loss : 0.16187, Training Acc : 0.922, Run Time : 0.51
INFO:root:2019-05-10 23:52:15, Epoch : 1, Step : 6827, Training Loss : 0.14370, Training Acc : 0.928, Run Time : 4.03
INFO:root:2019-05-10 23:52:16, Epoch : 1, Step : 6828, Training Loss : 0.15793, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-10 23:52:30, Epoch : 1, Step : 6829, Training Loss : 0.16500, Training Acc : 0.922, Run Time : 14.20
INFO:root:2019-05-10 23:52:30, Epoch : 1, Step : 6830, Training Loss : 0.13736, Training Acc : 0.939, Run Time : 0.32
INFO:root:2019-05-10 23:52:30, Epoch : 1, Step : 6831, Training Loss : 0.16647, Training Acc : 0.933, Run Time : 0.43
INFO:root:2019-05-10 23:52:31, Epoch : 1, Step : 6832, Training Loss : 0.12956, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-10 23:52:32, Epoch : 1, Step : 6833, Training Loss : 0.16977, Training Acc : 0.922, Run Time : 0.57
INFO:root:2019-05-10 23:52:47, Epoch : 1, Step : 6834, Training Loss : 0.32141, Training Acc : 0.850, Run Time : 15.22
INFO:root:2019-05-10 23:52:47, Epoch : 1, Step : 6835, Training Loss : 0.18807, Training Acc : 0.911, Run Time : 0.27
INFO:root:2019-05-10 23:52:47, Epoch : 1, Step : 6836, Training Loss : 0.14380, Training Acc : 0.928, Run Time : 0.35
INFO:root:2019-05-10 23:52:48, Epoch : 1, Step : 6837, Training Loss : 0.10905, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-10 23:52:48, Epoch : 1, Step : 6838, Training Loss : 0.14114, Training Acc : 0.928, Run Time : 0.59
INFO:root:2019-05-10 23:53:04, Epoch : 1, Step : 6839, Training Loss : 0.15040, Training Acc : 0.944, Run Time : 15.28
INFO:root:2019-05-10 23:53:05, Epoch : 1, Step : 6840, Training Loss : 0.11632, Training Acc : 0.956, Run Time : 0.84
INFO:root:2019-05-10 23:53:05, Epoch : 1, Step : 6841, Training Loss : 0.12078, Training Acc : 0.922, Run Time : 0.40
INFO:root:2019-05-10 23:53:05, Epoch : 1, Step : 6842, Training Loss : 0.11898, Training Acc : 0.956, Run Time : 0.53
INFO:root:2019-05-10 23:53:06, Epoch : 1, Step : 6843, Training Loss : 0.14060, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-10 23:53:13, Epoch : 1, Step : 6844, Training Loss : 0.12547, Training Acc : 0.956, Run Time : 6.65
INFO:root:2019-05-10 23:53:13, Epoch : 1, Step : 6845, Training Loss : 0.10803, Training Acc : 0.967, Run Time : 0.33
INFO:root:2019-05-10 23:53:16, Epoch : 1, Step : 6846, Training Loss : 0.08980, Training Acc : 0.967, Run Time : 2.65
INFO:root:2019-05-10 23:53:16, Epoch : 1, Step : 6847, Training Loss : 0.12209, Training Acc : 0.950, Run Time : 0.93
INFO:root:2019-05-10 23:53:30, Epoch : 1, Step : 6848, Training Loss : 0.11342, Training Acc : 0.972, Run Time : 13.50
INFO:root:2019-05-10 23:53:31, Epoch : 1, Step : 6849, Training Loss : 0.13382, Training Acc : 0.961, Run Time : 0.57
INFO:root:2019-05-10 23:53:31, Epoch : 1, Step : 6850, Training Loss : 0.11545, Training Acc : 0.967, Run Time : 0.51
INFO:root:2019-05-10 23:53:32, Epoch : 1, Step : 6851, Training Loss : 0.13122, Training Acc : 0.956, Run Time : 0.52
INFO:root:2019-05-10 23:53:38, Epoch : 1, Step : 6852, Training Loss : 0.12872, Training Acc : 0.956, Run Time : 6.08
INFO:root:2019-05-10 23:53:38, Epoch : 1, Step : 6853, Training Loss : 0.12089, Training Acc : 0.967, Run Time : 0.59
INFO:root:2019-05-10 23:53:39, Epoch : 1, Step : 6854, Training Loss : 0.10271, Training Acc : 0.967, Run Time : 0.87
INFO:root:2019-05-10 23:53:40, Epoch : 1, Step : 6855, Training Loss : 0.15562, Training Acc : 0.911, Run Time : 1.17
INFO:root:2019-05-10 23:53:43, Epoch : 1, Step : 6856, Training Loss : 0.11303, Training Acc : 0.944, Run Time : 3.10
INFO:root:2019-05-10 23:53:46, Epoch : 1, Step : 6857, Training Loss : 0.11989, Training Acc : 0.950, Run Time : 2.85
INFO:root:2019-05-10 23:53:48, Epoch : 1, Step : 6858, Training Loss : 0.11511, Training Acc : 0.972, Run Time : 2.25
INFO:root:2019-05-10 23:53:50, Epoch : 1, Step : 6859, Training Loss : 0.09204, Training Acc : 0.978, Run Time : 1.83
INFO:root:2019-05-10 23:53:53, Epoch : 1, Step : 6860, Training Loss : 0.11167, Training Acc : 0.961, Run Time : 2.52
INFO:root:2019-05-10 23:54:02, Epoch : 1, Step : 6861, Training Loss : 0.12558, Training Acc : 0.967, Run Time : 8.88
INFO:root:2019-05-10 23:54:02, Epoch : 1, Step : 6862, Training Loss : 0.11767, Training Acc : 0.956, Run Time : 0.37
INFO:root:2019-05-10 23:54:02, Epoch : 1, Step : 6863, Training Loss : 0.10038, Training Acc : 0.978, Run Time : 0.42
INFO:root:2019-05-10 23:54:03, Epoch : 1, Step : 6864, Training Loss : 0.13062, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-10 23:54:04, Epoch : 1, Step : 6865, Training Loss : 0.12869, Training Acc : 0.944, Run Time : 0.91
INFO:root:2019-05-10 23:54:11, Epoch : 1, Step : 6866, Training Loss : 0.12509, Training Acc : 0.933, Run Time : 6.99
INFO:root:2019-05-10 23:54:11, Epoch : 1, Step : 6867, Training Loss : 0.12548, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-10 23:54:12, Epoch : 1, Step : 6868, Training Loss : 0.12231, Training Acc : 0.933, Run Time : 0.47
INFO:root:2019-05-10 23:54:14, Epoch : 1, Step : 6869, Training Loss : 0.11764, Training Acc : 0.944, Run Time : 1.83
INFO:root:2019-05-10 23:54:20, Epoch : 1, Step : 6870, Training Loss : 0.14285, Training Acc : 0.944, Run Time : 6.60
INFO:root:2019-05-10 23:54:21, Epoch : 1, Step : 6871, Training Loss : 0.11165, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-10 23:54:28, Epoch : 1, Step : 6872, Training Loss : 0.13337, Training Acc : 0.933, Run Time : 7.38
INFO:root:2019-05-10 23:54:30, Epoch : 1, Step : 6873, Training Loss : 0.12543, Training Acc : 0.956, Run Time : 1.67
INFO:root:2019-05-10 23:54:30, Epoch : 1, Step : 6874, Training Loss : 0.11263, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-10 23:54:31, Epoch : 1, Step : 6875, Training Loss : 0.12996, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-10 23:54:31, Epoch : 1, Step : 6876, Training Loss : 0.14620, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-10 23:54:33, Epoch : 1, Step : 6877, Training Loss : 0.08226, Training Acc : 0.983, Run Time : 2.46
INFO:root:2019-05-10 23:54:35, Epoch : 1, Step : 6878, Training Loss : 0.10519, Training Acc : 0.961, Run Time : 2.00
INFO:root:2019-05-10 23:54:44, Epoch : 1, Step : 6879, Training Loss : 0.10307, Training Acc : 0.944, Run Time : 8.76
INFO:root:2019-05-10 23:54:45, Epoch : 1, Step : 6880, Training Loss : 0.11513, Training Acc : 0.961, Run Time : 0.38
INFO:root:2019-05-10 23:54:52, Epoch : 1, Step : 6881, Training Loss : 0.11832, Training Acc : 0.944, Run Time : 7.15
INFO:root:2019-05-10 23:54:52, Epoch : 1, Step : 6882, Training Loss : 0.09622, Training Acc : 0.950, Run Time : 0.58
INFO:root:2019-05-10 23:54:53, Epoch : 1, Step : 6883, Training Loss : 0.10897, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-10 23:54:53, Epoch : 1, Step : 6884, Training Loss : 0.08050, Training Acc : 0.983, Run Time : 0.49
INFO:root:2019-05-10 23:55:03, Epoch : 1, Step : 6885, Training Loss : 0.10889, Training Acc : 0.933, Run Time : 10.16
INFO:root:2019-05-10 23:55:04, Epoch : 1, Step : 6886, Training Loss : 0.08945, Training Acc : 0.961, Run Time : 0.81
INFO:root:2019-05-10 23:55:05, Epoch : 1, Step : 6887, Training Loss : 0.09568, Training Acc : 0.961, Run Time : 0.58
INFO:root:2019-05-10 23:55:05, Epoch : 1, Step : 6888, Training Loss : 0.10516, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-10 23:55:20, Epoch : 1, Step : 6889, Training Loss : 0.11099, Training Acc : 0.956, Run Time : 14.52
INFO:root:2019-05-10 23:55:20, Epoch : 1, Step : 6890, Training Loss : 0.12976, Training Acc : 0.961, Run Time : 0.35
INFO:root:2019-05-10 23:55:21, Epoch : 1, Step : 6891, Training Loss : 0.30987, Training Acc : 0.939, Run Time : 0.40
INFO:root:2019-05-10 23:55:21, Epoch : 1, Step : 6892, Training Loss : 0.39094, Training Acc : 0.906, Run Time : 0.43
INFO:root:2019-05-10 23:55:22, Epoch : 1, Step : 6893, Training Loss : 0.23020, Training Acc : 0.939, Run Time : 1.21
INFO:root:2019-05-10 23:55:40, Epoch : 1, Step : 6894, Training Loss : 0.13476, Training Acc : 0.944, Run Time : 17.35
INFO:root:2019-05-10 23:55:41, Epoch : 1, Step : 6895, Training Loss : 0.27216, Training Acc : 0.889, Run Time : 1.54
INFO:root:2019-05-10 23:55:41, Epoch : 1, Step : 6896, Training Loss : 0.22482, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-10 23:55:42, Epoch : 1, Step : 6897, Training Loss : 0.21764, Training Acc : 0.900, Run Time : 0.50
INFO:root:2019-05-10 23:55:42, Epoch : 1, Step : 6898, Training Loss : 0.24107, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-10 23:55:45, Epoch : 1, Step : 6899, Training Loss : 0.15177, Training Acc : 0.922, Run Time : 2.10
INFO:root:2019-05-10 23:55:52, Epoch : 1, Step : 6900, Training Loss : 0.17824, Training Acc : 0.933, Run Time : 7.28
INFO:root:2019-05-10 23:55:53, Epoch : 1, Step : 6901, Training Loss : 0.13884, Training Acc : 0.944, Run Time : 0.85
INFO:root:2019-05-10 23:55:53, Epoch : 1, Step : 6902, Training Loss : 0.11726, Training Acc : 0.939, Run Time : 0.54
INFO:root:2019-05-10 23:55:58, Epoch : 1, Step : 6903, Training Loss : 0.14464, Training Acc : 0.933, Run Time : 4.79
INFO:root:2019-05-10 23:55:59, Epoch : 1, Step : 6904, Training Loss : 0.14610, Training Acc : 0.928, Run Time : 0.92
INFO:root:2019-05-10 23:56:00, Epoch : 1, Step : 6905, Training Loss : 0.21144, Training Acc : 0.894, Run Time : 0.67
INFO:root:2019-05-10 23:56:01, Epoch : 1, Step : 6906, Training Loss : 0.57240, Training Acc : 0.883, Run Time : 1.64
INFO:root:2019-05-10 23:56:05, Epoch : 1, Step : 6907, Training Loss : 0.65104, Training Acc : 0.811, Run Time : 4.21
INFO:root:2019-05-10 23:56:06, Epoch : 1, Step : 6908, Training Loss : 0.59946, Training Acc : 0.811, Run Time : 0.58
INFO:root:2019-05-10 23:56:20, Epoch : 1, Step : 6909, Training Loss : 0.64091, Training Acc : 0.811, Run Time : 13.84
INFO:root:2019-05-10 23:56:20, Epoch : 1, Step : 6910, Training Loss : 0.62098, Training Acc : 0.828, Run Time : 0.33
INFO:root:2019-05-10 23:56:21, Epoch : 1, Step : 6911, Training Loss : 0.41977, Training Acc : 0.861, Run Time : 0.47
INFO:root:2019-05-10 23:56:22, Epoch : 1, Step : 6912, Training Loss : 0.38153, Training Acc : 0.867, Run Time : 1.19
INFO:root:2019-05-10 23:56:32, Epoch : 1, Step : 6913, Training Loss : 0.46520, Training Acc : 0.817, Run Time : 10.42
INFO:root:2019-05-10 23:56:33, Epoch : 1, Step : 6914, Training Loss : 0.40854, Training Acc : 0.789, Run Time : 0.49
INFO:root:2019-05-10 23:56:33, Epoch : 1, Step : 6915, Training Loss : 0.35735, Training Acc : 0.833, Run Time : 0.45
INFO:root:2019-05-10 23:56:34, Epoch : 1, Step : 6916, Training Loss : 0.39965, Training Acc : 0.867, Run Time : 0.43
INFO:root:2019-05-10 23:56:35, Epoch : 1, Step : 6917, Training Loss : 0.27557, Training Acc : 0.883, Run Time : 1.51
INFO:root:2019-05-10 23:56:41, Epoch : 1, Step : 6918, Training Loss : 0.34380, Training Acc : 0.861, Run Time : 5.48
INFO:root:2019-05-10 23:56:41, Epoch : 1, Step : 6919, Training Loss : 0.34781, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-10 23:56:44, Epoch : 1, Step : 6920, Training Loss : 0.29799, Training Acc : 0.844, Run Time : 3.05
INFO:root:2019-05-10 23:56:45, Epoch : 1, Step : 6921, Training Loss : 0.47160, Training Acc : 0.761, Run Time : 0.70
INFO:root:2019-05-10 23:56:56, Epoch : 1, Step : 6922, Training Loss : 0.43895, Training Acc : 0.856, Run Time : 11.48
INFO:root:2019-05-10 23:56:57, Epoch : 1, Step : 6923, Training Loss : 0.42457, Training Acc : 0.811, Run Time : 0.32
INFO:root:2019-05-10 23:56:57, Epoch : 1, Step : 6924, Training Loss : 0.43979, Training Acc : 0.778, Run Time : 0.41
INFO:root:2019-05-10 23:56:58, Epoch : 1, Step : 6925, Training Loss : 0.39740, Training Acc : 0.839, Run Time : 0.50
INFO:root:2019-05-10 23:57:03, Epoch : 1, Step : 6926, Training Loss : 0.40199, Training Acc : 0.839, Run Time : 5.85
INFO:root:2019-05-10 23:57:04, Epoch : 1, Step : 6927, Training Loss : 0.36528, Training Acc : 0.789, Run Time : 0.96
INFO:root:2019-05-10 23:57:05, Epoch : 1, Step : 6928, Training Loss : 0.30107, Training Acc : 0.861, Run Time : 0.44
INFO:root:2019-05-10 23:57:11, Epoch : 1, Step : 6929, Training Loss : 0.33744, Training Acc : 0.856, Run Time : 6.01
INFO:root:2019-05-10 23:57:11, Epoch : 1, Step : 6930, Training Loss : 0.25391, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-10 23:57:15, Epoch : 1, Step : 6931, Training Loss : 0.32332, Training Acc : 0.861, Run Time : 3.57
INFO:root:2019-05-10 23:57:15, Epoch : 1, Step : 6932, Training Loss : 0.33318, Training Acc : 0.839, Run Time : 0.46
INFO:root:2019-05-10 23:57:28, Epoch : 1, Step : 6933, Training Loss : 0.26510, Training Acc : 0.883, Run Time : 12.28
INFO:root:2019-05-10 23:57:28, Epoch : 1, Step : 6934, Training Loss : 0.50018, Training Acc : 0.778, Run Time : 0.63
INFO:root:2019-05-10 23:57:29, Epoch : 1, Step : 6935, Training Loss : 0.45005, Training Acc : 0.794, Run Time : 0.48
INFO:root:2019-05-10 23:57:29, Epoch : 1, Step : 6936, Training Loss : 0.27490, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-10 23:57:30, Epoch : 1, Step : 6937, Training Loss : 0.41012, Training Acc : 0.778, Run Time : 0.47
INFO:root:2019-05-10 23:57:36, Epoch : 1, Step : 6938, Training Loss : 0.37147, Training Acc : 0.828, Run Time : 6.73
INFO:root:2019-05-10 23:57:37, Epoch : 1, Step : 6939, Training Loss : 0.23425, Training Acc : 0.906, Run Time : 0.37
INFO:root:2019-05-10 23:57:44, Epoch : 1, Step : 6940, Training Loss : 0.47558, Training Acc : 0.722, Run Time : 6.81
INFO:root:2019-05-10 23:57:44, Epoch : 1, Step : 6941, Training Loss : 0.27590, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 23:57:45, Epoch : 1, Step : 6942, Training Loss : 0.38041, Training Acc : 0.811, Run Time : 0.65
INFO:root:2019-05-10 23:57:46, Epoch : 1, Step : 6943, Training Loss : 0.37578, Training Acc : 0.811, Run Time : 1.55
INFO:root:2019-05-10 23:57:58, Epoch : 1, Step : 6944, Training Loss : 0.27411, Training Acc : 0.850, Run Time : 11.57
INFO:root:2019-05-10 23:57:58, Epoch : 1, Step : 6945, Training Loss : 0.34326, Training Acc : 0.817, Run Time : 0.26
INFO:root:2019-05-10 23:57:59, Epoch : 1, Step : 6946, Training Loss : 0.42375, Training Acc : 0.733, Run Time : 0.47
INFO:root:2019-05-10 23:57:59, Epoch : 1, Step : 6947, Training Loss : 0.38416, Training Acc : 0.772, Run Time : 0.52
INFO:root:2019-05-10 23:58:00, Epoch : 1, Step : 6948, Training Loss : 0.33748, Training Acc : 0.850, Run Time : 0.49
INFO:root:2019-05-10 23:58:24, Epoch : 1, Step : 6949, Training Loss : 0.37133, Training Acc : 0.772, Run Time : 24.24
INFO:root:2019-05-10 23:58:25, Epoch : 1, Step : 6950, Training Loss : 0.40310, Training Acc : 0.789, Run Time : 0.76
INFO:root:2019-05-10 23:58:25, Epoch : 1, Step : 6951, Training Loss : 0.33152, Training Acc : 0.828, Run Time : 0.45
INFO:root:2019-05-10 23:58:25, Epoch : 1, Step : 6952, Training Loss : 0.29238, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 23:58:26, Epoch : 1, Step : 6953, Training Loss : 0.34951, Training Acc : 0.844, Run Time : 0.47
INFO:root:2019-05-10 23:58:39, Epoch : 1, Step : 6954, Training Loss : 0.39305, Training Acc : 0.794, Run Time : 13.57
INFO:root:2019-05-10 23:58:40, Epoch : 1, Step : 6955, Training Loss : 0.31801, Training Acc : 0.850, Run Time : 0.32
INFO:root:2019-05-10 23:58:40, Epoch : 1, Step : 6956, Training Loss : 0.32012, Training Acc : 0.817, Run Time : 0.30
INFO:root:2019-05-10 23:58:41, Epoch : 1, Step : 6957, Training Loss : 0.40744, Training Acc : 0.789, Run Time : 0.56
INFO:root:2019-05-10 23:58:50, Epoch : 1, Step : 6958, Training Loss : 0.31922, Training Acc : 0.872, Run Time : 9.47
INFO:root:2019-05-10 23:58:51, Epoch : 1, Step : 6959, Training Loss : 0.38972, Training Acc : 0.772, Run Time : 0.50
INFO:root:2019-05-10 23:58:51, Epoch : 1, Step : 6960, Training Loss : 0.40588, Training Acc : 0.772, Run Time : 0.51
INFO:root:2019-05-10 23:58:52, Epoch : 1, Step : 6961, Training Loss : 0.26728, Training Acc : 0.906, Run Time : 0.44
INFO:root:2019-05-10 23:58:52, Epoch : 1, Step : 6962, Training Loss : 0.33430, Training Acc : 0.817, Run Time : 0.47
INFO:root:2019-05-10 23:59:00, Epoch : 1, Step : 6963, Training Loss : 0.44364, Training Acc : 0.761, Run Time : 7.58
INFO:root:2019-05-10 23:59:00, Epoch : 1, Step : 6964, Training Loss : 0.37546, Training Acc : 0.806, Run Time : 0.61
INFO:root:2019-05-10 23:59:09, Epoch : 1, Step : 6965, Training Loss : 0.25204, Training Acc : 0.911, Run Time : 8.50
INFO:root:2019-05-10 23:59:09, Epoch : 1, Step : 6966, Training Loss : 0.42791, Training Acc : 0.750, Run Time : 0.42
INFO:root:2019-05-10 23:59:10, Epoch : 1, Step : 6967, Training Loss : 0.41319, Training Acc : 0.778, Run Time : 0.41
INFO:root:2019-05-10 23:59:10, Epoch : 1, Step : 6968, Training Loss : 0.35053, Training Acc : 0.839, Run Time : 0.49
INFO:root:2019-05-10 23:59:20, Epoch : 1, Step : 6969, Training Loss : 0.51366, Training Acc : 0.700, Run Time : 10.28
INFO:root:2019-05-10 23:59:21, Epoch : 1, Step : 6970, Training Loss : 0.29383, Training Acc : 0.861, Run Time : 0.71
INFO:root:2019-05-10 23:59:22, Epoch : 1, Step : 6971, Training Loss : 0.44390, Training Acc : 0.728, Run Time : 0.50
INFO:root:2019-05-10 23:59:22, Epoch : 1, Step : 6972, Training Loss : 0.30993, Training Acc : 0.839, Run Time : 0.44
INFO:root:2019-05-10 23:59:22, Epoch : 1, Step : 6973, Training Loss : 0.29871, Training Acc : 0.867, Run Time : 0.38
INFO:root:2019-05-10 23:59:30, Epoch : 1, Step : 6974, Training Loss : 0.48759, Training Acc : 0.711, Run Time : 8.03
INFO:root:2019-05-10 23:59:33, Epoch : 1, Step : 6975, Training Loss : 0.44105, Training Acc : 0.756, Run Time : 2.13
INFO:root:2019-05-10 23:59:34, Epoch : 1, Step : 6976, Training Loss : 0.32639, Training Acc : 0.839, Run Time : 1.59
INFO:root:2019-05-10 23:59:35, Epoch : 1, Step : 6977, Training Loss : 0.34867, Training Acc : 0.794, Run Time : 0.48
INFO:root:2019-05-10 23:59:44, Epoch : 1, Step : 6978, Training Loss : 0.38102, Training Acc : 0.811, Run Time : 9.65
INFO:root:2019-05-10 23:59:45, Epoch : 1, Step : 6979, Training Loss : 0.47570, Training Acc : 0.694, Run Time : 0.41
INFO:root:2019-05-10 23:59:45, Epoch : 1, Step : 6980, Training Loss : 0.24687, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-10 23:59:46, Epoch : 1, Step : 6981, Training Loss : 0.44619, Training Acc : 0.750, Run Time : 0.49
INFO:root:2019-05-10 23:59:53, Epoch : 1, Step : 6982, Training Loss : 0.26640, Training Acc : 0.856, Run Time : 7.41
INFO:root:2019-05-10 23:59:54, Epoch : 1, Step : 6983, Training Loss : 0.38214, Training Acc : 0.750, Run Time : 0.45
INFO:root:2019-05-10 23:59:55, Epoch : 1, Step : 6984, Training Loss : 0.30571, Training Acc : 0.878, Run Time : 1.61
INFO:root:2019-05-10 23:59:56, Epoch : 1, Step : 6985, Training Loss : 0.28841, Training Acc : 0.850, Run Time : 0.57
INFO:root:2019-05-11 00:00:08, Epoch : 1, Step : 6986, Training Loss : 0.23925, Training Acc : 0.889, Run Time : 12.01
INFO:root:2019-05-11 00:00:08, Epoch : 1, Step : 6987, Training Loss : 0.29187, Training Acc : 0.861, Run Time : 0.62
INFO:root:2019-05-11 00:00:09, Epoch : 1, Step : 6988, Training Loss : 0.27132, Training Acc : 0.856, Run Time : 0.43
INFO:root:2019-05-11 00:00:14, Epoch : 1, Step : 6989, Training Loss : 0.37918, Training Acc : 0.783, Run Time : 5.24
INFO:root:2019-05-11 00:00:14, Epoch : 1, Step : 6990, Training Loss : 0.31078, Training Acc : 0.817, Run Time : 0.43
INFO:root:2019-05-11 00:00:15, Epoch : 1, Step : 6991, Training Loss : 0.24973, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-11 00:00:21, Epoch : 1, Step : 6992, Training Loss : 0.23293, Training Acc : 0.922, Run Time : 6.38
INFO:root:2019-05-11 00:00:23, Epoch : 1, Step : 6993, Training Loss : 0.30650, Training Acc : 0.861, Run Time : 1.41
INFO:root:2019-05-11 00:00:23, Epoch : 1, Step : 6994, Training Loss : 0.22179, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-11 00:00:24, Epoch : 1, Step : 6995, Training Loss : 0.27412, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-11 00:00:33, Epoch : 1, Step : 6996, Training Loss : 0.24071, Training Acc : 0.906, Run Time : 9.41
INFO:root:2019-05-11 00:00:34, Epoch : 1, Step : 6997, Training Loss : 0.32166, Training Acc : 0.833, Run Time : 1.03
INFO:root:2019-05-11 00:00:35, Epoch : 1, Step : 6998, Training Loss : 0.28766, Training Acc : 0.861, Run Time : 0.48
INFO:root:2019-05-11 00:00:35, Epoch : 1, Step : 6999, Training Loss : 0.39810, Training Acc : 0.806, Run Time : 0.46
INFO:root:2019-05-11 00:00:36, Epoch : 1, Step : 7000, Training Loss : 0.34549, Training Acc : 0.839, Run Time : 0.63
INFO:root:2019-05-11 00:00:43, Epoch : 1, Step : 7001, Training Loss : 0.94477, Training Acc : 0.594, Run Time : 6.94
INFO:root:2019-05-11 00:00:43, Epoch : 1, Step : 7002, Training Loss : 0.85158, Training Acc : 0.706, Run Time : 0.50
INFO:root:2019-05-11 00:00:52, Epoch : 1, Step : 7003, Training Loss : 0.73604, Training Acc : 0.650, Run Time : 8.97
INFO:root:2019-05-11 00:00:53, Epoch : 1, Step : 7004, Training Loss : 0.83278, Training Acc : 0.589, Run Time : 0.50
INFO:root:2019-05-11 00:00:53, Epoch : 1, Step : 7005, Training Loss : 0.53207, Training Acc : 0.756, Run Time : 0.39
INFO:root:2019-05-11 00:00:54, Epoch : 1, Step : 7006, Training Loss : 0.39296, Training Acc : 0.794, Run Time : 0.68
INFO:root:2019-05-11 00:01:06, Epoch : 1, Step : 7007, Training Loss : 0.38485, Training Acc : 0.839, Run Time : 12.27
INFO:root:2019-05-11 00:01:06, Epoch : 1, Step : 7008, Training Loss : 0.34224, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-11 00:01:07, Epoch : 1, Step : 7009, Training Loss : 0.51375, Training Acc : 0.739, Run Time : 0.61
INFO:root:2019-05-11 00:01:07, Epoch : 1, Step : 7010, Training Loss : 0.42654, Training Acc : 0.778, Run Time : 0.44
INFO:root:2019-05-11 00:01:08, Epoch : 1, Step : 7011, Training Loss : 0.35554, Training Acc : 0.861, Run Time : 0.44
INFO:root:2019-05-11 00:01:20, Epoch : 1, Step : 7012, Training Loss : 0.41965, Training Acc : 0.783, Run Time : 11.96
INFO:root:2019-05-11 00:01:20, Epoch : 1, Step : 7013, Training Loss : 0.49199, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-11 00:01:21, Epoch : 1, Step : 7014, Training Loss : 0.32686, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-11 00:01:21, Epoch : 1, Step : 7015, Training Loss : 0.55709, Training Acc : 0.806, Run Time : 0.45
INFO:root:2019-05-11 00:01:23, Epoch : 1, Step : 7016, Training Loss : 0.43291, Training Acc : 0.844, Run Time : 1.97
INFO:root:2019-05-11 00:01:31, Epoch : 1, Step : 7017, Training Loss : 0.48404, Training Acc : 0.817, Run Time : 8.12
INFO:root:2019-05-11 00:01:32, Epoch : 1, Step : 7018, Training Loss : 0.58023, Training Acc : 0.789, Run Time : 0.84
INFO:root:2019-05-11 00:01:33, Epoch : 1, Step : 7019, Training Loss : 0.46562, Training Acc : 0.778, Run Time : 0.46
INFO:root:2019-05-11 00:01:35, Epoch : 1, Step : 7020, Training Loss : 0.34760, Training Acc : 0.850, Run Time : 2.49
INFO:root:2019-05-11 00:01:44, Epoch : 1, Step : 7021, Training Loss : 0.43471, Training Acc : 0.756, Run Time : 8.93
INFO:root:2019-05-11 00:01:44, Epoch : 1, Step : 7022, Training Loss : 0.41735, Training Acc : 0.794, Run Time : 0.43
INFO:root:2019-05-11 00:01:45, Epoch : 1, Step : 7023, Training Loss : 0.35182, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-11 00:01:52, Epoch : 1, Step : 7024, Training Loss : 0.36790, Training Acc : 0.867, Run Time : 6.81
INFO:root:2019-05-11 00:01:52, Epoch : 1, Step : 7025, Training Loss : 0.48122, Training Acc : 0.756, Run Time : 0.45
INFO:root:2019-05-11 00:01:54, Epoch : 1, Step : 7026, Training Loss : 0.38328, Training Acc : 0.839, Run Time : 1.56
INFO:root:2019-05-11 00:01:54, Epoch : 1, Step : 7027, Training Loss : 0.38578, Training Acc : 0.833, Run Time : 0.68
INFO:root:2019-05-11 00:02:03, Epoch : 1, Step : 7028, Training Loss : 0.31268, Training Acc : 0.883, Run Time : 9.00
INFO:root:2019-05-11 00:02:04, Epoch : 1, Step : 7029, Training Loss : 0.29477, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-11 00:02:13, Epoch : 1, Step : 7030, Training Loss : 0.28269, Training Acc : 0.839, Run Time : 9.28
INFO:root:2019-05-11 00:02:14, Epoch : 1, Step : 7031, Training Loss : 0.43056, Training Acc : 0.794, Run Time : 1.18
INFO:root:2019-05-11 00:02:16, Epoch : 1, Step : 7032, Training Loss : 0.48799, Training Acc : 0.761, Run Time : 1.22
INFO:root:2019-05-11 00:02:16, Epoch : 1, Step : 7033, Training Loss : 0.41038, Training Acc : 0.761, Run Time : 0.52
INFO:root:2019-05-11 00:02:20, Epoch : 1, Step : 7034, Training Loss : 0.45029, Training Acc : 0.772, Run Time : 3.92
INFO:root:2019-05-11 00:02:20, Epoch : 1, Step : 7035, Training Loss : 0.31590, Training Acc : 0.844, Run Time : 0.44
INFO:root:2019-05-11 00:02:28, Epoch : 1, Step : 7036, Training Loss : 0.49421, Training Acc : 0.728, Run Time : 7.81
INFO:root:2019-05-11 00:02:29, Epoch : 1, Step : 7037, Training Loss : 0.36686, Training Acc : 0.844, Run Time : 0.64
INFO:root:2019-05-11 00:02:31, Epoch : 1, Step : 7038, Training Loss : 0.43845, Training Acc : 0.756, Run Time : 1.86
INFO:root:2019-05-11 00:02:31, Epoch : 1, Step : 7039, Training Loss : 0.40525, Training Acc : 0.839, Run Time : 0.48
INFO:root:2019-05-11 00:02:50, Epoch : 1, Step : 7040, Training Loss : 0.21050, Training Acc : 0.922, Run Time : 18.50
INFO:root:2019-05-11 00:02:51, Epoch : 1, Step : 7041, Training Loss : 0.37537, Training Acc : 0.811, Run Time : 0.84
INFO:root:2019-05-11 00:02:51, Epoch : 1, Step : 7042, Training Loss : 0.18393, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-11 00:02:52, Epoch : 1, Step : 7043, Training Loss : 0.30763, Training Acc : 0.856, Run Time : 0.45
INFO:root:2019-05-11 00:02:52, Epoch : 1, Step : 7044, Training Loss : 0.31229, Training Acc : 0.883, Run Time : 0.43
INFO:root:2019-05-11 00:03:01, Epoch : 1, Step : 7045, Training Loss : 0.43056, Training Acc : 0.806, Run Time : 8.66
INFO:root:2019-05-11 00:03:01, Epoch : 1, Step : 7046, Training Loss : 0.38370, Training Acc : 0.811, Run Time : 0.43
INFO:root:2019-05-11 00:03:03, Epoch : 1, Step : 7047, Training Loss : 0.37446, Training Acc : 0.828, Run Time : 1.64
INFO:root:2019-05-11 00:03:04, Epoch : 1, Step : 7048, Training Loss : 0.31280, Training Acc : 0.872, Run Time : 0.96
INFO:root:2019-05-11 00:03:20, Epoch : 1, Step : 7049, Training Loss : 0.29959, Training Acc : 0.867, Run Time : 16.31
INFO:root:2019-05-11 00:03:20, Epoch : 1, Step : 7050, Training Loss : 0.22972, Training Acc : 0.883, Run Time : 0.34
INFO:root:2019-05-11 00:03:21, Epoch : 1, Step : 7051, Training Loss : 0.33834, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-11 00:03:21, Epoch : 1, Step : 7052, Training Loss : 0.26713, Training Acc : 0.867, Run Time : 0.50
INFO:root:2019-05-11 00:03:22, Epoch : 1, Step : 7053, Training Loss : 0.39770, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-11 00:03:37, Epoch : 1, Step : 7054, Training Loss : 0.29592, Training Acc : 0.894, Run Time : 15.38
INFO:root:2019-05-11 00:03:38, Epoch : 1, Step : 7055, Training Loss : 0.40353, Training Acc : 0.844, Run Time : 0.55
INFO:root:2019-05-11 00:03:38, Epoch : 1, Step : 7056, Training Loss : 0.54704, Training Acc : 0.772, Run Time : 0.45
INFO:root:2019-05-11 00:03:39, Epoch : 1, Step : 7057, Training Loss : 0.46342, Training Acc : 0.794, Run Time : 0.50
INFO:root:2019-05-11 00:03:39, Epoch : 1, Step : 7058, Training Loss : 0.19691, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-11 00:03:44, Epoch : 1, Step : 7059, Training Loss : 0.25731, Training Acc : 0.883, Run Time : 4.51
INFO:root:2019-05-11 00:03:44, Epoch : 1, Step : 7060, Training Loss : 0.29624, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 00:03:56, Epoch : 1, Step : 7061, Training Loss : 0.27488, Training Acc : 0.889, Run Time : 11.74
INFO:root:2019-05-11 00:03:56, Epoch : 1, Step : 7062, Training Loss : 0.27875, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-11 00:03:59, Epoch : 1, Step : 7063, Training Loss : 0.40277, Training Acc : 0.889, Run Time : 2.51
INFO:root:2019-05-11 00:04:15, Epoch : 1, Step : 7064, Training Loss : 0.27803, Training Acc : 0.900, Run Time : 16.66
INFO:root:2019-05-11 00:04:19, Epoch : 1, Step : 7065, Training Loss : 0.27213, Training Acc : 0.917, Run Time : 4.07
INFO:root:2019-05-11 00:04:20, Epoch : 1, Step : 7066, Training Loss : 0.17775, Training Acc : 0.950, Run Time : 0.35
INFO:root:2019-05-11 00:04:20, Epoch : 1, Step : 7067, Training Loss : 0.31407, Training Acc : 0.872, Run Time : 0.45
INFO:root:2019-05-11 00:04:21, Epoch : 1, Step : 7068, Training Loss : 0.26436, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-11 00:04:21, Epoch : 1, Step : 7069, Training Loss : 0.21783, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-11 00:04:35, Epoch : 1, Step : 7070, Training Loss : 0.12381, Training Acc : 0.967, Run Time : 13.74
INFO:root:2019-05-11 00:04:35, Epoch : 1, Step : 7071, Training Loss : 0.15506, Training Acc : 0.950, Run Time : 0.33
INFO:root:2019-05-11 00:04:36, Epoch : 1, Step : 7072, Training Loss : 0.12754, Training Acc : 0.978, Run Time : 0.46
INFO:root:2019-05-11 00:04:36, Epoch : 1, Step : 7073, Training Loss : 0.24085, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-11 00:04:37, Epoch : 1, Step : 7074, Training Loss : 0.20027, Training Acc : 0.950, Run Time : 1.14
INFO:root:2019-05-11 00:04:44, Epoch : 1, Step : 7075, Training Loss : 0.13313, Training Acc : 0.961, Run Time : 7.12
INFO:root:2019-05-11 00:04:45, Epoch : 1, Step : 7076, Training Loss : 0.14781, Training Acc : 0.944, Run Time : 0.39
INFO:root:2019-05-11 00:04:56, Epoch : 1, Step : 7077, Training Loss : 0.15263, Training Acc : 0.961, Run Time : 10.81
INFO:root:2019-05-11 00:04:56, Epoch : 1, Step : 7078, Training Loss : 0.17625, Training Acc : 0.950, Run Time : 0.36
INFO:root:2019-05-11 00:04:56, Epoch : 1, Step : 7079, Training Loss : 0.21912, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-11 00:05:06, Epoch : 1, Step : 7080, Training Loss : 0.23063, Training Acc : 0.917, Run Time : 9.36
INFO:root:2019-05-11 00:05:06, Epoch : 1, Step : 7081, Training Loss : 0.22947, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 00:05:07, Epoch : 1, Step : 7082, Training Loss : 0.14162, Training Acc : 0.961, Run Time : 0.49
INFO:root:2019-05-11 00:05:08, Epoch : 1, Step : 7083, Training Loss : 0.17901, Training Acc : 0.917, Run Time : 1.31
INFO:root:2019-05-11 00:05:08, Epoch : 1, Step : 7084, Training Loss : 0.28985, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-11 00:05:18, Epoch : 1, Step : 7085, Training Loss : 0.17868, Training Acc : 0.928, Run Time : 9.26
INFO:root:2019-05-11 00:05:18, Epoch : 1, Step : 7086, Training Loss : 0.40474, Training Acc : 0.833, Run Time : 0.66
INFO:root:2019-05-11 00:05:19, Epoch : 1, Step : 7087, Training Loss : 0.41888, Training Acc : 0.761, Run Time : 1.12
INFO:root:2019-05-11 00:05:20, Epoch : 1, Step : 7088, Training Loss : 0.27055, Training Acc : 0.922, Run Time : 0.59
INFO:root:2019-05-11 00:05:22, Epoch : 1, Step : 7089, Training Loss : 0.26671, Training Acc : 0.878, Run Time : 2.28
INFO:root:2019-05-11 00:05:24, Epoch : 1, Step : 7090, Training Loss : 0.17802, Training Acc : 0.956, Run Time : 1.43
INFO:root:2019-05-11 00:05:34, Epoch : 1, Step : 7091, Training Loss : 0.41930, Training Acc : 0.839, Run Time : 10.51
INFO:root:2019-05-11 00:05:35, Epoch : 1, Step : 7092, Training Loss : 0.22301, Training Acc : 0.928, Run Time : 0.34
INFO:root:2019-05-11 00:05:35, Epoch : 1, Step : 7093, Training Loss : 0.22663, Training Acc : 0.922, Run Time : 0.55
INFO:root:2019-05-11 00:05:36, Epoch : 1, Step : 7094, Training Loss : 0.19476, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-11 00:05:45, Epoch : 1, Step : 7095, Training Loss : 0.22570, Training Acc : 0.911, Run Time : 9.48
INFO:root:2019-05-11 00:05:46, Epoch : 1, Step : 7096, Training Loss : 0.14884, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-11 00:05:46, Epoch : 1, Step : 7097, Training Loss : 0.19294, Training Acc : 0.933, Run Time : 0.29
INFO:root:2019-05-11 00:05:46, Epoch : 1, Step : 7098, Training Loss : 0.19142, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-11 00:05:54, Epoch : 1, Step : 7099, Training Loss : 0.22562, Training Acc : 0.911, Run Time : 7.47
INFO:root:2019-05-11 00:05:54, Epoch : 1, Step : 7100, Training Loss : 0.33041, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-11 00:06:00, Epoch : 1, Step : 7101, Training Loss : 0.18371, Training Acc : 0.922, Run Time : 6.06
INFO:root:2019-05-11 00:06:01, Epoch : 1, Step : 7102, Training Loss : 0.42514, Training Acc : 0.794, Run Time : 0.45
INFO:root:2019-05-11 00:06:01, Epoch : 1, Step : 7103, Training Loss : 0.33226, Training Acc : 0.833, Run Time : 0.44
INFO:root:2019-05-11 00:06:03, Epoch : 1, Step : 7104, Training Loss : 0.41724, Training Acc : 0.817, Run Time : 1.37
INFO:root:2019-05-11 00:06:10, Epoch : 1, Step : 7105, Training Loss : 0.38766, Training Acc : 0.817, Run Time : 7.39
INFO:root:2019-05-11 00:06:10, Epoch : 1, Step : 7106, Training Loss : 0.33206, Training Acc : 0.872, Run Time : 0.44
INFO:root:2019-05-11 00:06:12, Epoch : 1, Step : 7107, Training Loss : 0.40228, Training Acc : 0.822, Run Time : 1.72
INFO:root:2019-05-11 00:06:13, Epoch : 1, Step : 7108, Training Loss : 0.25344, Training Acc : 0.900, Run Time : 1.04
INFO:root:2019-05-11 00:06:23, Epoch : 1, Step : 7109, Training Loss : 0.43198, Training Acc : 0.772, Run Time : 9.46
INFO:root:2019-05-11 00:06:23, Epoch : 1, Step : 7110, Training Loss : 0.57230, Training Acc : 0.722, Run Time : 0.37
INFO:root:2019-05-11 00:06:23, Epoch : 1, Step : 7111, Training Loss : 0.64579, Training Acc : 0.644, Run Time : 0.49
INFO:root:2019-05-11 00:06:24, Epoch : 1, Step : 7112, Training Loss : 0.28294, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-11 00:06:31, Epoch : 1, Step : 7113, Training Loss : 0.30903, Training Acc : 0.833, Run Time : 7.59
INFO:root:2019-05-11 00:06:32, Epoch : 1, Step : 7114, Training Loss : 0.41671, Training Acc : 0.772, Run Time : 0.44
INFO:root:2019-05-11 00:06:34, Epoch : 1, Step : 7115, Training Loss : 0.35314, Training Acc : 0.850, Run Time : 1.96
INFO:root:2019-05-11 00:06:35, Epoch : 1, Step : 7116, Training Loss : 0.39027, Training Acc : 0.822, Run Time : 1.02
INFO:root:2019-05-11 00:06:43, Epoch : 1, Step : 7117, Training Loss : 0.28498, Training Acc : 0.856, Run Time : 7.97
INFO:root:2019-05-11 00:06:43, Epoch : 1, Step : 7118, Training Loss : 0.19001, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-11 00:06:44, Epoch : 1, Step : 7119, Training Loss : 0.21079, Training Acc : 0.917, Run Time : 1.21
INFO:root:2019-05-11 00:06:46, Epoch : 1, Step : 7120, Training Loss : 0.25610, Training Acc : 0.889, Run Time : 1.72
INFO:root:2019-05-11 00:06:59, Epoch : 1, Step : 7121, Training Loss : 0.27419, Training Acc : 0.894, Run Time : 12.69
INFO:root:2019-05-11 00:06:59, Epoch : 1, Step : 7122, Training Loss : 0.26731, Training Acc : 0.883, Run Time : 0.35
INFO:root:2019-05-11 00:07:00, Epoch : 1, Step : 7123, Training Loss : 0.34411, Training Acc : 0.844, Run Time : 0.44
INFO:root:2019-05-11 00:07:00, Epoch : 1, Step : 7124, Training Loss : 0.15899, Training Acc : 0.956, Run Time : 0.45
INFO:root:2019-05-11 00:07:01, Epoch : 1, Step : 7125, Training Loss : 0.11824, Training Acc : 0.972, Run Time : 0.72
INFO:root:2019-05-11 00:07:14, Epoch : 1, Step : 7126, Training Loss : 0.17601, Training Acc : 0.944, Run Time : 12.75
INFO:root:2019-05-11 00:07:14, Epoch : 1, Step : 7127, Training Loss : 0.23478, Training Acc : 0.922, Run Time : 0.29
INFO:root:2019-05-11 00:07:14, Epoch : 1, Step : 7128, Training Loss : 0.43161, Training Acc : 0.833, Run Time : 0.47
INFO:root:2019-05-11 00:07:15, Epoch : 1, Step : 7129, Training Loss : 0.38901, Training Acc : 0.844, Run Time : 0.44
INFO:root:2019-05-11 00:07:16, Epoch : 1, Step : 7130, Training Loss : 0.42688, Training Acc : 0.839, Run Time : 1.25
INFO:root:2019-05-11 00:07:24, Epoch : 1, Step : 7131, Training Loss : 0.26543, Training Acc : 0.883, Run Time : 7.92
INFO:root:2019-05-11 00:07:24, Epoch : 1, Step : 7132, Training Loss : 0.26874, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-11 00:07:25, Epoch : 1, Step : 7133, Training Loss : 0.24639, Training Acc : 0.900, Run Time : 1.10
INFO:root:2019-05-11 00:07:33, Epoch : 1, Step : 7134, Training Loss : 0.21693, Training Acc : 0.889, Run Time : 7.28
INFO:root:2019-05-11 00:07:33, Epoch : 1, Step : 7135, Training Loss : 0.23519, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-11 00:07:34, Epoch : 1, Step : 7136, Training Loss : 0.22900, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-11 00:07:42, Epoch : 1, Step : 7137, Training Loss : 0.18591, Training Acc : 0.922, Run Time : 8.72
INFO:root:2019-05-11 00:07:43, Epoch : 1, Step : 7138, Training Loss : 0.22806, Training Acc : 0.894, Run Time : 0.34
INFO:root:2019-05-11 00:07:43, Epoch : 1, Step : 7139, Training Loss : 0.26645, Training Acc : 0.894, Run Time : 0.43
INFO:root:2019-05-11 00:07:44, Epoch : 1, Step : 7140, Training Loss : 0.48298, Training Acc : 0.772, Run Time : 0.47
INFO:root:2019-05-11 00:07:51, Epoch : 1, Step : 7141, Training Loss : 0.49721, Training Acc : 0.778, Run Time : 7.82
INFO:root:2019-05-11 00:07:52, Epoch : 1, Step : 7142, Training Loss : 0.24285, Training Acc : 0.872, Run Time : 0.94
INFO:root:2019-05-11 00:07:53, Epoch : 1, Step : 7143, Training Loss : 0.18261, Training Acc : 0.944, Run Time : 0.69
INFO:root:2019-05-11 00:07:54, Epoch : 1, Step : 7144, Training Loss : 0.12009, Training Acc : 0.950, Run Time : 1.36
INFO:root:2019-05-11 00:08:02, Epoch : 1, Step : 7145, Training Loss : 0.18917, Training Acc : 0.922, Run Time : 7.37
INFO:root:2019-05-11 00:08:03, Epoch : 1, Step : 7146, Training Loss : 0.22986, Training Acc : 0.894, Run Time : 0.98
INFO:root:2019-05-11 00:08:03, Epoch : 1, Step : 7147, Training Loss : 0.15105, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-11 00:08:06, Epoch : 1, Step : 7148, Training Loss : 0.36078, Training Acc : 0.839, Run Time : 2.99
INFO:root:2019-05-11 00:08:18, Epoch : 1, Step : 7149, Training Loss : 0.62643, Training Acc : 0.728, Run Time : 12.00
INFO:root:2019-05-11 00:08:19, Epoch : 1, Step : 7150, Training Loss : 0.41551, Training Acc : 0.828, Run Time : 0.51
INFO:root:2019-05-11 00:08:19, Epoch : 1, Step : 7151, Training Loss : 0.35459, Training Acc : 0.833, Run Time : 0.47
INFO:root:2019-05-11 00:08:20, Epoch : 1, Step : 7152, Training Loss : 0.43510, Training Acc : 0.789, Run Time : 0.42
INFO:root:2019-05-11 00:08:20, Epoch : 1, Step : 7153, Training Loss : 0.44387, Training Acc : 0.767, Run Time : 0.46
INFO:root:2019-05-11 00:08:30, Epoch : 1, Step : 7154, Training Loss : 0.43812, Training Acc : 0.778, Run Time : 10.29
INFO:root:2019-05-11 00:08:31, Epoch : 1, Step : 7155, Training Loss : 0.36642, Training Acc : 0.856, Run Time : 0.95
INFO:root:2019-05-11 00:08:32, Epoch : 1, Step : 7156, Training Loss : 0.75673, Training Acc : 0.683, Run Time : 0.46
INFO:root:2019-05-11 00:08:32, Epoch : 1, Step : 7157, Training Loss : 0.58039, Training Acc : 0.744, Run Time : 0.49
INFO:root:2019-05-11 00:08:41, Epoch : 1, Step : 7158, Training Loss : 0.36375, Training Acc : 0.828, Run Time : 9.13
INFO:root:2019-05-11 00:08:42, Epoch : 1, Step : 7159, Training Loss : 0.37838, Training Acc : 0.850, Run Time : 0.61
INFO:root:2019-05-11 00:08:43, Epoch : 1, Step : 7160, Training Loss : 0.37616, Training Acc : 0.844, Run Time : 0.45
INFO:root:2019-05-11 00:08:47, Epoch : 1, Step : 7161, Training Loss : 0.14080, Training Acc : 0.939, Run Time : 4.75
INFO:root:2019-05-11 00:08:48, Epoch : 1, Step : 7162, Training Loss : 0.30606, Training Acc : 0.867, Run Time : 0.71
INFO:root:2019-05-11 00:08:48, Epoch : 1, Step : 7163, Training Loss : 0.34572, Training Acc : 0.839, Run Time : 0.48
INFO:root:2019-05-11 00:08:55, Epoch : 1, Step : 7164, Training Loss : 0.21584, Training Acc : 0.922, Run Time : 6.48
INFO:root:2019-05-11 00:08:55, Epoch : 1, Step : 7165, Training Loss : 0.19983, Training Acc : 0.928, Run Time : 0.50
INFO:root:2019-05-11 00:08:56, Epoch : 1, Step : 7166, Training Loss : 0.16745, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-11 00:09:03, Epoch : 1, Step : 7167, Training Loss : 0.23888, Training Acc : 0.906, Run Time : 7.24
INFO:root:2019-05-11 00:09:04, Epoch : 1, Step : 7168, Training Loss : 0.18831, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-11 00:09:04, Epoch : 1, Step : 7169, Training Loss : 0.21691, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-11 00:09:11, Epoch : 1, Step : 7170, Training Loss : 0.16303, Training Acc : 0.950, Run Time : 7.13
INFO:root:2019-05-11 00:09:12, Epoch : 1, Step : 7171, Training Loss : 0.19066, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-11 00:09:13, Epoch : 1, Step : 7172, Training Loss : 0.14461, Training Acc : 0.961, Run Time : 0.95
INFO:root:2019-05-11 00:09:21, Epoch : 1, Step : 7173, Training Loss : 0.16132, Training Acc : 0.939, Run Time : 8.33
INFO:root:2019-05-11 00:09:22, Epoch : 1, Step : 7174, Training Loss : 0.12748, Training Acc : 0.956, Run Time : 0.73
INFO:root:2019-05-11 00:09:22, Epoch : 1, Step : 7175, Training Loss : 0.20911, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-11 00:09:23, Epoch : 1, Step : 7176, Training Loss : 0.21306, Training Acc : 0.900, Run Time : 0.51
INFO:root:2019-05-11 00:09:25, Epoch : 1, Step : 7177, Training Loss : 0.14795, Training Acc : 0.950, Run Time : 2.53
INFO:root:2019-05-11 00:09:36, Epoch : 1, Step : 7178, Training Loss : 0.12061, Training Acc : 0.944, Run Time : 10.39
INFO:root:2019-05-11 00:09:36, Epoch : 1, Step : 7179, Training Loss : 0.20925, Training Acc : 0.922, Run Time : 0.31
INFO:root:2019-05-11 00:09:36, Epoch : 1, Step : 7180, Training Loss : 0.16561, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-11 00:09:43, Epoch : 1, Step : 7181, Training Loss : 0.20116, Training Acc : 0.883, Run Time : 6.68
INFO:root:2019-05-11 00:09:44, Epoch : 1, Step : 7182, Training Loss : 0.14894, Training Acc : 0.967, Run Time : 0.86
INFO:root:2019-05-11 00:09:44, Epoch : 1, Step : 7183, Training Loss : 0.14029, Training Acc : 0.961, Run Time : 0.45
INFO:root:2019-05-11 00:09:45, Epoch : 1, Step : 7184, Training Loss : 0.14330, Training Acc : 0.967, Run Time : 0.46
INFO:root:2019-05-11 00:09:45, Epoch : 1, Step : 7185, Training Loss : 0.10490, Training Acc : 0.961, Run Time : 0.55
INFO:root:2019-05-11 00:09:53, Epoch : 1, Step : 7186, Training Loss : 0.15227, Training Acc : 0.939, Run Time : 7.83
INFO:root:2019-05-11 00:09:54, Epoch : 1, Step : 7187, Training Loss : 0.14595, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-11 00:09:54, Epoch : 1, Step : 7188, Training Loss : 0.13312, Training Acc : 0.967, Run Time : 0.88
INFO:root:2019-05-11 00:10:03, Epoch : 1, Step : 7189, Training Loss : 0.29370, Training Acc : 0.844, Run Time : 8.34
INFO:root:2019-05-11 00:10:04, Epoch : 1, Step : 7190, Training Loss : 0.35821, Training Acc : 0.833, Run Time : 0.95
INFO:root:2019-05-11 00:10:04, Epoch : 1, Step : 7191, Training Loss : 0.24190, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-11 00:10:06, Epoch : 1, Step : 7192, Training Loss : 0.65612, Training Acc : 0.672, Run Time : 2.08
INFO:root:2019-05-11 00:10:13, Epoch : 1, Step : 7193, Training Loss : 0.37588, Training Acc : 0.811, Run Time : 6.51
INFO:root:2019-05-11 00:10:13, Epoch : 1, Step : 7194, Training Loss : 0.40743, Training Acc : 0.822, Run Time : 0.44
INFO:root:2019-05-11 00:10:16, Epoch : 1, Step : 7195, Training Loss : 0.30561, Training Acc : 0.861, Run Time : 2.39
INFO:root:2019-05-11 00:10:23, Epoch : 1, Step : 7196, Training Loss : 0.32450, Training Acc : 0.867, Run Time : 6.96
INFO:root:2019-05-11 00:10:23, Epoch : 1, Step : 7197, Training Loss : 0.21074, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 00:10:23, Epoch : 1, Step : 7198, Training Loss : 0.43635, Training Acc : 0.811, Run Time : 0.45
INFO:root:2019-05-11 00:10:24, Epoch : 1, Step : 7199, Training Loss : 0.33630, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-11 00:10:36, Epoch : 1, Step : 7200, Training Loss : 0.48329, Training Acc : 0.811, Run Time : 12.13
INFO:root:2019-05-11 00:10:37, Epoch : 1, Step : 7201, Training Loss : 0.72430, Training Acc : 0.667, Run Time : 0.71
INFO:root:2019-05-11 00:10:37, Epoch : 1, Step : 7202, Training Loss : 0.64406, Training Acc : 0.733, Run Time : 0.23
INFO:root:2019-05-11 00:10:37, Epoch : 1, Step : 7203, Training Loss : 0.37361, Training Acc : 0.822, Run Time : 0.48
INFO:root:2019-05-11 00:10:38, Epoch : 1, Step : 7204, Training Loss : 0.52817, Training Acc : 0.756, Run Time : 0.49
INFO:root:2019-05-11 00:10:49, Epoch : 1, Step : 7205, Training Loss : 0.53179, Training Acc : 0.778, Run Time : 10.79
INFO:root:2019-05-11 00:10:49, Epoch : 1, Step : 7206, Training Loss : 0.39394, Training Acc : 0.839, Run Time : 0.49
INFO:root:2019-05-11 00:10:50, Epoch : 1, Step : 7207, Training Loss : 0.64862, Training Acc : 0.711, Run Time : 0.47
INFO:root:2019-05-11 00:10:56, Epoch : 1, Step : 7208, Training Loss : 0.52662, Training Acc : 0.811, Run Time : 6.35
INFO:root:2019-05-11 00:10:57, Epoch : 1, Step : 7209, Training Loss : 0.34176, Training Acc : 0.844, Run Time : 0.85
INFO:root:2019-05-11 00:10:57, Epoch : 1, Step : 7210, Training Loss : 0.22358, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-11 00:10:58, Epoch : 1, Step : 7211, Training Loss : 0.27079, Training Acc : 0.894, Run Time : 0.51
INFO:root:2019-05-11 00:10:59, Epoch : 1, Step : 7212, Training Loss : 0.17548, Training Acc : 0.944, Run Time : 1.39
INFO:root:2019-05-11 00:11:14, Epoch : 1, Step : 7213, Training Loss : 0.24600, Training Acc : 0.900, Run Time : 14.31
INFO:root:2019-05-11 00:11:14, Epoch : 1, Step : 7214, Training Loss : 0.21196, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-11 00:11:15, Epoch : 1, Step : 7215, Training Loss : 0.31304, Training Acc : 0.906, Run Time : 0.56
INFO:root:2019-05-11 00:11:15, Epoch : 1, Step : 7216, Training Loss : 0.35730, Training Acc : 0.850, Run Time : 0.48
INFO:root:2019-05-11 00:11:16, Epoch : 1, Step : 7217, Training Loss : 0.17354, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-11 00:11:26, Epoch : 1, Step : 7218, Training Loss : 0.11571, Training Acc : 0.967, Run Time : 10.23
INFO:root:2019-05-11 00:11:26, Epoch : 1, Step : 7219, Training Loss : 0.17435, Training Acc : 0.944, Run Time : 0.42
INFO:root:2019-05-11 00:11:28, Epoch : 1, Step : 7220, Training Loss : 0.21954, Training Acc : 0.922, Run Time : 1.61
INFO:root:2019-05-11 00:11:29, Epoch : 1, Step : 7221, Training Loss : 0.17183, Training Acc : 0.950, Run Time : 1.39
INFO:root:2019-05-11 00:11:30, Epoch : 1, Step : 7222, Training Loss : 0.12575, Training Acc : 0.956, Run Time : 0.70
INFO:root:2019-05-11 00:11:38, Epoch : 1, Step : 7223, Training Loss : 0.24671, Training Acc : 0.906, Run Time : 7.83
INFO:root:2019-05-11 00:11:38, Epoch : 1, Step : 7224, Training Loss : 0.32501, Training Acc : 0.889, Run Time : 0.71
INFO:root:2019-05-11 00:11:39, Epoch : 1, Step : 7225, Training Loss : 0.36969, Training Acc : 0.839, Run Time : 0.58
INFO:root:2019-05-11 00:11:40, Epoch : 1, Step : 7226, Training Loss : 0.41939, Training Acc : 0.811, Run Time : 0.49
INFO:root:2019-05-11 00:11:42, Epoch : 1, Step : 7227, Training Loss : 0.36127, Training Acc : 0.850, Run Time : 2.77
INFO:root:2019-05-11 00:11:44, Epoch : 1, Step : 7228, Training Loss : 0.29816, Training Acc : 0.883, Run Time : 1.18
INFO:root:2019-05-11 00:11:55, Epoch : 1, Step : 7229, Training Loss : 0.23003, Training Acc : 0.894, Run Time : 11.34
INFO:root:2019-05-11 00:11:55, Epoch : 1, Step : 7230, Training Loss : 0.31771, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-11 00:11:56, Epoch : 1, Step : 7231, Training Loss : 0.18679, Training Acc : 0.922, Run Time : 0.36
INFO:root:2019-05-11 00:11:56, Epoch : 1, Step : 7232, Training Loss : 0.24445, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-11 00:11:56, Epoch : 1, Step : 7233, Training Loss : 0.24681, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-11 00:12:05, Epoch : 1, Step : 7234, Training Loss : 0.21780, Training Acc : 0.917, Run Time : 8.61
INFO:root:2019-05-11 00:12:05, Epoch : 1, Step : 7235, Training Loss : 0.18454, Training Acc : 0.939, Run Time : 0.36
INFO:root:2019-05-11 00:12:06, Epoch : 1, Step : 7236, Training Loss : 0.18321, Training Acc : 0.917, Run Time : 0.53
INFO:root:2019-05-11 00:12:06, Epoch : 1, Step : 7237, Training Loss : 0.14711, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-11 00:12:15, Epoch : 1, Step : 7238, Training Loss : 0.17175, Training Acc : 0.928, Run Time : 8.94
INFO:root:2019-05-11 00:12:16, Epoch : 1, Step : 7239, Training Loss : 0.18513, Training Acc : 0.922, Run Time : 0.43
INFO:root:2019-05-11 00:12:16, Epoch : 1, Step : 7240, Training Loss : 0.12380, Training Acc : 0.944, Run Time : 0.41
INFO:root:2019-05-11 00:12:23, Epoch : 1, Step : 7241, Training Loss : 0.16264, Training Acc : 0.956, Run Time : 6.48
INFO:root:2019-05-11 00:12:23, Epoch : 1, Step : 7242, Training Loss : 0.08681, Training Acc : 0.989, Run Time : 0.56
INFO:root:2019-05-11 00:12:24, Epoch : 1, Step : 7243, Training Loss : 0.15219, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-11 00:12:31, Epoch : 1, Step : 7244, Training Loss : 0.15004, Training Acc : 0.928, Run Time : 7.38
INFO:root:2019-05-11 00:12:32, Epoch : 1, Step : 7245, Training Loss : 0.12388, Training Acc : 0.961, Run Time : 0.76
INFO:root:2019-05-11 00:12:32, Epoch : 1, Step : 7246, Training Loss : 0.18064, Training Acc : 0.922, Run Time : 0.44
INFO:root:2019-05-11 00:12:34, Epoch : 1, Step : 7247, Training Loss : 0.29256, Training Acc : 0.883, Run Time : 1.45
INFO:root:2019-05-11 00:12:34, Epoch : 1, Step : 7248, Training Loss : 0.31925, Training Acc : 0.833, Run Time : 0.38
INFO:root:2019-05-11 00:12:44, Epoch : 1, Step : 7249, Training Loss : 0.37234, Training Acc : 0.839, Run Time : 9.61
INFO:root:2019-05-11 00:12:44, Epoch : 1, Step : 7250, Training Loss : 0.16147, Training Acc : 0.950, Run Time : 0.41
INFO:root:2019-05-11 00:12:45, Epoch : 1, Step : 7251, Training Loss : 0.15102, Training Acc : 0.967, Run Time : 0.48
INFO:root:2019-05-11 00:12:46, Epoch : 1, Step : 7252, Training Loss : 0.12474, Training Acc : 0.944, Run Time : 1.49
INFO:root:2019-05-11 00:12:53, Epoch : 1, Step : 7253, Training Loss : 0.14224, Training Acc : 0.944, Run Time : 7.29
INFO:root:2019-05-11 00:12:54, Epoch : 1, Step : 7254, Training Loss : 0.12047, Training Acc : 0.961, Run Time : 0.45
INFO:root:2019-05-11 00:12:54, Epoch : 1, Step : 7255, Training Loss : 0.08234, Training Acc : 0.989, Run Time : 0.46
INFO:root:2019-05-11 00:13:02, Epoch : 1, Step : 7256, Training Loss : 0.10146, Training Acc : 0.956, Run Time : 7.41
INFO:root:2019-05-11 00:13:03, Epoch : 1, Step : 7257, Training Loss : 0.11696, Training Acc : 0.961, Run Time : 0.77
INFO:root:2019-05-11 00:13:03, Epoch : 1, Step : 7258, Training Loss : 0.10680, Training Acc : 0.972, Run Time : 0.47
INFO:root:2019-05-11 00:13:04, Epoch : 1, Step : 7259, Training Loss : 0.08424, Training Acc : 0.983, Run Time : 0.55
INFO:root:2019-05-11 00:13:05, Epoch : 1, Step : 7260, Training Loss : 0.08273, Training Acc : 0.989, Run Time : 1.17
INFO:root:2019-05-11 00:13:15, Epoch : 1, Step : 7261, Training Loss : 0.15435, Training Acc : 0.939, Run Time : 10.54
INFO:root:2019-05-11 00:13:16, Epoch : 1, Step : 7262, Training Loss : 0.17497, Training Acc : 0.928, Run Time : 0.51
INFO:root:2019-05-11 00:13:16, Epoch : 1, Step : 7263, Training Loss : 0.12077, Training Acc : 0.961, Run Time : 0.46
INFO:root:2019-05-11 00:13:20, Epoch : 1, Step : 7264, Training Loss : 0.07809, Training Acc : 0.983, Run Time : 4.18
INFO:root:2019-05-11 00:13:22, Epoch : 1, Step : 7265, Training Loss : 0.12028, Training Acc : 0.950, Run Time : 1.22
INFO:root:2019-05-11 00:13:22, Epoch : 1, Step : 7266, Training Loss : 0.13225, Training Acc : 0.956, Run Time : 0.46
INFO:root:2019-05-11 00:13:23, Epoch : 1, Step : 7267, Training Loss : 0.15437, Training Acc : 0.939, Run Time : 0.62
INFO:root:2019-05-11 00:13:30, Epoch : 1, Step : 7268, Training Loss : 0.05951, Training Acc : 0.989, Run Time : 7.46
INFO:root:2019-05-11 00:13:31, Epoch : 1, Step : 7269, Training Loss : 0.12088, Training Acc : 0.961, Run Time : 0.63
INFO:root:2019-05-11 00:13:31, Epoch : 1, Step : 7270, Training Loss : 0.05810, Training Acc : 0.989, Run Time : 0.44
INFO:root:2019-05-11 00:13:33, Epoch : 1, Step : 7271, Training Loss : 0.17501, Training Acc : 0.911, Run Time : 1.59
INFO:root:2019-05-11 00:13:36, Epoch : 1, Step : 7272, Training Loss : 0.11402, Training Acc : 0.939, Run Time : 3.37
INFO:root:2019-05-11 00:13:47, Epoch : 1, Step : 7273, Training Loss : 0.14723, Training Acc : 0.950, Run Time : 11.12
INFO:root:2019-05-11 00:13:48, Epoch : 1, Step : 7274, Training Loss : 0.10136, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-11 00:13:48, Epoch : 1, Step : 7275, Training Loss : 0.10300, Training Acc : 0.967, Run Time : 0.46
INFO:root:2019-05-11 00:13:49, Epoch : 1, Step : 7276, Training Loss : 0.07346, Training Acc : 0.989, Run Time : 0.46
INFO:root:2019-05-11 00:13:51, Epoch : 1, Step : 7277, Training Loss : 0.18332, Training Acc : 0.922, Run Time : 2.39
INFO:root:2019-05-11 00:13:53, Epoch : 1, Step : 7278, Training Loss : 0.14354, Training Acc : 0.933, Run Time : 1.93
INFO:root:2019-05-11 00:13:56, Epoch : 1, Step : 7279, Training Loss : 0.17602, Training Acc : 0.944, Run Time : 2.64
INFO:root:2019-05-11 00:14:05, Epoch : 1, Step : 7280, Training Loss : 0.19343, Training Acc : 0.928, Run Time : 8.89
INFO:root:2019-05-11 00:14:05, Epoch : 1, Step : 7281, Training Loss : 0.20296, Training Acc : 0.933, Run Time : 0.64
INFO:root:2019-05-11 00:14:06, Epoch : 1, Step : 7282, Training Loss : 0.18066, Training Acc : 0.939, Run Time : 0.52
INFO:root:2019-05-11 00:14:10, Epoch : 1, Step : 7283, Training Loss : 0.18213, Training Acc : 0.961, Run Time : 3.91
INFO:root:2019-05-11 00:14:10, Epoch : 1, Step : 7284, Training Loss : 0.14413, Training Acc : 0.961, Run Time : 0.54
INFO:root:2019-05-11 00:14:11, Epoch : 1, Step : 7285, Training Loss : 0.25638, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-11 00:14:11, Epoch : 1, Step : 7286, Training Loss : 0.37165, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-11 00:14:16, Epoch : 1, Step : 7287, Training Loss : 0.29667, Training Acc : 0.933, Run Time : 4.79
INFO:root:2019-05-11 00:14:16, Epoch : 1, Step : 7288, Training Loss : 0.23857, Training Acc : 0.917, Run Time : 0.48
INFO:root:2019-05-11 00:14:26, Epoch : 1, Step : 7289, Training Loss : 0.20656, Training Acc : 0.928, Run Time : 9.69
INFO:root:2019-05-11 00:14:26, Epoch : 1, Step : 7290, Training Loss : 0.17711, Training Acc : 0.933, Run Time : 0.39
INFO:root:2019-05-11 00:14:27, Epoch : 1, Step : 7291, Training Loss : 0.15862, Training Acc : 0.961, Run Time : 0.52
INFO:root:2019-05-11 00:14:27, Epoch : 1, Step : 7292, Training Loss : 0.17902, Training Acc : 0.922, Run Time : 0.40
INFO:root:2019-05-11 00:14:34, Epoch : 1, Step : 7293, Training Loss : 0.12888, Training Acc : 0.967, Run Time : 6.60
INFO:root:2019-05-11 00:14:35, Epoch : 1, Step : 7294, Training Loss : 0.15906, Training Acc : 0.928, Run Time : 0.50
INFO:root:2019-05-11 00:14:36, Epoch : 1, Step : 7295, Training Loss : 0.18952, Training Acc : 0.917, Run Time : 1.84
INFO:root:2019-05-11 00:14:42, Epoch : 1, Step : 7296, Training Loss : 0.24765, Training Acc : 0.906, Run Time : 6.08
INFO:root:2019-05-11 00:14:43, Epoch : 1, Step : 7297, Training Loss : 0.19442, Training Acc : 0.922, Run Time : 0.66
INFO:root:2019-05-11 00:14:44, Epoch : 1, Step : 7298, Training Loss : 0.13903, Training Acc : 0.939, Run Time : 0.54
INFO:root:2019-05-11 00:14:52, Epoch : 1, Step : 7299, Training Loss : 0.40073, Training Acc : 0.867, Run Time : 8.36
INFO:root:2019-05-11 00:14:52, Epoch : 1, Step : 7300, Training Loss : 0.70493, Training Acc : 0.739, Run Time : 0.45
INFO:root:2019-05-11 00:14:54, Epoch : 1, Step : 7301, Training Loss : 0.67138, Training Acc : 0.756, Run Time : 1.51
INFO:root:2019-05-11 00:14:56, Epoch : 1, Step : 7302, Training Loss : 0.53543, Training Acc : 0.778, Run Time : 1.69
INFO:root:2019-05-11 00:15:05, Epoch : 1, Step : 7303, Training Loss : 0.71992, Training Acc : 0.683, Run Time : 9.42
INFO:root:2019-05-11 00:15:06, Epoch : 1, Step : 7304, Training Loss : 0.47117, Training Acc : 0.811, Run Time : 0.51
INFO:root:2019-05-11 00:15:06, Epoch : 1, Step : 7305, Training Loss : 0.42629, Training Acc : 0.828, Run Time : 0.44
INFO:root:2019-05-11 00:15:06, Epoch : 1, Step : 7306, Training Loss : 0.41475, Training Acc : 0.833, Run Time : 0.47
INFO:root:2019-05-11 00:15:12, Epoch : 1, Step : 7307, Training Loss : 0.19549, Training Acc : 0.939, Run Time : 5.62
INFO:root:2019-05-11 00:15:13, Epoch : 1, Step : 7308, Training Loss : 0.37919, Training Acc : 0.844, Run Time : 0.44
INFO:root:2019-05-11 00:15:13, Epoch : 1, Step : 7309, Training Loss : 0.36254, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-11 00:15:20, Epoch : 1, Step : 7310, Training Loss : 0.43116, Training Acc : 0.839, Run Time : 6.86
INFO:root:2019-05-11 00:15:20, Epoch : 1, Step : 7311, Training Loss : 0.39282, Training Acc : 0.833, Run Time : 0.47
INFO:root:2019-05-11 00:15:26, Epoch : 1, Step : 7312, Training Loss : 0.30508, Training Acc : 0.878, Run Time : 6.11
INFO:root:2019-05-11 00:15:27, Epoch : 1, Step : 7313, Training Loss : 0.22261, Training Acc : 0.933, Run Time : 0.98
INFO:root:2019-05-11 00:15:38, Epoch : 1, Step : 7314, Training Loss : 0.34945, Training Acc : 0.867, Run Time : 10.07
INFO:root:2019-05-11 00:15:38, Epoch : 1, Step : 7315, Training Loss : 0.40536, Training Acc : 0.861, Run Time : 0.25
INFO:root:2019-05-11 00:15:38, Epoch : 1, Step : 7316, Training Loss : 0.61660, Training Acc : 0.783, Run Time : 0.42
INFO:root:2019-05-11 00:15:39, Epoch : 1, Step : 7317, Training Loss : 0.34968, Training Acc : 0.883, Run Time : 0.43
INFO:root:2019-05-11 00:15:39, Epoch : 1, Step : 7318, Training Loss : 0.38242, Training Acc : 0.878, Run Time : 0.44
INFO:root:2019-05-11 00:15:48, Epoch : 1, Step : 7319, Training Loss : 0.42840, Training Acc : 0.817, Run Time : 8.96
INFO:root:2019-05-11 00:15:48, Epoch : 1, Step : 7320, Training Loss : 0.37772, Training Acc : 0.889, Run Time : 0.42
INFO:root:2019-05-11 00:15:55, Epoch : 1, Step : 7321, Training Loss : 0.21753, Training Acc : 0.917, Run Time : 6.34
INFO:root:2019-05-11 00:15:56, Epoch : 1, Step : 7322, Training Loss : 0.16765, Training Acc : 0.944, Run Time : 0.75
INFO:root:2019-05-11 00:15:56, Epoch : 1, Step : 7323, Training Loss : 0.15841, Training Acc : 0.972, Run Time : 0.48
INFO:root:2019-05-11 00:15:56, Epoch : 1, Step : 7324, Training Loss : 0.29968, Training Acc : 0.872, Run Time : 0.51
INFO:root:2019-05-11 00:16:04, Epoch : 1, Step : 7325, Training Loss : 0.20390, Training Acc : 0.922, Run Time : 7.51
INFO:root:2019-05-11 00:16:04, Epoch : 1, Step : 7326, Training Loss : 0.34180, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-11 00:16:12, Epoch : 1, Step : 7327, Training Loss : 0.24428, Training Acc : 0.911, Run Time : 7.71
INFO:root:2019-05-11 00:16:13, Epoch : 1, Step : 7328, Training Loss : 0.16329, Training Acc : 0.939, Run Time : 0.36
INFO:root:2019-05-11 00:16:13, Epoch : 1, Step : 7329, Training Loss : 0.26976, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-11 00:16:13, Epoch : 1, Step : 7330, Training Loss : 0.31759, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-11 00:16:24, Epoch : 1, Step : 7331, Training Loss : 0.27098, Training Acc : 0.889, Run Time : 10.71
INFO:root:2019-05-11 00:16:25, Epoch : 1, Step : 7332, Training Loss : 0.34989, Training Acc : 0.850, Run Time : 0.40
INFO:root:2019-05-11 00:16:25, Epoch : 1, Step : 7333, Training Loss : 0.20776, Training Acc : 0.922, Run Time : 0.45
INFO:root:2019-05-11 00:16:25, Epoch : 1, Step : 7334, Training Loss : 0.22822, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-11 00:16:34, Epoch : 1, Step : 7335, Training Loss : 0.22812, Training Acc : 0.900, Run Time : 8.15
INFO:root:2019-05-11 00:16:34, Epoch : 1, Step : 7336, Training Loss : 0.19351, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-11 00:16:35, Epoch : 1, Step : 7337, Training Loss : 0.14406, Training Acc : 0.939, Run Time : 0.92
INFO:root:2019-05-11 00:16:37, Epoch : 1, Step : 7338, Training Loss : 0.19353, Training Acc : 0.933, Run Time : 1.79
INFO:root:2019-05-11 00:16:46, Epoch : 1, Step : 7339, Training Loss : 0.24032, Training Acc : 0.911, Run Time : 9.11
INFO:root:2019-05-11 00:16:46, Epoch : 1, Step : 7340, Training Loss : 0.36939, Training Acc : 0.822, Run Time : 0.39
INFO:root:2019-05-11 00:16:47, Epoch : 1, Step : 7341, Training Loss : 0.53033, Training Acc : 0.761, Run Time : 0.52
INFO:root:2019-05-11 00:16:47, Epoch : 1, Step : 7342, Training Loss : 0.24931, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-11 00:16:56, Epoch : 1, Step : 7343, Training Loss : 0.14011, Training Acc : 0.939, Run Time : 8.82
INFO:root:2019-05-11 00:16:57, Epoch : 1, Step : 7344, Training Loss : 0.16389, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-11 00:17:04, Epoch : 1, Step : 7345, Training Loss : 0.17381, Training Acc : 0.928, Run Time : 7.67
INFO:root:2019-05-11 00:17:05, Epoch : 1, Step : 7346, Training Loss : 0.23432, Training Acc : 0.906, Run Time : 0.60
INFO:root:2019-05-11 00:17:05, Epoch : 1, Step : 7347, Training Loss : 0.27038, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-11 00:17:06, Epoch : 1, Step : 7348, Training Loss : 0.33890, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-11 00:17:06, Epoch : 1, Step : 7349, Training Loss : 0.21423, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-11 00:17:18, Epoch : 1, Step : 7350, Training Loss : 0.20619, Training Acc : 0.928, Run Time : 11.98
INFO:root:2019-05-11 00:17:19, Epoch : 1, Step : 7351, Training Loss : 0.37903, Training Acc : 0.828, Run Time : 0.48
INFO:root:2019-05-11 00:17:19, Epoch : 1, Step : 7352, Training Loss : 0.29771, Training Acc : 0.872, Run Time : 0.52
INFO:root:2019-05-11 00:17:20, Epoch : 1, Step : 7353, Training Loss : 0.40873, Training Acc : 0.800, Run Time : 0.47
INFO:root:2019-05-11 00:17:22, Epoch : 1, Step : 7354, Training Loss : 0.29689, Training Acc : 0.883, Run Time : 2.83
INFO:root:2019-05-11 00:17:26, Epoch : 1, Step : 7355, Training Loss : 0.41953, Training Acc : 0.783, Run Time : 3.66
INFO:root:2019-05-11 00:17:37, Epoch : 1, Step : 7356, Training Loss : 0.35722, Training Acc : 0.817, Run Time : 11.33
INFO:root:2019-05-11 00:17:38, Epoch : 1, Step : 7357, Training Loss : 0.49792, Training Acc : 0.756, Run Time : 0.40
INFO:root:2019-05-11 00:17:38, Epoch : 1, Step : 7358, Training Loss : 0.34713, Training Acc : 0.822, Run Time : 0.46
INFO:root:2019-05-11 00:17:44, Epoch : 1, Step : 7359, Training Loss : 0.33164, Training Acc : 0.856, Run Time : 5.39
INFO:root:2019-05-11 00:17:44, Epoch : 1, Step : 7360, Training Loss : 0.37022, Training Acc : 0.806, Run Time : 0.78
INFO:root:2019-05-11 00:17:45, Epoch : 1, Step : 7361, Training Loss : 0.35762, Training Acc : 0.817, Run Time : 0.46
INFO:root:2019-05-11 00:17:47, Epoch : 1, Step : 7362, Training Loss : 0.31094, Training Acc : 0.878, Run Time : 1.60
INFO:root:2019-05-11 00:17:53, Epoch : 1, Step : 7363, Training Loss : 0.36494, Training Acc : 0.828, Run Time : 6.70
INFO:root:2019-05-11 00:17:54, Epoch : 1, Step : 7364, Training Loss : 0.42900, Training Acc : 0.772, Run Time : 0.45
INFO:root:2019-05-11 00:17:54, Epoch : 1, Step : 7365, Training Loss : 0.39985, Training Acc : 0.794, Run Time : 0.67
INFO:root:2019-05-11 00:18:04, Epoch : 1, Step : 7366, Training Loss : 0.30764, Training Acc : 0.900, Run Time : 9.94
INFO:root:2019-05-11 00:18:05, Epoch : 1, Step : 7367, Training Loss : 0.30385, Training Acc : 0.850, Run Time : 0.36
INFO:root:2019-05-11 00:18:05, Epoch : 1, Step : 7368, Training Loss : 0.33066, Training Acc : 0.828, Run Time : 0.47
INFO:root:2019-05-11 00:18:06, Epoch : 1, Step : 7369, Training Loss : 0.48411, Training Acc : 0.772, Run Time : 0.48
INFO:root:2019-05-11 00:18:15, Epoch : 1, Step : 7370, Training Loss : 0.33295, Training Acc : 0.817, Run Time : 9.15
INFO:root:2019-05-11 00:18:15, Epoch : 1, Step : 7371, Training Loss : 0.31169, Training Acc : 0.872, Run Time : 0.43
INFO:root:2019-05-11 00:18:17, Epoch : 1, Step : 7372, Training Loss : 0.48151, Training Acc : 0.778, Run Time : 2.01
INFO:root:2019-05-11 00:18:23, Epoch : 1, Step : 7373, Training Loss : 0.52369, Training Acc : 0.783, Run Time : 5.91
INFO:root:2019-05-11 00:18:25, Epoch : 1, Step : 7374, Training Loss : 0.30242, Training Acc : 0.861, Run Time : 1.87
INFO:root:2019-05-11 00:18:30, Epoch : 1, Step : 7375, Training Loss : 0.33177, Training Acc : 0.844, Run Time : 4.86
INFO:root:2019-05-11 00:18:31, Epoch : 1, Step : 7376, Training Loss : 0.35364, Training Acc : 0.844, Run Time : 0.74
INFO:root:2019-05-11 00:18:31, Epoch : 1, Step : 7377, Training Loss : 0.44991, Training Acc : 0.778, Run Time : 0.49
INFO:root:2019-05-11 00:18:32, Epoch : 1, Step : 7378, Training Loss : 0.35706, Training Acc : 0.817, Run Time : 0.50
INFO:root:2019-05-11 00:18:32, Epoch : 1, Step : 7379, Training Loss : 0.27535, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-11 00:18:49, Epoch : 1, Step : 7380, Training Loss : 0.39189, Training Acc : 0.817, Run Time : 16.99
INFO:root:2019-05-11 00:18:49, Epoch : 1, Step : 7381, Training Loss : 0.25181, Training Acc : 0.911, Run Time : 0.35
INFO:root:2019-05-11 00:18:50, Epoch : 1, Step : 7382, Training Loss : 0.25122, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-11 00:18:50, Epoch : 1, Step : 7383, Training Loss : 0.24267, Training Acc : 0.894, Run Time : 0.44
INFO:root:2019-05-11 00:18:55, Epoch : 1, Step : 7384, Training Loss : 0.17482, Training Acc : 0.944, Run Time : 5.07
INFO:root:2019-05-11 00:18:56, Epoch : 1, Step : 7385, Training Loss : 0.18886, Training Acc : 0.928, Run Time : 0.62
INFO:root:2019-05-11 00:18:56, Epoch : 1, Step : 7386, Training Loss : 0.21080, Training Acc : 0.917, Run Time : 0.51
INFO:root:2019-05-11 00:19:05, Epoch : 1, Step : 7387, Training Loss : 0.16169, Training Acc : 0.944, Run Time : 8.28
INFO:root:2019-05-11 00:19:05, Epoch : 1, Step : 7388, Training Loss : 0.11856, Training Acc : 0.961, Run Time : 0.67
INFO:root:2019-05-11 00:19:17, Epoch : 1, Step : 7389, Training Loss : 0.26988, Training Acc : 0.889, Run Time : 11.20
INFO:root:2019-05-11 00:19:17, Epoch : 1, Step : 7390, Training Loss : 0.12375, Training Acc : 0.961, Run Time : 0.26
INFO:root:2019-05-11 00:19:17, Epoch : 1, Step : 7391, Training Loss : 0.30569, Training Acc : 0.878, Run Time : 0.29
INFO:root:2019-05-11 00:19:18, Epoch : 1, Step : 7392, Training Loss : 0.28122, Training Acc : 0.878, Run Time : 0.45
INFO:root:2019-05-11 00:19:18, Epoch : 1, Step : 7393, Training Loss : 0.37731, Training Acc : 0.822, Run Time : 0.47
INFO:root:2019-05-11 00:19:25, Epoch : 1, Step : 7394, Training Loss : 0.30488, Training Acc : 0.861, Run Time : 6.61
INFO:root:2019-05-11 00:19:25, Epoch : 1, Step : 7395, Training Loss : 0.38957, Training Acc : 0.844, Run Time : 0.42
INFO:root:2019-05-11 00:19:39, Epoch : 1, Step : 7396, Training Loss : 0.23491, Training Acc : 0.894, Run Time : 13.99
INFO:root:2019-05-11 00:19:39, Epoch : 1, Step : 7397, Training Loss : 0.22399, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-11 00:19:40, Epoch : 1, Step : 7398, Training Loss : 0.27283, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-11 00:19:47, Epoch : 1, Step : 7399, Training Loss : 0.24300, Training Acc : 0.911, Run Time : 7.39
INFO:root:2019-05-11 00:19:49, Epoch : 1, Step : 7400, Training Loss : 0.18360, Training Acc : 0.939, Run Time : 1.66
INFO:root:2019-05-11 00:19:50, Epoch : 1, Step : 7401, Training Loss : 0.17453, Training Acc : 0.911, Run Time : 0.87
INFO:root:2019-05-11 00:19:50, Epoch : 1, Step : 7402, Training Loss : 0.14365, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-11 00:19:51, Epoch : 1, Step : 7403, Training Loss : 0.18735, Training Acc : 0.911, Run Time : 0.49
INFO:root:2019-05-11 00:19:55, Epoch : 1, Step : 7404, Training Loss : 0.18978, Training Acc : 0.939, Run Time : 4.20
INFO:root:2019-05-11 00:19:55, Epoch : 1, Step : 7405, Training Loss : 0.31588, Training Acc : 0.861, Run Time : 0.46
INFO:root:2019-05-11 00:20:10, Epoch : 1, Step : 7406, Training Loss : 0.25494, Training Acc : 0.872, Run Time : 14.18
INFO:root:2019-05-11 00:20:10, Epoch : 1, Step : 7407, Training Loss : 0.32945, Training Acc : 0.839, Run Time : 0.36
INFO:root:2019-05-11 00:20:10, Epoch : 1, Step : 7408, Training Loss : 0.41567, Training Acc : 0.833, Run Time : 0.50
INFO:root:2019-05-11 00:20:12, Epoch : 1, Step : 7409, Training Loss : 0.35550, Training Acc : 0.833, Run Time : 1.60
INFO:root:2019-05-11 00:20:13, Epoch : 1, Step : 7410, Training Loss : 0.34037, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-11 00:20:16, Epoch : 1, Step : 7411, Training Loss : 0.47087, Training Acc : 0.828, Run Time : 3.29
INFO:root:2019-05-11 00:20:17, Epoch : 1, Step : 7412, Training Loss : 0.57367, Training Acc : 0.794, Run Time : 0.68
INFO:root:2019-05-11 00:20:34, Epoch : 1, Step : 7413, Training Loss : 0.73092, Training Acc : 0.711, Run Time : 17.08
INFO:root:2019-05-11 00:20:34, Epoch : 1, Step : 7414, Training Loss : 0.36379, Training Acc : 0.861, Run Time : 0.31
INFO:root:2019-05-11 00:20:34, Epoch : 1, Step : 7415, Training Loss : 0.25491, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-11 00:20:35, Epoch : 1, Step : 7416, Training Loss : 0.20562, Training Acc : 0.944, Run Time : 0.43
INFO:root:2019-05-11 00:20:35, Epoch : 1, Step : 7417, Training Loss : 0.20469, Training Acc : 0.922, Run Time : 0.50
INFO:root:2019-05-11 00:20:45, Epoch : 1, Step : 7418, Training Loss : 0.22152, Training Acc : 0.922, Run Time : 9.80
INFO:root:2019-05-11 00:20:46, Epoch : 1, Step : 7419, Training Loss : 0.32883, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-11 00:20:46, Epoch : 1, Step : 7420, Training Loss : 0.33750, Training Acc : 0.867, Run Time : 0.80
INFO:root:2019-05-11 00:20:58, Epoch : 1, Step : 7421, Training Loss : 0.26354, Training Acc : 0.867, Run Time : 11.94
INFO:root:2019-05-11 00:20:59, Epoch : 1, Step : 7422, Training Loss : 0.23803, Training Acc : 0.906, Run Time : 0.43
INFO:root:2019-05-11 00:20:59, Epoch : 1, Step : 7423, Training Loss : 0.24152, Training Acc : 0.917, Run Time : 0.57
INFO:root:2019-05-11 00:21:00, Epoch : 1, Step : 7424, Training Loss : 0.18103, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-11 00:21:00, Epoch : 1, Step : 7425, Training Loss : 0.30023, Training Acc : 0.867, Run Time : 0.48
INFO:root:2019-05-11 00:21:11, Epoch : 1, Step : 7426, Training Loss : 0.23155, Training Acc : 0.917, Run Time : 10.31
INFO:root:2019-05-11 00:21:12, Epoch : 1, Step : 7427, Training Loss : 0.29223, Training Acc : 0.883, Run Time : 1.16
INFO:root:2019-05-11 00:21:12, Epoch : 1, Step : 7428, Training Loss : 0.29579, Training Acc : 0.861, Run Time : 0.48
INFO:root:2019-05-11 00:21:13, Epoch : 1, Step : 7429, Training Loss : 0.20120, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-11 00:21:24, Epoch : 1, Step : 7430, Training Loss : 0.19440, Training Acc : 0.922, Run Time : 10.85
INFO:root:2019-05-11 00:21:24, Epoch : 1, Step : 7431, Training Loss : 0.15091, Training Acc : 0.961, Run Time : 0.82
INFO:root:2019-05-11 00:21:25, Epoch : 1, Step : 7432, Training Loss : 0.22893, Training Acc : 0.906, Run Time : 0.48
INFO:root:2019-05-11 00:21:25, Epoch : 1, Step : 7433, Training Loss : 0.15040, Training Acc : 0.972, Run Time : 0.45
INFO:root:2019-05-11 00:21:35, Epoch : 1, Step : 7434, Training Loss : 0.33440, Training Acc : 0.839, Run Time : 9.63
INFO:root:2019-05-11 00:21:35, Epoch : 1, Step : 7435, Training Loss : 0.18727, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-11 00:21:36, Epoch : 1, Step : 7436, Training Loss : 0.18587, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-11 00:21:37, Epoch : 1, Step : 7437, Training Loss : 0.14327, Training Acc : 0.944, Run Time : 0.72
INFO:root:2019-05-11 00:21:45, Epoch : 1, Step : 7438, Training Loss : 0.18116, Training Acc : 0.939, Run Time : 8.10
INFO:root:2019-05-11 00:21:45, Epoch : 1, Step : 7439, Training Loss : 0.10355, Training Acc : 0.972, Run Time : 0.44
INFO:root:2019-05-11 00:21:46, Epoch : 1, Step : 7440, Training Loss : 0.10513, Training Acc : 0.967, Run Time : 0.47
INFO:root:2019-05-11 00:21:55, Epoch : 1, Step : 7441, Training Loss : 0.23495, Training Acc : 0.883, Run Time : 9.33
INFO:root:2019-05-11 00:21:55, Epoch : 1, Step : 7442, Training Loss : 0.12738, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 00:21:56, Epoch : 1, Step : 7443, Training Loss : 0.04801, Training Acc : 0.994, Run Time : 0.46
INFO:root:2019-05-11 00:21:56, Epoch : 1, Step : 7444, Training Loss : 0.12596, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-11 00:22:05, Epoch : 1, Step : 7445, Training Loss : 0.22396, Training Acc : 0.933, Run Time : 9.12
INFO:root:2019-05-11 00:22:06, Epoch : 1, Step : 7446, Training Loss : 0.20248, Training Acc : 0.933, Run Time : 0.27
INFO:root:2019-05-11 00:22:06, Epoch : 1, Step : 7447, Training Loss : 0.13183, Training Acc : 0.972, Run Time : 0.46
INFO:root:2019-05-11 00:22:08, Epoch : 1, Step : 7448, Training Loss : 0.15207, Training Acc : 0.944, Run Time : 2.42
INFO:root:2019-05-11 00:22:19, Epoch : 1, Step : 7449, Training Loss : 0.26524, Training Acc : 0.889, Run Time : 10.54
INFO:root:2019-05-11 00:22:19, Epoch : 1, Step : 7450, Training Loss : 0.13337, Training Acc : 0.961, Run Time : 0.30
INFO:root:2019-05-11 00:22:20, Epoch : 1, Step : 7451, Training Loss : 0.15501, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-11 00:22:20, Epoch : 1, Step : 7452, Training Loss : 0.11371, Training Acc : 0.961, Run Time : 0.38
INFO:root:2019-05-11 00:22:21, Epoch : 1, Step : 7453, Training Loss : 0.03670, Training Acc : 0.994, Run Time : 0.85
INFO:root:2019-05-11 00:22:30, Epoch : 1, Step : 7454, Training Loss : 0.15075, Training Acc : 0.944, Run Time : 8.55
INFO:root:2019-05-11 00:22:30, Epoch : 1, Step : 7455, Training Loss : 0.09384, Training Acc : 0.989, Run Time : 0.53
INFO:root:2019-05-11 00:22:31, Epoch : 1, Step : 7456, Training Loss : 0.14176, Training Acc : 0.950, Run Time : 1.18
INFO:root:2019-05-11 00:22:32, Epoch : 1, Step : 7457, Training Loss : 0.12524, Training Acc : 0.967, Run Time : 0.45
INFO:root:2019-05-11 00:22:41, Epoch : 1, Step : 7458, Training Loss : 0.10671, Training Acc : 0.967, Run Time : 9.30
INFO:root:2019-05-11 00:22:42, Epoch : 1, Step : 7459, Training Loss : 0.14344, Training Acc : 0.939, Run Time : 0.61
INFO:root:2019-05-11 00:22:42, Epoch : 1, Step : 7460, Training Loss : 0.26184, Training Acc : 0.872, Run Time : 0.66
INFO:root:2019-05-11 00:22:49, Epoch : 1, Step : 7461, Training Loss : 0.05418, Training Acc : 0.983, Run Time : 6.49
INFO:root:2019-05-11 00:22:49, Epoch : 1, Step : 7462, Training Loss : 0.14272, Training Acc : 0.911, Run Time : 0.69
INFO:root:2019-05-11 00:22:50, Epoch : 1, Step : 7463, Training Loss : 0.40232, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-11 00:22:55, Epoch : 1, Step : 7464, Training Loss : 0.09298, Training Acc : 0.972, Run Time : 5.38
INFO:root:2019-05-11 00:22:56, Epoch : 1, Step : 7465, Training Loss : 0.25951, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-11 00:23:06, Epoch : 1, Step : 7466, Training Loss : 0.31471, Training Acc : 0.856, Run Time : 10.73
INFO:root:2019-05-11 00:23:07, Epoch : 1, Step : 7467, Training Loss : 0.45526, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-11 00:23:07, Epoch : 1, Step : 7468, Training Loss : 0.28596, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-11 00:23:09, Epoch : 1, Step : 7469, Training Loss : 0.23306, Training Acc : 0.911, Run Time : 1.29
INFO:root:2019-05-11 00:23:09, Epoch : 1, Step : 7470, Training Loss : 0.16631, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-11 00:23:17, Epoch : 1, Step : 7471, Training Loss : 0.36391, Training Acc : 0.872, Run Time : 8.04
INFO:root:2019-05-11 00:23:18, Epoch : 1, Step : 7472, Training Loss : 0.40305, Training Acc : 0.883, Run Time : 0.92
INFO:root:2019-05-11 00:23:19, Epoch : 1, Step : 7473, Training Loss : 0.31400, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-11 00:23:26, Epoch : 1, Step : 7474, Training Loss : 0.22413, Training Acc : 0.906, Run Time : 7.85
INFO:root:2019-05-11 00:23:27, Epoch : 1, Step : 7475, Training Loss : 0.27517, Training Acc : 0.911, Run Time : 1.01
INFO:root:2019-05-11 00:23:30, Epoch : 1, Step : 7476, Training Loss : 0.23435, Training Acc : 0.894, Run Time : 2.11
INFO:root:2019-05-11 00:23:30, Epoch : 1, Step : 7477, Training Loss : 0.24691, Training Acc : 0.900, Run Time : 0.54
INFO:root:2019-05-11 00:23:42, Epoch : 1, Step : 7478, Training Loss : 0.23205, Training Acc : 0.922, Run Time : 12.21
INFO:root:2019-05-11 00:23:43, Epoch : 1, Step : 7479, Training Loss : 0.40897, Training Acc : 0.817, Run Time : 0.33
INFO:root:2019-05-11 00:23:43, Epoch : 1, Step : 7480, Training Loss : 0.41209, Training Acc : 0.839, Run Time : 0.44
INFO:root:2019-05-11 00:23:43, Epoch : 1, Step : 7481, Training Loss : 0.25146, Training Acc : 0.872, Run Time : 0.22
INFO:root:2019-05-11 00:23:44, Epoch : 1, Step : 7482, Training Loss : 0.26450, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-11 00:23:52, Epoch : 1, Step : 7483, Training Loss : 0.23970, Training Acc : 0.911, Run Time : 8.29
INFO:root:2019-05-11 00:23:52, Epoch : 1, Step : 7484, Training Loss : 0.28976, Training Acc : 0.906, Run Time : 0.44
INFO:root:2019-05-11 00:23:54, Epoch : 1, Step : 7485, Training Loss : 0.24945, Training Acc : 0.867, Run Time : 1.58
INFO:root:2019-05-11 00:23:55, Epoch : 1, Step : 7486, Training Loss : 0.17666, Training Acc : 0.922, Run Time : 0.65
INFO:root:2019-05-11 00:24:07, Epoch : 1, Step : 7487, Training Loss : 0.32933, Training Acc : 0.828, Run Time : 11.81
INFO:root:2019-05-11 00:24:07, Epoch : 1, Step : 7488, Training Loss : 0.24050, Training Acc : 0.911, Run Time : 0.42
INFO:root:2019-05-11 00:24:07, Epoch : 1, Step : 7489, Training Loss : 0.19043, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 00:24:08, Epoch : 1, Step : 7490, Training Loss : 0.23220, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-11 00:24:16, Epoch : 1, Step : 7491, Training Loss : 0.27487, Training Acc : 0.906, Run Time : 8.61
INFO:root:2019-05-11 00:24:17, Epoch : 1, Step : 7492, Training Loss : 0.21540, Training Acc : 0.928, Run Time : 0.42
INFO:root:2019-05-11 00:24:18, Epoch : 1, Step : 7493, Training Loss : 0.16172, Training Acc : 0.944, Run Time : 0.76
INFO:root:2019-05-11 00:24:19, Epoch : 1, Step : 7494, Training Loss : 0.26682, Training Acc : 0.900, Run Time : 1.62
INFO:root:2019-05-11 00:24:30, Epoch : 1, Step : 7495, Training Loss : 0.15708, Training Acc : 0.950, Run Time : 11.06
INFO:root:2019-05-11 00:24:31, Epoch : 1, Step : 7496, Training Loss : 0.12900, Training Acc : 0.950, Run Time : 0.72
INFO:root:2019-05-11 00:24:31, Epoch : 1, Step : 7497, Training Loss : 0.10309, Training Acc : 0.967, Run Time : 0.49
INFO:root:2019-05-11 00:24:32, Epoch : 1, Step : 7498, Training Loss : 0.17982, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-11 00:24:40, Epoch : 1, Step : 7499, Training Loss : 0.15606, Training Acc : 0.944, Run Time : 8.54
INFO:root:2019-05-11 00:24:41, Epoch : 1, Step : 7500, Training Loss : 0.16438, Training Acc : 0.933, Run Time : 0.60
INFO:root:2019-05-11 00:24:42, Epoch : 1, Step : 7501, Training Loss : 0.19112, Training Acc : 0.939, Run Time : 0.90
INFO:root:2019-05-11 00:24:43, Epoch : 1, Step : 7502, Training Loss : 0.22796, Training Acc : 0.917, Run Time : 1.12
INFO:root:2019-05-11 00:24:48, Epoch : 1, Step : 7503, Training Loss : 0.22703, Training Acc : 0.917, Run Time : 5.35
INFO:root:2019-05-11 00:24:49, Epoch : 1, Step : 7504, Training Loss : 0.31504, Training Acc : 0.867, Run Time : 0.58
INFO:root:2019-05-11 00:24:53, Epoch : 1, Step : 7505, Training Loss : 0.21588, Training Acc : 0.939, Run Time : 4.14
INFO:root:2019-05-11 00:24:54, Epoch : 1, Step : 7506, Training Loss : 0.20173, Training Acc : 0.917, Run Time : 1.33
INFO:root:2019-05-11 00:25:05, Epoch : 1, Step : 7507, Training Loss : 0.16304, Training Acc : 0.928, Run Time : 10.99
INFO:root:2019-05-11 00:25:06, Epoch : 1, Step : 7508, Training Loss : 0.07698, Training Acc : 0.972, Run Time : 0.38
INFO:root:2019-05-11 00:25:06, Epoch : 1, Step : 7509, Training Loss : 0.11883, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-11 00:25:17, Epoch : 1, Step : 7510, Training Loss : 0.19793, Training Acc : 0.917, Run Time : 10.47
INFO:root:2019-05-11 00:25:17, Epoch : 1, Step : 7511, Training Loss : 0.22895, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-11 00:25:18, Epoch : 1, Step : 7512, Training Loss : 0.26752, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-11 00:25:18, Epoch : 1, Step : 7513, Training Loss : 0.20493, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-11 00:25:19, Epoch : 1, Step : 7514, Training Loss : 0.17597, Training Acc : 0.933, Run Time : 0.34
INFO:root:2019-05-11 00:25:26, Epoch : 1, Step : 7515, Training Loss : 0.22834, Training Acc : 0.906, Run Time : 7.73
INFO:root:2019-05-11 00:25:27, Epoch : 1, Step : 7516, Training Loss : 0.14690, Training Acc : 0.944, Run Time : 0.39
INFO:root:2019-05-11 00:25:35, Epoch : 1, Step : 7517, Training Loss : 0.25096, Training Acc : 0.889, Run Time : 8.12
INFO:root:2019-05-11 00:25:35, Epoch : 1, Step : 7518, Training Loss : 0.24746, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-11 00:25:38, Epoch : 1, Step : 7519, Training Loss : 0.21268, Training Acc : 0.911, Run Time : 2.29
INFO:root:2019-05-11 00:25:48, Epoch : 1, Step : 7520, Training Loss : 0.20768, Training Acc : 0.922, Run Time : 10.74
INFO:root:2019-05-11 00:25:49, Epoch : 1, Step : 7521, Training Loss : 0.41139, Training Acc : 0.833, Run Time : 0.39
INFO:root:2019-05-11 00:25:49, Epoch : 1, Step : 7522, Training Loss : 0.18145, Training Acc : 0.928, Run Time : 0.43
INFO:root:2019-05-11 00:25:50, Epoch : 1, Step : 7523, Training Loss : 0.17338, Training Acc : 0.917, Run Time : 0.50
INFO:root:2019-05-11 00:25:50, Epoch : 1, Step : 7524, Training Loss : 0.06616, Training Acc : 0.989, Run Time : 0.74
INFO:root:2019-05-11 00:25:59, Epoch : 1, Step : 7525, Training Loss : 0.18800, Training Acc : 0.922, Run Time : 8.32
INFO:root:2019-05-11 00:25:59, Epoch : 1, Step : 7526, Training Loss : 0.05474, Training Acc : 0.989, Run Time : 0.66
INFO:root:2019-05-11 00:26:07, Epoch : 1, Step : 7527, Training Loss : 0.11724, Training Acc : 0.944, Run Time : 7.89
INFO:root:2019-05-11 00:26:08, Epoch : 1, Step : 7528, Training Loss : 0.23470, Training Acc : 0.900, Run Time : 0.63
INFO:root:2019-05-11 00:26:08, Epoch : 1, Step : 7529, Training Loss : 0.19871, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-11 00:26:09, Epoch : 1, Step : 7530, Training Loss : 0.16606, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-11 00:26:18, Epoch : 1, Step : 7531, Training Loss : 0.25199, Training Acc : 0.911, Run Time : 8.85
INFO:root:2019-05-11 00:26:19, Epoch : 1, Step : 7532, Training Loss : 0.42825, Training Acc : 0.872, Run Time : 1.09
INFO:root:2019-05-11 00:26:19, Epoch : 1, Step : 7533, Training Loss : 0.30764, Training Acc : 0.856, Run Time : 0.44
INFO:root:2019-05-11 00:26:20, Epoch : 1, Step : 7534, Training Loss : 0.24518, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-11 00:26:32, Epoch : 1, Step : 7535, Training Loss : 0.36460, Training Acc : 0.833, Run Time : 12.77
INFO:root:2019-05-11 00:26:33, Epoch : 1, Step : 7536, Training Loss : 0.32454, Training Acc : 0.883, Run Time : 0.60
INFO:root:2019-05-11 00:26:33, Epoch : 1, Step : 7537, Training Loss : 0.30488, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-11 00:26:35, Epoch : 1, Step : 7538, Training Loss : 0.14765, Training Acc : 0.944, Run Time : 1.74
INFO:root:2019-05-11 00:26:36, Epoch : 1, Step : 7539, Training Loss : 0.31950, Training Acc : 0.883, Run Time : 0.40
INFO:root:2019-05-11 00:26:45, Epoch : 1, Step : 7540, Training Loss : 0.15252, Training Acc : 0.917, Run Time : 9.80
INFO:root:2019-05-11 00:26:46, Epoch : 1, Step : 7541, Training Loss : 0.28966, Training Acc : 0.878, Run Time : 0.44
INFO:root:2019-05-11 00:26:46, Epoch : 1, Step : 7542, Training Loss : 0.36950, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-11 00:26:48, Epoch : 1, Step : 7543, Training Loss : 0.68323, Training Acc : 0.761, Run Time : 1.87
INFO:root:2019-05-11 00:26:57, Epoch : 1, Step : 7544, Training Loss : 0.35477, Training Acc : 0.883, Run Time : 8.79
INFO:root:2019-05-11 00:26:57, Epoch : 1, Step : 7545, Training Loss : 0.45180, Training Acc : 0.772, Run Time : 0.44
INFO:root:2019-05-11 00:26:58, Epoch : 1, Step : 7546, Training Loss : 0.75424, Training Acc : 0.733, Run Time : 0.45
INFO:root:2019-05-11 00:26:58, Epoch : 1, Step : 7547, Training Loss : 0.61029, Training Acc : 0.767, Run Time : 0.46
INFO:root:2019-05-11 00:27:09, Epoch : 1, Step : 7548, Training Loss : 0.25876, Training Acc : 0.894, Run Time : 10.34
INFO:root:2019-05-11 00:27:09, Epoch : 1, Step : 7549, Training Loss : 0.27029, Training Acc : 0.833, Run Time : 0.41
INFO:root:2019-05-11 00:27:09, Epoch : 1, Step : 7550, Training Loss : 0.25413, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-11 00:27:10, Epoch : 1, Step : 7551, Training Loss : 0.29640, Training Acc : 0.889, Run Time : 0.49
INFO:root:2019-05-11 00:27:21, Epoch : 1, Step : 7552, Training Loss : 0.23826, Training Acc : 0.894, Run Time : 11.08
INFO:root:2019-05-11 00:27:22, Epoch : 1, Step : 7553, Training Loss : 0.44793, Training Acc : 0.783, Run Time : 0.87
INFO:root:2019-05-11 00:27:22, Epoch : 1, Step : 7554, Training Loss : 0.48442, Training Acc : 0.800, Run Time : 0.48
INFO:root:2019-05-11 00:27:23, Epoch : 1, Step : 7555, Training Loss : 0.17525, Training Acc : 0.939, Run Time : 0.49
INFO:root:2019-05-11 00:27:23, Epoch : 1, Step : 7556, Training Loss : 0.24462, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-11 00:27:31, Epoch : 1, Step : 7557, Training Loss : 0.09567, Training Acc : 0.967, Run Time : 7.21
INFO:root:2019-05-11 00:27:33, Epoch : 1, Step : 7558, Training Loss : 0.24530, Training Acc : 0.911, Run Time : 2.14
INFO:root:2019-05-11 00:27:33, Epoch : 1, Step : 7559, Training Loss : 0.18975, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-11 00:27:34, Epoch : 1, Step : 7560, Training Loss : 0.28769, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-11 00:27:46, Epoch : 1, Step : 7561, Training Loss : 0.25800, Training Acc : 0.867, Run Time : 12.19
INFO:root:2019-05-11 00:27:46, Epoch : 1, Step : 7562, Training Loss : 0.05183, Training Acc : 0.994, Run Time : 0.44
INFO:root:2019-05-11 00:27:48, Epoch : 1, Step : 7563, Training Loss : 0.29762, Training Acc : 0.939, Run Time : 1.62
INFO:root:2019-05-11 00:27:54, Epoch : 1, Step : 7564, Training Loss : 0.07054, Training Acc : 0.972, Run Time : 6.33
INFO:root:2019-05-11 00:27:55, Epoch : 1, Step : 7565, Training Loss : 0.19595, Training Acc : 0.883, Run Time : 0.52
INFO:root:2019-05-11 00:27:55, Epoch : 1, Step : 7566, Training Loss : 0.17637, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-11 00:27:56, Epoch : 1, Step : 7567, Training Loss : 0.26414, Training Acc : 0.911, Run Time : 0.58
INFO:root:2019-05-11 00:27:56, Epoch : 1, Step : 7568, Training Loss : 0.18873, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-11 00:28:04, Epoch : 1, Step : 7569, Training Loss : 0.28755, Training Acc : 0.861, Run Time : 7.75
INFO:root:2019-05-11 00:28:04, Epoch : 1, Step : 7570, Training Loss : 0.65722, Training Acc : 0.750, Run Time : 0.44
INFO:root:2019-05-11 00:28:06, Epoch : 1, Step : 7571, Training Loss : 0.68397, Training Acc : 0.789, Run Time : 1.58
INFO:root:2019-05-11 00:28:13, Epoch : 1, Step : 7572, Training Loss : 0.51167, Training Acc : 0.772, Run Time : 7.50
INFO:root:2019-05-11 00:28:14, Epoch : 1, Step : 7573, Training Loss : 0.13000, Training Acc : 0.950, Run Time : 0.58
INFO:root:2019-05-11 00:28:15, Epoch : 1, Step : 7574, Training Loss : 0.12535, Training Acc : 0.961, Run Time : 0.50
INFO:root:2019-05-11 00:28:17, Epoch : 1, Step : 7575, Training Loss : 0.12753, Training Acc : 0.956, Run Time : 2.04
INFO:root:2019-05-11 00:28:22, Epoch : 1, Step : 7576, Training Loss : 0.16269, Training Acc : 0.939, Run Time : 5.26
INFO:root:2019-05-11 00:28:23, Epoch : 1, Step : 7577, Training Loss : 0.11743, Training Acc : 0.961, Run Time : 1.01
INFO:root:2019-05-11 00:28:23, Epoch : 1, Step : 7578, Training Loss : 0.17568, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-11 00:28:31, Epoch : 1, Step : 7579, Training Loss : 0.23551, Training Acc : 0.900, Run Time : 7.78
INFO:root:2019-05-11 00:28:32, Epoch : 1, Step : 7580, Training Loss : 0.15115, Training Acc : 0.928, Run Time : 0.57
INFO:root:2019-05-11 00:28:32, Epoch : 1, Step : 7581, Training Loss : 0.22561, Training Acc : 0.906, Run Time : 0.50
INFO:root:2019-05-11 00:28:33, Epoch : 1, Step : 7582, Training Loss : 0.15482, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-11 00:28:43, Epoch : 1, Step : 7583, Training Loss : 0.20149, Training Acc : 0.900, Run Time : 10.57
INFO:root:2019-05-11 00:28:44, Epoch : 1, Step : 7584, Training Loss : 0.14810, Training Acc : 0.928, Run Time : 0.63
INFO:root:2019-05-11 00:28:44, Epoch : 1, Step : 7585, Training Loss : 0.11889, Training Acc : 0.967, Run Time : 0.48
INFO:root:2019-05-11 00:28:47, Epoch : 1, Step : 7586, Training Loss : 0.13945, Training Acc : 0.956, Run Time : 2.87
INFO:root:2019-05-11 00:28:52, Epoch : 1, Step : 7587, Training Loss : 0.15601, Training Acc : 0.944, Run Time : 4.34
INFO:root:2019-05-11 00:28:52, Epoch : 1, Step : 7588, Training Loss : 0.26849, Training Acc : 0.872, Run Time : 0.53
INFO:root:2019-05-11 00:29:05, Epoch : 1, Step : 7589, Training Loss : 0.17618, Training Acc : 0.917, Run Time : 12.85
INFO:root:2019-05-11 00:29:05, Epoch : 1, Step : 7590, Training Loss : 0.22651, Training Acc : 0.900, Run Time : 0.30
INFO:root:2019-05-11 00:29:06, Epoch : 1, Step : 7591, Training Loss : 0.26527, Training Acc : 0.889, Run Time : 0.44
INFO:root:2019-05-11 00:29:06, Epoch : 1, Step : 7592, Training Loss : 0.49958, Training Acc : 0.756, Run Time : 0.43
INFO:root:2019-05-11 00:29:07, Epoch : 1, Step : 7593, Training Loss : 0.35343, Training Acc : 0.856, Run Time : 0.52
INFO:root:2019-05-11 00:29:20, Epoch : 1, Step : 7594, Training Loss : 0.34437, Training Acc : 0.844, Run Time : 13.71
INFO:root:2019-05-11 00:29:21, Epoch : 1, Step : 7595, Training Loss : 0.54878, Training Acc : 0.767, Run Time : 0.28
INFO:root:2019-05-11 00:29:21, Epoch : 1, Step : 7596, Training Loss : 0.27026, Training Acc : 0.878, Run Time : 0.46
INFO:root:2019-05-11 00:29:21, Epoch : 1, Step : 7597, Training Loss : 0.30866, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-11 00:29:23, Epoch : 1, Step : 7598, Training Loss : 0.24233, Training Acc : 0.878, Run Time : 1.67
INFO:root:2019-05-11 00:29:28, Epoch : 1, Step : 7599, Training Loss : 0.48868, Training Acc : 0.811, Run Time : 5.26
INFO:root:2019-05-11 00:29:34, Epoch : 1, Step : 7600, Training Loss : 0.67217, Training Acc : 0.700, Run Time : 5.74
INFO:root:2019-05-11 00:29:35, Epoch : 1, Step : 7601, Training Loss : 0.30217, Training Acc : 0.839, Run Time : 0.93
INFO:root:2019-05-11 00:29:36, Epoch : 1, Step : 7602, Training Loss : 0.39304, Training Acc : 0.828, Run Time : 0.50
INFO:root:2019-05-11 00:29:37, Epoch : 1, Step : 7603, Training Loss : 0.47499, Training Acc : 0.811, Run Time : 0.91
INFO:root:2019-05-11 00:29:44, Epoch : 1, Step : 7604, Training Loss : 0.32959, Training Acc : 0.883, Run Time : 7.55
INFO:root:2019-05-11 00:29:45, Epoch : 1, Step : 7605, Training Loss : 0.65719, Training Acc : 0.761, Run Time : 0.48
INFO:root:2019-05-11 00:29:46, Epoch : 1, Step : 7606, Training Loss : 0.48434, Training Acc : 0.817, Run Time : 1.05
INFO:root:2019-05-11 00:29:52, Epoch : 1, Step : 7607, Training Loss : 0.28194, Training Acc : 0.856, Run Time : 6.68
INFO:root:2019-05-11 00:29:53, Epoch : 1, Step : 7608, Training Loss : 0.20329, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-11 00:29:53, Epoch : 1, Step : 7609, Training Loss : 0.20288, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-11 00:29:54, Epoch : 1, Step : 7610, Training Loss : 0.20131, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-11 00:30:07, Epoch : 1, Step : 7611, Training Loss : 0.37238, Training Acc : 0.856, Run Time : 13.28
INFO:root:2019-05-11 00:30:07, Epoch : 1, Step : 7612, Training Loss : 0.45710, Training Acc : 0.794, Run Time : 0.26
INFO:root:2019-05-11 00:30:08, Epoch : 1, Step : 7613, Training Loss : 0.43039, Training Acc : 0.778, Run Time : 0.44
INFO:root:2019-05-11 00:30:08, Epoch : 1, Step : 7614, Training Loss : 0.33472, Training Acc : 0.850, Run Time : 0.44
INFO:root:2019-05-11 00:30:09, Epoch : 1, Step : 7615, Training Loss : 0.25423, Training Acc : 0.900, Run Time : 0.45
INFO:root:2019-05-11 00:30:17, Epoch : 1, Step : 7616, Training Loss : 0.18725, Training Acc : 0.939, Run Time : 8.11
INFO:root:2019-05-11 00:30:18, Epoch : 1, Step : 7617, Training Loss : 0.16503, Training Acc : 0.961, Run Time : 1.56
INFO:root:2019-05-11 00:30:19, Epoch : 1, Step : 7618, Training Loss : 0.27088, Training Acc : 0.911, Run Time : 0.49
INFO:root:2019-05-11 00:30:19, Epoch : 1, Step : 7619, Training Loss : 0.27623, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-11 00:30:29, Epoch : 1, Step : 7620, Training Loss : 0.35369, Training Acc : 0.839, Run Time : 9.69
INFO:root:2019-05-11 00:30:29, Epoch : 1, Step : 7621, Training Loss : 0.53293, Training Acc : 0.778, Run Time : 0.48
INFO:root:2019-05-11 00:30:30, Epoch : 1, Step : 7622, Training Loss : 0.37417, Training Acc : 0.828, Run Time : 1.01
INFO:root:2019-05-11 00:30:31, Epoch : 1, Step : 7623, Training Loss : 0.34499, Training Acc : 0.856, Run Time : 0.48
INFO:root:2019-05-11 00:30:32, Epoch : 1, Step : 7624, Training Loss : 0.23854, Training Acc : 0.906, Run Time : 1.55
INFO:root:2019-05-11 00:30:35, Epoch : 1, Step : 7625, Training Loss : 0.21330, Training Acc : 0.900, Run Time : 2.28
INFO:root:2019-05-11 00:30:43, Epoch : 1, Step : 7626, Training Loss : 0.23766, Training Acc : 0.906, Run Time : 8.36
INFO:root:2019-05-11 00:30:43, Epoch : 1, Step : 7627, Training Loss : 0.19486, Training Acc : 0.922, Run Time : 0.43
INFO:root:2019-05-11 00:30:44, Epoch : 1, Step : 7628, Training Loss : 0.24355, Training Acc : 0.900, Run Time : 0.41
INFO:root:2019-05-11 00:30:44, Epoch : 1, Step : 7629, Training Loss : 0.17552, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-11 00:30:52, Epoch : 1, Step : 7630, Training Loss : 0.23383, Training Acc : 0.928, Run Time : 7.74
INFO:root:2019-05-11 00:30:52, Epoch : 1, Step : 7631, Training Loss : 0.18134, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-11 00:30:53, Epoch : 1, Step : 7632, Training Loss : 0.35457, Training Acc : 0.817, Run Time : 0.88
INFO:root:2019-05-11 00:31:02, Epoch : 1, Step : 7633, Training Loss : 0.31693, Training Acc : 0.861, Run Time : 8.25
INFO:root:2019-05-11 00:31:02, Epoch : 1, Step : 7634, Training Loss : 0.32620, Training Acc : 0.839, Run Time : 0.59
INFO:root:2019-05-11 00:31:03, Epoch : 1, Step : 7635, Training Loss : 0.33467, Training Acc : 0.867, Run Time : 0.45
INFO:root:2019-05-11 00:31:08, Epoch : 1, Step : 7636, Training Loss : 0.49389, Training Acc : 0.839, Run Time : 5.54
INFO:root:2019-05-11 00:31:09, Epoch : 1, Step : 7637, Training Loss : 0.17465, Training Acc : 0.944, Run Time : 1.31
INFO:root:2019-05-11 00:31:10, Epoch : 1, Step : 7638, Training Loss : 0.16223, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-11 00:31:10, Epoch : 1, Step : 7639, Training Loss : 0.17461, Training Acc : 0.922, Run Time : 0.47
INFO:root:2019-05-11 00:31:17, Epoch : 1, Step : 7640, Training Loss : 0.14185, Training Acc : 0.950, Run Time : 6.71
INFO:root:2019-05-11 00:31:18, Epoch : 1, Step : 7641, Training Loss : 0.31371, Training Acc : 0.889, Run Time : 0.74
INFO:root:2019-05-11 00:31:20, Epoch : 1, Step : 7642, Training Loss : 0.31753, Training Acc : 0.900, Run Time : 2.54
INFO:root:2019-05-11 00:31:21, Epoch : 1, Step : 7643, Training Loss : 0.28501, Training Acc : 0.856, Run Time : 0.44
INFO:root:2019-05-11 00:31:31, Epoch : 1, Step : 7644, Training Loss : 0.27608, Training Acc : 0.883, Run Time : 9.84
INFO:root:2019-05-11 00:31:31, Epoch : 1, Step : 7645, Training Loss : 0.05969, Training Acc : 0.983, Run Time : 0.51
INFO:root:2019-05-11 00:31:32, Epoch : 1, Step : 7646, Training Loss : 0.17403, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-11 00:31:32, Epoch : 1, Step : 7647, Training Loss : 0.10476, Training Acc : 0.967, Run Time : 0.50
INFO:root:2019-05-11 00:31:36, Epoch : 1, Step : 7648, Training Loss : 0.44048, Training Acc : 0.828, Run Time : 4.07
INFO:root:2019-05-11 00:31:37, Epoch : 1, Step : 7649, Training Loss : 0.27319, Training Acc : 0.900, Run Time : 0.75
INFO:root:2019-05-11 00:31:44, Epoch : 1, Step : 7650, Training Loss : 0.51423, Training Acc : 0.822, Run Time : 6.72
INFO:root:2019-05-11 00:31:44, Epoch : 1, Step : 7651, Training Loss : 0.21048, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 00:31:52, Epoch : 1, Step : 7652, Training Loss : 0.48058, Training Acc : 0.794, Run Time : 7.86
INFO:root:2019-05-11 00:31:52, Epoch : 1, Step : 7653, Training Loss : 0.30492, Training Acc : 0.883, Run Time : 0.44
INFO:root:2019-05-11 00:31:54, Epoch : 1, Step : 7654, Training Loss : 0.46222, Training Acc : 0.817, Run Time : 1.25
INFO:root:2019-05-11 00:31:54, Epoch : 1, Step : 7655, Training Loss : 0.39260, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-11 00:31:56, Epoch : 1, Step : 7656, Training Loss : 0.32694, Training Acc : 0.867, Run Time : 1.67
INFO:root:2019-05-11 00:32:01, Epoch : 1, Step : 7657, Training Loss : 0.20849, Training Acc : 0.911, Run Time : 5.41
INFO:root:2019-05-11 00:32:02, Epoch : 1, Step : 7658, Training Loss : 0.18315, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-11 00:32:03, Epoch : 1, Step : 7659, Training Loss : 0.45724, Training Acc : 0.844, Run Time : 1.09
INFO:root:2019-05-11 00:32:06, Epoch : 1, Step : 7660, Training Loss : 0.57501, Training Acc : 0.833, Run Time : 3.21
INFO:root:2019-05-11 00:32:12, Epoch : 1, Step : 7661, Training Loss : 0.78501, Training Acc : 0.733, Run Time : 5.70
INFO:root:2019-05-11 00:32:12, Epoch : 1, Step : 7662, Training Loss : 0.84639, Training Acc : 0.728, Run Time : 0.64
INFO:root:2019-05-11 00:32:13, Epoch : 1, Step : 7663, Training Loss : 0.91821, Training Acc : 0.728, Run Time : 0.46
INFO:root:2019-05-11 00:32:21, Epoch : 1, Step : 7664, Training Loss : 0.69478, Training Acc : 0.811, Run Time : 8.28
INFO:root:2019-05-11 00:32:22, Epoch : 1, Step : 7665, Training Loss : 0.62659, Training Acc : 0.817, Run Time : 0.54
INFO:root:2019-05-11 00:32:22, Epoch : 1, Step : 7666, Training Loss : 0.18803, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 00:32:23, Epoch : 1, Step : 7667, Training Loss : 0.28966, Training Acc : 0.867, Run Time : 1.05
INFO:root:2019-05-11 00:32:31, Epoch : 1, Step : 7668, Training Loss : 0.20313, Training Acc : 0.933, Run Time : 7.52
INFO:root:2019-05-11 00:32:32, Epoch : 1, Step : 7669, Training Loss : 0.23731, Training Acc : 0.917, Run Time : 1.12
INFO:root:2019-05-11 00:32:32, Epoch : 1, Step : 7670, Training Loss : 0.27295, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-11 00:32:44, Epoch : 1, Step : 7671, Training Loss : 0.20008, Training Acc : 0.911, Run Time : 11.75
INFO:root:2019-05-11 00:32:44, Epoch : 1, Step : 7672, Training Loss : 0.25338, Training Acc : 0.917, Run Time : 0.30
INFO:root:2019-05-11 00:32:45, Epoch : 1, Step : 7673, Training Loss : 0.36139, Training Acc : 0.811, Run Time : 0.45
INFO:root:2019-05-11 00:32:45, Epoch : 1, Step : 7674, Training Loss : 0.24758, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-11 00:32:46, Epoch : 1, Step : 7675, Training Loss : 0.30496, Training Acc : 0.822, Run Time : 0.45
INFO:root:2019-05-11 00:32:54, Epoch : 1, Step : 7676, Training Loss : 0.34365, Training Acc : 0.839, Run Time : 8.90
INFO:root:2019-05-11 00:32:55, Epoch : 1, Step : 7677, Training Loss : 0.22950, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 00:32:55, Epoch : 1, Step : 7678, Training Loss : 0.22230, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-11 00:32:56, Epoch : 1, Step : 7679, Training Loss : 0.24974, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-11 00:33:05, Epoch : 1, Step : 7680, Training Loss : 0.23283, Training Acc : 0.928, Run Time : 9.36
INFO:root:2019-05-11 00:33:06, Epoch : 1, Step : 7681, Training Loss : 0.12855, Training Acc : 0.950, Run Time : 0.90
INFO:root:2019-05-11 00:33:07, Epoch : 1, Step : 7682, Training Loss : 0.13586, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-11 00:33:15, Epoch : 1, Step : 7683, Training Loss : 0.16675, Training Acc : 0.950, Run Time : 8.06
INFO:root:2019-05-11 00:33:15, Epoch : 1, Step : 7684, Training Loss : 0.15271, Training Acc : 0.944, Run Time : 0.50
INFO:root:2019-05-11 00:33:16, Epoch : 1, Step : 7685, Training Loss : 0.16918, Training Acc : 0.950, Run Time : 0.44
INFO:root:2019-05-11 00:33:16, Epoch : 1, Step : 7686, Training Loss : 0.16565, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-11 00:33:16, Epoch : 1, Step : 7687, Training Loss : 0.18684, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-11 00:33:26, Epoch : 1, Step : 7688, Training Loss : 0.16189, Training Acc : 0.967, Run Time : 9.50
INFO:root:2019-05-11 00:33:26, Epoch : 1, Step : 7689, Training Loss : 0.13703, Training Acc : 0.978, Run Time : 0.43
INFO:root:2019-05-11 00:33:27, Epoch : 1, Step : 7690, Training Loss : 0.19097, Training Acc : 0.950, Run Time : 0.62
INFO:root:2019-05-11 00:33:35, Epoch : 1, Step : 7691, Training Loss : 0.39406, Training Acc : 0.789, Run Time : 7.53
INFO:root:2019-05-11 00:33:35, Epoch : 1, Step : 7692, Training Loss : 0.33033, Training Acc : 0.822, Run Time : 0.38
INFO:root:2019-05-11 00:33:35, Epoch : 1, Step : 7693, Training Loss : 0.29938, Training Acc : 0.883, Run Time : 0.42
INFO:root:2019-05-11 00:33:36, Epoch : 1, Step : 7694, Training Loss : 0.27564, Training Acc : 0.878, Run Time : 0.44
INFO:root:2019-05-11 00:33:36, Epoch : 1, Step : 7695, Training Loss : 0.48949, Training Acc : 0.806, Run Time : 0.64
INFO:root:2019-05-11 00:33:44, Epoch : 1, Step : 7696, Training Loss : 0.29860, Training Acc : 0.861, Run Time : 7.66
INFO:root:2019-05-11 00:33:45, Epoch : 1, Step : 7697, Training Loss : 0.18477, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-11 00:33:45, Epoch : 1, Step : 7698, Training Loss : 0.11911, Training Acc : 0.944, Run Time : 0.93
INFO:root:2019-05-11 00:33:47, Epoch : 1, Step : 7699, Training Loss : 0.19491, Training Acc : 0.939, Run Time : 1.67
INFO:root:2019-05-11 00:33:56, Epoch : 1, Step : 7700, Training Loss : 0.26572, Training Acc : 0.883, Run Time : 8.69
INFO:root:2019-05-11 00:33:57, Epoch : 1, Step : 7701, Training Loss : 0.15813, Training Acc : 0.950, Run Time : 1.55
INFO:root:2019-05-11 00:34:08, Epoch : 1, Step : 7702, Training Loss : 0.32567, Training Acc : 0.828, Run Time : 10.18
INFO:root:2019-05-11 00:34:08, Epoch : 1, Step : 7703, Training Loss : 0.13908, Training Acc : 0.961, Run Time : 0.23
INFO:root:2019-05-11 00:34:08, Epoch : 1, Step : 7704, Training Loss : 0.23024, Training Acc : 0.917, Run Time : 0.23
INFO:root:2019-05-11 00:34:08, Epoch : 1, Step : 7705, Training Loss : 0.08600, Training Acc : 0.972, Run Time : 0.47
INFO:root:2019-05-11 00:34:09, Epoch : 1, Step : 7706, Training Loss : 0.13656, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-11 00:34:20, Epoch : 1, Step : 7707, Training Loss : 0.07247, Training Acc : 0.989, Run Time : 11.35
INFO:root:2019-05-11 00:34:21, Epoch : 1, Step : 7708, Training Loss : 0.12069, Training Acc : 0.950, Run Time : 0.44
INFO:root:2019-05-11 00:34:21, Epoch : 1, Step : 7709, Training Loss : 0.10207, Training Acc : 0.978, Run Time : 0.45
INFO:root:2019-05-11 00:34:27, Epoch : 1, Step : 7710, Training Loss : 0.14139, Training Acc : 0.933, Run Time : 5.93
INFO:root:2019-05-11 00:34:28, Epoch : 1, Step : 7711, Training Loss : 0.16736, Training Acc : 0.933, Run Time : 0.84
INFO:root:2019-05-11 00:34:28, Epoch : 1, Step : 7712, Training Loss : 0.60145, Training Acc : 0.794, Run Time : 0.46
INFO:root:2019-05-11 00:34:29, Epoch : 1, Step : 7713, Training Loss : 0.81802, Training Acc : 0.644, Run Time : 0.46
INFO:root:2019-05-11 00:34:31, Epoch : 1, Step : 7714, Training Loss : 0.63054, Training Acc : 0.733, Run Time : 2.02
INFO:root:2019-05-11 00:34:40, Epoch : 1, Step : 7715, Training Loss : 0.31037, Training Acc : 0.867, Run Time : 8.95
INFO:root:2019-05-11 00:34:41, Epoch : 1, Step : 7716, Training Loss : 0.17379, Training Acc : 0.944, Run Time : 1.06
INFO:root:2019-05-11 00:34:41, Epoch : 1, Step : 7717, Training Loss : 0.27313, Training Acc : 0.861, Run Time : 0.45
INFO:root:2019-05-11 00:34:42, Epoch : 1, Step : 7718, Training Loss : 0.34697, Training Acc : 0.867, Run Time : 1.11
INFO:root:2019-05-11 00:34:48, Epoch : 1, Step : 7719, Training Loss : 0.31358, Training Acc : 0.850, Run Time : 5.59
INFO:root:2019-05-11 00:34:49, Epoch : 1, Step : 7720, Training Loss : 0.32802, Training Acc : 0.839, Run Time : 0.76
INFO:root:2019-05-11 00:34:54, Epoch : 1, Step : 7721, Training Loss : 0.26067, Training Acc : 0.856, Run Time : 5.19
INFO:root:2019-05-11 00:34:55, Epoch : 1, Step : 7722, Training Loss : 0.16134, Training Acc : 0.933, Run Time : 1.10
INFO:root:2019-05-11 00:34:56, Epoch : 1, Step : 7723, Training Loss : 0.18083, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-11 00:35:06, Epoch : 1, Step : 7724, Training Loss : 0.20647, Training Acc : 0.928, Run Time : 10.52
INFO:root:2019-05-11 00:35:06, Epoch : 1, Step : 7725, Training Loss : 0.21494, Training Acc : 0.878, Run Time : 0.39
INFO:root:2019-05-11 00:35:07, Epoch : 1, Step : 7726, Training Loss : 0.16964, Training Acc : 0.928, Run Time : 0.79
INFO:root:2019-05-11 00:35:08, Epoch : 1, Step : 7727, Training Loss : 0.20379, Training Acc : 0.917, Run Time : 0.81
INFO:root:2019-05-11 00:35:11, Epoch : 1, Step : 7728, Training Loss : 0.15865, Training Acc : 0.956, Run Time : 3.09
INFO:root:2019-05-11 00:35:12, Epoch : 1, Step : 7729, Training Loss : 0.21955, Training Acc : 0.900, Run Time : 1.01
INFO:root:2019-05-11 00:35:13, Epoch : 1, Step : 7730, Training Loss : 0.20150, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-11 00:35:22, Epoch : 1, Step : 7731, Training Loss : 0.11917, Training Acc : 0.972, Run Time : 9.55
INFO:root:2019-05-11 00:35:23, Epoch : 1, Step : 7732, Training Loss : 0.13282, Training Acc : 0.956, Run Time : 0.91
INFO:root:2019-05-11 00:35:24, Epoch : 1, Step : 7733, Training Loss : 0.09359, Training Acc : 0.989, Run Time : 0.46
INFO:root:2019-05-11 00:35:24, Epoch : 1, Step : 7734, Training Loss : 0.12243, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-11 00:35:33, Epoch : 1, Step : 7735, Training Loss : 0.13833, Training Acc : 0.922, Run Time : 9.28
INFO:root:2019-05-11 00:35:34, Epoch : 1, Step : 7736, Training Loss : 0.14340, Training Acc : 0.961, Run Time : 0.45
INFO:root:2019-05-11 00:35:34, Epoch : 1, Step : 7737, Training Loss : 0.12343, Training Acc : 0.972, Run Time : 0.47
INFO:root:2019-05-11 00:35:35, Epoch : 1, Step : 7738, Training Loss : 0.16890, Training Acc : 0.944, Run Time : 0.44
INFO:root:2019-05-11 00:35:40, Epoch : 1, Step : 7739, Training Loss : 0.11026, Training Acc : 0.978, Run Time : 5.23
INFO:root:2019-05-11 00:35:40, Epoch : 1, Step : 7740, Training Loss : 0.10281, Training Acc : 0.972, Run Time : 0.51
INFO:root:2019-05-11 00:35:42, Epoch : 1, Step : 7741, Training Loss : 0.09278, Training Acc : 0.978, Run Time : 1.98
INFO:root:2019-05-11 00:35:44, Epoch : 1, Step : 7742, Training Loss : 0.11679, Training Acc : 0.978, Run Time : 2.02
INFO:root:2019-05-11 00:35:56, Epoch : 1, Step : 7743, Training Loss : 0.07086, Training Acc : 1.000, Run Time : 11.41
INFO:root:2019-05-11 00:35:56, Epoch : 1, Step : 7744, Training Loss : 0.04662, Training Acc : 0.994, Run Time : 0.48
INFO:root:2019-05-11 00:35:57, Epoch : 1, Step : 7745, Training Loss : 0.11208, Training Acc : 0.956, Run Time : 0.48
INFO:root:2019-05-11 00:35:58, Epoch : 1, Step : 7746, Training Loss : 0.08727, Training Acc : 0.972, Run Time : 0.87
INFO:root:2019-05-11 00:35:58, Epoch : 1, Step : 7747, Training Loss : 0.05829, Training Acc : 0.989, Run Time : 0.56
INFO:root:2019-05-11 00:36:02, Epoch : 1, Step : 7748, Training Loss : 0.04063, Training Acc : 1.000, Run Time : 3.85
INFO:root:2019-05-11 00:36:03, Epoch : 1, Step : 7749, Training Loss : 0.03437, Training Acc : 1.000, Run Time : 1.15
INFO:root:2019-05-11 00:36:14, Epoch : 1, Step : 7750, Training Loss : 0.15177, Training Acc : 0.933, Run Time : 10.62
INFO:root:2019-05-11 00:36:14, Epoch : 1, Step : 7751, Training Loss : 0.13848, Training Acc : 0.944, Run Time : 0.55
INFO:root:2019-05-11 00:36:15, Epoch : 1, Step : 7752, Training Loss : 0.06840, Training Acc : 0.989, Run Time : 0.48
INFO:root:2019-05-11 00:36:16, Epoch : 1, Step : 7753, Training Loss : 0.14883, Training Acc : 0.950, Run Time : 0.78
INFO:root:2019-05-11 00:36:23, Epoch : 1, Step : 7754, Training Loss : 0.10760, Training Acc : 0.961, Run Time : 7.01
INFO:root:2019-05-11 00:36:23, Epoch : 1, Step : 7755, Training Loss : 0.08851, Training Acc : 0.967, Run Time : 0.45
INFO:root:2019-05-11 00:36:30, Epoch : 1, Step : 7756, Training Loss : 0.06052, Training Acc : 0.989, Run Time : 6.44
INFO:root:2019-05-11 00:36:30, Epoch : 1, Step : 7757, Training Loss : 0.07437, Training Acc : 0.978, Run Time : 0.71
INFO:root:2019-05-11 00:36:31, Epoch : 1, Step : 7758, Training Loss : 0.04231, Training Acc : 0.994, Run Time : 0.45
INFO:root:2019-05-11 00:36:31, Epoch : 1, Step : 7759, Training Loss : 0.05591, Training Acc : 0.994, Run Time : 0.51
INFO:root:2019-05-11 00:36:40, Epoch : 1, Step : 7760, Training Loss : 0.05247, Training Acc : 0.989, Run Time : 9.12
INFO:root:2019-05-11 00:36:41, Epoch : 1, Step : 7761, Training Loss : 0.06550, Training Acc : 0.989, Run Time : 0.86
INFO:root:2019-05-11 00:36:42, Epoch : 1, Step : 7762, Training Loss : 0.08533, Training Acc : 0.972, Run Time : 0.38
INFO:root:2019-05-11 00:36:42, Epoch : 1, Step : 7763, Training Loss : 0.06315, Training Acc : 0.994, Run Time : 0.45
INFO:root:2019-05-11 00:36:52, Epoch : 1, Step : 7764, Training Loss : 0.07245, Training Acc : 0.983, Run Time : 9.55
INFO:root:2019-05-11 00:36:52, Epoch : 1, Step : 7765, Training Loss : 0.12368, Training Acc : 0.972, Run Time : 0.72
INFO:root:2019-05-11 00:36:53, Epoch : 1, Step : 7766, Training Loss : 0.07342, Training Acc : 0.989, Run Time : 0.46
INFO:root:2019-05-11 00:36:53, Epoch : 1, Step : 7767, Training Loss : 0.09040, Training Acc : 0.967, Run Time : 0.46
INFO:root:2019-05-11 00:37:01, Epoch : 1, Step : 7768, Training Loss : 0.14157, Training Acc : 0.956, Run Time : 7.68
INFO:root:2019-05-11 00:37:01, Epoch : 1, Step : 7769, Training Loss : 0.05585, Training Acc : 0.994, Run Time : 0.45
INFO:root:2019-05-11 00:37:02, Epoch : 1, Step : 7770, Training Loss : 0.07081, Training Acc : 0.978, Run Time : 1.05
INFO:root:2019-05-11 00:37:03, Epoch : 1, Step : 7771, Training Loss : 0.25418, Training Acc : 0.894, Run Time : 0.54
INFO:root:2019-05-11 00:37:15, Epoch : 1, Step : 7772, Training Loss : 0.19346, Training Acc : 0.917, Run Time : 11.60
INFO:root:2019-05-11 00:37:15, Epoch : 1, Step : 7773, Training Loss : 0.20950, Training Acc : 0.894, Run Time : 0.44
INFO:root:2019-05-11 00:37:15, Epoch : 1, Step : 7774, Training Loss : 0.14436, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-11 00:37:16, Epoch : 1, Step : 7775, Training Loss : 0.14408, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-11 00:37:22, Epoch : 1, Step : 7776, Training Loss : 0.22947, Training Acc : 0.922, Run Time : 6.54
INFO:root:2019-05-11 00:37:23, Epoch : 1, Step : 7777, Training Loss : 0.15996, Training Acc : 0.939, Run Time : 0.43
INFO:root:2019-05-11 00:37:23, Epoch : 1, Step : 7778, Training Loss : 0.15703, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-11 00:37:25, Epoch : 1, Step : 7779, Training Loss : 0.15549, Training Acc : 0.950, Run Time : 2.04
INFO:root:2019-05-11 00:37:35, Epoch : 1, Step : 7780, Training Loss : 0.16656, Training Acc : 0.933, Run Time : 10.06
INFO:root:2019-05-11 00:37:36, Epoch : 1, Step : 7781, Training Loss : 0.29753, Training Acc : 0.872, Run Time : 0.37
INFO:root:2019-05-11 00:37:36, Epoch : 1, Step : 7782, Training Loss : 0.18099, Training Acc : 0.928, Run Time : 0.49
INFO:root:2019-05-11 00:37:45, Epoch : 1, Step : 7783, Training Loss : 0.07067, Training Acc : 0.978, Run Time : 8.46
INFO:root:2019-05-11 00:37:46, Epoch : 1, Step : 7784, Training Loss : 0.17324, Training Acc : 0.922, Run Time : 1.66
INFO:root:2019-05-11 00:37:47, Epoch : 1, Step : 7785, Training Loss : 0.28686, Training Acc : 0.850, Run Time : 0.52
INFO:root:2019-05-11 00:37:47, Epoch : 1, Step : 7786, Training Loss : 0.34348, Training Acc : 0.844, Run Time : 0.50
INFO:root:2019-05-11 00:37:48, Epoch : 1, Step : 7787, Training Loss : 0.36202, Training Acc : 0.872, Run Time : 0.47
INFO:root:2019-05-11 00:37:54, Epoch : 1, Step : 7788, Training Loss : 0.35143, Training Acc : 0.894, Run Time : 6.43
INFO:root:2019-05-11 00:37:55, Epoch : 1, Step : 7789, Training Loss : 0.29137, Training Acc : 0.883, Run Time : 0.44
INFO:root:2019-05-11 00:37:55, Epoch : 1, Step : 7790, Training Loss : 0.16686, Training Acc : 0.939, Run Time : 0.47
INFO:root:2019-05-11 00:38:05, Epoch : 1, Step : 7791, Training Loss : 0.15859, Training Acc : 0.922, Run Time : 9.38
INFO:root:2019-05-11 00:38:05, Epoch : 1, Step : 7792, Training Loss : 0.21157, Training Acc : 0.928, Run Time : 0.36
INFO:root:2019-05-11 00:38:06, Epoch : 1, Step : 7793, Training Loss : 0.22526, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-11 00:38:06, Epoch : 1, Step : 7794, Training Loss : 0.27860, Training Acc : 0.911, Run Time : 0.44
INFO:root:2019-05-11 00:38:16, Epoch : 1, Step : 7795, Training Loss : 0.16504, Training Acc : 0.950, Run Time : 9.61
INFO:root:2019-05-11 00:38:16, Epoch : 1, Step : 7796, Training Loss : 0.10343, Training Acc : 0.972, Run Time : 0.45
INFO:root:2019-05-11 00:38:16, Epoch : 1, Step : 7797, Training Loss : 0.14773, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-11 00:38:23, Epoch : 1, Step : 7798, Training Loss : 0.27582, Training Acc : 0.856, Run Time : 6.77
INFO:root:2019-05-11 00:38:24, Epoch : 1, Step : 7799, Training Loss : 0.37333, Training Acc : 0.833, Run Time : 0.63
INFO:root:2019-05-11 00:38:24, Epoch : 1, Step : 7800, Training Loss : 0.42403, Training Acc : 0.794, Run Time : 0.43
INFO:root:2019-05-11 00:38:25, Epoch : 1, Step : 7801, Training Loss : 1.51235, Training Acc : 0.483, Run Time : 1.07
INFO:root:2019-05-11 00:38:35, Epoch : 1, Step : 7802, Training Loss : 1.38926, Training Acc : 0.561, Run Time : 9.16
INFO:root:2019-05-11 00:38:35, Epoch : 1, Step : 7803, Training Loss : 1.02064, Training Acc : 0.644, Run Time : 0.41
INFO:root:2019-05-11 00:38:35, Epoch : 1, Step : 7804, Training Loss : 0.86664, Training Acc : 0.661, Run Time : 0.29
INFO:root:2019-05-11 00:38:36, Epoch : 1, Step : 7805, Training Loss : 0.87127, Training Acc : 0.694, Run Time : 0.46
INFO:root:2019-05-11 00:38:36, Epoch : 1, Step : 7806, Training Loss : 0.77665, Training Acc : 0.694, Run Time : 0.64
INFO:root:2019-05-11 00:38:45, Epoch : 1, Step : 7807, Training Loss : 0.88172, Training Acc : 0.628, Run Time : 8.95
INFO:root:2019-05-11 00:38:46, Epoch : 1, Step : 7808, Training Loss : 0.42927, Training Acc : 0.811, Run Time : 0.44
INFO:root:2019-05-11 00:38:54, Epoch : 1, Step : 7809, Training Loss : 0.27766, Training Acc : 0.878, Run Time : 8.43
INFO:root:2019-05-11 00:38:55, Epoch : 1, Step : 7810, Training Loss : 0.18175, Training Acc : 0.917, Run Time : 0.32
INFO:root:2019-05-11 00:38:55, Epoch : 1, Step : 7811, Training Loss : 0.16379, Training Acc : 0.939, Run Time : 0.59
INFO:root:2019-05-11 00:38:56, Epoch : 1, Step : 7812, Training Loss : 0.23299, Training Acc : 0.917, Run Time : 0.73
INFO:root:2019-05-11 00:38:56, Epoch : 1, Step : 7813, Training Loss : 0.15766, Training Acc : 0.928, Run Time : 0.35
INFO:root:2019-05-11 00:39:03, Epoch : 1, Step : 7814, Training Loss : 0.19355, Training Acc : 0.928, Run Time : 7.21
INFO:root:2019-05-11 00:39:04, Epoch : 1, Step : 7815, Training Loss : 0.19707, Training Acc : 0.922, Run Time : 0.45
INFO:root:2019-05-11 00:39:05, Epoch : 1, Step : 7816, Training Loss : 0.16606, Training Acc : 0.956, Run Time : 0.99
INFO:root:2019-05-11 00:39:05, Epoch : 1, Step : 7817, Training Loss : 0.24668, Training Acc : 0.917, Run Time : 0.50
INFO:root:2019-05-11 00:39:17, Epoch : 1, Step : 7818, Training Loss : 0.15835, Training Acc : 0.956, Run Time : 11.71
INFO:root:2019-05-11 00:39:17, Epoch : 1, Step : 7819, Training Loss : 0.15567, Training Acc : 0.939, Run Time : 0.40
INFO:root:2019-05-11 00:39:18, Epoch : 1, Step : 7820, Training Loss : 0.29690, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-11 00:39:18, Epoch : 1, Step : 7821, Training Loss : 0.34525, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-11 00:39:19, Epoch : 1, Step : 7822, Training Loss : 0.18968, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-11 00:39:28, Epoch : 1, Step : 7823, Training Loss : 0.25440, Training Acc : 0.922, Run Time : 8.92
INFO:root:2019-05-11 00:39:28, Epoch : 1, Step : 7824, Training Loss : 0.34316, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-11 00:39:29, Epoch : 1, Step : 7825, Training Loss : 0.14625, Training Acc : 0.933, Run Time : 0.45
INFO:root:2019-05-11 00:39:29, Epoch : 1, Step : 7826, Training Loss : 0.33913, Training Acc : 0.917, Run Time : 0.70
INFO:root:2019-05-11 00:39:41, Epoch : 1, Step : 7827, Training Loss : 0.24883, Training Acc : 0.944, Run Time : 11.35
INFO:root:2019-05-11 00:39:41, Epoch : 1, Step : 7828, Training Loss : 0.30794, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-11 00:39:42, Epoch : 1, Step : 7829, Training Loss : 0.21367, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-11 00:39:42, Epoch : 1, Step : 7830, Training Loss : 0.70550, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-11 00:39:43, Epoch : 1, Step : 7831, Training Loss : 0.26430, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-11 00:39:51, Epoch : 1, Step : 7832, Training Loss : 0.29710, Training Acc : 0.894, Run Time : 8.73
INFO:root:2019-05-11 00:39:52, Epoch : 1, Step : 7833, Training Loss : 0.58008, Training Acc : 0.844, Run Time : 0.55
INFO:root:2019-05-11 00:39:52, Epoch : 1, Step : 7834, Training Loss : 0.63392, Training Acc : 0.856, Run Time : 0.49
INFO:root:2019-05-11 00:39:53, Epoch : 1, Step : 7835, Training Loss : 1.25837, Training Acc : 0.761, Run Time : 0.48
INFO:root:2019-05-11 00:40:02, Epoch : 1, Step : 7836, Training Loss : 0.65804, Training Acc : 0.817, Run Time : 9.30
INFO:root:2019-05-11 00:40:03, Epoch : 1, Step : 7837, Training Loss : 0.65100, Training Acc : 0.817, Run Time : 0.68
INFO:root:2019-05-11 00:40:03, Epoch : 1, Step : 7838, Training Loss : 0.58769, Training Acc : 0.789, Run Time : 0.47
INFO:root:2019-05-11 00:40:10, Epoch : 1, Step : 7839, Training Loss : 0.22029, Training Acc : 0.889, Run Time : 6.51
INFO:root:2019-05-11 00:40:11, Epoch : 1, Step : 7840, Training Loss : 0.33027, Training Acc : 0.878, Run Time : 0.89
INFO:root:2019-05-11 00:40:11, Epoch : 1, Step : 7841, Training Loss : 0.36993, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-11 00:40:12, Epoch : 1, Step : 7842, Training Loss : 0.39521, Training Acc : 0.822, Run Time : 0.46
INFO:root:2019-05-11 00:40:12, Epoch : 1, Step : 7843, Training Loss : 0.26685, Training Acc : 0.844, Run Time : 0.46
INFO:root:2019-05-11 00:40:23, Epoch : 1, Step : 7844, Training Loss : 0.47659, Training Acc : 0.778, Run Time : 11.16
INFO:root:2019-05-11 00:40:24, Epoch : 1, Step : 7845, Training Loss : 0.40801, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-11 00:40:24, Epoch : 1, Step : 7846, Training Loss : 0.25384, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-11 00:40:25, Epoch : 1, Step : 7847, Training Loss : 0.29479, Training Acc : 0.850, Run Time : 0.48
INFO:root:2019-05-11 00:40:25, Epoch : 1, Step : 7848, Training Loss : 0.32751, Training Acc : 0.850, Run Time : 0.75
INFO:root:2019-05-11 00:40:32, Epoch : 1, Step : 7849, Training Loss : 0.37492, Training Acc : 0.811, Run Time : 6.20
INFO:root:2019-05-11 00:40:32, Epoch : 1, Step : 7850, Training Loss : 0.34980, Training Acc : 0.850, Run Time : 0.44
INFO:root:2019-05-11 00:40:35, Epoch : 1, Step : 7851, Training Loss : 0.41573, Training Acc : 0.806, Run Time : 2.94
INFO:root:2019-05-11 00:40:35, Epoch : 1, Step : 7852, Training Loss : 0.54520, Training Acc : 0.750, Run Time : 0.44
INFO:root:2019-05-11 00:40:42, Epoch : 1, Step : 7853, Training Loss : 0.38345, Training Acc : 0.828, Run Time : 6.61
INFO:root:2019-05-11 00:40:42, Epoch : 1, Step : 7854, Training Loss : 0.36312, Training Acc : 0.833, Run Time : 0.49
INFO:root:2019-05-11 00:40:43, Epoch : 1, Step : 7855, Training Loss : 0.38203, Training Acc : 0.833, Run Time : 0.76
INFO:root:2019-05-11 00:40:45, Epoch : 1, Step : 7856, Training Loss : 0.43944, Training Acc : 0.783, Run Time : 1.62
INFO:root:2019-05-11 00:40:54, Epoch : 1, Step : 7857, Training Loss : 0.35021, Training Acc : 0.850, Run Time : 9.34
INFO:root:2019-05-11 00:40:54, Epoch : 1, Step : 7858, Training Loss : 0.44747, Training Acc : 0.783, Run Time : 0.23
INFO:root:2019-05-11 00:40:55, Epoch : 1, Step : 7859, Training Loss : 0.47055, Training Acc : 0.783, Run Time : 0.54
INFO:root:2019-05-11 00:40:55, Epoch : 1, Step : 7860, Training Loss : 0.45436, Training Acc : 0.800, Run Time : 0.50
INFO:root:2019-05-11 00:41:04, Epoch : 1, Step : 7861, Training Loss : 0.56876, Training Acc : 0.767, Run Time : 8.92
INFO:root:2019-05-11 00:41:05, Epoch : 1, Step : 7862, Training Loss : 0.53586, Training Acc : 0.739, Run Time : 0.28
INFO:root:2019-05-11 00:41:05, Epoch : 1, Step : 7863, Training Loss : 0.43451, Training Acc : 0.806, Run Time : 0.51
INFO:root:2019-05-11 00:41:06, Epoch : 1, Step : 7864, Training Loss : 0.37906, Training Acc : 0.839, Run Time : 0.46
INFO:root:2019-05-11 00:41:18, Epoch : 1, Step : 7865, Training Loss : 0.37369, Training Acc : 0.839, Run Time : 12.04
INFO:root:2019-05-11 00:41:19, Epoch : 1, Step : 7866, Training Loss : 0.40022, Training Acc : 0.800, Run Time : 1.06
INFO:root:2019-05-11 00:41:19, Epoch : 1, Step : 7867, Training Loss : 0.38340, Training Acc : 0.850, Run Time : 0.43
INFO:root:2019-05-11 00:41:26, Epoch : 1, Step : 7868, Training Loss : 0.30574, Training Acc : 0.889, Run Time : 6.49
INFO:root:2019-05-11 00:41:27, Epoch : 1, Step : 7869, Training Loss : 0.33791, Training Acc : 0.850, Run Time : 0.88
INFO:root:2019-05-11 00:41:32, Epoch : 1, Step : 7870, Training Loss : 0.34797, Training Acc : 0.900, Run Time : 5.81
INFO:root:2019-05-11 00:41:33, Epoch : 1, Step : 7871, Training Loss : 0.32803, Training Acc : 0.861, Run Time : 0.66
INFO:root:2019-05-11 00:41:33, Epoch : 1, Step : 7872, Training Loss : 0.28487, Training Acc : 0.900, Run Time : 0.43
INFO:root:2019-05-11 00:41:34, Epoch : 1, Step : 7873, Training Loss : 0.28029, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-11 00:41:34, Epoch : 1, Step : 7874, Training Loss : 0.19725, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-11 00:41:44, Epoch : 1, Step : 7875, Training Loss : 0.24413, Training Acc : 0.917, Run Time : 9.37
INFO:root:2019-05-11 00:41:44, Epoch : 1, Step : 7876, Training Loss : 0.34389, Training Acc : 0.878, Run Time : 0.45
INFO:root:2019-05-11 00:41:45, Epoch : 1, Step : 7877, Training Loss : 0.18644, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-11 00:41:45, Epoch : 1, Step : 7878, Training Loss : 0.29737, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-11 00:41:54, Epoch : 1, Step : 7879, Training Loss : 0.29447, Training Acc : 0.856, Run Time : 9.28
INFO:root:2019-05-11 00:41:55, Epoch : 1, Step : 7880, Training Loss : 0.26672, Training Acc : 0.883, Run Time : 0.50
INFO:root:2019-05-11 00:41:55, Epoch : 1, Step : 7881, Training Loss : 0.21416, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-11 00:41:56, Epoch : 1, Step : 7882, Training Loss : 0.17028, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-11 00:42:05, Epoch : 1, Step : 7883, Training Loss : 0.21756, Training Acc : 0.917, Run Time : 9.08
INFO:root:2019-05-11 00:42:05, Epoch : 1, Step : 7884, Training Loss : 0.14505, Training Acc : 0.939, Run Time : 0.35
INFO:root:2019-05-11 00:42:06, Epoch : 1, Step : 7885, Training Loss : 0.21031, Training Acc : 0.906, Run Time : 0.45
INFO:root:2019-05-11 00:42:14, Epoch : 1, Step : 7886, Training Loss : 0.11530, Training Acc : 0.950, Run Time : 7.94
INFO:root:2019-05-11 00:42:14, Epoch : 1, Step : 7887, Training Loss : 0.15849, Training Acc : 0.933, Run Time : 0.33
INFO:root:2019-05-11 00:42:14, Epoch : 1, Step : 7888, Training Loss : 0.20480, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-11 00:42:15, Epoch : 1, Step : 7889, Training Loss : 0.14058, Training Acc : 0.972, Run Time : 0.44
INFO:root:2019-05-11 00:42:15, Epoch : 1, Step : 7890, Training Loss : 0.16514, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-11 00:42:25, Epoch : 1, Step : 7891, Training Loss : 0.17063, Training Acc : 0.944, Run Time : 9.71
INFO:root:2019-05-11 00:42:25, Epoch : 1, Step : 7892, Training Loss : 0.11646, Training Acc : 0.967, Run Time : 0.45
INFO:root:2019-05-11 00:42:26, Epoch : 1, Step : 7893, Training Loss : 0.17637, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-11 00:42:26, Epoch : 1, Step : 7894, Training Loss : 0.13615, Training Acc : 0.956, Run Time : 0.46
INFO:root:2019-05-11 00:42:33, Epoch : 1, Step : 7895, Training Loss : 0.16512, Training Acc : 0.956, Run Time : 7.10
INFO:root:2019-05-11 00:42:34, Epoch : 1, Step : 7896, Training Loss : 0.14152, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-11 00:42:34, Epoch : 1, Step : 7897, Training Loss : 0.18085, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-11 00:42:38, Epoch : 1, Step : 7898, Training Loss : 0.12475, Training Acc : 0.967, Run Time : 3.91
INFO:root:2019-05-11 00:42:39, Epoch : 1, Step : 7899, Training Loss : 0.14288, Training Acc : 0.939, Run Time : 0.63
INFO:root:2019-05-11 00:42:47, Epoch : 1, Step : 7900, Training Loss : 0.13700, Training Acc : 0.950, Run Time : 8.22
INFO:root:2019-05-11 00:42:48, Epoch : 1, Step : 7901, Training Loss : 0.21520, Training Acc : 0.922, Run Time : 0.89
INFO:root:2019-05-11 00:42:48, Epoch : 1, Step : 7902, Training Loss : 0.16148, Training Acc : 0.933, Run Time : 0.43
INFO:root:2019-05-11 00:42:49, Epoch : 1, Step : 7903, Training Loss : 0.16991, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-11 00:42:50, Epoch : 1, Step : 7904, Training Loss : 0.12791, Training Acc : 0.950, Run Time : 0.79
INFO:root:2019-05-11 00:42:55, Epoch : 1, Step : 7905, Training Loss : 0.19823, Training Acc : 0.911, Run Time : 5.62
INFO:root:2019-05-11 00:42:57, Epoch : 1, Step : 7906, Training Loss : 0.11999, Training Acc : 0.950, Run Time : 1.18
INFO:root:2019-05-11 00:43:05, Epoch : 1, Step : 7907, Training Loss : 0.15875, Training Acc : 0.928, Run Time : 8.97
INFO:root:2019-05-11 00:43:06, Epoch : 1, Step : 7908, Training Loss : 0.14115, Training Acc : 0.956, Run Time : 0.54
INFO:root:2019-05-11 00:43:06, Epoch : 1, Step : 7909, Training Loss : 0.22947, Training Acc : 0.911, Run Time : 0.43
INFO:root:2019-05-11 00:43:07, Epoch : 1, Step : 7910, Training Loss : 0.19905, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-11 00:43:07, Epoch : 1, Step : 7911, Training Loss : 0.18437, Training Acc : 0.928, Run Time : 0.51
INFO:root:2019-05-11 00:43:19, Epoch : 1, Step : 7912, Training Loss : 0.20899, Training Acc : 0.894, Run Time : 11.46
INFO:root:2019-05-11 00:43:20, Epoch : 1, Step : 7913, Training Loss : 0.18215, Training Acc : 0.928, Run Time : 1.54
INFO:root:2019-05-11 00:43:21, Epoch : 1, Step : 7914, Training Loss : 0.19193, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-11 00:43:21, Epoch : 1, Step : 7915, Training Loss : 0.19263, Training Acc : 0.906, Run Time : 0.59
INFO:root:2019-05-11 00:43:22, Epoch : 1, Step : 7916, Training Loss : 0.17959, Training Acc : 0.922, Run Time : 0.81
INFO:root:2019-05-11 00:43:28, Epoch : 1, Step : 7917, Training Loss : 0.14248, Training Acc : 0.950, Run Time : 5.57
INFO:root:2019-05-11 00:43:29, Epoch : 1, Step : 7918, Training Loss : 0.23121, Training Acc : 0.894, Run Time : 1.08
INFO:root:2019-05-11 00:43:29, Epoch : 1, Step : 7919, Training Loss : 0.19510, Training Acc : 0.933, Run Time : 0.47
INFO:root:2019-05-11 00:43:42, Epoch : 1, Step : 7920, Training Loss : 0.19650, Training Acc : 0.917, Run Time : 13.01
INFO:root:2019-05-11 00:43:43, Epoch : 1, Step : 7921, Training Loss : 0.22207, Training Acc : 0.894, Run Time : 0.41
INFO:root:2019-05-11 00:43:43, Epoch : 1, Step : 7922, Training Loss : 0.26730, Training Acc : 0.861, Run Time : 0.43
INFO:root:2019-05-11 00:43:44, Epoch : 1, Step : 7923, Training Loss : 0.18650, Training Acc : 0.939, Run Time : 0.43
INFO:root:2019-05-11 00:43:44, Epoch : 1, Step : 7924, Training Loss : 0.19873, Training Acc : 0.917, Run Time : 0.54
INFO:root:2019-05-11 00:43:58, Epoch : 1, Step : 7925, Training Loss : 0.15494, Training Acc : 0.950, Run Time : 14.06
INFO:root:2019-05-11 00:43:59, Epoch : 1, Step : 7926, Training Loss : 0.17247, Training Acc : 0.911, Run Time : 0.24
INFO:root:2019-05-11 00:43:59, Epoch : 1, Step : 7927, Training Loss : 0.11448, Training Acc : 0.972, Run Time : 0.46
INFO:root:2019-05-11 00:43:59, Epoch : 1, Step : 7928, Training Loss : 0.19726, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-11 00:44:07, Epoch : 1, Step : 7929, Training Loss : 0.12067, Training Acc : 0.961, Run Time : 7.88
INFO:root:2019-05-11 00:44:08, Epoch : 1, Step : 7930, Training Loss : 0.13068, Training Acc : 0.956, Run Time : 0.76
INFO:root:2019-05-11 00:44:14, Epoch : 1, Step : 7931, Training Loss : 0.09798, Training Acc : 0.978, Run Time : 6.29
INFO:root:2019-05-11 00:44:15, Epoch : 1, Step : 7932, Training Loss : 0.12548, Training Acc : 0.972, Run Time : 0.62
INFO:root:2019-05-11 00:44:15, Epoch : 1, Step : 7933, Training Loss : 0.13292, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-11 00:44:16, Epoch : 1, Step : 7934, Training Loss : 0.11514, Training Acc : 0.967, Run Time : 0.49
INFO:root:2019-05-11 00:44:22, Epoch : 1, Step : 7935, Training Loss : 0.13551, Training Acc : 0.950, Run Time : 5.83
INFO:root:2019-05-11 00:44:25, Epoch : 1, Step : 7936, Training Loss : 0.10881, Training Acc : 0.956, Run Time : 3.27
INFO:root:2019-05-11 00:44:26, Epoch : 1, Step : 7937, Training Loss : 0.09067, Training Acc : 0.972, Run Time : 0.43
INFO:root:2019-05-11 00:44:26, Epoch : 1, Step : 7938, Training Loss : 0.25678, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-11 00:44:32, Epoch : 1, Step : 7939, Training Loss : 0.11547, Training Acc : 0.956, Run Time : 5.72
INFO:root:2019-05-11 00:44:32, Epoch : 1, Step : 7940, Training Loss : 0.15976, Training Acc : 0.939, Run Time : 0.57
INFO:root:2019-05-11 00:44:33, Epoch : 1, Step : 7941, Training Loss : 0.06734, Training Acc : 0.978, Run Time : 0.44
INFO:root:2019-05-11 00:44:35, Epoch : 1, Step : 7942, Training Loss : 0.05955, Training Acc : 0.989, Run Time : 1.82
INFO:root:2019-05-11 00:44:36, Epoch : 1, Step : 7943, Training Loss : 0.05915, Training Acc : 0.983, Run Time : 1.30
INFO:root:2019-05-11 00:44:50, Epoch : 1, Step : 7944, Training Loss : 0.04082, Training Acc : 0.994, Run Time : 14.01
INFO:root:2019-05-11 00:44:50, Epoch : 1, Step : 7945, Training Loss : 0.04182, Training Acc : 0.994, Run Time : 0.35
INFO:root:2019-05-11 00:44:51, Epoch : 1, Step : 7946, Training Loss : 0.04257, Training Acc : 1.000, Run Time : 0.44
INFO:root:2019-05-11 00:44:51, Epoch : 1, Step : 7947, Training Loss : 0.07458, Training Acc : 0.983, Run Time : 0.44
INFO:root:2019-05-11 00:44:56, Epoch : 1, Step : 7948, Training Loss : 0.06497, Training Acc : 0.972, Run Time : 4.99
INFO:root:2019-05-11 00:44:56, Epoch : 1, Step : 7949, Training Loss : 0.07258, Training Acc : 0.972, Run Time : 0.42
INFO:root:2019-05-11 00:45:02, Epoch : 1, Step : 7950, Training Loss : 0.06802, Training Acc : 0.978, Run Time : 5.17
INFO:root:2019-05-11 00:45:02, Epoch : 1, Step : 7951, Training Loss : 0.08286, Training Acc : 0.961, Run Time : 0.56
INFO:root:2019-05-11 00:45:04, Epoch : 1, Step : 7952, Training Loss : 0.09004, Training Acc : 0.956, Run Time : 1.39
INFO:root:2019-05-11 00:45:05, Epoch : 1, Step : 7953, Training Loss : 0.08474, Training Acc : 0.961, Run Time : 1.58
INFO:root:2019-05-11 00:45:06, Epoch : 1, Step : 7954, Training Loss : 0.37825, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-11 00:45:16, Epoch : 1, Step : 7955, Training Loss : 0.32652, Training Acc : 0.883, Run Time : 10.79
INFO:root:2019-05-11 00:45:17, Epoch : 1, Step : 7956, Training Loss : 0.32173, Training Acc : 0.872, Run Time : 0.49
INFO:root:2019-05-11 00:45:17, Epoch : 1, Step : 7957, Training Loss : 0.24917, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-11 00:45:18, Epoch : 1, Step : 7958, Training Loss : 0.22210, Training Acc : 0.883, Run Time : 0.48
INFO:root:2019-05-11 00:45:26, Epoch : 1, Step : 7959, Training Loss : 0.11290, Training Acc : 0.944, Run Time : 8.25
INFO:root:2019-05-11 00:45:27, Epoch : 1, Step : 7960, Training Loss : 0.10519, Training Acc : 0.944, Run Time : 0.50
INFO:root:2019-05-11 00:45:27, Epoch : 1, Step : 7961, Training Loss : 0.09865, Training Acc : 0.956, Run Time : 0.43
INFO:root:2019-05-11 00:45:29, Epoch : 1, Step : 7962, Training Loss : 0.11604, Training Acc : 0.944, Run Time : 2.27
INFO:root:2019-05-11 00:45:37, Epoch : 1, Step : 7963, Training Loss : 0.09950, Training Acc : 0.983, Run Time : 7.29
INFO:root:2019-05-11 00:45:44, Epoch : 1, Step : 7964, Training Loss : 0.06275, Training Acc : 0.989, Run Time : 7.51
INFO:root:2019-05-11 00:45:45, Epoch : 1, Step : 7965, Training Loss : 0.08769, Training Acc : 0.972, Run Time : 0.55
INFO:root:2019-05-11 00:45:45, Epoch : 1, Step : 7966, Training Loss : 0.07437, Training Acc : 0.978, Run Time : 0.43
INFO:root:2019-05-11 00:45:46, Epoch : 1, Step : 7967, Training Loss : 0.09435, Training Acc : 0.983, Run Time : 0.46
INFO:root:2019-05-11 00:45:46, Epoch : 1, Step : 7968, Training Loss : 0.18032, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-11 00:45:56, Epoch : 1, Step : 7969, Training Loss : 0.18740, Training Acc : 0.944, Run Time : 10.40
INFO:root:2019-05-11 00:45:57, Epoch : 1, Step : 7970, Training Loss : 0.21249, Training Acc : 0.944, Run Time : 0.68
INFO:root:2019-05-11 00:45:58, Epoch : 1, Step : 7971, Training Loss : 0.22137, Training Acc : 0.939, Run Time : 0.47
INFO:root:2019-05-11 00:45:59, Epoch : 1, Step : 7972, Training Loss : 0.09987, Training Acc : 0.956, Run Time : 1.18
INFO:root:2019-05-11 00:46:07, Epoch : 1, Step : 7973, Training Loss : 0.16929, Training Acc : 0.933, Run Time : 8.39
INFO:root:2019-05-11 00:46:08, Epoch : 1, Step : 7974, Training Loss : 0.18847, Training Acc : 0.928, Run Time : 0.91
INFO:root:2019-05-11 00:46:09, Epoch : 1, Step : 7975, Training Loss : 0.12422, Training Acc : 0.956, Run Time : 0.46
INFO:root:2019-05-11 00:46:09, Epoch : 1, Step : 7976, Training Loss : 0.12350, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-11 00:46:18, Epoch : 1, Step : 7977, Training Loss : 0.13745, Training Acc : 0.939, Run Time : 8.74
INFO:root:2019-05-11 00:46:19, Epoch : 1, Step : 7978, Training Loss : 0.14268, Training Acc : 0.944, Run Time : 0.88
INFO:root:2019-05-11 00:46:19, Epoch : 1, Step : 7979, Training Loss : 0.06797, Training Acc : 0.978, Run Time : 0.46
INFO:root:2019-05-11 00:46:20, Epoch : 1, Step : 7980, Training Loss : 0.15377, Training Acc : 0.950, Run Time : 1.33
INFO:root:2019-05-11 00:46:27, Epoch : 1, Step : 7981, Training Loss : 0.14145, Training Acc : 0.933, Run Time : 6.64
INFO:root:2019-05-11 00:46:27, Epoch : 1, Step : 7982, Training Loss : 0.10434, Training Acc : 0.939, Run Time : 0.41
INFO:root:2019-05-11 00:46:28, Epoch : 1, Step : 7983, Training Loss : 0.21687, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-11 00:46:28, Epoch : 1, Step : 7984, Training Loss : 0.13894, Training Acc : 0.956, Run Time : 0.52
INFO:root:2019-05-11 00:46:36, Epoch : 1, Step : 7985, Training Loss : 0.14312, Training Acc : 0.928, Run Time : 7.37
INFO:root:2019-05-11 00:46:36, Epoch : 1, Step : 7986, Training Loss : 0.08130, Training Acc : 0.967, Run Time : 0.61
INFO:root:2019-05-11 00:46:40, Epoch : 1, Step : 7987, Training Loss : 0.16161, Training Acc : 0.917, Run Time : 3.84
INFO:root:2019-05-11 00:46:41, Epoch : 1, Step : 7988, Training Loss : 0.12166, Training Acc : 0.950, Run Time : 0.88
INFO:root:2019-05-11 00:46:42, Epoch : 1, Step : 7989, Training Loss : 0.13879, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-11 00:46:43, Epoch : 1, Step : 7990, Training Loss : 0.19230, Training Acc : 0.894, Run Time : 1.91
INFO:root:2019-05-11 00:46:50, Epoch : 1, Step : 7991, Training Loss : 0.16361, Training Acc : 0.906, Run Time : 6.79
INFO:root:2019-05-11 00:46:51, Epoch : 1, Step : 7992, Training Loss : 0.18853, Training Acc : 0.889, Run Time : 0.49
INFO:root:2019-05-11 00:46:51, Epoch : 1, Step : 7993, Training Loss : 0.17289, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-11 00:46:54, Epoch : 1, Step : 7994, Training Loss : 0.13526, Training Acc : 0.967, Run Time : 3.17
INFO:root:2019-05-11 00:46:56, Epoch : 1, Step : 7995, Training Loss : 0.11506, Training Acc : 0.961, Run Time : 1.99
INFO:root:2019-05-11 00:47:07, Epoch : 1, Step : 7996, Training Loss : 0.13022, Training Acc : 0.933, Run Time : 10.57
INFO:root:2019-05-11 00:47:07, Epoch : 1, Step : 7997, Training Loss : 0.14903, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-11 00:47:08, Epoch : 1, Step : 7998, Training Loss : 0.12980, Training Acc : 0.956, Run Time : 0.48
INFO:root:2019-05-11 00:47:08, Epoch : 1, Step : 7999, Training Loss : 0.14177, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-11 00:47:10, Epoch : 1, Step : 8000, Training Loss : 0.16816, Training Acc : 0.911, Run Time : 1.30
INFO:root:2019-05-11 00:47:18, Epoch : 1, Step : 8001, Training Loss : 0.26234, Training Acc : 0.889, Run Time : 7.96
INFO:root:2019-05-11 00:47:18, Epoch : 1, Step : 8002, Training Loss : 0.19110, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-11 00:47:18, Epoch : 1, Step : 8003, Training Loss : 0.14197, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-11 00:47:25, Epoch : 1, Step : 8004, Training Loss : 0.18547, Training Acc : 0.928, Run Time : 6.83
INFO:root:2019-05-11 00:47:26, Epoch : 1, Step : 8005, Training Loss : 0.15307, Training Acc : 0.928, Run Time : 0.80
INFO:root:2019-05-11 00:47:27, Epoch : 1, Step : 8006, Training Loss : 0.24328, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-11 00:47:34, Epoch : 1, Step : 8007, Training Loss : 0.17627, Training Acc : 0.911, Run Time : 7.23
INFO:root:2019-05-11 00:47:34, Epoch : 1, Step : 8008, Training Loss : 0.19012, Training Acc : 0.933, Run Time : 0.60
INFO:root:2019-05-11 00:47:35, Epoch : 1, Step : 8009, Training Loss : 0.24017, Training Acc : 0.889, Run Time : 0.40
INFO:root:2019-05-11 00:47:35, Epoch : 1, Step : 8010, Training Loss : 0.19373, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-11 00:47:44, Epoch : 1, Step : 8011, Training Loss : 0.23426, Training Acc : 0.894, Run Time : 8.48
INFO:root:2019-05-11 00:47:44, Epoch : 1, Step : 8012, Training Loss : 0.18070, Training Acc : 0.933, Run Time : 0.43
INFO:root:2019-05-11 00:47:45, Epoch : 1, Step : 8013, Training Loss : 0.19317, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-11 00:47:45, Epoch : 1, Step : 8014, Training Loss : 0.24391, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-11 00:47:54, Epoch : 1, Step : 8015, Training Loss : 0.19320, Training Acc : 0.922, Run Time : 8.84
INFO:root:2019-05-11 00:47:54, Epoch : 1, Step : 8016, Training Loss : 0.14752, Training Acc : 0.944, Run Time : 0.43
INFO:root:2019-05-11 00:47:55, Epoch : 1, Step : 8017, Training Loss : 0.17182, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-11 00:48:06, Epoch : 1, Step : 8018, Training Loss : 0.15694, Training Acc : 0.933, Run Time : 11.14
INFO:root:2019-05-11 00:48:07, Epoch : 1, Step : 8019, Training Loss : 0.14695, Training Acc : 0.928, Run Time : 1.02
INFO:root:2019-05-11 00:48:07, Epoch : 1, Step : 8020, Training Loss : 0.19729, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-11 00:48:08, Epoch : 1, Step : 8021, Training Loss : 0.14041, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-11 00:48:08, Epoch : 1, Step : 8022, Training Loss : 0.18262, Training Acc : 0.906, Run Time : 0.45
INFO:root:2019-05-11 00:48:12, Epoch : 1, Step : 8023, Training Loss : 0.25964, Training Acc : 0.872, Run Time : 4.07
INFO:root:2019-05-11 00:48:13, Epoch : 1, Step : 8024, Training Loss : 0.18561, Training Acc : 0.917, Run Time : 0.57
INFO:root:2019-05-11 00:48:25, Epoch : 1, Step : 8025, Training Loss : 0.16125, Training Acc : 0.922, Run Time : 12.14
INFO:root:2019-05-11 00:48:26, Epoch : 1, Step : 8026, Training Loss : 0.20468, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-11 00:48:26, Epoch : 1, Step : 8027, Training Loss : 0.23668, Training Acc : 0.878, Run Time : 0.49
INFO:root:2019-05-11 00:48:27, Epoch : 1, Step : 8028, Training Loss : 0.21382, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-11 00:48:36, Epoch : 1, Step : 8029, Training Loss : 0.14060, Training Acc : 0.944, Run Time : 9.68
INFO:root:2019-05-11 00:48:37, Epoch : 1, Step : 8030, Training Loss : 0.12757, Training Acc : 0.944, Run Time : 0.62
INFO:root:2019-05-11 00:48:37, Epoch : 1, Step : 8031, Training Loss : 0.24445, Training Acc : 0.900, Run Time : 0.43
INFO:root:2019-05-11 00:48:38, Epoch : 1, Step : 8032, Training Loss : 0.17796, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-11 00:48:38, Epoch : 1, Step : 8033, Training Loss : 0.16764, Training Acc : 0.911, Run Time : 0.50
INFO:root:2019-05-11 00:48:43, Epoch : 1, Step : 8034, Training Loss : 0.17773, Training Acc : 0.928, Run Time : 5.03
INFO:root:2019-05-11 00:48:45, Epoch : 1, Step : 8035, Training Loss : 0.19480, Training Acc : 0.928, Run Time : 1.31
INFO:root:2019-05-11 00:48:53, Epoch : 1, Step : 8036, Training Loss : 0.17043, Training Acc : 0.939, Run Time : 8.47
INFO:root:2019-05-11 00:48:53, Epoch : 1, Step : 8037, Training Loss : 0.21760, Training Acc : 0.911, Run Time : 0.43
INFO:root:2019-05-11 00:48:54, Epoch : 1, Step : 8038, Training Loss : 0.22146, Training Acc : 0.911, Run Time : 0.52
INFO:root:2019-05-11 00:48:54, Epoch : 1, Step : 8039, Training Loss : 0.24787, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-11 00:49:07, Epoch : 1, Step : 8040, Training Loss : 0.24442, Training Acc : 0.900, Run Time : 12.54
INFO:root:2019-05-11 00:49:07, Epoch : 1, Step : 8041, Training Loss : 0.23198, Training Acc : 0.917, Run Time : 0.22
INFO:root:2019-05-11 00:49:07, Epoch : 1, Step : 8042, Training Loss : 0.28971, Training Acc : 0.894, Run Time : 0.25
INFO:root:2019-05-11 00:49:08, Epoch : 1, Step : 8043, Training Loss : 0.34009, Training Acc : 0.839, Run Time : 0.54
INFO:root:2019-05-11 00:49:08, Epoch : 1, Step : 8044, Training Loss : 0.31010, Training Acc : 0.900, Run Time : 0.43
INFO:root:2019-05-11 00:49:20, Epoch : 1, Step : 8045, Training Loss : 0.27374, Training Acc : 0.878, Run Time : 11.05
INFO:root:2019-05-11 00:49:20, Epoch : 1, Step : 8046, Training Loss : 0.31901, Training Acc : 0.867, Run Time : 0.41
INFO:root:2019-05-11 00:49:20, Epoch : 1, Step : 8047, Training Loss : 0.28556, Training Acc : 0.900, Run Time : 0.44
INFO:root:2019-05-11 00:49:21, Epoch : 1, Step : 8048, Training Loss : 0.20619, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-11 00:49:26, Epoch : 1, Step : 8049, Training Loss : 0.20123, Training Acc : 0.911, Run Time : 4.70
INFO:root:2019-05-11 00:49:26, Epoch : 1, Step : 8050, Training Loss : 0.23276, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-11 00:49:38, Epoch : 1, Step : 8051, Training Loss : 0.25113, Training Acc : 0.906, Run Time : 12.17
INFO:root:2019-05-11 00:49:38, Epoch : 1, Step : 8052, Training Loss : 0.26958, Training Acc : 0.889, Run Time : 0.37
INFO:root:2019-05-11 00:49:39, Epoch : 1, Step : 8053, Training Loss : 0.20447, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-11 00:49:40, Epoch : 1, Step : 8054, Training Loss : 0.20929, Training Acc : 0.911, Run Time : 1.11
INFO:root:2019-05-11 00:49:40, Epoch : 1, Step : 8055, Training Loss : 0.23253, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-11 00:49:45, Epoch : 1, Step : 8056, Training Loss : 0.23561, Training Acc : 0.917, Run Time : 4.58
INFO:root:2019-05-11 00:49:46, Epoch : 1, Step : 8057, Training Loss : 0.29812, Training Acc : 0.861, Run Time : 0.93
INFO:root:2019-05-11 00:49:56, Epoch : 1, Step : 8058, Training Loss : 0.22823, Training Acc : 0.894, Run Time : 9.62
INFO:root:2019-05-11 00:49:56, Epoch : 1, Step : 8059, Training Loss : 0.21974, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-11 00:49:57, Epoch : 1, Step : 8060, Training Loss : 0.21824, Training Acc : 0.889, Run Time : 1.33
INFO:root:2019-05-11 00:50:05, Epoch : 1, Step : 8061, Training Loss : 0.20905, Training Acc : 0.900, Run Time : 7.65
INFO:root:2019-05-11 00:50:06, Epoch : 1, Step : 8062, Training Loss : 0.22445, Training Acc : 0.906, Run Time : 0.50
INFO:root:2019-05-11 00:50:06, Epoch : 1, Step : 8063, Training Loss : 0.25789, Training Acc : 0.878, Run Time : 0.43
INFO:root:2019-05-11 00:50:06, Epoch : 1, Step : 8064, Training Loss : 0.22045, Training Acc : 0.906, Run Time : 0.49
INFO:root:2019-05-11 00:50:12, Epoch : 1, Step : 8065, Training Loss : 0.22265, Training Acc : 0.906, Run Time : 5.49
INFO:root:2019-05-11 00:50:13, Epoch : 1, Step : 8066, Training Loss : 0.23684, Training Acc : 0.883, Run Time : 0.63
INFO:root:2019-05-11 00:50:13, Epoch : 1, Step : 8067, Training Loss : 0.23912, Training Acc : 0.917, Run Time : 0.48
INFO:root:2019-05-11 00:50:15, Epoch : 1, Step : 8068, Training Loss : 0.24270, Training Acc : 0.900, Run Time : 2.30
INFO:root:2019-05-11 00:50:16, Epoch : 1, Step : 8069, Training Loss : 0.20105, Training Acc : 0.928, Run Time : 0.64
INFO:root:2019-05-11 00:50:26, Epoch : 1, Step : 8070, Training Loss : 0.17179, Training Acc : 0.939, Run Time : 10.20
INFO:root:2019-05-11 00:50:27, Epoch : 1, Step : 8071, Training Loss : 0.13232, Training Acc : 0.967, Run Time : 0.41
INFO:root:2019-05-11 00:50:27, Epoch : 1, Step : 8072, Training Loss : 0.25400, Training Acc : 0.872, Run Time : 0.53
INFO:root:2019-05-11 00:50:28, Epoch : 1, Step : 8073, Training Loss : 0.21610, Training Acc : 0.928, Run Time : 0.43
INFO:root:2019-05-11 00:50:35, Epoch : 1, Step : 8074, Training Loss : 0.18757, Training Acc : 0.944, Run Time : 7.66
INFO:root:2019-05-11 00:50:36, Epoch : 1, Step : 8075, Training Loss : 0.24366, Training Acc : 0.894, Run Time : 0.70
INFO:root:2019-05-11 00:50:36, Epoch : 1, Step : 8076, Training Loss : 0.19482, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-11 00:50:41, Epoch : 1, Step : 8077, Training Loss : 0.21843, Training Acc : 0.900, Run Time : 4.92
INFO:root:2019-05-11 00:50:43, Epoch : 1, Step : 8078, Training Loss : 0.25077, Training Acc : 0.883, Run Time : 1.38
INFO:root:2019-05-11 00:50:43, Epoch : 1, Step : 8079, Training Loss : 0.18944, Training Acc : 0.911, Run Time : 0.51
INFO:root:2019-05-11 00:50:51, Epoch : 1, Step : 8080, Training Loss : 0.18565, Training Acc : 0.939, Run Time : 7.81
INFO:root:2019-05-11 00:50:51, Epoch : 1, Step : 8081, Training Loss : 0.27295, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-11 00:50:52, Epoch : 1, Step : 8082, Training Loss : 0.18021, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-11 00:50:56, Epoch : 1, Step : 8083, Training Loss : 0.17144, Training Acc : 0.917, Run Time : 4.53
INFO:root:2019-05-11 00:50:57, Epoch : 1, Step : 8084, Training Loss : 0.21380, Training Acc : 0.906, Run Time : 0.99
INFO:root:2019-05-11 00:50:58, Epoch : 1, Step : 8085, Training Loss : 0.20757, Training Acc : 0.911, Run Time : 0.80
INFO:root:2019-05-11 00:51:10, Epoch : 1, Step : 8086, Training Loss : 0.21405, Training Acc : 0.911, Run Time : 11.52
INFO:root:2019-05-11 00:51:10, Epoch : 1, Step : 8087, Training Loss : 0.23008, Training Acc : 0.911, Run Time : 0.31
INFO:root:2019-05-11 00:51:10, Epoch : 1, Step : 8088, Training Loss : 0.29621, Training Acc : 0.889, Run Time : 0.34
INFO:root:2019-05-11 00:51:11, Epoch : 1, Step : 8089, Training Loss : 0.20514, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-11 00:51:12, Epoch : 1, Step : 8090, Training Loss : 0.47647, Training Acc : 0.806, Run Time : 1.00
INFO:root:2019-05-11 00:51:15, Epoch : 1, Step : 8091, Training Loss : 0.45603, Training Acc : 0.806, Run Time : 3.58
INFO:root:2019-05-11 00:51:16, Epoch : 1, Step : 8092, Training Loss : 0.33240, Training Acc : 0.856, Run Time : 0.45
INFO:root:2019-05-11 00:51:26, Epoch : 1, Step : 8093, Training Loss : 0.32023, Training Acc : 0.844, Run Time : 10.31
INFO:root:2019-05-11 00:51:27, Epoch : 1, Step : 8094, Training Loss : 0.17826, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-11 00:51:27, Epoch : 1, Step : 8095, Training Loss : 0.20484, Training Acc : 0.922, Run Time : 0.63
INFO:root:2019-05-11 00:51:28, Epoch : 1, Step : 8096, Training Loss : 0.30602, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-11 00:51:35, Epoch : 1, Step : 8097, Training Loss : 0.25495, Training Acc : 0.883, Run Time : 7.73
INFO:root:2019-05-11 00:51:36, Epoch : 1, Step : 8098, Training Loss : 0.27207, Training Acc : 0.861, Run Time : 0.86
INFO:root:2019-05-11 00:51:44, Epoch : 1, Step : 8099, Training Loss : 0.12768, Training Acc : 0.967, Run Time : 7.45
INFO:root:2019-05-11 00:51:44, Epoch : 1, Step : 8100, Training Loss : 0.21804, Training Acc : 0.928, Run Time : 0.58
INFO:root:2019-05-11 00:51:50, Epoch : 1, Step : 8101, Training Loss : 0.24907, Training Acc : 0.917, Run Time : 6.07
INFO:root:2019-05-11 00:51:51, Epoch : 1, Step : 8102, Training Loss : 0.18581, Training Acc : 0.939, Run Time : 0.60
INFO:root:2019-05-11 00:51:51, Epoch : 1, Step : 8103, Training Loss : 0.17719, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-11 00:51:52, Epoch : 1, Step : 8104, Training Loss : 0.30298, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-11 00:51:52, Epoch : 1, Step : 8105, Training Loss : 0.28789, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-11 00:51:56, Epoch : 1, Step : 8106, Training Loss : 0.26539, Training Acc : 0.900, Run Time : 3.94
INFO:root:2019-05-11 00:51:57, Epoch : 1, Step : 8107, Training Loss : 0.31001, Training Acc : 0.900, Run Time : 0.40
INFO:root:2019-05-11 00:52:08, Epoch : 1, Step : 8108, Training Loss : 0.22607, Training Acc : 0.889, Run Time : 10.94
INFO:root:2019-05-11 00:52:08, Epoch : 1, Step : 8109, Training Loss : 0.15758, Training Acc : 0.939, Run Time : 0.57
INFO:root:2019-05-11 00:52:09, Epoch : 1, Step : 8110, Training Loss : 0.21890, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-11 00:52:09, Epoch : 1, Step : 8111, Training Loss : 0.22316, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-11 00:52:12, Epoch : 1, Step : 8112, Training Loss : 0.24959, Training Acc : 0.906, Run Time : 3.18
INFO:root:2019-05-11 00:52:13, Epoch : 1, Step : 8113, Training Loss : 0.25687, Training Acc : 0.872, Run Time : 1.02
INFO:root:2019-05-11 00:52:16, Epoch : 1, Step : 8114, Training Loss : 0.23305, Training Acc : 0.911, Run Time : 3.18
INFO:root:2019-05-11 00:52:26, Epoch : 1, Step : 8115, Training Loss : 0.20899, Training Acc : 0.917, Run Time : 9.18
INFO:root:2019-05-11 00:52:26, Epoch : 1, Step : 8116, Training Loss : 0.21471, Training Acc : 0.906, Run Time : 0.44
INFO:root:2019-05-11 00:52:27, Epoch : 1, Step : 8117, Training Loss : 0.24489, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-11 00:52:34, Epoch : 1, Step : 8118, Training Loss : 0.19886, Training Acc : 0.900, Run Time : 7.86
INFO:root:2019-05-11 00:52:35, Epoch : 1, Step : 8119, Training Loss : 0.13761, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-11 00:52:35, Epoch : 1, Step : 8120, Training Loss : 0.16540, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-11 00:52:36, Epoch : 1, Step : 8121, Training Loss : 0.20338, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-11 00:52:43, Epoch : 1, Step : 8122, Training Loss : 0.19837, Training Acc : 0.900, Run Time : 7.08
INFO:root:2019-05-11 00:52:43, Epoch : 1, Step : 8123, Training Loss : 0.22285, Training Acc : 0.917, Run Time : 0.52
INFO:root:2019-05-11 00:52:44, Epoch : 1, Step : 8124, Training Loss : 0.29383, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-11 00:52:52, Epoch : 1, Step : 8125, Training Loss : 0.20430, Training Acc : 0.900, Run Time : 8.37
INFO:root:2019-05-11 00:52:53, Epoch : 1, Step : 8126, Training Loss : 0.23130, Training Acc : 0.878, Run Time : 0.88
INFO:root:2019-05-11 00:53:01, Epoch : 1, Step : 8127, Training Loss : 0.22345, Training Acc : 0.872, Run Time : 7.64
INFO:root:2019-05-11 00:53:01, Epoch : 1, Step : 8128, Training Loss : 0.27268, Training Acc : 0.861, Run Time : 0.50
INFO:root:2019-05-11 00:53:02, Epoch : 1, Step : 8129, Training Loss : 0.20012, Training Acc : 0.900, Run Time : 0.48
INFO:root:2019-05-11 00:53:02, Epoch : 1, Step : 8130, Training Loss : 0.21782, Training Acc : 0.911, Run Time : 0.49
INFO:root:2019-05-11 00:53:03, Epoch : 1, Step : 8131, Training Loss : 0.22492, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-11 00:53:13, Epoch : 1, Step : 8132, Training Loss : 0.26783, Training Acc : 0.861, Run Time : 10.38
INFO:root:2019-05-11 00:53:14, Epoch : 1, Step : 8133, Training Loss : 0.19604, Training Acc : 0.889, Run Time : 0.52
INFO:root:2019-05-11 00:53:14, Epoch : 1, Step : 8134, Training Loss : 0.24160, Training Acc : 0.878, Run Time : 0.46
INFO:root:2019-05-11 00:53:15, Epoch : 1, Step : 8135, Training Loss : 0.34868, Training Acc : 0.806, Run Time : 0.45
INFO:root:2019-05-11 00:53:22, Epoch : 1, Step : 8136, Training Loss : 0.43714, Training Acc : 0.789, Run Time : 7.15
INFO:root:2019-05-11 00:53:22, Epoch : 1, Step : 8137, Training Loss : 0.32865, Training Acc : 0.822, Run Time : 0.45
INFO:root:2019-05-11 00:53:23, Epoch : 1, Step : 8138, Training Loss : 0.30034, Training Acc : 0.828, Run Time : 0.48
INFO:root:2019-05-11 00:53:23, Epoch : 1, Step : 8139, Training Loss : 0.19164, Training Acc : 0.883, Run Time : 0.78
INFO:root:2019-05-11 00:53:34, Epoch : 1, Step : 8140, Training Loss : 0.18575, Training Acc : 0.894, Run Time : 10.16
INFO:root:2019-05-11 00:53:34, Epoch : 1, Step : 8141, Training Loss : 0.24920, Training Acc : 0.872, Run Time : 0.69
INFO:root:2019-05-11 00:53:40, Epoch : 1, Step : 8142, Training Loss : 0.14955, Training Acc : 0.944, Run Time : 5.68
INFO:root:2019-05-11 00:53:41, Epoch : 1, Step : 8143, Training Loss : 0.19108, Training Acc : 0.928, Run Time : 0.77
INFO:root:2019-05-11 00:53:41, Epoch : 1, Step : 8144, Training Loss : 0.22655, Training Acc : 0.906, Run Time : 0.43
INFO:root:2019-05-11 00:53:42, Epoch : 1, Step : 8145, Training Loss : 0.26241, Training Acc : 0.867, Run Time : 0.45
INFO:root:2019-05-11 00:53:42, Epoch : 1, Step : 8146, Training Loss : 0.23145, Training Acc : 0.900, Run Time : 0.51
INFO:root:2019-05-11 00:53:55, Epoch : 1, Step : 8147, Training Loss : 0.17976, Training Acc : 0.928, Run Time : 12.62
INFO:root:2019-05-11 00:53:55, Epoch : 1, Step : 8148, Training Loss : 0.13422, Training Acc : 0.956, Run Time : 0.33
INFO:root:2019-05-11 00:53:56, Epoch : 1, Step : 8149, Training Loss : 0.21648, Training Acc : 0.894, Run Time : 0.51
INFO:root:2019-05-11 00:53:56, Epoch : 1, Step : 8150, Training Loss : 0.19267, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-11 00:53:56, Epoch : 1, Step : 8151, Training Loss : 0.19962, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-11 00:54:07, Epoch : 1, Step : 8152, Training Loss : 0.24258, Training Acc : 0.878, Run Time : 10.90
INFO:root:2019-05-11 00:54:08, Epoch : 1, Step : 8153, Training Loss : 0.18612, Training Acc : 0.928, Run Time : 0.44
INFO:root:2019-05-11 00:54:08, Epoch : 1, Step : 8154, Training Loss : 0.28876, Training Acc : 0.844, Run Time : 0.46
INFO:root:2019-05-11 00:54:09, Epoch : 1, Step : 8155, Training Loss : 0.24129, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-11 00:54:10, Epoch : 1, Step : 8156, Training Loss : 0.30086, Training Acc : 0.850, Run Time : 0.87
INFO:root:2019-05-11 00:54:14, Epoch : 1, Step : 8157, Training Loss : 0.19403, Training Acc : 0.917, Run Time : 4.41
INFO:root:2019-05-11 00:54:14, Epoch : 1, Step : 8158, Training Loss : 0.25009, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-11 00:54:25, Epoch : 1, Step : 8159, Training Loss : 0.23314, Training Acc : 0.889, Run Time : 10.57
INFO:root:2019-05-11 00:54:25, Epoch : 1, Step : 8160, Training Loss : 0.19653, Training Acc : 0.917, Run Time : 0.34
INFO:root:2019-05-11 00:54:26, Epoch : 1, Step : 8161, Training Loss : 0.10858, Training Acc : 0.972, Run Time : 0.46
INFO:root:2019-05-11 00:54:26, Epoch : 1, Step : 8162, Training Loss : 0.11294, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-11 00:54:33, Epoch : 1, Step : 8163, Training Loss : 0.12336, Training Acc : 0.961, Run Time : 7.15
INFO:root:2019-05-11 00:54:34, Epoch : 1, Step : 8164, Training Loss : 0.08851, Training Acc : 0.972, Run Time : 0.42
INFO:root:2019-05-11 00:54:34, Epoch : 1, Step : 8165, Training Loss : 0.11711, Training Acc : 0.956, Run Time : 0.40
INFO:root:2019-05-11 00:54:41, Epoch : 1, Step : 8166, Training Loss : 0.08106, Training Acc : 0.961, Run Time : 6.92
INFO:root:2019-05-11 00:54:42, Epoch : 1, Step : 8167, Training Loss : 0.18436, Training Acc : 0.911, Run Time : 0.70
INFO:root:2019-05-11 00:54:42, Epoch : 1, Step : 8168, Training Loss : 0.11241, Training Acc : 0.956, Run Time : 0.46
INFO:root:2019-05-11 00:54:43, Epoch : 1, Step : 8169, Training Loss : 0.14030, Training Acc : 0.939, Run Time : 0.49
INFO:root:2019-05-11 00:54:55, Epoch : 1, Step : 8170, Training Loss : 0.15679, Training Acc : 0.922, Run Time : 11.73
INFO:root:2019-05-11 00:54:55, Epoch : 1, Step : 8171, Training Loss : 0.11600, Training Acc : 0.944, Run Time : 0.33
INFO:root:2019-05-11 00:54:55, Epoch : 1, Step : 8172, Training Loss : 0.12254, Training Acc : 0.956, Run Time : 0.44
INFO:root:2019-05-11 00:54:56, Epoch : 1, Step : 8173, Training Loss : 0.14862, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-11 00:54:56, Epoch : 1, Step : 8174, Training Loss : 0.20388, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-11 00:55:09, Epoch : 1, Step : 8175, Training Loss : 0.09941, Training Acc : 0.972, Run Time : 12.48
INFO:root:2019-05-11 00:55:09, Epoch : 1, Step : 8176, Training Loss : 0.18051, Training Acc : 0.939, Run Time : 0.30
INFO:root:2019-05-11 00:55:09, Epoch : 1, Step : 8177, Training Loss : 0.09397, Training Acc : 0.961, Run Time : 0.44
INFO:root:2019-05-11 00:55:10, Epoch : 1, Step : 8178, Training Loss : 0.15644, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-11 00:55:11, Epoch : 1, Step : 8179, Training Loss : 0.14576, Training Acc : 0.922, Run Time : 0.69
INFO:root:2019-05-11 00:55:15, Epoch : 1, Step : 8180, Training Loss : 0.14785, Training Acc : 0.933, Run Time : 4.05
INFO:root:2019-05-11 00:55:15, Epoch : 1, Step : 8181, Training Loss : 0.13863, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-11 00:55:29, Epoch : 1, Step : 8182, Training Loss : 0.12948, Training Acc : 0.950, Run Time : 13.35
INFO:root:2019-05-11 00:55:29, Epoch : 1, Step : 8183, Training Loss : 0.08597, Training Acc : 0.967, Run Time : 0.27
INFO:root:2019-05-11 00:55:29, Epoch : 1, Step : 8184, Training Loss : 0.10091, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-11 00:55:30, Epoch : 1, Step : 8185, Training Loss : 0.09496, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-11 00:55:30, Epoch : 1, Step : 8186, Training Loss : 0.09740, Training Acc : 0.956, Run Time : 0.48
INFO:root:2019-05-11 00:55:41, Epoch : 1, Step : 8187, Training Loss : 0.07196, Training Acc : 0.967, Run Time : 11.21
INFO:root:2019-05-11 00:55:43, Epoch : 1, Step : 8188, Training Loss : 0.09915, Training Acc : 0.956, Run Time : 1.59
INFO:root:2019-05-11 00:55:43, Epoch : 1, Step : 8189, Training Loss : 0.18572, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-11 00:55:44, Epoch : 1, Step : 8190, Training Loss : 0.15363, Training Acc : 0.933, Run Time : 0.65
INFO:root:2019-05-11 00:55:45, Epoch : 1, Step : 8191, Training Loss : 0.18821, Training Acc : 0.917, Run Time : 0.54
INFO:root:2019-05-11 00:55:45, Epoch : 1, Step : 8192, Training Loss : 0.23311, Training Acc : 0.906, Run Time : 0.72
INFO:root:2019-05-11 00:55:54, Epoch : 1, Step : 8193, Training Loss : 0.44653, Training Acc : 0.839, Run Time : 8.72
INFO:root:2019-05-11 00:55:55, Epoch : 1, Step : 8194, Training Loss : 0.39433, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-11 00:55:55, Epoch : 1, Step : 8195, Training Loss : 0.34471, Training Acc : 0.922, Run Time : 0.44
INFO:root:2019-05-11 00:56:00, Epoch : 1, Step : 8196, Training Loss : 0.21429, Training Acc : 0.939, Run Time : 4.80
INFO:root:2019-05-11 00:56:00, Epoch : 1, Step : 8197, Training Loss : 0.26723, Training Acc : 0.900, Run Time : 0.65
INFO:root:2019-05-11 00:56:01, Epoch : 1, Step : 8198, Training Loss : 0.30612, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-11 00:56:05, Epoch : 1, Step : 8199, Training Loss : 0.14223, Training Acc : 0.933, Run Time : 3.70
INFO:root:2019-05-11 00:56:05, Epoch : 1, Step : 8200, Training Loss : 0.21389, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-11 00:56:19, Epoch : 1, Step : 8201, Training Loss : 0.27307, Training Acc : 0.878, Run Time : 13.53
INFO:root:2019-05-11 00:56:19, Epoch : 1, Step : 8202, Training Loss : 0.53156, Training Acc : 0.822, Run Time : 0.22
INFO:root:2019-05-11 00:56:19, Epoch : 1, Step : 8203, Training Loss : 0.64791, Training Acc : 0.744, Run Time : 0.45
INFO:root:2019-05-11 00:56:20, Epoch : 1, Step : 8204, Training Loss : 0.62074, Training Acc : 0.750, Run Time : 0.47
INFO:root:2019-05-11 00:56:20, Epoch : 1, Step : 8205, Training Loss : 0.59126, Training Acc : 0.761, Run Time : 0.46
INFO:root:2019-05-11 00:56:30, Epoch : 1, Step : 8206, Training Loss : 0.36288, Training Acc : 0.828, Run Time : 10.05
INFO:root:2019-05-11 00:56:31, Epoch : 1, Step : 8207, Training Loss : 0.64090, Training Acc : 0.756, Run Time : 0.45
INFO:root:2019-05-11 00:56:31, Epoch : 1, Step : 8208, Training Loss : 0.30162, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-11 00:56:32, Epoch : 1, Step : 8209, Training Loss : 0.49063, Training Acc : 0.856, Run Time : 0.44
INFO:root:2019-05-11 00:56:33, Epoch : 1, Step : 8210, Training Loss : 0.21474, Training Acc : 0.933, Run Time : 1.75
INFO:root:2019-05-11 00:56:39, Epoch : 1, Step : 8211, Training Loss : 0.30573, Training Acc : 0.844, Run Time : 5.52
INFO:root:2019-05-11 00:56:39, Epoch : 1, Step : 8212, Training Loss : 0.31946, Training Acc : 0.844, Run Time : 0.49
INFO:root:2019-05-11 00:56:41, Epoch : 1, Step : 8213, Training Loss : 0.25992, Training Acc : 0.878, Run Time : 1.96
INFO:root:2019-05-11 00:56:43, Epoch : 1, Step : 8214, Training Loss : 0.29145, Training Acc : 0.850, Run Time : 1.99
INFO:root:2019-05-11 00:56:54, Epoch : 1, Step : 8215, Training Loss : 0.20233, Training Acc : 0.906, Run Time : 10.53
INFO:root:2019-05-11 00:56:54, Epoch : 1, Step : 8216, Training Loss : 0.30659, Training Acc : 0.878, Run Time : 0.51
INFO:root:2019-05-11 00:56:55, Epoch : 1, Step : 8217, Training Loss : 0.27724, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-11 00:56:55, Epoch : 1, Step : 8218, Training Loss : 0.22221, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-11 00:56:57, Epoch : 1, Step : 8219, Training Loss : 0.24199, Training Acc : 0.922, Run Time : 1.47
INFO:root:2019-05-11 00:57:03, Epoch : 1, Step : 8220, Training Loss : 0.27856, Training Acc : 0.878, Run Time : 6.49
INFO:root:2019-05-11 00:57:04, Epoch : 1, Step : 8221, Training Loss : 0.34635, Training Acc : 0.833, Run Time : 0.45
INFO:root:2019-05-11 00:57:04, Epoch : 1, Step : 8222, Training Loss : 0.35854, Training Acc : 0.839, Run Time : 0.65
INFO:root:2019-05-11 00:57:11, Epoch : 1, Step : 8223, Training Loss : 0.21075, Training Acc : 0.911, Run Time : 6.95
INFO:root:2019-05-11 00:57:12, Epoch : 1, Step : 8224, Training Loss : 0.16445, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-11 00:57:12, Epoch : 1, Step : 8225, Training Loss : 0.14742, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-11 00:57:21, Epoch : 1, Step : 8226, Training Loss : 0.33378, Training Acc : 0.922, Run Time : 8.36
INFO:root:2019-05-11 00:57:21, Epoch : 1, Step : 8227, Training Loss : 0.09288, Training Acc : 0.961, Run Time : 0.42
INFO:root:2019-05-11 00:57:21, Epoch : 1, Step : 8228, Training Loss : 0.14942, Training Acc : 0.961, Run Time : 0.43
INFO:root:2019-05-11 00:57:22, Epoch : 1, Step : 8229, Training Loss : 0.12606, Training Acc : 0.967, Run Time : 0.45
INFO:root:2019-05-11 00:57:23, Epoch : 1, Step : 8230, Training Loss : 0.10432, Training Acc : 0.978, Run Time : 1.41
INFO:root:2019-05-11 00:57:27, Epoch : 1, Step : 8231, Training Loss : 0.09912, Training Acc : 0.972, Run Time : 3.55
INFO:root:2019-05-11 00:57:38, Epoch : 1, Step : 8232, Training Loss : 0.05404, Training Acc : 0.978, Run Time : 11.19
INFO:root:2019-05-11 00:57:38, Epoch : 1, Step : 8233, Training Loss : 0.11259, Training Acc : 0.972, Run Time : 0.21
INFO:root:2019-05-11 00:57:38, Epoch : 1, Step : 8234, Training Loss : 0.08316, Training Acc : 0.989, Run Time : 0.22
INFO:root:2019-05-11 00:57:39, Epoch : 1, Step : 8235, Training Loss : 0.08619, Training Acc : 0.983, Run Time : 0.44
INFO:root:2019-05-11 00:57:39, Epoch : 1, Step : 8236, Training Loss : 0.08056, Training Acc : 0.978, Run Time : 0.49
INFO:root:2019-05-11 00:57:48, Epoch : 1, Step : 8237, Training Loss : 0.08211, Training Acc : 0.989, Run Time : 8.50
INFO:root:2019-05-11 00:57:49, Epoch : 1, Step : 8238, Training Loss : 0.05607, Training Acc : 0.994, Run Time : 0.92
INFO:root:2019-05-11 00:57:49, Epoch : 1, Step : 8239, Training Loss : 0.08292, Training Acc : 0.983, Run Time : 0.56
INFO:root:2019-05-11 00:57:50, Epoch : 1, Step : 8240, Training Loss : 0.08472, Training Acc : 0.972, Run Time : 0.50
INFO:root:2019-05-11 00:58:00, Epoch : 1, Step : 8241, Training Loss : 0.13635, Training Acc : 0.944, Run Time : 10.27
INFO:root:2019-05-11 00:58:00, Epoch : 1, Step : 8242, Training Loss : 0.21134, Training Acc : 0.900, Run Time : 0.30
INFO:root:2019-05-11 00:58:01, Epoch : 1, Step : 8243, Training Loss : 0.07339, Training Acc : 0.972, Run Time : 0.47
INFO:root:2019-05-11 00:58:01, Epoch : 1, Step : 8244, Training Loss : 0.08628, Training Acc : 0.961, Run Time : 0.45
INFO:root:2019-05-11 00:58:02, Epoch : 1, Step : 8245, Training Loss : 0.16165, Training Acc : 0.950, Run Time : 0.44
INFO:root:2019-05-11 00:58:09, Epoch : 1, Step : 8246, Training Loss : 0.07150, Training Acc : 0.983, Run Time : 7.19
INFO:root:2019-05-11 00:58:10, Epoch : 1, Step : 8247, Training Loss : 0.03723, Training Acc : 1.000, Run Time : 1.06
INFO:root:2019-05-11 00:58:11, Epoch : 1, Step : 8248, Training Loss : 0.05815, Training Acc : 0.978, Run Time : 0.47
INFO:root:2019-05-11 00:58:11, Epoch : 1, Step : 8249, Training Loss : 0.18797, Training Acc : 0.917, Run Time : 0.51
INFO:root:2019-05-11 00:58:27, Epoch : 1, Step : 8250, Training Loss : 0.14100, Training Acc : 0.944, Run Time : 15.70
INFO:root:2019-05-11 00:58:27, Epoch : 1, Step : 8251, Training Loss : 0.09575, Training Acc : 0.972, Run Time : 0.26
INFO:root:2019-05-11 00:58:27, Epoch : 1, Step : 8252, Training Loss : 0.12254, Training Acc : 0.972, Run Time : 0.35
INFO:root:2019-05-11 00:58:28, Epoch : 1, Step : 8253, Training Loss : 0.09309, Training Acc : 0.978, Run Time : 0.44
INFO:root:2019-05-11 00:58:28, Epoch : 1, Step : 8254, Training Loss : 0.06250, Training Acc : 0.994, Run Time : 0.51
INFO:root:2019-05-11 00:58:40, Epoch : 1, Step : 8255, Training Loss : 0.13352, Training Acc : 0.956, Run Time : 11.48
INFO:root:2019-05-11 00:58:41, Epoch : 1, Step : 8256, Training Loss : 0.09929, Training Acc : 0.967, Run Time : 0.75
INFO:root:2019-05-11 00:58:41, Epoch : 1, Step : 8257, Training Loss : 0.10504, Training Acc : 0.972, Run Time : 0.41
INFO:root:2019-05-11 00:58:41, Epoch : 1, Step : 8258, Training Loss : 0.07030, Training Acc : 0.978, Run Time : 0.47
INFO:root:2019-05-11 00:58:42, Epoch : 1, Step : 8259, Training Loss : 0.09562, Training Acc : 0.978, Run Time : 0.45
INFO:root:2019-05-11 00:58:51, Epoch : 1, Step : 8260, Training Loss : 0.06673, Training Acc : 0.983, Run Time : 8.73
INFO:root:2019-05-11 00:58:51, Epoch : 1, Step : 8261, Training Loss : 0.10663, Training Acc : 0.956, Run Time : 0.43
INFO:root:2019-05-11 00:58:52, Epoch : 1, Step : 8262, Training Loss : 0.12950, Training Acc : 0.944, Run Time : 0.49
INFO:root:2019-05-11 00:58:52, Epoch : 1, Step : 8263, Training Loss : 0.10403, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-11 00:58:56, Epoch : 1, Step : 8264, Training Loss : 0.13125, Training Acc : 0.933, Run Time : 3.62
INFO:root:2019-05-11 00:58:56, Epoch : 1, Step : 8265, Training Loss : 0.12915, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-11 00:59:10, Epoch : 1, Step : 8266, Training Loss : 0.12193, Training Acc : 0.956, Run Time : 14.25
INFO:root:2019-05-11 00:59:11, Epoch : 1, Step : 8267, Training Loss : 0.04588, Training Acc : 0.989, Run Time : 0.53
INFO:root:2019-05-11 00:59:11, Epoch : 1, Step : 8268, Training Loss : 0.06862, Training Acc : 0.978, Run Time : 0.55
INFO:root:2019-05-11 00:59:12, Epoch : 1, Step : 8269, Training Loss : 0.09671, Training Acc : 0.961, Run Time : 0.45
INFO:root:2019-05-11 00:59:19, Epoch : 1, Step : 8270, Training Loss : 0.19437, Training Acc : 0.933, Run Time : 7.13
INFO:root:2019-05-11 00:59:20, Epoch : 1, Step : 8271, Training Loss : 0.08931, Training Acc : 0.972, Run Time : 0.77
INFO:root:2019-05-11 00:59:20, Epoch : 1, Step : 8272, Training Loss : 0.04518, Training Acc : 1.000, Run Time : 0.46
INFO:root:2019-05-11 00:59:21, Epoch : 1, Step : 8273, Training Loss : 0.12730, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-11 00:59:24, Epoch : 1, Step : 8274, Training Loss : 0.10713, Training Acc : 0.978, Run Time : 3.78
INFO:root:2019-05-11 00:59:29, Epoch : 1, Step : 8275, Training Loss : 0.08999, Training Acc : 0.967, Run Time : 4.79
INFO:root:2019-05-11 00:59:30, Epoch : 1, Step : 8276, Training Loss : 0.14908, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-11 00:59:30, Epoch : 1, Step : 8277, Training Loss : 0.14833, Training Acc : 0.944, Run Time : 0.63
INFO:root:2019-05-11 00:59:36, Epoch : 1, Step : 8278, Training Loss : 0.10020, Training Acc : 0.967, Run Time : 5.27
INFO:root:2019-05-11 00:59:37, Epoch : 1, Step : 8279, Training Loss : 0.17083, Training Acc : 0.917, Run Time : 1.35
INFO:root:2019-05-11 00:59:40, Epoch : 1, Step : 8280, Training Loss : 0.08851, Training Acc : 0.967, Run Time : 3.27
INFO:root:2019-05-11 00:59:41, Epoch : 1, Step : 8281, Training Loss : 0.11597, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-11 00:59:43, Epoch : 1, Step : 8282, Training Loss : 0.11880, Training Acc : 0.967, Run Time : 2.21
INFO:root:2019-05-11 00:59:52, Epoch : 1, Step : 8283, Training Loss : 0.23619, Training Acc : 0.922, Run Time : 9.32
INFO:root:2019-05-11 00:59:53, Epoch : 1, Step : 8284, Training Loss : 0.17110, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-11 00:59:53, Epoch : 1, Step : 8285, Training Loss : 0.16470, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-11 00:59:54, Epoch : 1, Step : 8286, Training Loss : 0.17740, Training Acc : 0.939, Run Time : 0.88
INFO:root:2019-05-11 00:59:55, Epoch : 1, Step : 8287, Training Loss : 0.17813, Training Acc : 0.922, Run Time : 0.86
INFO:root:2019-05-11 01:00:02, Epoch : 1, Step : 8288, Training Loss : 0.13137, Training Acc : 0.950, Run Time : 7.11
INFO:root:2019-05-11 01:00:02, Epoch : 1, Step : 8289, Training Loss : 0.13215, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-11 01:00:03, Epoch : 1, Step : 8290, Training Loss : 0.19197, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-11 01:00:04, Epoch : 1, Step : 8291, Training Loss : 0.17243, Training Acc : 0.922, Run Time : 1.43
INFO:root:2019-05-11 01:00:14, Epoch : 1, Step : 8292, Training Loss : 0.16382, Training Acc : 0.944, Run Time : 9.78
INFO:root:2019-05-11 01:00:15, Epoch : 1, Step : 8293, Training Loss : 0.15160, Training Acc : 0.961, Run Time : 0.44
INFO:root:2019-05-11 01:00:16, Epoch : 1, Step : 8294, Training Loss : 0.16617, Training Acc : 0.933, Run Time : 1.14
INFO:root:2019-05-11 01:00:16, Epoch : 1, Step : 8295, Training Loss : 0.19752, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-11 01:00:17, Epoch : 1, Step : 8296, Training Loss : 0.15695, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-11 01:00:24, Epoch : 1, Step : 8297, Training Loss : 0.06767, Training Acc : 0.989, Run Time : 7.59
INFO:root:2019-05-11 01:00:25, Epoch : 1, Step : 8298, Training Loss : 0.10980, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-11 01:00:25, Epoch : 1, Step : 8299, Training Loss : 0.15005, Training Acc : 0.933, Run Time : 0.45
INFO:root:2019-05-11 01:00:32, Epoch : 1, Step : 8300, Training Loss : 0.11739, Training Acc : 0.961, Run Time : 6.56
INFO:root:2019-05-11 01:00:33, Epoch : 1, Step : 8301, Training Loss : 0.19001, Training Acc : 0.933, Run Time : 0.85
INFO:root:2019-05-11 01:00:33, Epoch : 1, Step : 8302, Training Loss : 0.21902, Training Acc : 0.917, Run Time : 0.48
INFO:root:2019-05-11 01:00:36, Epoch : 1, Step : 8303, Training Loss : 0.07095, Training Acc : 0.989, Run Time : 2.58
INFO:root:2019-05-11 01:00:36, Epoch : 1, Step : 8304, Training Loss : 0.10911, Training Acc : 0.944, Run Time : 0.63
INFO:root:2019-05-11 01:00:48, Epoch : 1, Step : 8305, Training Loss : 0.17185, Training Acc : 0.944, Run Time : 11.88
INFO:root:2019-05-11 01:00:48, Epoch : 1, Step : 8306, Training Loss : 0.12830, Training Acc : 0.944, Run Time : 0.24
INFO:root:2019-05-11 01:00:49, Epoch : 1, Step : 8307, Training Loss : 0.04346, Training Acc : 0.994, Run Time : 0.44
INFO:root:2019-05-11 01:00:49, Epoch : 1, Step : 8308, Training Loss : 0.25659, Training Acc : 0.883, Run Time : 0.42
INFO:root:2019-05-11 01:00:50, Epoch : 1, Step : 8309, Training Loss : 0.09031, Training Acc : 0.967, Run Time : 0.45
INFO:root:2019-05-11 01:00:54, Epoch : 1, Step : 8310, Training Loss : 0.20136, Training Acc : 0.922, Run Time : 4.84
INFO:root:2019-05-11 01:00:55, Epoch : 1, Step : 8311, Training Loss : 0.23187, Training Acc : 0.956, Run Time : 0.35
INFO:root:2019-05-11 01:01:05, Epoch : 1, Step : 8312, Training Loss : 0.08029, Training Acc : 0.978, Run Time : 10.06
INFO:root:2019-05-11 01:01:05, Epoch : 1, Step : 8313, Training Loss : 0.09780, Training Acc : 0.956, Run Time : 0.40
INFO:root:2019-05-11 01:01:06, Epoch : 1, Step : 8314, Training Loss : 0.07138, Training Acc : 0.978, Run Time : 0.45
INFO:root:2019-05-11 01:01:06, Epoch : 1, Step : 8315, Training Loss : 0.07720, Training Acc : 0.967, Run Time : 0.48
INFO:root:2019-05-11 01:01:15, Epoch : 1, Step : 8316, Training Loss : 0.06317, Training Acc : 0.983, Run Time : 8.66
INFO:root:2019-05-11 01:01:15, Epoch : 1, Step : 8317, Training Loss : 0.14342, Training Acc : 0.928, Run Time : 0.43
INFO:root:2019-05-11 01:01:18, Epoch : 1, Step : 8318, Training Loss : 0.12017, Training Acc : 0.939, Run Time : 2.36
INFO:root:2019-05-11 01:01:26, Epoch : 1, Step : 8319, Training Loss : 0.05226, Training Acc : 0.994, Run Time : 7.95
INFO:root:2019-05-11 01:01:26, Epoch : 1, Step : 8320, Training Loss : 0.10318, Training Acc : 0.972, Run Time : 0.50
INFO:root:2019-05-11 01:01:28, Epoch : 1, Step : 8321, Training Loss : 0.08124, Training Acc : 0.978, Run Time : 1.57
INFO:root:2019-05-11 01:01:34, Epoch : 1, Step : 8322, Training Loss : 0.07228, Training Acc : 0.978, Run Time : 6.39
INFO:root:2019-05-11 01:01:34, Epoch : 1, Step : 8323, Training Loss : 0.05404, Training Acc : 0.989, Run Time : 0.39
INFO:root:2019-05-11 01:01:35, Epoch : 1, Step : 8324, Training Loss : 0.04091, Training Acc : 0.989, Run Time : 0.46
INFO:root:2019-05-11 01:01:43, Epoch : 1, Step : 8325, Training Loss : 0.02456, Training Acc : 1.000, Run Time : 7.67
INFO:root:2019-05-11 01:01:43, Epoch : 1, Step : 8326, Training Loss : 0.02205, Training Acc : 1.000, Run Time : 0.62
INFO:root:2019-05-11 01:01:44, Epoch : 1, Step : 8327, Training Loss : 0.02728, Training Acc : 1.000, Run Time : 0.46
INFO:root:2019-05-11 01:01:44, Epoch : 1, Step : 8328, Training Loss : 0.06715, Training Acc : 0.983, Run Time : 0.48
INFO:root:2019-05-11 01:01:45, Epoch : 1, Step : 8329, Training Loss : 0.03184, Training Acc : 0.994, Run Time : 0.48
INFO:root:2019-05-11 01:01:55, Epoch : 1, Step : 8330, Training Loss : 0.05865, Training Acc : 0.967, Run Time : 10.08
INFO:root:2019-05-11 01:01:55, Epoch : 1, Step : 8331, Training Loss : 0.04126, Training Acc : 0.989, Run Time : 0.47
INFO:root:2019-05-11 01:01:56, Epoch : 1, Step : 8332, Training Loss : 0.06841, Training Acc : 0.983, Run Time : 0.50
INFO:root:2019-05-11 01:01:56, Epoch : 1, Step : 8333, Training Loss : 0.07232, Training Acc : 0.983, Run Time : 0.45
INFO:root:2019-05-11 01:02:04, Epoch : 1, Step : 8334, Training Loss : 0.14908, Training Acc : 0.944, Run Time : 7.90
INFO:root:2019-05-11 01:02:05, Epoch : 1, Step : 8335, Training Loss : 0.06234, Training Acc : 0.983, Run Time : 0.48
INFO:root:2019-05-11 01:02:05, Epoch : 1, Step : 8336, Training Loss : 0.05221, Training Acc : 0.983, Run Time : 0.38
INFO:root:2019-05-11 01:02:05, Epoch : 1, Step : 8337, Training Loss : 0.03357, Training Acc : 0.989, Run Time : 0.38
INFO:root:2019-05-11 01:02:13, Epoch : 1, Step : 8338, Training Loss : 0.03374, Training Acc : 0.994, Run Time : 8.14
INFO:root:2019-05-11 01:02:14, Epoch : 1, Step : 8339, Training Loss : 0.04089, Training Acc : 0.994, Run Time : 0.47
INFO:root:2019-05-11 01:02:14, Epoch : 1, Step : 8340, Training Loss : 0.05806, Training Acc : 0.983, Run Time : 0.47
INFO:root:2019-05-11 01:02:15, Epoch : 1, Step : 8341, Training Loss : 0.03602, Training Acc : 0.989, Run Time : 0.53
INFO:root:2019-05-11 01:02:26, Epoch : 1, Step : 8342, Training Loss : 0.08036, Training Acc : 0.972, Run Time : 10.72
INFO:root:2019-05-11 01:02:26, Epoch : 1, Step : 8343, Training Loss : 0.05757, Training Acc : 0.978, Run Time : 0.46
INFO:root:2019-05-11 01:02:27, Epoch : 1, Step : 8344, Training Loss : 0.04345, Training Acc : 0.983, Run Time : 0.47
INFO:root:2019-05-11 01:02:31, Epoch : 1, Step : 8345, Training Loss : 0.02483, Training Acc : 1.000, Run Time : 4.58
INFO:root:2019-05-11 01:02:32, Epoch : 1, Step : 8346, Training Loss : 0.09848, Training Acc : 0.967, Run Time : 0.54
INFO:root:2019-05-11 01:02:32, Epoch : 1, Step : 8347, Training Loss : 0.02674, Training Acc : 0.994, Run Time : 0.49
INFO:root:2019-05-11 01:02:33, Epoch : 1, Step : 8348, Training Loss : 0.05413, Training Acc : 0.978, Run Time : 1.25
INFO:root:2019-05-11 01:02:43, Epoch : 1, Step : 8349, Training Loss : 0.14259, Training Acc : 0.939, Run Time : 9.40
INFO:root:2019-05-11 01:02:43, Epoch : 1, Step : 8350, Training Loss : 0.03392, Training Acc : 0.989, Run Time : 0.47
INFO:root:2019-05-11 01:02:44, Epoch : 1, Step : 8351, Training Loss : 0.01704, Training Acc : 1.000, Run Time : 0.47
INFO:root:2019-05-11 01:02:45, Epoch : 1, Step : 8352, Training Loss : 0.10301, Training Acc : 0.944, Run Time : 1.53
INFO:root:2019-05-11 01:02:47, Epoch : 1, Step : 8353, Training Loss : 0.02735, Training Acc : 0.989, Run Time : 1.29
INFO:root:2019-05-11 01:03:00, Epoch : 1, Step : 8354, Training Loss : 0.03609, Training Acc : 0.989, Run Time : 13.65
INFO:root:2019-05-11 01:03:00, Epoch : 1, Step : 8355, Training Loss : 0.03557, Training Acc : 0.994, Run Time : 0.27
INFO:root:2019-05-11 01:03:01, Epoch : 1, Step : 8356, Training Loss : 0.02175, Training Acc : 1.000, Run Time : 0.45
INFO:root:2019-05-11 01:03:01, Epoch : 1, Step : 8357, Training Loss : 0.02106, Training Acc : 1.000, Run Time : 0.49
INFO:root:2019-05-11 01:03:02, Epoch : 1, Step : 8358, Training Loss : 0.06413, Training Acc : 0.978, Run Time : 0.30
INFO:root:2019-05-11 01:03:16, Epoch : 1, Step : 8359, Training Loss : 0.06978, Training Acc : 0.978, Run Time : 14.47
INFO:root:2019-05-11 01:03:16, Epoch : 1, Step : 8360, Training Loss : 0.02941, Training Acc : 1.000, Run Time : 0.31
INFO:root:2019-05-11 01:03:17, Epoch : 1, Step : 8361, Training Loss : 0.03583, Training Acc : 0.989, Run Time : 0.43
INFO:root:2019-05-11 01:03:17, Epoch : 1, Step : 8362, Training Loss : 0.03028, Training Acc : 0.989, Run Time : 0.47
INFO:root:2019-05-11 01:03:18, Epoch : 1, Step : 8363, Training Loss : 0.08444, Training Acc : 0.967, Run Time : 0.47
INFO:root:2019-05-11 01:03:26, Epoch : 1, Step : 8364, Training Loss : 0.19103, Training Acc : 0.900, Run Time : 8.04
INFO:root:2019-05-11 01:03:27, Epoch : 1, Step : 8365, Training Loss : 0.04579, Training Acc : 0.989, Run Time : 0.71
INFO:root:2019-05-11 01:03:30, Epoch : 1, Step : 8366, Training Loss : 0.23475, Training Acc : 0.906, Run Time : 3.47
INFO:root:2019-05-11 01:03:31, Epoch : 1, Step : 8367, Training Loss : 0.05733, Training Acc : 0.978, Run Time : 0.45
INFO:root:2019-05-11 01:03:33, Epoch : 1, Step : 8368, Training Loss : 0.19645, Training Acc : 0.917, Run Time : 2.93
INFO:root:2019-05-11 01:03:34, Epoch : 1, Step : 8369, Training Loss : 0.06199, Training Acc : 0.983, Run Time : 0.54
INFO:root:2019-05-11 01:03:40, Epoch : 1, Step : 8370, Training Loss : 0.13785, Training Acc : 0.956, Run Time : 5.97
INFO:root:2019-05-11 01:03:41, Epoch : 1, Step : 8371, Training Loss : 0.19650, Training Acc : 0.928, Run Time : 0.65
INFO:root:2019-05-11 01:03:41, Epoch : 1, Step : 8372, Training Loss : 0.06683, Training Acc : 0.978, Run Time : 0.60
INFO:root:2019-05-11 01:03:42, Epoch : 1, Step : 8373, Training Loss : 0.23198, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-11 01:03:54, Epoch : 1, Step : 8374, Training Loss : 0.08061, Training Acc : 0.967, Run Time : 11.87
INFO:root:2019-05-11 01:03:54, Epoch : 1, Step : 8375, Training Loss : 0.05400, Training Acc : 0.978, Run Time : 0.48
INFO:root:2019-05-11 01:03:55, Epoch : 1, Step : 8376, Training Loss : 0.14463, Training Acc : 0.944, Run Time : 0.54
INFO:root:2019-05-11 01:03:55, Epoch : 1, Step : 8377, Training Loss : 0.02686, Training Acc : 0.994, Run Time : 0.45
INFO:root:2019-05-11 01:04:03, Epoch : 1, Step : 8378, Training Loss : 0.05003, Training Acc : 0.983, Run Time : 8.24
INFO:root:2019-05-11 01:04:04, Epoch : 1, Step : 8379, Training Loss : 0.04885, Training Acc : 1.000, Run Time : 0.41
INFO:root:2019-05-11 01:04:04, Epoch : 1, Step : 8380, Training Loss : 0.08032, Training Acc : 0.972, Run Time : 0.46
INFO:root:2019-05-11 01:04:05, Epoch : 1, Step : 8381, Training Loss : 0.30684, Training Acc : 0.883, Run Time : 0.55
INFO:root:2019-05-11 01:04:14, Epoch : 1, Step : 8382, Training Loss : 0.15904, Training Acc : 0.933, Run Time : 9.82
INFO:root:2019-05-11 01:04:15, Epoch : 1, Step : 8383, Training Loss : 0.15739, Training Acc : 0.922, Run Time : 0.63
INFO:root:2019-05-11 01:04:15, Epoch : 1, Step : 8384, Training Loss : 0.09456, Training Acc : 0.967, Run Time : 0.39
INFO:root:2019-05-11 01:04:16, Epoch : 1, Step : 8385, Training Loss : 0.35092, Training Acc : 0.861, Run Time : 0.46
INFO:root:2019-05-11 01:04:24, Epoch : 1, Step : 8386, Training Loss : 0.06074, Training Acc : 0.978, Run Time : 8.48
INFO:root:2019-05-11 01:04:25, Epoch : 1, Step : 8387, Training Loss : 0.16190, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-11 01:04:25, Epoch : 1, Step : 8388, Training Loss : 0.10806, Training Acc : 0.967, Run Time : 0.43
INFO:root:2019-05-11 01:04:26, Epoch : 1, Step : 8389, Training Loss : 0.08357, Training Acc : 0.961, Run Time : 0.40
INFO:root:2019-05-11 01:04:26, Epoch : 1, Step : 8390, Training Loss : 0.05438, Training Acc : 0.978, Run Time : 0.46
INFO:root:2019-05-11 01:04:35, Epoch : 1, Step : 8391, Training Loss : 0.05316, Training Acc : 0.983, Run Time : 9.34
INFO:root:2019-05-11 01:04:36, Epoch : 1, Step : 8392, Training Loss : 0.11742, Training Acc : 0.972, Run Time : 0.44
INFO:root:2019-05-11 01:04:37, Epoch : 1, Step : 8393, Training Loss : 0.08831, Training Acc : 0.961, Run Time : 0.59
INFO:root:2019-05-11 01:04:43, Epoch : 1, Step : 8394, Training Loss : 0.14197, Training Acc : 0.933, Run Time : 6.23
INFO:root:2019-05-11 01:04:43, Epoch : 1, Step : 8395, Training Loss : 0.08563, Training Acc : 0.967, Run Time : 0.38
INFO:root:2019-05-11 01:04:44, Epoch : 1, Step : 8396, Training Loss : 0.17002, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-11 01:04:44, Epoch : 1, Step : 8397, Training Loss : 0.07633, Training Acc : 0.967, Run Time : 0.86
INFO:root:2019-05-11 01:04:52, Epoch : 1, Step : 8398, Training Loss : 0.08037, Training Acc : 0.972, Run Time : 7.37
INFO:root:2019-05-11 01:04:53, Epoch : 1, Step : 8399, Training Loss : 0.12850, Training Acc : 0.972, Run Time : 1.03
INFO:root:2019-05-11 01:04:53, Epoch : 1, Step : 8400, Training Loss : 0.15013, Training Acc : 0.922, Run Time : 0.56
INFO:root:2019-05-11 01:04:54, Epoch : 1, Step : 8401, Training Loss : 0.38589, Training Acc : 0.839, Run Time : 0.78
INFO:root:2019-05-11 01:04:56, Epoch : 1, Step : 8402, Training Loss : 0.49242, Training Acc : 0.806, Run Time : 1.78
INFO:root:2019-05-11 01:05:06, Epoch : 1, Step : 8403, Training Loss : 0.44046, Training Acc : 0.828, Run Time : 10.38
INFO:root:2019-05-11 01:05:07, Epoch : 1, Step : 8404, Training Loss : 0.51986, Training Acc : 0.800, Run Time : 0.45
INFO:root:2019-05-11 01:05:07, Epoch : 1, Step : 8405, Training Loss : 0.49077, Training Acc : 0.850, Run Time : 0.45
INFO:root:2019-05-11 01:05:08, Epoch : 1, Step : 8406, Training Loss : 0.36825, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-11 01:05:09, Epoch : 1, Step : 8407, Training Loss : 0.24748, Training Acc : 0.894, Run Time : 1.27
INFO:root:2019-05-11 01:05:18, Epoch : 1, Step : 8408, Training Loss : 0.30739, Training Acc : 0.867, Run Time : 9.04
INFO:root:2019-05-11 01:05:19, Epoch : 1, Step : 8409, Training Loss : 0.17302, Training Acc : 0.933, Run Time : 0.56
INFO:root:2019-05-11 01:05:19, Epoch : 1, Step : 8410, Training Loss : 0.20552, Training Acc : 0.917, Run Time : 0.53
INFO:root:2019-05-11 01:05:20, Epoch : 1, Step : 8411, Training Loss : 0.17847, Training Acc : 0.928, Run Time : 0.68
INFO:root:2019-05-11 01:05:28, Epoch : 1, Step : 8412, Training Loss : 0.13855, Training Acc : 0.928, Run Time : 8.54
INFO:root:2019-05-11 01:05:29, Epoch : 1, Step : 8413, Training Loss : 0.18651, Training Acc : 0.900, Run Time : 0.69
INFO:root:2019-05-11 01:05:29, Epoch : 1, Step : 8414, Training Loss : 0.10140, Training Acc : 0.972, Run Time : 0.44
INFO:root:2019-05-11 01:05:30, Epoch : 1, Step : 8415, Training Loss : 0.18403, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-11 01:05:36, Epoch : 1, Step : 8416, Training Loss : 0.16104, Training Acc : 0.928, Run Time : 5.66
INFO:root:2019-05-11 01:05:36, Epoch : 1, Step : 8417, Training Loss : 0.07442, Training Acc : 0.978, Run Time : 0.79
INFO:root:2019-05-11 01:05:48, Epoch : 1, Step : 8418, Training Loss : 0.12039, Training Acc : 0.961, Run Time : 11.90
INFO:root:2019-05-11 01:05:49, Epoch : 1, Step : 8419, Training Loss : 0.12818, Training Acc : 0.944, Run Time : 0.41
INFO:root:2019-05-11 01:05:49, Epoch : 1, Step : 8420, Training Loss : 0.08991, Training Acc : 0.950, Run Time : 0.22
INFO:root:2019-05-11 01:05:49, Epoch : 1, Step : 8421, Training Loss : 0.09667, Training Acc : 0.961, Run Time : 0.46
INFO:root:2019-05-11 01:05:50, Epoch : 1, Step : 8422, Training Loss : 0.09564, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-11 01:05:55, Epoch : 1, Step : 8423, Training Loss : 0.09121, Training Acc : 0.950, Run Time : 4.95
INFO:root:2019-05-11 01:05:55, Epoch : 1, Step : 8424, Training Loss : 0.09396, Training Acc : 0.967, Run Time : 0.50
INFO:root:2019-05-11 01:06:08, Epoch : 1, Step : 8425, Training Loss : 0.05595, Training Acc : 0.983, Run Time : 12.95
INFO:root:2019-05-11 01:06:09, Epoch : 1, Step : 8426, Training Loss : 0.22315, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-11 01:06:09, Epoch : 1, Step : 8427, Training Loss : 0.69028, Training Acc : 0.828, Run Time : 0.46
INFO:root:2019-05-11 01:06:10, Epoch : 1, Step : 8428, Training Loss : 0.56224, Training Acc : 0.850, Run Time : 0.46
INFO:root:2019-05-11 01:06:19, Epoch : 1, Step : 8429, Training Loss : 0.53945, Training Acc : 0.850, Run Time : 8.95
INFO:root:2019-05-11 01:06:19, Epoch : 1, Step : 8430, Training Loss : 0.58496, Training Acc : 0.828, Run Time : 0.80
INFO:root:2019-05-11 01:06:20, Epoch : 1, Step : 8431, Training Loss : 0.16307, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-11 01:06:20, Epoch : 1, Step : 8432, Training Loss : 0.26226, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-11 01:06:26, Epoch : 1, Step : 8433, Training Loss : 0.28302, Training Acc : 0.883, Run Time : 5.68
INFO:root:2019-05-11 01:06:26, Epoch : 1, Step : 8434, Training Loss : 0.28554, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-11 01:06:36, Epoch : 1, Step : 8435, Training Loss : 0.39931, Training Acc : 0.817, Run Time : 9.56
INFO:root:2019-05-11 01:06:37, Epoch : 1, Step : 8436, Training Loss : 0.26630, Training Acc : 0.867, Run Time : 0.59
INFO:root:2019-05-11 01:06:37, Epoch : 1, Step : 8437, Training Loss : 0.26185, Training Acc : 0.894, Run Time : 0.76
INFO:root:2019-05-11 01:06:38, Epoch : 1, Step : 8438, Training Loss : 0.15338, Training Acc : 0.928, Run Time : 0.93
INFO:root:2019-05-11 01:06:45, Epoch : 1, Step : 8439, Training Loss : 0.15835, Training Acc : 0.939, Run Time : 6.56
INFO:root:2019-05-11 01:06:46, Epoch : 1, Step : 8440, Training Loss : 0.20654, Training Acc : 0.917, Run Time : 0.81
INFO:root:2019-05-11 01:06:46, Epoch : 1, Step : 8441, Training Loss : 0.16491, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-11 01:06:46, Epoch : 1, Step : 8442, Training Loss : 0.20487, Training Acc : 0.894, Run Time : 0.43
INFO:root:2019-05-11 01:06:54, Epoch : 1, Step : 8443, Training Loss : 0.23690, Training Acc : 0.867, Run Time : 7.06
INFO:root:2019-05-11 01:06:54, Epoch : 1, Step : 8444, Training Loss : 0.52385, Training Acc : 0.744, Run Time : 0.65
INFO:root:2019-05-11 01:06:55, Epoch : 1, Step : 8445, Training Loss : 0.27222, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-11 01:06:56, Epoch : 1, Step : 8446, Training Loss : 0.29704, Training Acc : 0.889, Run Time : 0.95
INFO:root:2019-05-11 01:07:00, Epoch : 1, Step : 8447, Training Loss : 0.14088, Training Acc : 0.956, Run Time : 4.04
INFO:root:2019-05-11 01:07:00, Epoch : 1, Step : 8448, Training Loss : 0.17887, Training Acc : 0.911, Run Time : 0.62
INFO:root:2019-05-11 01:07:08, Epoch : 1, Step : 8449, Training Loss : 0.20395, Training Acc : 0.906, Run Time : 7.76
INFO:root:2019-05-11 01:07:09, Epoch : 1, Step : 8450, Training Loss : 0.24734, Training Acc : 0.911, Run Time : 0.76
INFO:root:2019-05-11 01:07:09, Epoch : 1, Step : 8451, Training Loss : 0.26396, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-11 01:07:15, Epoch : 1, Step : 8452, Training Loss : 0.17354, Training Acc : 0.928, Run Time : 5.95
INFO:root:2019-05-11 01:07:16, Epoch : 1, Step : 8453, Training Loss : 0.22937, Training Acc : 0.911, Run Time : 0.76
INFO:root:2019-05-11 01:07:16, Epoch : 1, Step : 8454, Training Loss : 0.19178, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-11 01:07:22, Epoch : 1, Step : 8455, Training Loss : 0.24915, Training Acc : 0.900, Run Time : 6.07
INFO:root:2019-05-11 01:07:24, Epoch : 1, Step : 8456, Training Loss : 0.19093, Training Acc : 0.917, Run Time : 1.25
INFO:root:2019-05-11 01:07:24, Epoch : 1, Step : 8457, Training Loss : 0.18291, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-11 01:07:25, Epoch : 1, Step : 8458, Training Loss : 0.17055, Training Acc : 0.939, Run Time : 0.82
INFO:root:2019-05-11 01:07:26, Epoch : 1, Step : 8459, Training Loss : 0.31955, Training Acc : 0.883, Run Time : 1.42
INFO:root:2019-05-11 01:07:35, Epoch : 1, Step : 8460, Training Loss : 0.21998, Training Acc : 0.883, Run Time : 8.28
INFO:root:2019-05-11 01:07:35, Epoch : 1, Step : 8461, Training Loss : 0.15070, Training Acc : 0.956, Run Time : 0.49
INFO:root:2019-05-11 01:07:36, Epoch : 1, Step : 8462, Training Loss : 0.21133, Training Acc : 0.906, Run Time : 0.74
INFO:root:2019-05-11 01:07:45, Epoch : 1, Step : 8463, Training Loss : 0.20938, Training Acc : 0.889, Run Time : 8.87
INFO:root:2019-05-11 01:07:45, Epoch : 1, Step : 8464, Training Loss : 0.27122, Training Acc : 0.883, Run Time : 0.40
INFO:root:2019-05-11 01:07:46, Epoch : 1, Step : 8465, Training Loss : 0.21548, Training Acc : 0.906, Run Time : 0.43
INFO:root:2019-05-11 01:07:46, Epoch : 1, Step : 8466, Training Loss : 0.17227, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-11 01:07:47, Epoch : 1, Step : 8467, Training Loss : 0.21355, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-11 01:07:56, Epoch : 1, Step : 8468, Training Loss : 0.19449, Training Acc : 0.922, Run Time : 9.42
INFO:root:2019-05-11 01:07:56, Epoch : 1, Step : 8469, Training Loss : 0.20200, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-11 01:07:57, Epoch : 1, Step : 8470, Training Loss : 0.21000, Training Acc : 0.906, Run Time : 0.68
INFO:root:2019-05-11 01:07:58, Epoch : 1, Step : 8471, Training Loss : 0.13841, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-11 01:07:59, Epoch : 1, Step : 8472, Training Loss : 0.19205, Training Acc : 0.900, Run Time : 1.30
INFO:root:2019-05-11 01:08:06, Epoch : 1, Step : 8473, Training Loss : 0.16325, Training Acc : 0.933, Run Time : 6.67
INFO:root:2019-05-11 01:08:06, Epoch : 1, Step : 8474, Training Loss : 0.17405, Training Acc : 0.900, Run Time : 0.43
INFO:root:2019-05-11 01:08:07, Epoch : 1, Step : 8475, Training Loss : 0.17990, Training Acc : 0.922, Run Time : 0.54
INFO:root:2019-05-11 01:08:15, Epoch : 1, Step : 8476, Training Loss : 0.13993, Training Acc : 0.967, Run Time : 8.49
INFO:root:2019-05-11 01:08:16, Epoch : 1, Step : 8477, Training Loss : 0.20849, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-11 01:08:16, Epoch : 1, Step : 8478, Training Loss : 0.17693, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-11 01:08:17, Epoch : 1, Step : 8479, Training Loss : 0.11378, Training Acc : 0.967, Run Time : 0.47
INFO:root:2019-05-11 01:08:25, Epoch : 1, Step : 8480, Training Loss : 0.38520, Training Acc : 0.844, Run Time : 8.61
INFO:root:2019-05-11 01:08:26, Epoch : 1, Step : 8481, Training Loss : 0.20048, Training Acc : 0.900, Run Time : 0.40
INFO:root:2019-05-11 01:08:26, Epoch : 1, Step : 8482, Training Loss : 0.17796, Training Acc : 0.928, Run Time : 0.49
INFO:root:2019-05-11 01:08:26, Epoch : 1, Step : 8483, Training Loss : 0.24052, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-11 01:08:33, Epoch : 1, Step : 8484, Training Loss : 0.16898, Training Acc : 0.933, Run Time : 6.97
INFO:root:2019-05-11 01:08:34, Epoch : 1, Step : 8485, Training Loss : 0.15065, Training Acc : 0.939, Run Time : 0.41
INFO:root:2019-05-11 01:08:35, Epoch : 1, Step : 8486, Training Loss : 0.14436, Training Acc : 0.939, Run Time : 0.78
INFO:root:2019-05-11 01:08:35, Epoch : 1, Step : 8487, Training Loss : 0.14794, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-11 01:08:47, Epoch : 1, Step : 8488, Training Loss : 0.16116, Training Acc : 0.911, Run Time : 11.54
INFO:root:2019-05-11 01:08:47, Epoch : 1, Step : 8489, Training Loss : 0.10809, Training Acc : 0.967, Run Time : 0.31
INFO:root:2019-05-11 01:08:47, Epoch : 1, Step : 8490, Training Loss : 0.16654, Training Acc : 0.922, Run Time : 0.39
INFO:root:2019-05-11 01:08:48, Epoch : 1, Step : 8491, Training Loss : 0.14609, Training Acc : 0.939, Run Time : 0.52
INFO:root:2019-05-11 01:08:48, Epoch : 1, Step : 8492, Training Loss : 0.14624, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-11 01:08:59, Epoch : 1, Step : 8493, Training Loss : 0.17377, Training Acc : 0.933, Run Time : 10.81
INFO:root:2019-05-11 01:09:00, Epoch : 1, Step : 8494, Training Loss : 0.17262, Training Acc : 0.900, Run Time : 0.57
INFO:root:2019-05-11 01:09:00, Epoch : 1, Step : 8495, Training Loss : 0.17654, Training Acc : 0.889, Run Time : 0.60
INFO:root:2019-05-11 01:09:01, Epoch : 1, Step : 8496, Training Loss : 0.15964, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-11 01:09:02, Epoch : 1, Step : 8497, Training Loss : 0.16933, Training Acc : 0.917, Run Time : 1.18
INFO:root:2019-05-11 01:09:09, Epoch : 1, Step : 8498, Training Loss : 0.13691, Training Acc : 0.950, Run Time : 7.14
INFO:root:2019-05-11 01:09:10, Epoch : 1, Step : 8499, Training Loss : 0.15725, Training Acc : 0.928, Run Time : 1.32
INFO:root:2019-05-11 01:09:11, Epoch : 1, Step : 8500, Training Loss : 0.18304, Training Acc : 0.917, Run Time : 0.49
INFO:root:2019-05-11 01:09:13, Epoch : 1, Step : 8501, Training Loss : 0.13490, Training Acc : 0.939, Run Time : 2.21
INFO:root:2019-05-11 01:09:23, Epoch : 1, Step : 8502, Training Loss : 0.17634, Training Acc : 0.922, Run Time : 9.53
INFO:root:2019-05-11 01:09:23, Epoch : 1, Step : 8503, Training Loss : 0.14395, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-11 01:09:24, Epoch : 1, Step : 8504, Training Loss : 0.13434, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-11 01:09:24, Epoch : 1, Step : 8505, Training Loss : 0.15093, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-11 01:09:25, Epoch : 1, Step : 8506, Training Loss : 0.18057, Training Acc : 0.911, Run Time : 1.28
INFO:root:2019-05-11 01:09:38, Epoch : 1, Step : 8507, Training Loss : 0.09170, Training Acc : 0.961, Run Time : 13.05
INFO:root:2019-05-11 01:09:39, Epoch : 1, Step : 8508, Training Loss : 0.10735, Training Acc : 0.956, Run Time : 0.24
INFO:root:2019-05-11 01:09:39, Epoch : 1, Step : 8509, Training Loss : 0.08790, Training Acc : 0.972, Run Time : 0.43
INFO:root:2019-05-11 01:09:39, Epoch : 1, Step : 8510, Training Loss : 0.14871, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-11 01:09:40, Epoch : 1, Step : 8511, Training Loss : 0.14406, Training Acc : 0.939, Run Time : 0.52
INFO:root:2019-05-11 01:09:44, Epoch : 1, Step : 8512, Training Loss : 0.15440, Training Acc : 0.922, Run Time : 4.29
INFO:root:2019-05-11 01:09:45, Epoch : 1, Step : 8513, Training Loss : 0.12101, Training Acc : 0.917, Run Time : 0.48
INFO:root:2019-05-11 01:09:59, Epoch : 1, Step : 8514, Training Loss : 0.12060, Training Acc : 0.961, Run Time : 13.76
INFO:root:2019-05-11 01:09:59, Epoch : 1, Step : 8515, Training Loss : 0.10381, Training Acc : 0.950, Run Time : 0.23
INFO:root:2019-05-11 01:09:59, Epoch : 1, Step : 8516, Training Loss : 0.08259, Training Acc : 0.961, Run Time : 0.45
INFO:root:2019-05-11 01:10:01, Epoch : 1, Step : 8517, Training Loss : 0.15677, Training Acc : 0.917, Run Time : 1.43
INFO:root:2019-05-11 01:10:01, Epoch : 1, Step : 8518, Training Loss : 0.10059, Training Acc : 0.967, Run Time : 0.50
INFO:root:2019-05-11 01:10:05, Epoch : 1, Step : 8519, Training Loss : 0.09843, Training Acc : 0.956, Run Time : 3.50
INFO:root:2019-05-11 01:10:11, Epoch : 1, Step : 8520, Training Loss : 0.10757, Training Acc : 0.961, Run Time : 5.91
INFO:root:2019-05-11 01:10:11, Epoch : 1, Step : 8521, Training Loss : 0.10519, Training Acc : 0.956, Run Time : 0.62
INFO:root:2019-05-11 01:10:12, Epoch : 1, Step : 8522, Training Loss : 0.12613, Training Acc : 0.961, Run Time : 0.45
INFO:root:2019-05-11 01:10:14, Epoch : 1, Step : 8523, Training Loss : 0.87536, Training Acc : 0.783, Run Time : 2.84
INFO:root:2019-05-11 01:10:16, Epoch : 1, Step : 8524, Training Loss : 0.26839, Training Acc : 0.906, Run Time : 1.38
INFO:root:2019-05-11 01:10:26, Epoch : 1, Step : 8525, Training Loss : 0.41110, Training Acc : 0.878, Run Time : 10.15
INFO:root:2019-05-11 01:10:26, Epoch : 1, Step : 8526, Training Loss : 0.22507, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 01:10:27, Epoch : 1, Step : 8527, Training Loss : 0.62481, Training Acc : 0.878, Run Time : 0.96
INFO:root:2019-05-11 01:10:28, Epoch : 1, Step : 8528, Training Loss : 0.15209, Training Acc : 0.939, Run Time : 1.14
INFO:root:2019-05-11 01:10:29, Epoch : 1, Step : 8529, Training Loss : 0.23828, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-11 01:10:33, Epoch : 1, Step : 8530, Training Loss : 0.24424, Training Acc : 0.933, Run Time : 4.34
INFO:root:2019-05-11 01:10:41, Epoch : 1, Step : 8531, Training Loss : 0.21409, Training Acc : 0.928, Run Time : 7.52
INFO:root:2019-05-11 01:10:41, Epoch : 1, Step : 8532, Training Loss : 0.22836, Training Acc : 0.889, Run Time : 0.55
INFO:root:2019-05-11 01:10:42, Epoch : 1, Step : 8533, Training Loss : 0.33163, Training Acc : 0.817, Run Time : 0.48
INFO:root:2019-05-11 01:10:48, Epoch : 1, Step : 8534, Training Loss : 0.32409, Training Acc : 0.878, Run Time : 6.16
INFO:root:2019-05-11 01:10:49, Epoch : 1, Step : 8535, Training Loss : 0.19998, Training Acc : 0.911, Run Time : 0.97
INFO:root:2019-05-11 01:10:49, Epoch : 1, Step : 8536, Training Loss : 0.16751, Training Acc : 0.922, Run Time : 0.50
INFO:root:2019-05-11 01:10:50, Epoch : 1, Step : 8537, Training Loss : 0.10740, Training Acc : 0.967, Run Time : 0.51
INFO:root:2019-05-11 01:10:59, Epoch : 1, Step : 8538, Training Loss : 0.10038, Training Acc : 0.978, Run Time : 9.01
INFO:root:2019-05-11 01:11:00, Epoch : 1, Step : 8539, Training Loss : 0.22091, Training Acc : 0.911, Run Time : 0.51
INFO:root:2019-05-11 01:11:00, Epoch : 1, Step : 8540, Training Loss : 0.21914, Training Acc : 0.928, Run Time : 0.49
INFO:root:2019-05-11 01:11:00, Epoch : 1, Step : 8541, Training Loss : 0.31524, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-11 01:11:06, Epoch : 1, Step : 8542, Training Loss : 0.28117, Training Acc : 0.939, Run Time : 5.96
INFO:root:2019-05-11 01:11:10, Epoch : 1, Step : 8543, Training Loss : 0.20021, Training Acc : 0.944, Run Time : 3.84
INFO:root:2019-05-11 01:11:11, Epoch : 1, Step : 8544, Training Loss : 0.26722, Training Acc : 0.911, Run Time : 0.57
INFO:root:2019-05-11 01:11:11, Epoch : 1, Step : 8545, Training Loss : 0.06555, Training Acc : 0.978, Run Time : 0.61
INFO:root:2019-05-11 01:11:20, Epoch : 1, Step : 8546, Training Loss : 0.14289, Training Acc : 0.944, Run Time : 8.66
INFO:root:2019-05-11 01:11:21, Epoch : 1, Step : 8547, Training Loss : 0.26968, Training Acc : 0.917, Run Time : 1.15
INFO:root:2019-05-11 01:11:22, Epoch : 1, Step : 8548, Training Loss : 0.70825, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-11 01:11:22, Epoch : 1, Step : 8549, Training Loss : 0.51057, Training Acc : 0.872, Run Time : 0.49
INFO:root:2019-05-11 01:11:30, Epoch : 1, Step : 8550, Training Loss : 0.72092, Training Acc : 0.806, Run Time : 7.58
INFO:root:2019-05-11 01:11:30, Epoch : 1, Step : 8551, Training Loss : 0.13112, Training Acc : 0.972, Run Time : 0.71
INFO:root:2019-05-11 01:11:31, Epoch : 1, Step : 8552, Training Loss : 0.35022, Training Acc : 0.911, Run Time : 0.63
INFO:root:2019-05-11 01:11:32, Epoch : 1, Step : 8553, Training Loss : 0.21029, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-11 01:11:44, Epoch : 1, Step : 8554, Training Loss : 0.21067, Training Acc : 0.939, Run Time : 12.27
INFO:root:2019-05-11 01:11:44, Epoch : 1, Step : 8555, Training Loss : 0.20546, Training Acc : 0.911, Run Time : 0.44
INFO:root:2019-05-11 01:11:45, Epoch : 1, Step : 8556, Training Loss : 0.14687, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-11 01:11:45, Epoch : 1, Step : 8557, Training Loss : 0.20040, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-11 01:11:46, Epoch : 1, Step : 8558, Training Loss : 0.31452, Training Acc : 0.917, Run Time : 0.53
INFO:root:2019-05-11 01:11:55, Epoch : 1, Step : 8559, Training Loss : 0.28637, Training Acc : 0.883, Run Time : 9.05
INFO:root:2019-05-11 01:11:55, Epoch : 1, Step : 8560, Training Loss : 0.16583, Training Acc : 0.933, Run Time : 0.33
INFO:root:2019-05-11 01:11:56, Epoch : 1, Step : 8561, Training Loss : 0.22957, Training Acc : 0.883, Run Time : 0.81
INFO:root:2019-05-11 01:12:03, Epoch : 1, Step : 8562, Training Loss : 0.22076, Training Acc : 0.900, Run Time : 7.21
INFO:root:2019-05-11 01:12:04, Epoch : 1, Step : 8563, Training Loss : 0.14287, Training Acc : 0.956, Run Time : 0.53
INFO:root:2019-05-11 01:12:04, Epoch : 1, Step : 8564, Training Loss : 0.13083, Training Acc : 0.983, Run Time : 0.49
INFO:root:2019-05-11 01:12:14, Epoch : 1, Step : 8565, Training Loss : 0.13734, Training Acc : 0.939, Run Time : 9.76
INFO:root:2019-05-11 01:12:14, Epoch : 1, Step : 8566, Training Loss : 0.22607, Training Acc : 0.900, Run Time : 0.33
INFO:root:2019-05-11 01:12:15, Epoch : 1, Step : 8567, Training Loss : 0.44065, Training Acc : 0.789, Run Time : 0.49
INFO:root:2019-05-11 01:12:16, Epoch : 1, Step : 8568, Training Loss : 0.40981, Training Acc : 0.811, Run Time : 0.94
INFO:root:2019-05-11 01:12:21, Epoch : 1, Step : 8569, Training Loss : 0.36836, Training Acc : 0.828, Run Time : 5.76
INFO:root:2019-05-11 01:12:22, Epoch : 1, Step : 8570, Training Loss : 0.21249, Training Acc : 0.889, Run Time : 0.63
INFO:root:2019-05-11 01:12:23, Epoch : 1, Step : 8571, Training Loss : 0.19480, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-11 01:12:31, Epoch : 1, Step : 8572, Training Loss : 0.27263, Training Acc : 0.856, Run Time : 7.99
INFO:root:2019-05-11 01:12:32, Epoch : 1, Step : 8573, Training Loss : 0.21223, Training Acc : 0.906, Run Time : 1.20
INFO:root:2019-05-11 01:12:32, Epoch : 1, Step : 8574, Training Loss : 0.15635, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-11 01:12:33, Epoch : 1, Step : 8575, Training Loss : 0.35567, Training Acc : 0.833, Run Time : 1.17
INFO:root:2019-05-11 01:12:43, Epoch : 1, Step : 8576, Training Loss : 0.42071, Training Acc : 0.833, Run Time : 10.01
INFO:root:2019-05-11 01:12:44, Epoch : 1, Step : 8577, Training Loss : 0.41268, Training Acc : 0.811, Run Time : 0.58
INFO:root:2019-05-11 01:12:44, Epoch : 1, Step : 8578, Training Loss : 0.28135, Training Acc : 0.872, Run Time : 0.43
INFO:root:2019-05-11 01:12:45, Epoch : 1, Step : 8579, Training Loss : 0.34117, Training Acc : 0.828, Run Time : 0.47
INFO:root:2019-05-11 01:12:45, Epoch : 1, Step : 8580, Training Loss : 0.28690, Training Acc : 0.894, Run Time : 0.44
INFO:root:2019-05-11 01:12:58, Epoch : 1, Step : 8581, Training Loss : 0.27688, Training Acc : 0.878, Run Time : 12.40
INFO:root:2019-05-11 01:12:58, Epoch : 1, Step : 8582, Training Loss : 0.28847, Training Acc : 0.894, Run Time : 0.44
INFO:root:2019-05-11 01:12:59, Epoch : 1, Step : 8583, Training Loss : 0.23907, Training Acc : 0.878, Run Time : 0.51
INFO:root:2019-05-11 01:13:01, Epoch : 1, Step : 8584, Training Loss : 0.25263, Training Acc : 0.917, Run Time : 2.44
INFO:root:2019-05-11 01:13:02, Epoch : 1, Step : 8585, Training Loss : 0.22738, Training Acc : 0.900, Run Time : 0.56
INFO:root:2019-05-11 01:13:07, Epoch : 1, Step : 8586, Training Loss : 0.33926, Training Acc : 0.833, Run Time : 5.45
INFO:root:2019-05-11 01:13:08, Epoch : 1, Step : 8587, Training Loss : 0.31672, Training Acc : 0.889, Run Time : 1.39
INFO:root:2019-05-11 01:13:10, Epoch : 1, Step : 8588, Training Loss : 0.35239, Training Acc : 0.850, Run Time : 1.77
INFO:root:2019-05-11 01:13:17, Epoch : 1, Step : 8589, Training Loss : 0.27473, Training Acc : 0.878, Run Time : 6.61
INFO:root:2019-05-11 01:13:18, Epoch : 1, Step : 8590, Training Loss : 0.26675, Training Acc : 0.878, Run Time : 0.73
INFO:root:2019-05-11 01:13:18, Epoch : 1, Step : 8591, Training Loss : 0.14296, Training Acc : 0.967, Run Time : 0.57
INFO:root:2019-05-11 01:13:26, Epoch : 1, Step : 8592, Training Loss : 0.35327, Training Acc : 0.861, Run Time : 7.80
INFO:root:2019-05-11 01:13:26, Epoch : 1, Step : 8593, Training Loss : 0.30199, Training Acc : 0.883, Run Time : 0.39
INFO:root:2019-05-11 01:13:27, Epoch : 1, Step : 8594, Training Loss : 0.18559, Training Acc : 0.939, Run Time : 0.71
INFO:root:2019-05-11 01:13:28, Epoch : 1, Step : 8595, Training Loss : 0.20936, Training Acc : 0.911, Run Time : 0.53
INFO:root:2019-05-11 01:13:36, Epoch : 1, Step : 8596, Training Loss : 0.21823, Training Acc : 0.917, Run Time : 8.45
INFO:root:2019-05-11 01:13:36, Epoch : 1, Step : 8597, Training Loss : 0.18307, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-11 01:13:45, Epoch : 1, Step : 8598, Training Loss : 0.17190, Training Acc : 0.939, Run Time : 8.49
INFO:root:2019-05-11 01:13:45, Epoch : 1, Step : 8599, Training Loss : 0.23707, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-11 01:13:46, Epoch : 1, Step : 8600, Training Loss : 0.25332, Training Acc : 0.900, Run Time : 0.55
INFO:root:2019-05-11 01:13:47, Epoch : 1, Step : 8601, Training Loss : 0.84663, Training Acc : 0.722, Run Time : 1.39
INFO:root:2019-05-11 01:13:53, Epoch : 1, Step : 8602, Training Loss : 0.95675, Training Acc : 0.728, Run Time : 5.48
INFO:root:2019-05-11 01:13:53, Epoch : 1, Step : 8603, Training Loss : 1.59722, Training Acc : 0.517, Run Time : 0.41
INFO:root:2019-05-11 01:13:54, Epoch : 1, Step : 8604, Training Loss : 1.26878, Training Acc : 0.700, Run Time : 0.46
INFO:root:2019-05-11 01:13:57, Epoch : 1, Step : 8605, Training Loss : 1.16602, Training Acc : 0.639, Run Time : 3.45
INFO:root:2019-05-11 01:14:02, Epoch : 1, Step : 8606, Training Loss : 0.89174, Training Acc : 0.661, Run Time : 4.97
INFO:root:2019-05-11 01:14:03, Epoch : 1, Step : 8607, Training Loss : 0.46837, Training Acc : 0.839, Run Time : 0.49
INFO:root:2019-05-11 01:14:03, Epoch : 1, Step : 8608, Training Loss : 0.72853, Training Acc : 0.694, Run Time : 0.64
INFO:root:2019-05-11 01:14:13, Epoch : 1, Step : 8609, Training Loss : 0.82538, Training Acc : 0.656, Run Time : 9.38
INFO:root:2019-05-11 01:14:13, Epoch : 1, Step : 8610, Training Loss : 0.85457, Training Acc : 0.728, Run Time : 0.48
INFO:root:2019-05-11 01:14:14, Epoch : 1, Step : 8611, Training Loss : 0.49504, Training Acc : 0.778, Run Time : 0.47
INFO:root:2019-05-11 01:14:14, Epoch : 1, Step : 8612, Training Loss : 0.73539, Training Acc : 0.739, Run Time : 0.47
INFO:root:2019-05-11 01:14:23, Epoch : 1, Step : 8613, Training Loss : 0.65172, Training Acc : 0.739, Run Time : 8.85
INFO:root:2019-05-11 01:14:23, Epoch : 1, Step : 8614, Training Loss : 0.75940, Training Acc : 0.650, Run Time : 0.45
INFO:root:2019-05-11 01:14:31, Epoch : 1, Step : 8615, Training Loss : 0.74957, Training Acc : 0.650, Run Time : 8.03
INFO:root:2019-05-11 01:14:32, Epoch : 1, Step : 8616, Training Loss : 0.78693, Training Acc : 0.728, Run Time : 0.42
INFO:root:2019-05-11 01:14:32, Epoch : 1, Step : 8617, Training Loss : 0.60380, Training Acc : 0.750, Run Time : 0.48
INFO:root:2019-05-11 01:14:33, Epoch : 1, Step : 8618, Training Loss : 0.68968, Training Acc : 0.661, Run Time : 0.45
INFO:root:2019-05-11 01:14:33, Epoch : 1, Step : 8619, Training Loss : 0.59428, Training Acc : 0.683, Run Time : 0.54
INFO:root:2019-05-11 01:14:44, Epoch : 1, Step : 8620, Training Loss : 0.43298, Training Acc : 0.822, Run Time : 10.67
INFO:root:2019-05-11 01:14:44, Epoch : 1, Step : 8621, Training Loss : 0.87285, Training Acc : 0.578, Run Time : 0.45
INFO:root:2019-05-11 01:14:45, Epoch : 1, Step : 8622, Training Loss : 0.84342, Training Acc : 0.567, Run Time : 0.47
INFO:root:2019-05-11 01:14:45, Epoch : 1, Step : 8623, Training Loss : 0.74024, Training Acc : 0.656, Run Time : 0.45
INFO:root:2019-05-11 01:14:53, Epoch : 1, Step : 8624, Training Loss : 0.94770, Training Acc : 0.617, Run Time : 7.53
INFO:root:2019-05-11 01:14:54, Epoch : 1, Step : 8625, Training Loss : 0.92577, Training Acc : 0.606, Run Time : 0.75
INFO:root:2019-05-11 01:14:54, Epoch : 1, Step : 8626, Training Loss : 0.58159, Training Acc : 0.683, Run Time : 0.76
INFO:root:2019-05-11 01:14:56, Epoch : 1, Step : 8627, Training Loss : 0.52929, Training Acc : 0.744, Run Time : 1.19
INFO:root:2019-05-11 01:15:09, Epoch : 1, Step : 8628, Training Loss : 0.58597, Training Acc : 0.767, Run Time : 12.93
INFO:root:2019-05-11 01:15:09, Epoch : 1, Step : 8629, Training Loss : 0.52607, Training Acc : 0.783, Run Time : 0.31
INFO:root:2019-05-11 01:15:09, Epoch : 1, Step : 8630, Training Loss : 0.51188, Training Acc : 0.794, Run Time : 0.24
INFO:root:2019-05-11 01:15:10, Epoch : 1, Step : 8631, Training Loss : 0.76027, Training Acc : 0.661, Run Time : 0.50
INFO:root:2019-05-11 01:15:11, Epoch : 1, Step : 8632, Training Loss : 0.64267, Training Acc : 0.717, Run Time : 1.31
INFO:root:2019-05-11 01:15:23, Epoch : 1, Step : 8633, Training Loss : 0.46242, Training Acc : 0.778, Run Time : 11.66
INFO:root:2019-05-11 01:15:23, Epoch : 1, Step : 8634, Training Loss : 0.36329, Training Acc : 0.833, Run Time : 0.76
INFO:root:2019-05-11 01:15:24, Epoch : 1, Step : 8635, Training Loss : 0.36075, Training Acc : 0.839, Run Time : 0.50
INFO:root:2019-05-11 01:15:24, Epoch : 1, Step : 8636, Training Loss : 0.41182, Training Acc : 0.828, Run Time : 0.42
INFO:root:2019-05-11 01:15:25, Epoch : 1, Step : 8637, Training Loss : 0.29968, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-11 01:15:34, Epoch : 1, Step : 8638, Training Loss : 0.25458, Training Acc : 0.917, Run Time : 9.01
INFO:root:2019-05-11 01:15:34, Epoch : 1, Step : 8639, Training Loss : 0.55532, Training Acc : 0.744, Run Time : 0.44
INFO:root:2019-05-11 01:15:35, Epoch : 1, Step : 8640, Training Loss : 0.40978, Training Acc : 0.822, Run Time : 0.42
INFO:root:2019-05-11 01:15:35, Epoch : 1, Step : 8641, Training Loss : 0.53339, Training Acc : 0.694, Run Time : 0.45
INFO:root:2019-05-11 01:15:44, Epoch : 1, Step : 8642, Training Loss : 0.46771, Training Acc : 0.739, Run Time : 9.05
INFO:root:2019-05-11 01:15:45, Epoch : 1, Step : 8643, Training Loss : 0.32791, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-11 01:15:46, Epoch : 1, Step : 8644, Training Loss : 0.29109, Training Acc : 0.856, Run Time : 1.11
INFO:root:2019-05-11 01:15:46, Epoch : 1, Step : 8645, Training Loss : 0.36578, Training Acc : 0.856, Run Time : 0.48
INFO:root:2019-05-11 01:15:56, Epoch : 1, Step : 8646, Training Loss : 0.72570, Training Acc : 0.700, Run Time : 9.98
INFO:root:2019-05-11 01:15:56, Epoch : 1, Step : 8647, Training Loss : 0.91423, Training Acc : 0.606, Run Time : 0.29
INFO:root:2019-05-11 01:15:57, Epoch : 1, Step : 8648, Training Loss : 1.00850, Training Acc : 0.606, Run Time : 0.72
INFO:root:2019-05-11 01:15:58, Epoch : 1, Step : 8649, Training Loss : 0.51194, Training Acc : 0.794, Run Time : 0.67
INFO:root:2019-05-11 01:16:01, Epoch : 1, Step : 8650, Training Loss : 0.67320, Training Acc : 0.722, Run Time : 2.93
INFO:root:2019-05-11 01:16:02, Epoch : 1, Step : 8651, Training Loss : 0.87914, Training Acc : 0.583, Run Time : 1.73
INFO:root:2019-05-11 01:16:03, Epoch : 1, Step : 8652, Training Loss : 0.57240, Training Acc : 0.689, Run Time : 0.46
INFO:root:2019-05-11 01:16:16, Epoch : 1, Step : 8653, Training Loss : 0.55621, Training Acc : 0.744, Run Time : 13.61
INFO:root:2019-05-11 01:16:17, Epoch : 1, Step : 8654, Training Loss : 0.58844, Training Acc : 0.794, Run Time : 0.74
INFO:root:2019-05-11 01:16:20, Epoch : 1, Step : 8655, Training Loss : 0.36039, Training Acc : 0.850, Run Time : 2.40
INFO:root:2019-05-11 01:16:20, Epoch : 1, Step : 8656, Training Loss : 0.37602, Training Acc : 0.833, Run Time : 0.47
INFO:root:2019-05-11 01:16:21, Epoch : 1, Step : 8657, Training Loss : 0.45146, Training Acc : 0.783, Run Time : 0.47
INFO:root:2019-05-11 01:16:21, Epoch : 1, Step : 8658, Training Loss : 0.72164, Training Acc : 0.589, Run Time : 0.72
INFO:root:2019-05-11 01:16:33, Epoch : 1, Step : 8659, Training Loss : 0.50138, Training Acc : 0.744, Run Time : 12.04
INFO:root:2019-05-11 01:16:34, Epoch : 1, Step : 8660, Training Loss : 0.72894, Training Acc : 0.622, Run Time : 0.25
INFO:root:2019-05-11 01:16:34, Epoch : 1, Step : 8661, Training Loss : 0.69120, Training Acc : 0.650, Run Time : 0.45
INFO:root:2019-05-11 01:16:35, Epoch : 1, Step : 8662, Training Loss : 0.36669, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-11 01:16:35, Epoch : 1, Step : 8663, Training Loss : 0.37530, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-11 01:16:43, Epoch : 1, Step : 8664, Training Loss : 0.26256, Training Acc : 0.900, Run Time : 8.22
INFO:root:2019-05-11 01:16:44, Epoch : 1, Step : 8665, Training Loss : 0.76759, Training Acc : 0.606, Run Time : 0.41
INFO:root:2019-05-11 01:16:45, Epoch : 1, Step : 8666, Training Loss : 0.54475, Training Acc : 0.744, Run Time : 1.24
INFO:root:2019-05-11 01:16:45, Epoch : 1, Step : 8667, Training Loss : 0.50088, Training Acc : 0.783, Run Time : 0.39
INFO:root:2019-05-11 01:16:58, Epoch : 1, Step : 8668, Training Loss : 0.33790, Training Acc : 0.878, Run Time : 12.95
INFO:root:2019-05-11 01:16:59, Epoch : 1, Step : 8669, Training Loss : 0.34789, Training Acc : 0.883, Run Time : 0.37
INFO:root:2019-05-11 01:16:59, Epoch : 1, Step : 8670, Training Loss : 0.45811, Training Acc : 0.767, Run Time : 0.45
INFO:root:2019-05-11 01:17:00, Epoch : 1, Step : 8671, Training Loss : 0.29536, Training Acc : 0.911, Run Time : 1.00
INFO:root:2019-05-11 01:17:00, Epoch : 1, Step : 8672, Training Loss : 0.30653, Training Acc : 0.889, Run Time : 0.44
INFO:root:2019-05-11 01:17:10, Epoch : 1, Step : 8673, Training Loss : 0.35396, Training Acc : 0.867, Run Time : 9.69
INFO:root:2019-05-11 01:17:11, Epoch : 1, Step : 8674, Training Loss : 0.30882, Training Acc : 0.911, Run Time : 0.61
INFO:root:2019-05-11 01:17:11, Epoch : 1, Step : 8675, Training Loss : 0.42588, Training Acc : 0.822, Run Time : 0.58
INFO:root:2019-05-11 01:17:12, Epoch : 1, Step : 8676, Training Loss : 0.46390, Training Acc : 0.778, Run Time : 0.45
INFO:root:2019-05-11 01:17:22, Epoch : 1, Step : 8677, Training Loss : 0.53696, Training Acc : 0.711, Run Time : 9.75
INFO:root:2019-05-11 01:17:22, Epoch : 1, Step : 8678, Training Loss : 0.56424, Training Acc : 0.717, Run Time : 0.36
INFO:root:2019-05-11 01:17:22, Epoch : 1, Step : 8679, Training Loss : 0.23606, Training Acc : 0.950, Run Time : 0.54
INFO:root:2019-05-11 01:17:23, Epoch : 1, Step : 8680, Training Loss : 0.33675, Training Acc : 0.861, Run Time : 0.47
INFO:root:2019-05-11 01:17:23, Epoch : 1, Step : 8681, Training Loss : 0.39777, Training Acc : 0.822, Run Time : 0.44
INFO:root:2019-05-11 01:17:36, Epoch : 1, Step : 8682, Training Loss : 0.37569, Training Acc : 0.850, Run Time : 12.32
INFO:root:2019-05-11 01:17:36, Epoch : 1, Step : 8683, Training Loss : 0.30289, Training Acc : 0.856, Run Time : 0.42
INFO:root:2019-05-11 01:17:43, Epoch : 1, Step : 8684, Training Loss : 0.37744, Training Acc : 0.822, Run Time : 6.65
INFO:root:2019-05-11 01:17:44, Epoch : 1, Step : 8685, Training Loss : 0.44678, Training Acc : 0.806, Run Time : 0.88
INFO:root:2019-05-11 01:17:44, Epoch : 1, Step : 8686, Training Loss : 0.39049, Training Acc : 0.850, Run Time : 0.44
INFO:root:2019-05-11 01:17:45, Epoch : 1, Step : 8687, Training Loss : 0.28559, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-11 01:17:45, Epoch : 1, Step : 8688, Training Loss : 0.35244, Training Acc : 0.833, Run Time : 0.46
INFO:root:2019-05-11 01:17:53, Epoch : 1, Step : 8689, Training Loss : 0.44947, Training Acc : 0.778, Run Time : 8.15
INFO:root:2019-05-11 01:17:54, Epoch : 1, Step : 8690, Training Loss : 0.43394, Training Acc : 0.794, Run Time : 0.46
INFO:root:2019-05-11 01:17:54, Epoch : 1, Step : 8691, Training Loss : 0.34718, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-11 01:17:54, Epoch : 1, Step : 8692, Training Loss : 0.32151, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-11 01:18:04, Epoch : 1, Step : 8693, Training Loss : 0.42853, Training Acc : 0.811, Run Time : 9.79
INFO:root:2019-05-11 01:18:05, Epoch : 1, Step : 8694, Training Loss : 0.35307, Training Acc : 0.828, Run Time : 0.44
INFO:root:2019-05-11 01:18:05, Epoch : 1, Step : 8695, Training Loss : 0.35579, Training Acc : 0.878, Run Time : 0.54
INFO:root:2019-05-11 01:18:06, Epoch : 1, Step : 8696, Training Loss : 0.32082, Training Acc : 0.850, Run Time : 0.45
INFO:root:2019-05-11 01:18:12, Epoch : 1, Step : 8697, Training Loss : 0.29751, Training Acc : 0.883, Run Time : 6.69
INFO:root:2019-05-11 01:18:13, Epoch : 1, Step : 8698, Training Loss : 0.31818, Training Acc : 0.878, Run Time : 0.44
INFO:root:2019-05-11 01:18:13, Epoch : 1, Step : 8699, Training Loss : 0.26256, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-11 01:18:22, Epoch : 1, Step : 8700, Training Loss : 0.43545, Training Acc : 0.789, Run Time : 8.44
INFO:root:2019-05-11 01:18:23, Epoch : 1, Step : 8701, Training Loss : 0.36197, Training Acc : 0.822, Run Time : 0.94
INFO:root:2019-05-11 01:18:23, Epoch : 1, Step : 8702, Training Loss : 0.42504, Training Acc : 0.789, Run Time : 0.39
INFO:root:2019-05-11 01:18:24, Epoch : 1, Step : 8703, Training Loss : 0.39469, Training Acc : 0.806, Run Time : 0.46
INFO:root:2019-05-11 01:18:33, Epoch : 1, Step : 8704, Training Loss : 0.31310, Training Acc : 0.889, Run Time : 9.27
INFO:root:2019-05-11 01:18:33, Epoch : 1, Step : 8705, Training Loss : 0.23715, Training Acc : 0.911, Run Time : 0.64
INFO:root:2019-05-11 01:18:34, Epoch : 1, Step : 8706, Training Loss : 0.29955, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-11 01:18:34, Epoch : 1, Step : 8707, Training Loss : 0.38776, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-11 01:18:35, Epoch : 1, Step : 8708, Training Loss : 0.38546, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-11 01:18:43, Epoch : 1, Step : 8709, Training Loss : 0.44720, Training Acc : 0.772, Run Time : 8.15
INFO:root:2019-05-11 01:18:43, Epoch : 1, Step : 8710, Training Loss : 0.42707, Training Acc : 0.783, Run Time : 0.46
INFO:root:2019-05-11 01:18:44, Epoch : 1, Step : 8711, Training Loss : 0.41321, Training Acc : 0.806, Run Time : 0.49
INFO:root:2019-05-11 01:18:44, Epoch : 1, Step : 8712, Training Loss : 0.51123, Training Acc : 0.678, Run Time : 0.46
INFO:root:2019-05-11 01:18:54, Epoch : 1, Step : 8713, Training Loss : 0.28204, Training Acc : 0.894, Run Time : 9.94
INFO:root:2019-05-11 01:18:55, Epoch : 1, Step : 8714, Training Loss : 0.37754, Training Acc : 0.839, Run Time : 0.44
INFO:root:2019-05-11 01:18:55, Epoch : 1, Step : 8715, Training Loss : 0.44245, Training Acc : 0.761, Run Time : 0.47
INFO:root:2019-05-11 01:18:56, Epoch : 1, Step : 8716, Training Loss : 0.34589, Training Acc : 0.844, Run Time : 0.44
INFO:root:2019-05-11 01:19:04, Epoch : 1, Step : 8717, Training Loss : 0.28484, Training Acc : 0.894, Run Time : 8.06
INFO:root:2019-05-11 01:19:04, Epoch : 1, Step : 8718, Training Loss : 0.34818, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-11 01:19:05, Epoch : 1, Step : 8719, Training Loss : 0.38001, Training Acc : 0.850, Run Time : 0.49
INFO:root:2019-05-11 01:19:05, Epoch : 1, Step : 8720, Training Loss : 0.38607, Training Acc : 0.844, Run Time : 0.49
INFO:root:2019-05-11 01:19:14, Epoch : 1, Step : 8721, Training Loss : 0.28363, Training Acc : 0.867, Run Time : 8.53
INFO:root:2019-05-11 01:19:14, Epoch : 1, Step : 8722, Training Loss : 0.28049, Training Acc : 0.906, Run Time : 0.49
INFO:root:2019-05-11 01:19:15, Epoch : 1, Step : 8723, Training Loss : 0.49002, Training Acc : 0.733, Run Time : 0.49
INFO:root:2019-05-11 01:19:15, Epoch : 1, Step : 8724, Training Loss : 0.50328, Training Acc : 0.739, Run Time : 0.44
INFO:root:2019-05-11 01:19:26, Epoch : 1, Step : 8725, Training Loss : 0.35076, Training Acc : 0.839, Run Time : 10.69
INFO:root:2019-05-11 01:19:26, Epoch : 1, Step : 8726, Training Loss : 0.46015, Training Acc : 0.739, Run Time : 0.35
INFO:root:2019-05-11 01:19:27, Epoch : 1, Step : 8727, Training Loss : 0.47355, Training Acc : 0.744, Run Time : 0.75
INFO:root:2019-05-11 01:19:28, Epoch : 1, Step : 8728, Training Loss : 0.39957, Training Acc : 0.861, Run Time : 0.87
INFO:root:2019-05-11 01:19:28, Epoch : 1, Step : 8729, Training Loss : 0.47798, Training Acc : 0.756, Run Time : 0.47
INFO:root:2019-05-11 01:19:36, Epoch : 1, Step : 8730, Training Loss : 0.45321, Training Acc : 0.728, Run Time : 7.83
INFO:root:2019-05-11 01:19:37, Epoch : 1, Step : 8731, Training Loss : 0.44406, Training Acc : 0.778, Run Time : 1.33
INFO:root:2019-05-11 01:19:38, Epoch : 1, Step : 8732, Training Loss : 0.58996, Training Acc : 0.733, Run Time : 0.49
INFO:root:2019-05-11 01:19:38, Epoch : 1, Step : 8733, Training Loss : 0.74069, Training Acc : 0.650, Run Time : 0.49
INFO:root:2019-05-11 01:19:44, Epoch : 1, Step : 8734, Training Loss : 0.48972, Training Acc : 0.772, Run Time : 5.73
INFO:root:2019-05-11 01:19:45, Epoch : 1, Step : 8735, Training Loss : 0.41425, Training Acc : 0.794, Run Time : 0.44
INFO:root:2019-05-11 01:19:57, Epoch : 1, Step : 8736, Training Loss : 1.01327, Training Acc : 0.494, Run Time : 12.09
INFO:root:2019-05-11 01:19:57, Epoch : 1, Step : 8737, Training Loss : 0.58742, Training Acc : 0.661, Run Time : 0.32
INFO:root:2019-05-11 01:19:57, Epoch : 1, Step : 8738, Training Loss : 0.43705, Training Acc : 0.833, Run Time : 0.29
INFO:root:2019-05-11 01:19:59, Epoch : 1, Step : 8739, Training Loss : 0.37969, Training Acc : 0.800, Run Time : 1.67
INFO:root:2019-05-11 01:20:08, Epoch : 1, Step : 8740, Training Loss : 0.53115, Training Acc : 0.744, Run Time : 9.20
INFO:root:2019-05-11 01:20:08, Epoch : 1, Step : 8741, Training Loss : 0.57546, Training Acc : 0.694, Run Time : 0.22
INFO:root:2019-05-11 01:20:09, Epoch : 1, Step : 8742, Training Loss : 0.34363, Training Acc : 0.861, Run Time : 0.26
INFO:root:2019-05-11 01:20:09, Epoch : 1, Step : 8743, Training Loss : 0.59901, Training Acc : 0.689, Run Time : 0.60
INFO:root:2019-05-11 01:20:10, Epoch : 1, Step : 8744, Training Loss : 0.53039, Training Acc : 0.761, Run Time : 0.42
INFO:root:2019-05-11 01:20:21, Epoch : 1, Step : 8745, Training Loss : 0.59274, Training Acc : 0.678, Run Time : 10.92
INFO:root:2019-05-11 01:20:21, Epoch : 1, Step : 8746, Training Loss : 0.41158, Training Acc : 0.806, Run Time : 0.49
INFO:root:2019-05-11 01:20:22, Epoch : 1, Step : 8747, Training Loss : 0.50851, Training Acc : 0.761, Run Time : 0.44
INFO:root:2019-05-11 01:20:22, Epoch : 1, Step : 8748, Training Loss : 0.52787, Training Acc : 0.728, Run Time : 0.46
INFO:root:2019-05-11 01:20:22, Epoch : 1, Step : 8749, Training Loss : 0.69692, Training Acc : 0.672, Run Time : 0.43
INFO:root:2019-05-11 01:20:27, Epoch : 1, Step : 8750, Training Loss : 0.47223, Training Acc : 0.828, Run Time : 4.16
INFO:root:2019-05-11 01:20:30, Epoch : 1, Step : 8751, Training Loss : 0.57027, Training Acc : 0.661, Run Time : 3.78
INFO:root:2019-05-11 01:20:33, Epoch : 1, Step : 8752, Training Loss : 0.70217, Training Acc : 0.656, Run Time : 2.25
INFO:root:2019-05-11 01:20:33, Epoch : 1, Step : 8753, Training Loss : 0.40254, Training Acc : 0.822, Run Time : 0.45
INFO:root:2019-05-11 01:20:43, Epoch : 1, Step : 8754, Training Loss : 0.59793, Training Acc : 0.694, Run Time : 9.61
INFO:root:2019-05-11 01:20:43, Epoch : 1, Step : 8755, Training Loss : 0.60352, Training Acc : 0.700, Run Time : 0.60
INFO:root:2019-05-11 01:20:44, Epoch : 1, Step : 8756, Training Loss : 0.37937, Training Acc : 0.806, Run Time : 0.65
INFO:root:2019-05-11 01:20:48, Epoch : 1, Step : 8757, Training Loss : 0.53707, Training Acc : 0.722, Run Time : 3.62
INFO:root:2019-05-11 01:20:49, Epoch : 1, Step : 8758, Training Loss : 0.44161, Training Acc : 0.794, Run Time : 1.09
INFO:root:2019-05-11 01:20:49, Epoch : 1, Step : 8759, Training Loss : 0.43465, Training Acc : 0.811, Run Time : 0.50
INFO:root:2019-05-11 01:20:54, Epoch : 1, Step : 8760, Training Loss : 0.35496, Training Acc : 0.872, Run Time : 4.76
INFO:root:2019-05-11 01:20:54, Epoch : 1, Step : 8761, Training Loss : 0.28907, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-11 01:21:08, Epoch : 1, Step : 8762, Training Loss : 0.32479, Training Acc : 0.900, Run Time : 13.41
INFO:root:2019-05-11 01:21:08, Epoch : 1, Step : 8763, Training Loss : 0.24381, Training Acc : 0.944, Run Time : 0.29
INFO:root:2019-05-11 01:21:08, Epoch : 1, Step : 8764, Training Loss : 0.48009, Training Acc : 0.767, Run Time : 0.44
INFO:root:2019-05-11 01:21:20, Epoch : 1, Step : 8765, Training Loss : 0.35757, Training Acc : 0.856, Run Time : 11.46
INFO:root:2019-05-11 01:21:20, Epoch : 1, Step : 8766, Training Loss : 0.24241, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-11 01:21:21, Epoch : 1, Step : 8767, Training Loss : 0.36651, Training Acc : 0.861, Run Time : 0.25
INFO:root:2019-05-11 01:21:21, Epoch : 1, Step : 8768, Training Loss : 0.24928, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-11 01:21:21, Epoch : 1, Step : 8769, Training Loss : 0.31316, Training Acc : 0.894, Run Time : 0.41
INFO:root:2019-05-11 01:21:34, Epoch : 1, Step : 8770, Training Loss : 0.33910, Training Acc : 0.872, Run Time : 12.89
INFO:root:2019-05-11 01:21:35, Epoch : 1, Step : 8771, Training Loss : 0.34957, Training Acc : 0.844, Run Time : 0.27
INFO:root:2019-05-11 01:21:35, Epoch : 1, Step : 8772, Training Loss : 0.37997, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-11 01:21:36, Epoch : 1, Step : 8773, Training Loss : 0.28220, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-11 01:21:36, Epoch : 1, Step : 8774, Training Loss : 0.18414, Training Acc : 0.950, Run Time : 0.53
INFO:root:2019-05-11 01:21:49, Epoch : 1, Step : 8775, Training Loss : 0.22334, Training Acc : 0.911, Run Time : 12.76
INFO:root:2019-05-11 01:21:49, Epoch : 1, Step : 8776, Training Loss : 0.39493, Training Acc : 0.828, Run Time : 0.29
INFO:root:2019-05-11 01:21:50, Epoch : 1, Step : 8777, Training Loss : 0.51418, Training Acc : 0.722, Run Time : 0.43
INFO:root:2019-05-11 01:21:50, Epoch : 1, Step : 8778, Training Loss : 0.75560, Training Acc : 0.550, Run Time : 0.45
INFO:root:2019-05-11 01:21:51, Epoch : 1, Step : 8779, Training Loss : 0.53655, Training Acc : 0.756, Run Time : 0.53
INFO:root:2019-05-11 01:21:55, Epoch : 1, Step : 8780, Training Loss : 0.93256, Training Acc : 0.422, Run Time : 4.91
INFO:root:2019-05-11 01:21:56, Epoch : 1, Step : 8781, Training Loss : 0.53096, Training Acc : 0.733, Run Time : 0.40
INFO:root:2019-05-11 01:22:05, Epoch : 1, Step : 8782, Training Loss : 0.44001, Training Acc : 0.772, Run Time : 9.22
INFO:root:2019-05-11 01:22:05, Epoch : 1, Step : 8783, Training Loss : 0.36272, Training Acc : 0.867, Run Time : 0.40
INFO:root:2019-05-11 01:22:06, Epoch : 1, Step : 8784, Training Loss : 0.46325, Training Acc : 0.817, Run Time : 0.48
INFO:root:2019-05-11 01:22:06, Epoch : 1, Step : 8785, Training Loss : 0.65907, Training Acc : 0.689, Run Time : 0.47
INFO:root:2019-05-11 01:22:16, Epoch : 1, Step : 8786, Training Loss : 0.32724, Training Acc : 0.867, Run Time : 9.53
INFO:root:2019-05-11 01:22:16, Epoch : 1, Step : 8787, Training Loss : 0.45635, Training Acc : 0.772, Run Time : 0.46
INFO:root:2019-05-11 01:22:17, Epoch : 1, Step : 8788, Training Loss : 0.33706, Training Acc : 0.883, Run Time : 0.66
INFO:root:2019-05-11 01:22:18, Epoch : 1, Step : 8789, Training Loss : 0.44387, Training Acc : 0.783, Run Time : 0.43
INFO:root:2019-05-11 01:22:25, Epoch : 1, Step : 8790, Training Loss : 0.35439, Training Acc : 0.878, Run Time : 7.75
INFO:root:2019-05-11 01:22:26, Epoch : 1, Step : 8791, Training Loss : 0.43375, Training Acc : 0.789, Run Time : 0.43
INFO:root:2019-05-11 01:22:26, Epoch : 1, Step : 8792, Training Loss : 0.30808, Training Acc : 0.883, Run Time : 0.66
INFO:root:2019-05-11 01:22:28, Epoch : 1, Step : 8793, Training Loss : 0.21843, Training Acc : 0.939, Run Time : 1.54
INFO:root:2019-05-11 01:22:38, Epoch : 1, Step : 8794, Training Loss : 0.48342, Training Acc : 0.756, Run Time : 9.76
INFO:root:2019-05-11 01:22:38, Epoch : 1, Step : 8795, Training Loss : 0.23229, Training Acc : 0.906, Run Time : 0.44
INFO:root:2019-05-11 01:22:39, Epoch : 1, Step : 8796, Training Loss : 0.31470, Training Acc : 0.856, Run Time : 0.45
INFO:root:2019-05-11 01:22:39, Epoch : 1, Step : 8797, Training Loss : 0.28828, Training Acc : 0.883, Run Time : 0.72
INFO:root:2019-05-11 01:22:47, Epoch : 1, Step : 8798, Training Loss : 0.26111, Training Acc : 0.900, Run Time : 7.69
INFO:root:2019-05-11 01:22:48, Epoch : 1, Step : 8799, Training Loss : 0.25952, Training Acc : 0.906, Run Time : 1.51
INFO:root:2019-05-11 01:22:50, Epoch : 1, Step : 8800, Training Loss : 0.63856, Training Acc : 0.633, Run Time : 1.07
INFO:root:2019-05-11 01:22:50, Epoch : 1, Step : 8801, Training Loss : 0.90241, Training Acc : 0.661, Run Time : 0.95
INFO:root:2019-05-11 01:22:51, Epoch : 1, Step : 8802, Training Loss : 0.82254, Training Acc : 0.683, Run Time : 0.46
INFO:root:2019-05-11 01:23:02, Epoch : 1, Step : 8803, Training Loss : 0.64377, Training Acc : 0.756, Run Time : 11.18
INFO:root:2019-05-11 01:23:02, Epoch : 1, Step : 8804, Training Loss : 0.54697, Training Acc : 0.733, Run Time : 0.37
INFO:root:2019-05-11 01:23:03, Epoch : 1, Step : 8805, Training Loss : 0.42908, Training Acc : 0.806, Run Time : 0.36
INFO:root:2019-05-11 01:23:03, Epoch : 1, Step : 8806, Training Loss : 0.35384, Training Acc : 0.833, Run Time : 0.46
INFO:root:2019-05-11 01:23:04, Epoch : 1, Step : 8807, Training Loss : 0.36677, Training Acc : 0.822, Run Time : 0.30
INFO:root:2019-05-11 01:23:13, Epoch : 1, Step : 8808, Training Loss : 0.37025, Training Acc : 0.800, Run Time : 9.13
INFO:root:2019-05-11 01:23:13, Epoch : 1, Step : 8809, Training Loss : 0.41200, Training Acc : 0.789, Run Time : 0.44
INFO:root:2019-05-11 01:23:14, Epoch : 1, Step : 8810, Training Loss : 0.32853, Training Acc : 0.822, Run Time : 0.48
INFO:root:2019-05-11 01:23:14, Epoch : 1, Step : 8811, Training Loss : 0.32347, Training Acc : 0.828, Run Time : 0.46
INFO:root:2019-05-11 01:23:23, Epoch : 1, Step : 8812, Training Loss : 0.26774, Training Acc : 0.894, Run Time : 8.82
INFO:root:2019-05-11 01:23:23, Epoch : 1, Step : 8813, Training Loss : 0.33286, Training Acc : 0.828, Run Time : 0.24
INFO:root:2019-05-11 01:23:24, Epoch : 1, Step : 8814, Training Loss : 0.22242, Training Acc : 0.894, Run Time : 0.61
INFO:root:2019-05-11 01:23:24, Epoch : 1, Step : 8815, Training Loss : 0.46276, Training Acc : 0.728, Run Time : 0.70
INFO:root:2019-05-11 01:23:32, Epoch : 1, Step : 8816, Training Loss : 0.45377, Training Acc : 0.756, Run Time : 7.78
INFO:root:2019-05-11 01:23:33, Epoch : 1, Step : 8817, Training Loss : 0.32186, Training Acc : 0.794, Run Time : 0.42
INFO:root:2019-05-11 01:23:34, Epoch : 1, Step : 8818, Training Loss : 0.20403, Training Acc : 0.928, Run Time : 0.86
INFO:root:2019-05-11 01:23:34, Epoch : 1, Step : 8819, Training Loss : 0.18596, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-11 01:23:42, Epoch : 1, Step : 8820, Training Loss : 0.18318, Training Acc : 0.922, Run Time : 8.25
INFO:root:2019-05-11 01:23:43, Epoch : 1, Step : 8821, Training Loss : 0.15959, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-11 01:23:43, Epoch : 1, Step : 8822, Training Loss : 0.22514, Training Acc : 0.894, Run Time : 0.62
INFO:root:2019-05-11 01:23:44, Epoch : 1, Step : 8823, Training Loss : 0.12086, Training Acc : 0.956, Run Time : 0.34
INFO:root:2019-05-11 01:23:56, Epoch : 1, Step : 8824, Training Loss : 0.22680, Training Acc : 0.883, Run Time : 12.12
INFO:root:2019-05-11 01:23:56, Epoch : 1, Step : 8825, Training Loss : 0.29866, Training Acc : 0.861, Run Time : 0.30
INFO:root:2019-05-11 01:23:56, Epoch : 1, Step : 8826, Training Loss : 0.10390, Training Acc : 0.978, Run Time : 0.38
INFO:root:2019-05-11 01:24:11, Epoch : 1, Step : 8827, Training Loss : 0.21187, Training Acc : 0.894, Run Time : 14.08
INFO:root:2019-05-11 01:24:11, Epoch : 1, Step : 8828, Training Loss : 0.21523, Training Acc : 0.906, Run Time : 0.40
INFO:root:2019-05-11 01:24:11, Epoch : 1, Step : 8829, Training Loss : 0.13075, Training Acc : 0.939, Run Time : 0.23
INFO:root:2019-05-11 01:24:12, Epoch : 1, Step : 8830, Training Loss : 0.09473, Training Acc : 0.972, Run Time : 0.45
INFO:root:2019-05-11 01:24:12, Epoch : 1, Step : 8831, Training Loss : 0.08347, Training Acc : 0.989, Run Time : 0.50
INFO:root:2019-05-11 01:24:21, Epoch : 1, Step : 8832, Training Loss : 0.06586, Training Acc : 1.000, Run Time : 8.51
INFO:root:2019-05-11 01:24:21, Epoch : 1, Step : 8833, Training Loss : 0.23938, Training Acc : 0.894, Run Time : 0.54
INFO:root:2019-05-11 01:24:22, Epoch : 1, Step : 8834, Training Loss : 0.14706, Training Acc : 0.961, Run Time : 0.54
INFO:root:2019-05-11 01:24:22, Epoch : 1, Step : 8835, Training Loss : 0.13542, Training Acc : 0.961, Run Time : 0.46
INFO:root:2019-05-11 01:24:33, Epoch : 1, Step : 8836, Training Loss : 0.25360, Training Acc : 0.889, Run Time : 10.63
INFO:root:2019-05-11 01:24:33, Epoch : 1, Step : 8837, Training Loss : 0.28075, Training Acc : 0.856, Run Time : 0.40
INFO:root:2019-05-11 01:24:34, Epoch : 1, Step : 8838, Training Loss : 0.32266, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-11 01:24:35, Epoch : 1, Step : 8839, Training Loss : 0.38584, Training Acc : 0.839, Run Time : 1.09
INFO:root:2019-05-11 01:24:36, Epoch : 1, Step : 8840, Training Loss : 0.09111, Training Acc : 0.978, Run Time : 1.31
INFO:root:2019-05-11 01:24:46, Epoch : 1, Step : 8841, Training Loss : 0.19783, Training Acc : 0.928, Run Time : 10.05
INFO:root:2019-05-11 01:24:47, Epoch : 1, Step : 8842, Training Loss : 0.24949, Training Acc : 0.894, Run Time : 0.43
INFO:root:2019-05-11 01:24:47, Epoch : 1, Step : 8843, Training Loss : 0.15079, Training Acc : 0.956, Run Time : 0.59
INFO:root:2019-05-11 01:24:48, Epoch : 1, Step : 8844, Training Loss : 0.05957, Training Acc : 0.983, Run Time : 0.94
INFO:root:2019-05-11 01:24:50, Epoch : 1, Step : 8845, Training Loss : 0.12152, Training Acc : 0.956, Run Time : 1.54
INFO:root:2019-05-11 01:24:59, Epoch : 1, Step : 8846, Training Loss : 0.08113, Training Acc : 0.989, Run Time : 9.80
INFO:root:2019-05-11 01:25:00, Epoch : 1, Step : 8847, Training Loss : 0.11107, Training Acc : 0.967, Run Time : 0.46
INFO:root:2019-05-11 01:25:00, Epoch : 1, Step : 8848, Training Loss : 0.27002, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-11 01:25:01, Epoch : 1, Step : 8849, Training Loss : 0.17792, Training Acc : 0.939, Run Time : 0.49
INFO:root:2019-05-11 01:25:03, Epoch : 1, Step : 8850, Training Loss : 0.17248, Training Acc : 0.933, Run Time : 2.03
INFO:root:2019-05-11 01:25:13, Epoch : 1, Step : 8851, Training Loss : 0.17149, Training Acc : 0.928, Run Time : 10.40
INFO:root:2019-05-11 01:25:14, Epoch : 1, Step : 8852, Training Loss : 0.18111, Training Acc : 0.933, Run Time : 0.35
INFO:root:2019-05-11 01:25:14, Epoch : 1, Step : 8853, Training Loss : 0.14132, Training Acc : 0.928, Run Time : 0.44
INFO:root:2019-05-11 01:25:14, Epoch : 1, Step : 8854, Training Loss : 0.16297, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-11 01:25:15, Epoch : 1, Step : 8855, Training Loss : 0.34903, Training Acc : 0.883, Run Time : 0.94
INFO:root:2019-05-11 01:25:26, Epoch : 1, Step : 8856, Training Loss : 0.97972, Training Acc : 0.639, Run Time : 10.67
INFO:root:2019-05-11 01:25:26, Epoch : 1, Step : 8857, Training Loss : 0.73540, Training Acc : 0.644, Run Time : 0.38
INFO:root:2019-05-11 01:25:27, Epoch : 1, Step : 8858, Training Loss : 0.96113, Training Acc : 0.644, Run Time : 0.51
INFO:root:2019-05-11 01:25:27, Epoch : 1, Step : 8859, Training Loss : 0.82644, Training Acc : 0.639, Run Time : 0.46
INFO:root:2019-05-11 01:25:37, Epoch : 1, Step : 8860, Training Loss : 0.67546, Training Acc : 0.750, Run Time : 9.46
INFO:root:2019-05-11 01:25:37, Epoch : 1, Step : 8861, Training Loss : 0.19451, Training Acc : 0.933, Run Time : 0.39
INFO:root:2019-05-11 01:25:38, Epoch : 1, Step : 8862, Training Loss : 0.27129, Training Acc : 0.900, Run Time : 0.45
INFO:root:2019-05-11 01:25:38, Epoch : 1, Step : 8863, Training Loss : 0.19276, Training Acc : 0.922, Run Time : 0.43
INFO:root:2019-05-11 01:25:40, Epoch : 1, Step : 8864, Training Loss : 0.27795, Training Acc : 0.867, Run Time : 1.94
INFO:root:2019-05-11 01:25:47, Epoch : 1, Step : 8865, Training Loss : 0.41234, Training Acc : 0.806, Run Time : 6.55
INFO:root:2019-05-11 01:25:48, Epoch : 1, Step : 8866, Training Loss : 0.32482, Training Acc : 0.856, Run Time : 0.97
INFO:root:2019-05-11 01:25:48, Epoch : 1, Step : 8867, Training Loss : 0.24409, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-11 01:25:50, Epoch : 1, Step : 8868, Training Loss : 0.28075, Training Acc : 0.861, Run Time : 1.91
INFO:root:2019-05-11 01:25:53, Epoch : 1, Step : 8869, Training Loss : 0.26710, Training Acc : 0.872, Run Time : 2.72
INFO:root:2019-05-11 01:25:55, Epoch : 1, Step : 8870, Training Loss : 0.15958, Training Acc : 0.928, Run Time : 2.38
INFO:root:2019-05-11 01:26:04, Epoch : 1, Step : 8871, Training Loss : 0.22462, Training Acc : 0.928, Run Time : 8.67
INFO:root:2019-05-11 01:26:04, Epoch : 1, Step : 8872, Training Loss : 0.24927, Training Acc : 0.872, Run Time : 0.43
INFO:root:2019-05-11 01:26:05, Epoch : 1, Step : 8873, Training Loss : 0.13977, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-11 01:26:05, Epoch : 1, Step : 8874, Training Loss : 0.21401, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-11 01:26:15, Epoch : 1, Step : 8875, Training Loss : 0.18500, Training Acc : 0.939, Run Time : 9.56
INFO:root:2019-05-11 01:26:15, Epoch : 1, Step : 8876, Training Loss : 0.19721, Training Acc : 0.906, Run Time : 0.56
INFO:root:2019-05-11 01:26:16, Epoch : 1, Step : 8877, Training Loss : 0.24409, Training Acc : 0.889, Run Time : 0.46
INFO:root:2019-05-11 01:26:16, Epoch : 1, Step : 8878, Training Loss : 0.20148, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-11 01:26:19, Epoch : 1, Step : 8879, Training Loss : 0.13208, Training Acc : 0.961, Run Time : 2.54
INFO:root:2019-05-11 01:26:20, Epoch : 1, Step : 8880, Training Loss : 0.15585, Training Acc : 0.972, Run Time : 1.38
INFO:root:2019-05-11 01:26:22, Epoch : 1, Step : 8881, Training Loss : 0.17013, Training Acc : 0.944, Run Time : 2.24
INFO:root:2019-05-11 01:26:29, Epoch : 1, Step : 8882, Training Loss : 0.17647, Training Acc : 0.944, Run Time : 6.46
INFO:root:2019-05-11 01:26:29, Epoch : 1, Step : 8883, Training Loss : 0.16395, Training Acc : 0.933, Run Time : 0.54
INFO:root:2019-05-11 01:26:36, Epoch : 1, Step : 8884, Training Loss : 0.15635, Training Acc : 0.944, Run Time : 6.66
INFO:root:2019-05-11 01:26:37, Epoch : 1, Step : 8885, Training Loss : 0.17036, Training Acc : 0.922, Run Time : 0.52
INFO:root:2019-05-11 01:26:38, Epoch : 1, Step : 8886, Training Loss : 0.12515, Training Acc : 0.972, Run Time : 1.38
INFO:root:2019-05-11 01:26:38, Epoch : 1, Step : 8887, Training Loss : 0.17397, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-11 01:26:45, Epoch : 1, Step : 8888, Training Loss : 0.12826, Training Acc : 0.944, Run Time : 6.12
INFO:root:2019-05-11 01:26:45, Epoch : 1, Step : 8889, Training Loss : 0.12417, Training Acc : 0.967, Run Time : 0.46
INFO:root:2019-05-11 01:26:54, Epoch : 1, Step : 8890, Training Loss : 0.09584, Training Acc : 0.989, Run Time : 8.96
INFO:root:2019-05-11 01:26:54, Epoch : 1, Step : 8891, Training Loss : 0.17500, Training Acc : 0.944, Run Time : 0.40
INFO:root:2019-05-11 01:26:55, Epoch : 1, Step : 8892, Training Loss : 0.22614, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-11 01:26:55, Epoch : 1, Step : 8893, Training Loss : 0.15140, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-11 01:26:56, Epoch : 1, Step : 8894, Training Loss : 0.50323, Training Acc : 0.822, Run Time : 0.64
INFO:root:2019-05-11 01:27:04, Epoch : 1, Step : 8895, Training Loss : 0.30230, Training Acc : 0.900, Run Time : 8.53
INFO:root:2019-05-11 01:27:05, Epoch : 1, Step : 8896, Training Loss : 0.27436, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-11 01:27:06, Epoch : 1, Step : 8897, Training Loss : 0.22756, Training Acc : 0.928, Run Time : 1.06
INFO:root:2019-05-11 01:27:06, Epoch : 1, Step : 8898, Training Loss : 0.37762, Training Acc : 0.867, Run Time : 0.34
INFO:root:2019-05-11 01:27:16, Epoch : 1, Step : 8899, Training Loss : 0.19508, Training Acc : 0.944, Run Time : 9.92
INFO:root:2019-05-11 01:27:17, Epoch : 1, Step : 8900, Training Loss : 0.13898, Training Acc : 0.961, Run Time : 0.44
INFO:root:2019-05-11 01:27:23, Epoch : 1, Step : 8901, Training Loss : 0.10084, Training Acc : 0.972, Run Time : 6.65
INFO:root:2019-05-11 01:27:24, Epoch : 1, Step : 8902, Training Loss : 0.07691, Training Acc : 0.983, Run Time : 0.42
INFO:root:2019-05-11 01:27:24, Epoch : 1, Step : 8903, Training Loss : 0.07647, Training Acc : 0.989, Run Time : 0.57
INFO:root:2019-05-11 01:27:32, Epoch : 1, Step : 8904, Training Loss : 0.11082, Training Acc : 0.972, Run Time : 7.40
INFO:root:2019-05-11 01:27:32, Epoch : 1, Step : 8905, Training Loss : 0.12014, Training Acc : 0.967, Run Time : 0.73
INFO:root:2019-05-11 01:27:33, Epoch : 1, Step : 8906, Training Loss : 0.13092, Training Acc : 0.978, Run Time : 0.48
INFO:root:2019-05-11 01:27:34, Epoch : 1, Step : 8907, Training Loss : 0.09906, Training Acc : 0.978, Run Time : 1.26
INFO:root:2019-05-11 01:27:35, Epoch : 1, Step : 8908, Training Loss : 0.07052, Training Acc : 0.994, Run Time : 0.48
INFO:root:2019-05-11 01:27:48, Epoch : 1, Step : 8909, Training Loss : 0.06433, Training Acc : 0.983, Run Time : 13.54
INFO:root:2019-05-11 01:27:48, Epoch : 1, Step : 8910, Training Loss : 0.13415, Training Acc : 0.950, Run Time : 0.29
INFO:root:2019-05-11 01:27:49, Epoch : 1, Step : 8911, Training Loss : 0.08351, Training Acc : 0.983, Run Time : 0.53
INFO:root:2019-05-11 01:27:49, Epoch : 1, Step : 8912, Training Loss : 0.16169, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-11 01:27:50, Epoch : 1, Step : 8913, Training Loss : 0.10651, Training Acc : 0.967, Run Time : 0.41
INFO:root:2019-05-11 01:28:00, Epoch : 1, Step : 8914, Training Loss : 0.13017, Training Acc : 0.917, Run Time : 10.22
INFO:root:2019-05-11 01:28:01, Epoch : 1, Step : 8915, Training Loss : 0.41090, Training Acc : 0.456, Run Time : 0.53
Traceback (most recent call last):
  File "wsi/bin/train.py", line 257, in <module>
    main()
  File "wsi/bin/train.py", line 253, in main
    run(args)
  File "wsi/bin/train.py", line 213, in run
    dataloader_normal_train)
  File "wsi/bin/train.py", line 55, in train_epoch
    data_normal, target_normal = next(dataiter_normal)
  File "/scratch/sg5591/pyenv/py3.6.3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 572, in __next__
    raise StopIteration
StopIteration
