INFO:root:2019-05-10 22:51:48, Epoch : 1, Step : 1, Training Loss : 0.93996, Training Acc : 0.172, Run Time : 22.75
INFO:root:2019-05-10 22:51:48, Epoch : 1, Step : 2, Training Loss : 0.84703, Training Acc : 0.211, Run Time : 0.63
INFO:root:2019-05-10 22:51:49, Epoch : 1, Step : 3, Training Loss : 0.75227, Training Acc : 0.294, Run Time : 0.44
INFO:root:2019-05-10 22:51:49, Epoch : 1, Step : 4, Training Loss : 0.64869, Training Acc : 0.644, Run Time : 0.47
INFO:root:2019-05-10 22:51:57, Epoch : 1, Step : 5, Training Loss : 0.55475, Training Acc : 0.717, Run Time : 7.58
INFO:root:2019-05-10 22:51:58, Epoch : 1, Step : 6, Training Loss : 0.61785, Training Acc : 0.700, Run Time : 0.54
INFO:root:2019-05-10 22:51:58, Epoch : 1, Step : 7, Training Loss : 0.56170, Training Acc : 0.706, Run Time : 0.45
INFO:root:2019-05-10 22:52:08, Epoch : 1, Step : 8, Training Loss : 0.64516, Training Acc : 0.689, Run Time : 10.32
INFO:root:2019-05-10 22:52:09, Epoch : 1, Step : 9, Training Loss : 0.67512, Training Acc : 0.678, Run Time : 0.97
INFO:root:2019-05-10 22:52:11, Epoch : 1, Step : 10, Training Loss : 0.61059, Training Acc : 0.689, Run Time : 1.59
INFO:root:2019-05-10 22:52:20, Epoch : 1, Step : 11, Training Loss : 0.68702, Training Acc : 0.728, Run Time : 9.34
INFO:root:2019-05-10 22:52:21, Epoch : 1, Step : 12, Training Loss : 0.74867, Training Acc : 0.661, Run Time : 0.54
INFO:root:2019-05-10 22:52:22, Epoch : 1, Step : 13, Training Loss : 0.70946, Training Acc : 0.644, Run Time : 1.15
INFO:root:2019-05-10 22:52:30, Epoch : 1, Step : 14, Training Loss : 0.74475, Training Acc : 0.622, Run Time : 7.83
INFO:root:2019-05-10 22:52:30, Epoch : 1, Step : 15, Training Loss : 0.72348, Training Acc : 0.594, Run Time : 0.40
INFO:root:2019-05-10 22:52:31, Epoch : 1, Step : 16, Training Loss : 0.64423, Training Acc : 0.611, Run Time : 1.01
INFO:root:2019-05-10 22:52:34, Epoch : 1, Step : 17, Training Loss : 0.66292, Training Acc : 0.561, Run Time : 2.70
INFO:root:2019-05-10 22:52:39, Epoch : 1, Step : 18, Training Loss : 0.57348, Training Acc : 0.639, Run Time : 5.43
INFO:root:2019-05-10 22:52:40, Epoch : 1, Step : 19, Training Loss : 0.58845, Training Acc : 0.544, Run Time : 0.44
INFO:root:2019-05-10 22:52:40, Epoch : 1, Step : 20, Training Loss : 0.59769, Training Acc : 0.683, Run Time : 0.48
INFO:root:2019-05-10 22:52:46, Epoch : 1, Step : 21, Training Loss : 0.66822, Training Acc : 0.650, Run Time : 6.08
INFO:root:2019-05-10 22:52:47, Epoch : 1, Step : 22, Training Loss : 0.59764, Training Acc : 0.622, Run Time : 0.42
INFO:root:2019-05-10 22:52:47, Epoch : 1, Step : 23, Training Loss : 0.61589, Training Acc : 0.594, Run Time : 0.43
INFO:root:2019-05-10 22:52:47, Epoch : 1, Step : 24, Training Loss : 0.70065, Training Acc : 0.533, Run Time : 0.37
INFO:root:2019-05-10 22:52:48, Epoch : 1, Step : 25, Training Loss : 0.66568, Training Acc : 0.556, Run Time : 0.75
INFO:root:2019-05-10 22:52:57, Epoch : 1, Step : 26, Training Loss : 0.70001, Training Acc : 0.556, Run Time : 8.30
INFO:root:2019-05-10 22:52:57, Epoch : 1, Step : 27, Training Loss : 0.69519, Training Acc : 0.578, Run Time : 0.62
INFO:root:2019-05-10 22:52:58, Epoch : 1, Step : 28, Training Loss : 0.61183, Training Acc : 0.644, Run Time : 0.50
INFO:root:2019-05-10 22:53:05, Epoch : 1, Step : 29, Training Loss : 0.63887, Training Acc : 0.617, Run Time : 7.54
INFO:root:2019-05-10 22:53:06, Epoch : 1, Step : 30, Training Loss : 0.58586, Training Acc : 0.672, Run Time : 0.43
INFO:root:2019-05-10 22:53:06, Epoch : 1, Step : 31, Training Loss : 0.53233, Training Acc : 0.789, Run Time : 0.42
INFO:root:2019-05-10 22:53:07, Epoch : 1, Step : 32, Training Loss : 0.50294, Training Acc : 0.794, Run Time : 0.55
INFO:root:2019-05-10 22:53:09, Epoch : 1, Step : 33, Training Loss : 0.47875, Training Acc : 0.850, Run Time : 2.24
INFO:root:2019-05-10 22:53:09, Epoch : 1, Step : 34, Training Loss : 0.61418, Training Acc : 0.622, Run Time : 0.40
INFO:root:2019-05-10 22:53:10, Epoch : 1, Step : 35, Training Loss : 0.51052, Training Acc : 0.806, Run Time : 0.37
INFO:root:2019-05-10 22:53:11, Epoch : 1, Step : 36, Training Loss : 0.49617, Training Acc : 0.761, Run Time : 1.83
INFO:root:2019-05-10 22:53:21, Epoch : 1, Step : 37, Training Loss : 0.47871, Training Acc : 0.822, Run Time : 9.32
INFO:root:2019-05-10 22:53:21, Epoch : 1, Step : 38, Training Loss : 0.48059, Training Acc : 0.744, Run Time : 0.41
INFO:root:2019-05-10 22:53:22, Epoch : 1, Step : 39, Training Loss : 0.45811, Training Acc : 0.761, Run Time : 0.37
INFO:root:2019-05-10 22:53:23, Epoch : 1, Step : 40, Training Loss : 0.44841, Training Acc : 0.833, Run Time : 1.52
INFO:root:2019-05-10 22:53:30, Epoch : 1, Step : 41, Training Loss : 0.42843, Training Acc : 0.822, Run Time : 6.72
INFO:root:2019-05-10 22:53:30, Epoch : 1, Step : 42, Training Loss : 0.42685, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-10 22:53:31, Epoch : 1, Step : 43, Training Loss : 0.42213, Training Acc : 0.839, Run Time : 1.09
INFO:root:2019-05-10 22:53:34, Epoch : 1, Step : 44, Training Loss : 0.43163, Training Acc : 0.867, Run Time : 3.23
INFO:root:2019-05-10 22:53:36, Epoch : 1, Step : 45, Training Loss : 0.46792, Training Acc : 0.828, Run Time : 1.12
INFO:root:2019-05-10 22:53:36, Epoch : 1, Step : 46, Training Loss : 0.38688, Training Acc : 0.894, Run Time : 0.37
INFO:root:2019-05-10 22:53:37, Epoch : 1, Step : 47, Training Loss : 0.42503, Training Acc : 0.800, Run Time : 0.61
INFO:root:2019-05-10 22:53:37, Epoch : 1, Step : 48, Training Loss : 0.42526, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-10 22:53:37, Epoch : 1, Step : 49, Training Loss : 0.37052, Training Acc : 0.878, Run Time : 0.43
INFO:root:2019-05-10 22:53:44, Epoch : 1, Step : 50, Training Loss : 0.40518, Training Acc : 0.867, Run Time : 7.01
INFO:root:2019-05-10 22:53:45, Epoch : 1, Step : 51, Training Loss : 0.37012, Training Acc : 0.844, Run Time : 0.64
INFO:root:2019-05-10 22:53:47, Epoch : 1, Step : 52, Training Loss : 0.39254, Training Acc : 0.878, Run Time : 1.75
INFO:root:2019-05-10 22:53:56, Epoch : 1, Step : 53, Training Loss : 0.39115, Training Acc : 0.828, Run Time : 8.92
INFO:root:2019-05-10 22:53:56, Epoch : 1, Step : 54, Training Loss : 0.38933, Training Acc : 0.806, Run Time : 0.45
INFO:root:2019-05-10 22:53:57, Epoch : 1, Step : 55, Training Loss : 0.59253, Training Acc : 0.672, Run Time : 0.37
INFO:root:2019-05-10 22:53:57, Epoch : 1, Step : 56, Training Loss : 1.14415, Training Acc : 0.461, Run Time : 0.38
INFO:root:2019-05-10 22:53:58, Epoch : 1, Step : 57, Training Loss : 1.13793, Training Acc : 0.383, Run Time : 0.63
INFO:root:2019-05-10 22:54:04, Epoch : 1, Step : 58, Training Loss : 1.06953, Training Acc : 0.533, Run Time : 6.63
INFO:root:2019-05-10 22:54:06, Epoch : 1, Step : 59, Training Loss : 0.78354, Training Acc : 0.578, Run Time : 1.51
INFO:root:2019-05-10 22:54:14, Epoch : 1, Step : 60, Training Loss : 0.45405, Training Acc : 0.794, Run Time : 8.41
INFO:root:2019-05-10 22:54:15, Epoch : 1, Step : 61, Training Loss : 0.50308, Training Acc : 0.789, Run Time : 0.88
INFO:root:2019-05-10 22:54:23, Epoch : 1, Step : 62, Training Loss : 0.52382, Training Acc : 0.711, Run Time : 7.66
INFO:root:2019-05-10 22:54:24, Epoch : 1, Step : 63, Training Loss : 0.59677, Training Acc : 0.650, Run Time : 0.94
INFO:root:2019-05-10 22:54:24, Epoch : 1, Step : 64, Training Loss : 0.61107, Training Acc : 0.639, Run Time : 0.40
INFO:root:2019-05-10 22:54:25, Epoch : 1, Step : 65, Training Loss : 0.50651, Training Acc : 0.783, Run Time : 0.92
INFO:root:2019-05-10 22:54:31, Epoch : 1, Step : 66, Training Loss : 0.61772, Training Acc : 0.639, Run Time : 6.47
INFO:root:2019-05-10 22:54:32, Epoch : 1, Step : 67, Training Loss : 0.43156, Training Acc : 0.844, Run Time : 0.90
INFO:root:2019-05-10 22:54:33, Epoch : 1, Step : 68, Training Loss : 0.41606, Training Acc : 0.861, Run Time : 0.37
INFO:root:2019-05-10 22:54:34, Epoch : 1, Step : 69, Training Loss : 0.57856, Training Acc : 0.639, Run Time : 0.96
INFO:root:2019-05-10 22:54:43, Epoch : 1, Step : 70, Training Loss : 0.45215, Training Acc : 0.867, Run Time : 9.00
INFO:root:2019-05-10 22:54:44, Epoch : 1, Step : 71, Training Loss : 0.56270, Training Acc : 0.728, Run Time : 1.42
INFO:root:2019-05-10 22:54:55, Epoch : 1, Step : 72, Training Loss : 0.57514, Training Acc : 0.683, Run Time : 11.33
INFO:root:2019-05-10 22:54:56, Epoch : 1, Step : 73, Training Loss : 0.79030, Training Acc : 0.572, Run Time : 0.60
INFO:root:2019-05-10 22:54:57, Epoch : 1, Step : 74, Training Loss : 0.59981, Training Acc : 0.672, Run Time : 0.55
INFO:root:2019-05-10 22:55:03, Epoch : 1, Step : 75, Training Loss : 0.37914, Training Acc : 0.911, Run Time : 6.40
INFO:root:2019-05-10 22:55:03, Epoch : 1, Step : 76, Training Loss : 0.56875, Training Acc : 0.728, Run Time : 0.40
INFO:root:2019-05-10 22:55:04, Epoch : 1, Step : 77, Training Loss : 0.62224, Training Acc : 0.711, Run Time : 0.46
INFO:root:2019-05-10 22:55:05, Epoch : 1, Step : 78, Training Loss : 0.52726, Training Acc : 0.767, Run Time : 0.99
INFO:root:2019-05-10 22:55:13, Epoch : 1, Step : 79, Training Loss : 0.47648, Training Acc : 0.822, Run Time : 7.99
INFO:root:2019-05-10 22:55:13, Epoch : 1, Step : 80, Training Loss : 0.40356, Training Acc : 0.894, Run Time : 0.72
INFO:root:2019-05-10 22:55:14, Epoch : 1, Step : 81, Training Loss : 0.44033, Training Acc : 0.844, Run Time : 0.38
INFO:root:2019-05-10 22:55:14, Epoch : 1, Step : 82, Training Loss : 0.50493, Training Acc : 0.800, Run Time : 0.41
INFO:root:2019-05-10 22:55:15, Epoch : 1, Step : 83, Training Loss : 0.47744, Training Acc : 0.744, Run Time : 0.37
INFO:root:2019-05-10 22:55:32, Epoch : 1, Step : 84, Training Loss : 0.63016, Training Acc : 0.689, Run Time : 17.65
INFO:root:2019-05-10 22:55:34, Epoch : 1, Step : 85, Training Loss : 0.53103, Training Acc : 0.744, Run Time : 2.01
INFO:root:2019-05-10 22:55:35, Epoch : 1, Step : 86, Training Loss : 0.51466, Training Acc : 0.739, Run Time : 0.38
INFO:root:2019-05-10 22:55:42, Epoch : 1, Step : 87, Training Loss : 0.44736, Training Acc : 0.817, Run Time : 7.66
INFO:root:2019-05-10 22:55:46, Epoch : 1, Step : 88, Training Loss : 0.49449, Training Acc : 0.806, Run Time : 3.60
INFO:root:2019-05-10 22:55:46, Epoch : 1, Step : 89, Training Loss : 0.50987, Training Acc : 0.811, Run Time : 0.50
INFO:root:2019-05-10 22:55:48, Epoch : 1, Step : 90, Training Loss : 0.47621, Training Acc : 0.739, Run Time : 1.14
INFO:root:2019-05-10 22:55:58, Epoch : 1, Step : 91, Training Loss : 0.63312, Training Acc : 0.628, Run Time : 10.12
INFO:root:2019-05-10 22:55:58, Epoch : 1, Step : 92, Training Loss : 0.50572, Training Acc : 0.694, Run Time : 0.43
INFO:root:2019-05-10 22:55:59, Epoch : 1, Step : 93, Training Loss : 0.41777, Training Acc : 0.794, Run Time : 0.37
INFO:root:2019-05-10 22:55:59, Epoch : 1, Step : 94, Training Loss : 0.39187, Training Acc : 0.789, Run Time : 0.38
INFO:root:2019-05-10 22:56:04, Epoch : 1, Step : 95, Training Loss : 0.54702, Training Acc : 0.678, Run Time : 5.09
INFO:root:2019-05-10 22:56:05, Epoch : 1, Step : 96, Training Loss : 0.36624, Training Acc : 0.872, Run Time : 0.85
INFO:root:2019-05-10 22:56:06, Epoch : 1, Step : 97, Training Loss : 0.39699, Training Acc : 0.817, Run Time : 1.27
INFO:root:2019-05-10 22:56:15, Epoch : 1, Step : 98, Training Loss : 0.37172, Training Acc : 0.822, Run Time : 8.84
INFO:root:2019-05-10 22:56:15, Epoch : 1, Step : 99, Training Loss : 0.57298, Training Acc : 0.639, Run Time : 0.55
INFO:root:2019-05-10 22:56:16, Epoch : 1, Step : 100, Training Loss : 0.45410, Training Acc : 0.750, Run Time : 0.37
INFO:root:2019-05-10 22:56:27, Epoch : 1, Step : 101, Training Loss : 0.44757, Training Acc : 0.789, Run Time : 10.93
INFO:root:2019-05-10 22:56:27, Epoch : 1, Step : 102, Training Loss : 0.55083, Training Acc : 0.728, Run Time : 0.70
INFO:root:2019-05-10 22:56:28, Epoch : 1, Step : 103, Training Loss : 0.67198, Training Acc : 0.639, Run Time : 0.37
INFO:root:2019-05-10 22:56:29, Epoch : 1, Step : 104, Training Loss : 0.33706, Training Acc : 0.894, Run Time : 0.93
INFO:root:2019-05-10 22:56:35, Epoch : 1, Step : 105, Training Loss : 0.51936, Training Acc : 0.761, Run Time : 6.28
INFO:root:2019-05-10 22:56:36, Epoch : 1, Step : 106, Training Loss : 0.33682, Training Acc : 0.850, Run Time : 0.53
INFO:root:2019-05-10 22:56:36, Epoch : 1, Step : 107, Training Loss : 0.37688, Training Acc : 0.806, Run Time : 0.46
INFO:root:2019-05-10 22:56:36, Epoch : 1, Step : 108, Training Loss : 0.40108, Training Acc : 0.828, Run Time : 0.42
INFO:root:2019-05-10 22:56:37, Epoch : 1, Step : 109, Training Loss : 0.38690, Training Acc : 0.839, Run Time : 0.71
INFO:root:2019-05-10 22:56:45, Epoch : 1, Step : 110, Training Loss : 0.54432, Training Acc : 0.694, Run Time : 7.92
INFO:root:2019-05-10 22:56:46, Epoch : 1, Step : 111, Training Loss : 0.39426, Training Acc : 0.806, Run Time : 0.41
INFO:root:2019-05-10 22:56:46, Epoch : 1, Step : 112, Training Loss : 0.37992, Training Acc : 0.811, Run Time : 0.41
INFO:root:2019-05-10 22:56:47, Epoch : 1, Step : 113, Training Loss : 0.39636, Training Acc : 0.833, Run Time : 0.70
INFO:root:2019-05-10 22:56:53, Epoch : 1, Step : 114, Training Loss : 0.36773, Training Acc : 0.833, Run Time : 6.40
INFO:root:2019-05-10 22:56:54, Epoch : 1, Step : 115, Training Loss : 0.33665, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-10 22:56:55, Epoch : 1, Step : 116, Training Loss : 0.37321, Training Acc : 0.828, Run Time : 1.03
INFO:root:2019-05-10 22:56:56, Epoch : 1, Step : 117, Training Loss : 0.36576, Training Acc : 0.850, Run Time : 1.45
INFO:root:2019-05-10 22:56:56, Epoch : 1, Step : 118, Training Loss : 0.31111, Training Acc : 0.878, Run Time : 0.47
INFO:root:2019-05-10 22:56:57, Epoch : 1, Step : 119, Training Loss : 0.32308, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-10 22:56:58, Epoch : 1, Step : 120, Training Loss : 0.36780, Training Acc : 0.833, Run Time : 1.35
INFO:root:2019-05-10 22:57:06, Epoch : 1, Step : 121, Training Loss : 0.34632, Training Acc : 0.822, Run Time : 7.64
INFO:root:2019-05-10 22:57:06, Epoch : 1, Step : 122, Training Loss : 0.39854, Training Acc : 0.800, Run Time : 0.45
INFO:root:2019-05-10 22:57:07, Epoch : 1, Step : 123, Training Loss : 0.32933, Training Acc : 0.872, Run Time : 0.37
INFO:root:2019-05-10 22:57:07, Epoch : 1, Step : 124, Training Loss : 0.35278, Training Acc : 0.833, Run Time : 0.55
INFO:root:2019-05-10 22:57:19, Epoch : 1, Step : 125, Training Loss : 0.28713, Training Acc : 0.878, Run Time : 11.27
INFO:root:2019-05-10 22:57:19, Epoch : 1, Step : 126, Training Loss : 0.49484, Training Acc : 0.750, Run Time : 0.44
INFO:root:2019-05-10 22:57:19, Epoch : 1, Step : 127, Training Loss : 0.52594, Training Acc : 0.733, Run Time : 0.40
INFO:root:2019-05-10 22:57:20, Epoch : 1, Step : 128, Training Loss : 0.66132, Training Acc : 0.678, Run Time : 1.12
INFO:root:2019-05-10 22:57:25, Epoch : 1, Step : 129, Training Loss : 0.82908, Training Acc : 0.500, Run Time : 4.43
INFO:root:2019-05-10 22:57:26, Epoch : 1, Step : 130, Training Loss : 0.65513, Training Acc : 0.667, Run Time : 1.36
INFO:root:2019-05-10 22:57:34, Epoch : 1, Step : 131, Training Loss : 0.59989, Training Acc : 0.667, Run Time : 7.84
INFO:root:2019-05-10 22:57:35, Epoch : 1, Step : 132, Training Loss : 0.52271, Training Acc : 0.744, Run Time : 0.42
INFO:root:2019-05-10 22:57:35, Epoch : 1, Step : 133, Training Loss : 0.31806, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-10 22:57:36, Epoch : 1, Step : 134, Training Loss : 0.47657, Training Acc : 0.761, Run Time : 1.53
INFO:root:2019-05-10 22:57:45, Epoch : 1, Step : 135, Training Loss : 0.37533, Training Acc : 0.822, Run Time : 8.27
INFO:root:2019-05-10 22:57:45, Epoch : 1, Step : 136, Training Loss : 0.36797, Training Acc : 0.828, Run Time : 0.42
INFO:root:2019-05-10 22:57:46, Epoch : 1, Step : 137, Training Loss : 0.44683, Training Acc : 0.822, Run Time : 0.51
INFO:root:2019-05-10 22:57:47, Epoch : 1, Step : 138, Training Loss : 0.46206, Training Acc : 0.761, Run Time : 1.15
INFO:root:2019-05-10 22:57:55, Epoch : 1, Step : 139, Training Loss : 0.46617, Training Acc : 0.767, Run Time : 8.35
INFO:root:2019-05-10 22:57:56, Epoch : 1, Step : 140, Training Loss : 0.65759, Training Acc : 0.678, Run Time : 0.73
INFO:root:2019-05-10 22:57:56, Epoch : 1, Step : 141, Training Loss : 0.44225, Training Acc : 0.789, Run Time : 0.39
INFO:root:2019-05-10 22:58:04, Epoch : 1, Step : 142, Training Loss : 0.41356, Training Acc : 0.817, Run Time : 7.90
INFO:root:2019-05-10 22:58:05, Epoch : 1, Step : 143, Training Loss : 0.42075, Training Acc : 0.767, Run Time : 0.52
INFO:root:2019-05-10 22:58:05, Epoch : 1, Step : 144, Training Loss : 0.40282, Training Acc : 0.800, Run Time : 0.78
INFO:root:2019-05-10 22:58:16, Epoch : 1, Step : 145, Training Loss : 0.41964, Training Acc : 0.839, Run Time : 10.63
INFO:root:2019-05-10 22:58:16, Epoch : 1, Step : 146, Training Loss : 0.33708, Training Acc : 0.878, Run Time : 0.43
INFO:root:2019-05-10 22:58:17, Epoch : 1, Step : 147, Training Loss : 0.32549, Training Acc : 0.900, Run Time : 0.38
INFO:root:2019-05-10 22:58:17, Epoch : 1, Step : 148, Training Loss : 1.09434, Training Acc : 0.511, Run Time : 0.37
INFO:root:2019-05-10 22:58:18, Epoch : 1, Step : 149, Training Loss : 1.11380, Training Acc : 0.511, Run Time : 0.77
INFO:root:2019-05-10 22:58:24, Epoch : 1, Step : 150, Training Loss : 0.30090, Training Acc : 0.900, Run Time : 6.14
INFO:root:2019-05-10 22:58:25, Epoch : 1, Step : 151, Training Loss : 0.39212, Training Acc : 0.833, Run Time : 0.40
INFO:root:2019-05-10 22:58:25, Epoch : 1, Step : 152, Training Loss : 0.38216, Training Acc : 0.828, Run Time : 0.37
INFO:root:2019-05-10 22:58:27, Epoch : 1, Step : 153, Training Loss : 0.35419, Training Acc : 0.856, Run Time : 1.58
INFO:root:2019-05-10 22:58:34, Epoch : 1, Step : 154, Training Loss : 0.45575, Training Acc : 0.767, Run Time : 7.09
INFO:root:2019-05-10 22:58:34, Epoch : 1, Step : 155, Training Loss : 0.39621, Training Acc : 0.833, Run Time : 0.87
INFO:root:2019-05-10 22:58:35, Epoch : 1, Step : 156, Training Loss : 0.59475, Training Acc : 0.611, Run Time : 0.42
INFO:root:2019-05-10 22:58:41, Epoch : 1, Step : 157, Training Loss : 0.64861, Training Acc : 0.672, Run Time : 5.67
INFO:root:2019-05-10 22:58:41, Epoch : 1, Step : 158, Training Loss : 0.38741, Training Acc : 0.833, Run Time : 0.55
INFO:root:2019-05-10 22:58:42, Epoch : 1, Step : 159, Training Loss : 0.51146, Training Acc : 0.767, Run Time : 0.55
INFO:root:2019-05-10 22:58:42, Epoch : 1, Step : 160, Training Loss : 0.50331, Training Acc : 0.772, Run Time : 0.38
INFO:root:2019-05-10 22:58:51, Epoch : 1, Step : 161, Training Loss : 0.45171, Training Acc : 0.783, Run Time : 9.11
INFO:root:2019-05-10 22:58:52, Epoch : 1, Step : 162, Training Loss : 0.34952, Training Acc : 0.933, Run Time : 0.62
INFO:root:2019-05-10 22:58:52, Epoch : 1, Step : 163, Training Loss : 0.27837, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-10 22:58:54, Epoch : 1, Step : 164, Training Loss : 0.35062, Training Acc : 0.872, Run Time : 1.82
INFO:root:2019-05-10 22:58:59, Epoch : 1, Step : 165, Training Loss : 0.33944, Training Acc : 0.894, Run Time : 4.81
INFO:root:2019-05-10 22:58:59, Epoch : 1, Step : 166, Training Loss : 0.77860, Training Acc : 0.594, Run Time : 0.45
INFO:root:2019-05-10 22:59:00, Epoch : 1, Step : 167, Training Loss : 0.40458, Training Acc : 0.800, Run Time : 0.40
INFO:root:2019-05-10 22:59:01, Epoch : 1, Step : 168, Training Loss : 0.29508, Training Acc : 0.894, Run Time : 1.15
INFO:root:2019-05-10 22:59:05, Epoch : 1, Step : 169, Training Loss : 0.36146, Training Acc : 0.828, Run Time : 4.41
INFO:root:2019-05-10 22:59:06, Epoch : 1, Step : 170, Training Loss : 0.29693, Training Acc : 0.883, Run Time : 0.64
INFO:root:2019-05-10 22:59:06, Epoch : 1, Step : 171, Training Loss : 0.43261, Training Acc : 0.800, Run Time : 0.37
INFO:root:2019-05-10 22:59:08, Epoch : 1, Step : 172, Training Loss : 0.34156, Training Acc : 0.861, Run Time : 1.43
INFO:root:2019-05-10 22:59:17, Epoch : 1, Step : 173, Training Loss : 0.32126, Training Acc : 0.894, Run Time : 9.57
INFO:root:2019-05-10 22:59:18, Epoch : 1, Step : 174, Training Loss : 0.44012, Training Acc : 0.794, Run Time : 0.65
INFO:root:2019-05-10 22:59:18, Epoch : 1, Step : 175, Training Loss : 0.46423, Training Acc : 0.817, Run Time : 0.40
INFO:root:2019-05-10 22:59:20, Epoch : 1, Step : 176, Training Loss : 0.29042, Training Acc : 0.900, Run Time : 1.26
INFO:root:2019-05-10 22:59:28, Epoch : 1, Step : 177, Training Loss : 0.49330, Training Acc : 0.794, Run Time : 8.89
INFO:root:2019-05-10 22:59:29, Epoch : 1, Step : 178, Training Loss : 0.39209, Training Acc : 0.778, Run Time : 0.40
INFO:root:2019-05-10 22:59:29, Epoch : 1, Step : 179, Training Loss : 0.40156, Training Acc : 0.822, Run Time : 0.56
INFO:root:2019-05-10 22:59:31, Epoch : 1, Step : 180, Training Loss : 0.32213, Training Acc : 0.872, Run Time : 1.34
INFO:root:2019-05-10 22:59:42, Epoch : 1, Step : 181, Training Loss : 0.43222, Training Acc : 0.761, Run Time : 11.14
INFO:root:2019-05-10 22:59:42, Epoch : 1, Step : 182, Training Loss : 0.46229, Training Acc : 0.789, Run Time : 0.60
INFO:root:2019-05-10 22:59:43, Epoch : 1, Step : 183, Training Loss : 0.30910, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-10 22:59:52, Epoch : 1, Step : 184, Training Loss : 0.35268, Training Acc : 0.833, Run Time : 9.31
INFO:root:2019-05-10 22:59:53, Epoch : 1, Step : 185, Training Loss : 0.35015, Training Acc : 0.844, Run Time : 0.56
INFO:root:2019-05-10 22:59:53, Epoch : 1, Step : 186, Training Loss : 0.25681, Training Acc : 0.928, Run Time : 0.58
INFO:root:2019-05-10 22:59:56, Epoch : 1, Step : 187, Training Loss : 0.40373, Training Acc : 0.856, Run Time : 2.66
INFO:root:2019-05-10 22:59:56, Epoch : 1, Step : 188, Training Loss : 0.42874, Training Acc : 0.794, Run Time : 0.39
INFO:root:2019-05-10 22:59:57, Epoch : 1, Step : 189, Training Loss : 0.38792, Training Acc : 0.800, Run Time : 0.97
INFO:root:2019-05-10 23:00:06, Epoch : 1, Step : 190, Training Loss : 0.35447, Training Acc : 0.850, Run Time : 8.90
INFO:root:2019-05-10 23:00:07, Epoch : 1, Step : 191, Training Loss : 0.41470, Training Acc : 0.811, Run Time : 0.94
INFO:root:2019-05-10 23:00:13, Epoch : 1, Step : 192, Training Loss : 0.39536, Training Acc : 0.828, Run Time : 5.74
INFO:root:2019-05-10 23:00:15, Epoch : 1, Step : 193, Training Loss : 0.36583, Training Acc : 0.828, Run Time : 1.76
INFO:root:2019-05-10 23:00:15, Epoch : 1, Step : 194, Training Loss : 0.46567, Training Acc : 0.722, Run Time : 0.50
INFO:root:2019-05-10 23:00:16, Epoch : 1, Step : 195, Training Loss : 0.52694, Training Acc : 0.706, Run Time : 0.40
INFO:root:2019-05-10 23:00:16, Epoch : 1, Step : 196, Training Loss : 0.41845, Training Acc : 0.800, Run Time : 0.40
INFO:root:2019-05-10 23:00:17, Epoch : 1, Step : 197, Training Loss : 0.42602, Training Acc : 0.750, Run Time : 0.93
INFO:root:2019-05-10 23:00:24, Epoch : 1, Step : 198, Training Loss : 0.36934, Training Acc : 0.811, Run Time : 6.63
INFO:root:2019-05-10 23:00:24, Epoch : 1, Step : 199, Training Loss : 0.36218, Training Acc : 0.828, Run Time : 0.42
INFO:root:2019-05-10 23:00:24, Epoch : 1, Step : 200, Training Loss : 0.49586, Training Acc : 0.761, Run Time : 0.50
INFO:root:2019-05-10 23:00:32, Epoch : 1, Step : 201, Training Loss : 0.53936, Training Acc : 0.656, Run Time : 7.57
INFO:root:2019-05-10 23:00:33, Epoch : 1, Step : 202, Training Loss : 0.61396, Training Acc : 0.656, Run Time : 0.73
INFO:root:2019-05-10 23:00:34, Epoch : 1, Step : 203, Training Loss : 0.62678, Training Acc : 0.683, Run Time : 1.47
INFO:root:2019-05-10 23:00:42, Epoch : 1, Step : 204, Training Loss : 0.55146, Training Acc : 0.744, Run Time : 7.93
INFO:root:2019-05-10 23:00:43, Epoch : 1, Step : 205, Training Loss : 0.59747, Training Acc : 0.739, Run Time : 0.49
INFO:root:2019-05-10 23:00:43, Epoch : 1, Step : 206, Training Loss : 0.48179, Training Acc : 0.767, Run Time : 0.37
INFO:root:2019-05-10 23:00:44, Epoch : 1, Step : 207, Training Loss : 0.45702, Training Acc : 0.772, Run Time : 1.24
INFO:root:2019-05-10 23:00:46, Epoch : 1, Step : 208, Training Loss : 0.42760, Training Acc : 0.789, Run Time : 2.24
INFO:root:2019-05-10 23:00:52, Epoch : 1, Step : 209, Training Loss : 0.43585, Training Acc : 0.806, Run Time : 5.50
INFO:root:2019-05-10 23:00:53, Epoch : 1, Step : 210, Training Loss : 0.47347, Training Acc : 0.789, Run Time : 0.81
INFO:root:2019-05-10 23:00:54, Epoch : 1, Step : 211, Training Loss : 0.40716, Training Acc : 0.811, Run Time : 1.04
INFO:root:2019-05-10 23:01:01, Epoch : 1, Step : 212, Training Loss : 0.47368, Training Acc : 0.783, Run Time : 7.41
INFO:root:2019-05-10 23:01:02, Epoch : 1, Step : 213, Training Loss : 0.34292, Training Acc : 0.811, Run Time : 0.75
INFO:root:2019-05-10 23:01:02, Epoch : 1, Step : 214, Training Loss : 0.31946, Training Acc : 0.828, Run Time : 0.40
INFO:root:2019-05-10 23:01:08, Epoch : 1, Step : 215, Training Loss : 0.31531, Training Acc : 0.828, Run Time : 5.86
INFO:root:2019-05-10 23:01:09, Epoch : 1, Step : 216, Training Loss : 0.36169, Training Acc : 0.817, Run Time : 0.41
INFO:root:2019-05-10 23:01:09, Epoch : 1, Step : 217, Training Loss : 0.39081, Training Acc : 0.828, Run Time : 0.37
INFO:root:2019-05-10 23:01:09, Epoch : 1, Step : 218, Training Loss : 0.32844, Training Acc : 0.856, Run Time : 0.39
INFO:root:2019-05-10 23:01:10, Epoch : 1, Step : 219, Training Loss : 0.36846, Training Acc : 0.817, Run Time : 0.76
INFO:root:2019-05-10 23:01:16, Epoch : 1, Step : 220, Training Loss : 0.41892, Training Acc : 0.822, Run Time : 5.37
INFO:root:2019-05-10 23:01:16, Epoch : 1, Step : 221, Training Loss : 0.45711, Training Acc : 0.794, Run Time : 0.50
INFO:root:2019-05-10 23:01:16, Epoch : 1, Step : 222, Training Loss : 0.51598, Training Acc : 0.811, Run Time : 0.38
INFO:root:2019-05-10 23:01:17, Epoch : 1, Step : 223, Training Loss : 0.56238, Training Acc : 0.789, Run Time : 0.62
INFO:root:2019-05-10 23:01:17, Epoch : 1, Step : 224, Training Loss : 0.44236, Training Acc : 0.767, Run Time : 0.44
INFO:root:2019-05-10 23:01:18, Epoch : 1, Step : 225, Training Loss : 0.48789, Training Acc : 0.744, Run Time : 0.39
INFO:root:2019-05-10 23:01:19, Epoch : 1, Step : 226, Training Loss : 0.45979, Training Acc : 0.761, Run Time : 1.04
INFO:root:2019-05-10 23:01:23, Epoch : 1, Step : 227, Training Loss : 0.39689, Training Acc : 0.783, Run Time : 4.50
INFO:root:2019-05-10 23:01:24, Epoch : 1, Step : 228, Training Loss : 0.38436, Training Acc : 0.789, Run Time : 0.44
INFO:root:2019-05-10 23:01:24, Epoch : 1, Step : 229, Training Loss : 0.63692, Training Acc : 0.772, Run Time : 0.37
INFO:root:2019-05-10 23:01:26, Epoch : 1, Step : 230, Training Loss : 0.64412, Training Acc : 0.689, Run Time : 1.28
INFO:root:2019-05-10 23:01:33, Epoch : 1, Step : 231, Training Loss : 0.40518, Training Acc : 0.789, Run Time : 7.94
INFO:root:2019-05-10 23:01:34, Epoch : 1, Step : 232, Training Loss : 0.46356, Training Acc : 0.744, Run Time : 0.41
INFO:root:2019-05-10 23:01:34, Epoch : 1, Step : 233, Training Loss : 0.45315, Training Acc : 0.750, Run Time : 0.38
INFO:root:2019-05-10 23:01:36, Epoch : 1, Step : 234, Training Loss : 0.46461, Training Acc : 0.772, Run Time : 1.48
INFO:root:2019-05-10 23:01:43, Epoch : 1, Step : 235, Training Loss : 0.36032, Training Acc : 0.844, Run Time : 7.32
INFO:root:2019-05-10 23:01:43, Epoch : 1, Step : 236, Training Loss : 0.56514, Training Acc : 0.750, Run Time : 0.40
INFO:root:2019-05-10 23:01:44, Epoch : 1, Step : 237, Training Loss : 0.40507, Training Acc : 0.794, Run Time : 0.51
INFO:root:2019-05-10 23:01:53, Epoch : 1, Step : 238, Training Loss : 0.46022, Training Acc : 0.744, Run Time : 8.79
INFO:root:2019-05-10 23:01:53, Epoch : 1, Step : 239, Training Loss : 0.49829, Training Acc : 0.717, Run Time : 0.48
INFO:root:2019-05-10 23:01:54, Epoch : 1, Step : 240, Training Loss : 0.46664, Training Acc : 0.756, Run Time : 0.40
INFO:root:2019-05-10 23:01:54, Epoch : 1, Step : 241, Training Loss : 0.44516, Training Acc : 0.806, Run Time : 0.79
INFO:root:2019-05-10 23:02:04, Epoch : 1, Step : 242, Training Loss : 0.49596, Training Acc : 0.767, Run Time : 9.54
INFO:root:2019-05-10 23:02:04, Epoch : 1, Step : 243, Training Loss : 0.49235, Training Acc : 0.789, Run Time : 0.49
INFO:root:2019-05-10 23:02:05, Epoch : 1, Step : 244, Training Loss : 0.57587, Training Acc : 0.739, Run Time : 0.43
INFO:root:2019-05-10 23:02:05, Epoch : 1, Step : 245, Training Loss : 0.42745, Training Acc : 0.783, Run Time : 0.46
INFO:root:2019-05-10 23:02:10, Epoch : 1, Step : 246, Training Loss : 0.45086, Training Acc : 0.733, Run Time : 4.96
INFO:root:2019-05-10 23:02:11, Epoch : 1, Step : 247, Training Loss : 0.43854, Training Acc : 0.828, Run Time : 0.39
INFO:root:2019-05-10 23:02:11, Epoch : 1, Step : 248, Training Loss : 0.39383, Training Acc : 0.833, Run Time : 0.53
INFO:root:2019-05-10 23:02:12, Epoch : 1, Step : 249, Training Loss : 0.38762, Training Acc : 0.839, Run Time : 1.04
INFO:root:2019-05-10 23:02:16, Epoch : 1, Step : 250, Training Loss : 0.36380, Training Acc : 0.806, Run Time : 4.11
INFO:root:2019-05-10 23:02:17, Epoch : 1, Step : 251, Training Loss : 0.40256, Training Acc : 0.822, Run Time : 0.44
INFO:root:2019-05-10 23:02:17, Epoch : 1, Step : 252, Training Loss : 0.38646, Training Acc : 0.822, Run Time : 0.41
INFO:root:2019-05-10 23:02:18, Epoch : 1, Step : 253, Training Loss : 0.37456, Training Acc : 0.800, Run Time : 0.84
INFO:root:2019-05-10 23:02:21, Epoch : 1, Step : 254, Training Loss : 0.34355, Training Acc : 0.867, Run Time : 2.75
INFO:root:2019-05-10 23:02:25, Epoch : 1, Step : 255, Training Loss : 0.37244, Training Acc : 0.806, Run Time : 3.99
INFO:root:2019-05-10 23:02:26, Epoch : 1, Step : 256, Training Loss : 0.34179, Training Acc : 0.822, Run Time : 1.57
INFO:root:2019-05-10 23:02:28, Epoch : 1, Step : 257, Training Loss : 0.31446, Training Acc : 0.856, Run Time : 1.24
INFO:root:2019-05-10 23:02:28, Epoch : 1, Step : 258, Training Loss : 0.32293, Training Acc : 0.856, Run Time : 0.39
INFO:root:2019-05-10 23:02:28, Epoch : 1, Step : 259, Training Loss : 0.38015, Training Acc : 0.822, Run Time : 0.38
INFO:root:2019-05-10 23:02:29, Epoch : 1, Step : 260, Training Loss : 0.32086, Training Acc : 0.839, Run Time : 0.56
INFO:root:2019-05-10 23:02:30, Epoch : 1, Step : 261, Training Loss : 0.34557, Training Acc : 0.839, Run Time : 0.60
INFO:root:2019-05-10 23:02:30, Epoch : 1, Step : 262, Training Loss : 0.42428, Training Acc : 0.728, Run Time : 0.90
INFO:root:2019-05-10 23:02:35, Epoch : 1, Step : 263, Training Loss : 0.31064, Training Acc : 0.850, Run Time : 4.12
INFO:root:2019-05-10 23:02:35, Epoch : 1, Step : 264, Training Loss : 0.33514, Training Acc : 0.817, Run Time : 0.47
INFO:root:2019-05-10 23:02:35, Epoch : 1, Step : 265, Training Loss : 0.34634, Training Acc : 0.817, Run Time : 0.41
INFO:root:2019-05-10 23:02:38, Epoch : 1, Step : 266, Training Loss : 0.33273, Training Acc : 0.828, Run Time : 2.30
INFO:root:2019-05-10 23:02:46, Epoch : 1, Step : 267, Training Loss : 0.28990, Training Acc : 0.878, Run Time : 8.10
INFO:root:2019-05-10 23:02:46, Epoch : 1, Step : 268, Training Loss : 0.32291, Training Acc : 0.861, Run Time : 0.63
INFO:root:2019-05-10 23:02:47, Epoch : 1, Step : 269, Training Loss : 0.37666, Training Acc : 0.778, Run Time : 0.64
INFO:root:2019-05-10 23:02:48, Epoch : 1, Step : 270, Training Loss : 0.34667, Training Acc : 0.800, Run Time : 0.42
INFO:root:2019-05-10 23:02:56, Epoch : 1, Step : 271, Training Loss : 0.34230, Training Acc : 0.828, Run Time : 8.24
INFO:root:2019-05-10 23:02:56, Epoch : 1, Step : 272, Training Loss : 0.33791, Training Acc : 0.828, Run Time : 0.54
INFO:root:2019-05-10 23:02:57, Epoch : 1, Step : 273, Training Loss : 0.32552, Training Acc : 0.828, Run Time : 0.90
INFO:root:2019-05-10 23:03:04, Epoch : 1, Step : 274, Training Loss : 0.38241, Training Acc : 0.794, Run Time : 6.63
INFO:root:2019-05-10 23:03:04, Epoch : 1, Step : 275, Training Loss : 0.43336, Training Acc : 0.767, Run Time : 0.60
INFO:root:2019-05-10 23:03:05, Epoch : 1, Step : 276, Training Loss : 0.35497, Training Acc : 0.806, Run Time : 0.38
INFO:root:2019-05-10 23:03:06, Epoch : 1, Step : 277, Training Loss : 0.33869, Training Acc : 0.839, Run Time : 0.75
INFO:root:2019-05-10 23:03:15, Epoch : 1, Step : 278, Training Loss : 0.44893, Training Acc : 0.728, Run Time : 9.30
INFO:root:2019-05-10 23:03:15, Epoch : 1, Step : 279, Training Loss : 0.41579, Training Acc : 0.744, Run Time : 0.41
INFO:root:2019-05-10 23:03:16, Epoch : 1, Step : 280, Training Loss : 0.44078, Training Acc : 0.722, Run Time : 0.46
INFO:root:2019-05-10 23:03:17, Epoch : 1, Step : 281, Training Loss : 0.40993, Training Acc : 0.717, Run Time : 1.14
INFO:root:2019-05-10 23:03:25, Epoch : 1, Step : 282, Training Loss : 0.73949, Training Acc : 0.683, Run Time : 7.71
INFO:root:2019-05-10 23:03:25, Epoch : 1, Step : 283, Training Loss : 0.74886, Training Acc : 0.661, Run Time : 0.70
INFO:root:2019-05-10 23:03:26, Epoch : 1, Step : 284, Training Loss : 0.43872, Training Acc : 0.806, Run Time : 0.37
INFO:root:2019-05-10 23:03:26, Epoch : 1, Step : 285, Training Loss : 0.47184, Training Acc : 0.750, Run Time : 0.42
INFO:root:2019-05-10 23:03:27, Epoch : 1, Step : 286, Training Loss : 0.44126, Training Acc : 0.767, Run Time : 0.51
INFO:root:2019-05-10 23:03:28, Epoch : 1, Step : 287, Training Loss : 0.41502, Training Acc : 0.783, Run Time : 0.91
INFO:root:2019-05-10 23:03:28, Epoch : 1, Step : 288, Training Loss : 0.42372, Training Acc : 0.744, Run Time : 0.42
INFO:root:2019-05-10 23:03:28, Epoch : 1, Step : 289, Training Loss : 0.37871, Training Acc : 0.833, Run Time : 0.41
INFO:root:2019-05-10 23:03:33, Epoch : 1, Step : 290, Training Loss : 0.47196, Training Acc : 0.739, Run Time : 4.55
INFO:root:2019-05-10 23:03:34, Epoch : 1, Step : 291, Training Loss : 0.41409, Training Acc : 0.783, Run Time : 0.81
INFO:root:2019-05-10 23:03:34, Epoch : 1, Step : 292, Training Loss : 0.38137, Training Acc : 0.822, Run Time : 0.69
INFO:root:2019-05-10 23:03:36, Epoch : 1, Step : 293, Training Loss : 0.35642, Training Acc : 0.844, Run Time : 1.12
INFO:root:2019-05-10 23:03:43, Epoch : 1, Step : 294, Training Loss : 0.43248, Training Acc : 0.750, Run Time : 7.98
INFO:root:2019-05-10 23:03:44, Epoch : 1, Step : 295, Training Loss : 0.34686, Training Acc : 0.806, Run Time : 0.42
INFO:root:2019-05-10 23:03:44, Epoch : 1, Step : 296, Training Loss : 0.42558, Training Acc : 0.767, Run Time : 0.42
INFO:root:2019-05-10 23:03:45, Epoch : 1, Step : 297, Training Loss : 0.40011, Training Acc : 0.822, Run Time : 0.84
INFO:root:2019-05-10 23:03:52, Epoch : 1, Step : 298, Training Loss : 0.35647, Training Acc : 0.839, Run Time : 6.70
INFO:root:2019-05-10 23:03:52, Epoch : 1, Step : 299, Training Loss : 0.35960, Training Acc : 0.850, Run Time : 0.54
INFO:root:2019-05-10 23:03:53, Epoch : 1, Step : 300, Training Loss : 0.40626, Training Acc : 0.800, Run Time : 0.40
INFO:root:2019-05-10 23:03:54, Epoch : 1, Step : 301, Training Loss : 0.32224, Training Acc : 0.850, Run Time : 1.20
INFO:root:2019-05-10 23:04:03, Epoch : 1, Step : 302, Training Loss : 0.34408, Training Acc : 0.817, Run Time : 8.83
INFO:root:2019-05-10 23:04:04, Epoch : 1, Step : 303, Training Loss : 0.38170, Training Acc : 0.867, Run Time : 1.67
INFO:root:2019-05-10 23:04:05, Epoch : 1, Step : 304, Training Loss : 0.31074, Training Acc : 0.878, Run Time : 0.43
INFO:root:2019-05-10 23:04:06, Epoch : 1, Step : 305, Training Loss : 0.30934, Training Acc : 0.861, Run Time : 0.96
INFO:root:2019-05-10 23:04:06, Epoch : 1, Step : 306, Training Loss : 0.35187, Training Acc : 0.833, Run Time : 0.40
INFO:root:2019-05-10 23:04:07, Epoch : 1, Step : 307, Training Loss : 0.40344, Training Acc : 0.783, Run Time : 0.37
INFO:root:2019-05-10 23:04:07, Epoch : 1, Step : 308, Training Loss : 0.31475, Training Acc : 0.850, Run Time : 0.50
INFO:root:2019-05-10 23:04:10, Epoch : 1, Step : 309, Training Loss : 0.35583, Training Acc : 0.833, Run Time : 3.21
INFO:root:2019-05-10 23:04:11, Epoch : 1, Step : 310, Training Loss : 0.37015, Training Acc : 0.822, Run Time : 0.56
INFO:root:2019-05-10 23:04:11, Epoch : 1, Step : 311, Training Loss : 0.35458, Training Acc : 0.839, Run Time : 0.37
INFO:root:2019-05-10 23:04:12, Epoch : 1, Step : 312, Training Loss : 0.38646, Training Acc : 0.761, Run Time : 0.37
INFO:root:2019-05-10 23:04:12, Epoch : 1, Step : 313, Training Loss : 0.32973, Training Acc : 0.811, Run Time : 0.55
INFO:root:2019-05-10 23:04:20, Epoch : 1, Step : 314, Training Loss : 0.28958, Training Acc : 0.878, Run Time : 7.70
INFO:root:2019-05-10 23:04:20, Epoch : 1, Step : 315, Training Loss : 0.30839, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-10 23:04:21, Epoch : 1, Step : 316, Training Loss : 0.43508, Training Acc : 0.811, Run Time : 0.65
INFO:root:2019-05-10 23:04:22, Epoch : 1, Step : 317, Training Loss : 0.37796, Training Acc : 0.833, Run Time : 0.62
INFO:root:2019-05-10 23:04:26, Epoch : 1, Step : 318, Training Loss : 0.33521, Training Acc : 0.822, Run Time : 4.42
INFO:root:2019-05-10 23:04:27, Epoch : 1, Step : 319, Training Loss : 0.32245, Training Acc : 0.861, Run Time : 1.10
INFO:root:2019-05-10 23:04:28, Epoch : 1, Step : 320, Training Loss : 0.33396, Training Acc : 0.867, Run Time : 0.42
INFO:root:2019-05-10 23:04:28, Epoch : 1, Step : 321, Training Loss : 0.27851, Training Acc : 0.883, Run Time : 0.64
INFO:root:2019-05-10 23:04:30, Epoch : 1, Step : 322, Training Loss : 0.30487, Training Acc : 0.839, Run Time : 1.34
INFO:root:2019-05-10 23:04:30, Epoch : 1, Step : 323, Training Loss : 0.31457, Training Acc : 0.861, Run Time : 0.49
INFO:root:2019-05-10 23:04:31, Epoch : 1, Step : 324, Training Loss : 0.26022, Training Acc : 0.861, Run Time : 0.66
INFO:root:2019-05-10 23:04:34, Epoch : 1, Step : 325, Training Loss : 0.23924, Training Acc : 0.922, Run Time : 3.51
INFO:root:2019-05-10 23:04:35, Epoch : 1, Step : 326, Training Loss : 0.23358, Training Acc : 0.911, Run Time : 0.40
INFO:root:2019-05-10 23:04:35, Epoch : 1, Step : 327, Training Loss : 0.27902, Training Acc : 0.872, Run Time : 0.37
INFO:root:2019-05-10 23:04:37, Epoch : 1, Step : 328, Training Loss : 0.36249, Training Acc : 0.794, Run Time : 1.94
INFO:root:2019-05-10 23:04:44, Epoch : 1, Step : 329, Training Loss : 0.33162, Training Acc : 0.839, Run Time : 7.13
INFO:root:2019-05-10 23:04:45, Epoch : 1, Step : 330, Training Loss : 0.26636, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-10 23:04:45, Epoch : 1, Step : 331, Training Loss : 0.28742, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-10 23:04:46, Epoch : 1, Step : 332, Training Loss : 0.32441, Training Acc : 0.822, Run Time : 1.27
INFO:root:2019-05-10 23:04:54, Epoch : 1, Step : 333, Training Loss : 0.28898, Training Acc : 0.861, Run Time : 7.44
INFO:root:2019-05-10 23:04:54, Epoch : 1, Step : 334, Training Loss : 0.38358, Training Acc : 0.789, Run Time : 0.60
INFO:root:2019-05-10 23:04:55, Epoch : 1, Step : 335, Training Loss : 0.44359, Training Acc : 0.778, Run Time : 0.52
INFO:root:2019-05-10 23:04:55, Epoch : 1, Step : 336, Training Loss : 0.25040, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-10 23:05:01, Epoch : 1, Step : 337, Training Loss : 0.31373, Training Acc : 0.806, Run Time : 6.14
INFO:root:2019-05-10 23:05:03, Epoch : 1, Step : 338, Training Loss : 0.35306, Training Acc : 0.850, Run Time : 1.97
INFO:root:2019-05-10 23:05:04, Epoch : 1, Step : 339, Training Loss : 0.34512, Training Acc : 0.839, Run Time : 0.37
INFO:root:2019-05-10 23:05:04, Epoch : 1, Step : 340, Training Loss : 0.28136, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-10 23:05:05, Epoch : 1, Step : 341, Training Loss : 0.27242, Training Acc : 0.861, Run Time : 0.93
INFO:root:2019-05-10 23:05:13, Epoch : 1, Step : 342, Training Loss : 0.32192, Training Acc : 0.856, Run Time : 7.54
INFO:root:2019-05-10 23:05:13, Epoch : 1, Step : 343, Training Loss : 0.25582, Training Acc : 0.872, Run Time : 0.57
INFO:root:2019-05-10 23:05:14, Epoch : 1, Step : 344, Training Loss : 0.28746, Training Acc : 0.867, Run Time : 0.54
INFO:root:2019-05-10 23:05:14, Epoch : 1, Step : 345, Training Loss : 0.29459, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-10 23:05:21, Epoch : 1, Step : 346, Training Loss : 0.28967, Training Acc : 0.867, Run Time : 6.67
INFO:root:2019-05-10 23:05:21, Epoch : 1, Step : 347, Training Loss : 0.25352, Training Acc : 0.883, Run Time : 0.60
INFO:root:2019-05-10 23:05:22, Epoch : 1, Step : 348, Training Loss : 0.32193, Training Acc : 0.806, Run Time : 0.37
INFO:root:2019-05-10 23:05:23, Epoch : 1, Step : 349, Training Loss : 0.30612, Training Acc : 0.833, Run Time : 1.26
INFO:root:2019-05-10 23:05:32, Epoch : 1, Step : 350, Training Loss : 0.26679, Training Acc : 0.867, Run Time : 8.86
INFO:root:2019-05-10 23:05:32, Epoch : 1, Step : 351, Training Loss : 0.26554, Training Acc : 0.872, Run Time : 0.41
INFO:root:2019-05-10 23:05:33, Epoch : 1, Step : 352, Training Loss : 0.24554, Training Acc : 0.883, Run Time : 0.37
INFO:root:2019-05-10 23:05:33, Epoch : 1, Step : 353, Training Loss : 0.23420, Training Acc : 0.894, Run Time : 0.70
INFO:root:2019-05-10 23:05:41, Epoch : 1, Step : 354, Training Loss : 0.26687, Training Acc : 0.883, Run Time : 7.23
INFO:root:2019-05-10 23:05:42, Epoch : 1, Step : 355, Training Loss : 0.27831, Training Acc : 0.850, Run Time : 1.14
INFO:root:2019-05-10 23:05:42, Epoch : 1, Step : 356, Training Loss : 0.25212, Training Acc : 0.883, Run Time : 0.79
INFO:root:2019-05-10 23:05:45, Epoch : 1, Step : 357, Training Loss : 0.28176, Training Acc : 0.883, Run Time : 2.43
INFO:root:2019-05-10 23:05:46, Epoch : 1, Step : 358, Training Loss : 0.27640, Training Acc : 0.889, Run Time : 0.88
INFO:root:2019-05-10 23:05:47, Epoch : 1, Step : 359, Training Loss : 0.27878, Training Acc : 0.861, Run Time : 1.03
INFO:root:2019-05-10 23:05:54, Epoch : 1, Step : 360, Training Loss : 0.25642, Training Acc : 0.856, Run Time : 7.46
INFO:root:2019-05-10 23:05:55, Epoch : 1, Step : 361, Training Loss : 0.21452, Training Acc : 0.906, Run Time : 0.65
INFO:root:2019-05-10 23:05:55, Epoch : 1, Step : 362, Training Loss : 0.21165, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-10 23:05:56, Epoch : 1, Step : 363, Training Loss : 0.20732, Training Acc : 0.933, Run Time : 0.81
INFO:root:2019-05-10 23:06:03, Epoch : 1, Step : 364, Training Loss : 0.22179, Training Acc : 0.900, Run Time : 7.22
INFO:root:2019-05-10 23:06:04, Epoch : 1, Step : 365, Training Loss : 0.20410, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-10 23:06:04, Epoch : 1, Step : 366, Training Loss : 0.18776, Training Acc : 0.928, Run Time : 0.37
INFO:root:2019-05-10 23:06:05, Epoch : 1, Step : 367, Training Loss : 0.23738, Training Acc : 0.878, Run Time : 0.39
INFO:root:2019-05-10 23:06:06, Epoch : 1, Step : 368, Training Loss : 0.22525, Training Acc : 0.928, Run Time : 1.25
INFO:root:2019-05-10 23:06:15, Epoch : 1, Step : 369, Training Loss : 0.19889, Training Acc : 0.950, Run Time : 9.48
INFO:root:2019-05-10 23:06:16, Epoch : 1, Step : 370, Training Loss : 0.28078, Training Acc : 0.867, Run Time : 0.62
INFO:root:2019-05-10 23:06:16, Epoch : 1, Step : 371, Training Loss : 0.21222, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-10 23:06:21, Epoch : 1, Step : 372, Training Loss : 0.17758, Training Acc : 0.944, Run Time : 4.46
INFO:root:2019-05-10 23:06:21, Epoch : 1, Step : 373, Training Loss : 0.16274, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-10 23:06:22, Epoch : 1, Step : 374, Training Loss : 0.14518, Training Acc : 0.950, Run Time : 0.55
INFO:root:2019-05-10 23:06:31, Epoch : 1, Step : 375, Training Loss : 0.20394, Training Acc : 0.917, Run Time : 8.69
INFO:root:2019-05-10 23:06:31, Epoch : 1, Step : 376, Training Loss : 0.18093, Training Acc : 0.906, Run Time : 0.54
INFO:root:2019-05-10 23:06:31, Epoch : 1, Step : 377, Training Loss : 0.12415, Training Acc : 0.961, Run Time : 0.37
INFO:root:2019-05-10 23:06:32, Epoch : 1, Step : 378, Training Loss : 0.17016, Training Acc : 0.939, Run Time : 0.53
INFO:root:2019-05-10 23:06:33, Epoch : 1, Step : 379, Training Loss : 0.13872, Training Acc : 0.950, Run Time : 1.00
INFO:root:2019-05-10 23:06:42, Epoch : 1, Step : 380, Training Loss : 0.16978, Training Acc : 0.917, Run Time : 8.67
INFO:root:2019-05-10 23:06:42, Epoch : 1, Step : 381, Training Loss : 0.14897, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-10 23:06:42, Epoch : 1, Step : 382, Training Loss : 0.19195, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-10 23:06:43, Epoch : 1, Step : 383, Training Loss : 0.18445, Training Acc : 0.939, Run Time : 0.79
INFO:root:2019-05-10 23:06:51, Epoch : 1, Step : 384, Training Loss : 0.15223, Training Acc : 0.944, Run Time : 7.83
INFO:root:2019-05-10 23:06:52, Epoch : 1, Step : 385, Training Loss : 0.17855, Training Acc : 0.939, Run Time : 0.64
INFO:root:2019-05-10 23:06:52, Epoch : 1, Step : 386, Training Loss : 0.15837, Training Acc : 0.950, Run Time : 0.37
INFO:root:2019-05-10 23:06:53, Epoch : 1, Step : 387, Training Loss : 0.11812, Training Acc : 0.972, Run Time : 0.66
INFO:root:2019-05-10 23:07:06, Epoch : 1, Step : 388, Training Loss : 0.61556, Training Acc : 0.739, Run Time : 13.71
INFO:root:2019-05-10 23:07:12, Epoch : 1, Step : 389, Training Loss : 0.49487, Training Acc : 0.744, Run Time : 5.35
INFO:root:2019-05-10 23:07:12, Epoch : 1, Step : 390, Training Loss : 0.48169, Training Acc : 0.828, Run Time : 0.48
INFO:root:2019-05-10 23:07:13, Epoch : 1, Step : 391, Training Loss : 0.42013, Training Acc : 0.817, Run Time : 0.38
INFO:root:2019-05-10 23:07:13, Epoch : 1, Step : 392, Training Loss : 0.27701, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-10 23:07:14, Epoch : 1, Step : 393, Training Loss : 0.46627, Training Acc : 0.867, Run Time : 0.74
INFO:root:2019-05-10 23:07:15, Epoch : 1, Step : 394, Training Loss : 0.30898, Training Acc : 0.867, Run Time : 1.19
INFO:root:2019-05-10 23:07:16, Epoch : 1, Step : 395, Training Loss : 0.18694, Training Acc : 0.906, Run Time : 0.68
INFO:root:2019-05-10 23:07:16, Epoch : 1, Step : 396, Training Loss : 0.23576, Training Acc : 0.911, Run Time : 0.39
INFO:root:2019-05-10 23:07:17, Epoch : 1, Step : 397, Training Loss : 0.32660, Training Acc : 0.850, Run Time : 0.84
INFO:root:2019-05-10 23:07:23, Epoch : 1, Step : 398, Training Loss : 0.27564, Training Acc : 0.889, Run Time : 5.95
INFO:root:2019-05-10 23:07:23, Epoch : 1, Step : 399, Training Loss : 0.19635, Training Acc : 0.922, Run Time : 0.66
INFO:root:2019-05-10 23:07:24, Epoch : 1, Step : 400, Training Loss : 0.29878, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-10 23:07:24, Epoch : 1, Step : 401, Training Loss : 0.49452, Training Acc : 0.744, Run Time : 0.47
INFO:root:2019-05-10 23:07:32, Epoch : 1, Step : 402, Training Loss : 0.33957, Training Acc : 0.811, Run Time : 7.51
INFO:root:2019-05-10 23:07:32, Epoch : 1, Step : 403, Training Loss : 0.39045, Training Acc : 0.772, Run Time : 0.45
INFO:root:2019-05-10 23:07:33, Epoch : 1, Step : 404, Training Loss : 0.35483, Training Acc : 0.839, Run Time : 0.45
INFO:root:2019-05-10 23:07:33, Epoch : 1, Step : 405, Training Loss : 0.26021, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-10 23:07:34, Epoch : 1, Step : 406, Training Loss : 0.37949, Training Acc : 0.811, Run Time : 0.38
INFO:root:2019-05-10 23:07:35, Epoch : 1, Step : 407, Training Loss : 0.29736, Training Acc : 0.856, Run Time : 1.11
INFO:root:2019-05-10 23:07:42, Epoch : 1, Step : 408, Training Loss : 0.37193, Training Acc : 0.811, Run Time : 7.05
INFO:root:2019-05-10 23:07:42, Epoch : 1, Step : 409, Training Loss : 0.27299, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-10 23:07:43, Epoch : 1, Step : 410, Training Loss : 0.30603, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-10 23:07:50, Epoch : 1, Step : 411, Training Loss : 0.27938, Training Acc : 0.844, Run Time : 7.77
INFO:root:2019-05-10 23:07:51, Epoch : 1, Step : 412, Training Loss : 0.37533, Training Acc : 0.772, Run Time : 0.44
INFO:root:2019-05-10 23:07:51, Epoch : 1, Step : 413, Training Loss : 0.34495, Training Acc : 0.839, Run Time : 0.38
INFO:root:2019-05-10 23:07:52, Epoch : 1, Step : 414, Training Loss : 0.33911, Training Acc : 0.844, Run Time : 1.30
INFO:root:2019-05-10 23:08:01, Epoch : 1, Step : 415, Training Loss : 0.41110, Training Acc : 0.761, Run Time : 8.88
INFO:root:2019-05-10 23:08:02, Epoch : 1, Step : 416, Training Loss : 0.30942, Training Acc : 0.844, Run Time : 0.46
INFO:root:2019-05-10 23:08:02, Epoch : 1, Step : 417, Training Loss : 0.33904, Training Acc : 0.822, Run Time : 0.40
INFO:root:2019-05-10 23:08:03, Epoch : 1, Step : 418, Training Loss : 0.27890, Training Acc : 0.867, Run Time : 1.18
INFO:root:2019-05-10 23:08:12, Epoch : 1, Step : 419, Training Loss : 0.33554, Training Acc : 0.822, Run Time : 8.46
INFO:root:2019-05-10 23:08:12, Epoch : 1, Step : 420, Training Loss : 0.25066, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 23:08:13, Epoch : 1, Step : 421, Training Loss : 0.32839, Training Acc : 0.811, Run Time : 0.39
INFO:root:2019-05-10 23:08:13, Epoch : 1, Step : 422, Training Loss : 0.28847, Training Acc : 0.867, Run Time : 0.54
INFO:root:2019-05-10 23:08:23, Epoch : 1, Step : 423, Training Loss : 0.19606, Training Acc : 0.928, Run Time : 9.88
INFO:root:2019-05-10 23:08:24, Epoch : 1, Step : 424, Training Loss : 0.24444, Training Acc : 0.894, Run Time : 0.51
INFO:root:2019-05-10 23:08:25, Epoch : 1, Step : 425, Training Loss : 0.15776, Training Acc : 0.972, Run Time : 1.09
INFO:root:2019-05-10 23:08:35, Epoch : 1, Step : 426, Training Loss : 0.21752, Training Acc : 0.906, Run Time : 10.38
INFO:root:2019-05-10 23:08:36, Epoch : 1, Step : 427, Training Loss : 0.25341, Training Acc : 0.894, Run Time : 0.42
INFO:root:2019-05-10 23:08:36, Epoch : 1, Step : 428, Training Loss : 0.23660, Training Acc : 0.906, Run Time : 0.51
INFO:root:2019-05-10 23:08:37, Epoch : 1, Step : 429, Training Loss : 0.28775, Training Acc : 0.844, Run Time : 0.91
INFO:root:2019-05-10 23:08:46, Epoch : 1, Step : 430, Training Loss : 0.32337, Training Acc : 0.867, Run Time : 8.69
INFO:root:2019-05-10 23:08:46, Epoch : 1, Step : 431, Training Loss : 0.40580, Training Acc : 0.817, Run Time : 0.41
INFO:root:2019-05-10 23:08:46, Epoch : 1, Step : 432, Training Loss : 0.54748, Training Acc : 0.711, Run Time : 0.38
INFO:root:2019-05-10 23:08:47, Epoch : 1, Step : 433, Training Loss : 0.27586, Training Acc : 0.900, Run Time : 0.74
INFO:root:2019-05-10 23:08:52, Epoch : 1, Step : 434, Training Loss : 0.22353, Training Acc : 0.878, Run Time : 4.56
INFO:root:2019-05-10 23:08:52, Epoch : 1, Step : 435, Training Loss : 0.20867, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-10 23:08:53, Epoch : 1, Step : 436, Training Loss : 0.26377, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-10 23:08:53, Epoch : 1, Step : 437, Training Loss : 0.26232, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-10 23:08:55, Epoch : 1, Step : 438, Training Loss : 0.23554, Training Acc : 0.894, Run Time : 1.57
INFO:root:2019-05-10 23:09:01, Epoch : 1, Step : 439, Training Loss : 0.22374, Training Acc : 0.911, Run Time : 6.42
INFO:root:2019-05-10 23:09:01, Epoch : 1, Step : 440, Training Loss : 0.21552, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-10 23:09:02, Epoch : 1, Step : 441, Training Loss : 0.32809, Training Acc : 0.867, Run Time : 0.41
INFO:root:2019-05-10 23:09:03, Epoch : 1, Step : 442, Training Loss : 0.88872, Training Acc : 0.689, Run Time : 1.34
INFO:root:2019-05-10 23:09:14, Epoch : 1, Step : 443, Training Loss : 0.62674, Training Acc : 0.778, Run Time : 11.05
INFO:root:2019-05-10 23:09:15, Epoch : 1, Step : 444, Training Loss : 0.31814, Training Acc : 0.883, Run Time : 0.42
INFO:root:2019-05-10 23:09:15, Epoch : 1, Step : 445, Training Loss : 0.72168, Training Acc : 0.700, Run Time : 0.38
INFO:root:2019-05-10 23:09:26, Epoch : 1, Step : 446, Training Loss : 0.37023, Training Acc : 0.844, Run Time : 10.60
INFO:root:2019-05-10 23:09:29, Epoch : 1, Step : 447, Training Loss : 0.33140, Training Acc : 0.844, Run Time : 3.41
INFO:root:2019-05-10 23:09:29, Epoch : 1, Step : 448, Training Loss : 0.34293, Training Acc : 0.833, Run Time : 0.46
INFO:root:2019-05-10 23:09:30, Epoch : 1, Step : 449, Training Loss : 0.38279, Training Acc : 0.800, Run Time : 0.79
INFO:root:2019-05-10 23:09:42, Epoch : 1, Step : 450, Training Loss : 0.33509, Training Acc : 0.850, Run Time : 11.83
INFO:root:2019-05-10 23:09:42, Epoch : 1, Step : 451, Training Loss : 0.58225, Training Acc : 0.739, Run Time : 0.42
INFO:root:2019-05-10 23:09:43, Epoch : 1, Step : 452, Training Loss : 0.40612, Training Acc : 0.828, Run Time : 0.41
INFO:root:2019-05-10 23:09:43, Epoch : 1, Step : 453, Training Loss : 0.43415, Training Acc : 0.778, Run Time : 0.42
INFO:root:2019-05-10 23:09:44, Epoch : 1, Step : 454, Training Loss : 0.53996, Training Acc : 0.750, Run Time : 0.48
INFO:root:2019-05-10 23:09:49, Epoch : 1, Step : 455, Training Loss : 0.49025, Training Acc : 0.756, Run Time : 5.12
INFO:root:2019-05-10 23:09:52, Epoch : 1, Step : 456, Training Loss : 0.37419, Training Acc : 0.833, Run Time : 2.78
INFO:root:2019-05-10 23:09:53, Epoch : 1, Step : 457, Training Loss : 0.34808, Training Acc : 0.839, Run Time : 0.90
INFO:root:2019-05-10 23:09:59, Epoch : 1, Step : 458, Training Loss : 0.30154, Training Acc : 0.850, Run Time : 6.42
INFO:root:2019-05-10 23:10:00, Epoch : 1, Step : 459, Training Loss : 0.27746, Training Acc : 0.856, Run Time : 0.61
INFO:root:2019-05-10 23:10:00, Epoch : 1, Step : 460, Training Loss : 0.27730, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 23:10:01, Epoch : 1, Step : 461, Training Loss : 0.29545, Training Acc : 0.839, Run Time : 1.33
INFO:root:2019-05-10 23:10:08, Epoch : 1, Step : 462, Training Loss : 0.30676, Training Acc : 0.861, Run Time : 6.52
INFO:root:2019-05-10 23:10:08, Epoch : 1, Step : 463, Training Loss : 0.25725, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-10 23:10:09, Epoch : 1, Step : 464, Training Loss : 0.23887, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-10 23:10:10, Epoch : 1, Step : 465, Training Loss : 0.34424, Training Acc : 0.844, Run Time : 1.28
INFO:root:2019-05-10 23:10:19, Epoch : 1, Step : 466, Training Loss : 0.27615, Training Acc : 0.861, Run Time : 8.81
INFO:root:2019-05-10 23:10:19, Epoch : 1, Step : 467, Training Loss : 0.23562, Training Acc : 0.883, Run Time : 0.42
INFO:root:2019-05-10 23:10:20, Epoch : 1, Step : 468, Training Loss : 0.15483, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-10 23:10:21, Epoch : 1, Step : 469, Training Loss : 0.23701, Training Acc : 0.900, Run Time : 1.64
INFO:root:2019-05-10 23:10:31, Epoch : 1, Step : 470, Training Loss : 0.20319, Training Acc : 0.939, Run Time : 9.10
INFO:root:2019-05-10 23:10:31, Epoch : 1, Step : 471, Training Loss : 0.22120, Training Acc : 0.944, Run Time : 0.43
INFO:root:2019-05-10 23:10:31, Epoch : 1, Step : 472, Training Loss : 0.19981, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-10 23:10:32, Epoch : 1, Step : 473, Training Loss : 0.16624, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 23:10:42, Epoch : 1, Step : 474, Training Loss : 0.18806, Training Acc : 0.950, Run Time : 10.04
INFO:root:2019-05-10 23:10:43, Epoch : 1, Step : 475, Training Loss : 0.16346, Training Acc : 0.944, Run Time : 1.58
INFO:root:2019-05-10 23:10:44, Epoch : 1, Step : 476, Training Loss : 0.14572, Training Acc : 0.961, Run Time : 0.73
INFO:root:2019-05-10 23:10:49, Epoch : 1, Step : 477, Training Loss : 0.10354, Training Acc : 0.972, Run Time : 4.75
INFO:root:2019-05-10 23:10:53, Epoch : 1, Step : 478, Training Loss : 0.21285, Training Acc : 0.917, Run Time : 4.10
INFO:root:2019-05-10 23:10:53, Epoch : 1, Step : 479, Training Loss : 0.09193, Training Acc : 0.989, Run Time : 0.45
INFO:root:2019-05-10 23:10:54, Epoch : 1, Step : 480, Training Loss : 0.31128, Training Acc : 0.883, Run Time : 0.68
INFO:root:2019-05-10 23:10:55, Epoch : 1, Step : 481, Training Loss : 0.14452, Training Acc : 0.956, Run Time : 1.05
INFO:root:2019-05-10 23:11:04, Epoch : 1, Step : 482, Training Loss : 0.13725, Training Acc : 0.956, Run Time : 8.82
INFO:root:2019-05-10 23:11:17, Epoch : 1, Step : 483, Training Loss : 0.14458, Training Acc : 0.950, Run Time : 12.71
INFO:root:2019-05-10 23:11:18, Epoch : 1, Step : 484, Training Loss : 0.12528, Training Acc : 0.961, Run Time : 1.27
INFO:root:2019-05-10 23:11:18, Epoch : 1, Step : 485, Training Loss : 0.11151, Training Acc : 0.967, Run Time : 0.43
INFO:root:2019-05-10 23:11:20, Epoch : 1, Step : 486, Training Loss : 0.07701, Training Acc : 0.978, Run Time : 1.60
INFO:root:2019-05-10 23:11:28, Epoch : 1, Step : 487, Training Loss : 0.07162, Training Acc : 1.000, Run Time : 7.99
INFO:root:2019-05-10 23:11:28, Epoch : 1, Step : 488, Training Loss : 0.10319, Training Acc : 0.967, Run Time : 0.46
INFO:root:2019-05-10 23:11:29, Epoch : 1, Step : 489, Training Loss : 0.15791, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-10 23:11:30, Epoch : 1, Step : 490, Training Loss : 0.13902, Training Acc : 0.956, Run Time : 0.90
INFO:root:2019-05-10 23:11:33, Epoch : 1, Step : 491, Training Loss : 0.14861, Training Acc : 0.961, Run Time : 3.05
INFO:root:2019-05-10 23:11:33, Epoch : 1, Step : 492, Training Loss : 0.12905, Training Acc : 0.950, Run Time : 0.68
INFO:root:2019-05-10 23:11:34, Epoch : 1, Step : 493, Training Loss : 0.17703, Training Acc : 0.939, Run Time : 0.39
INFO:root:2019-05-10 23:11:34, Epoch : 1, Step : 494, Training Loss : 0.06056, Training Acc : 0.994, Run Time : 0.38
INFO:root:2019-05-10 23:11:35, Epoch : 1, Step : 495, Training Loss : 0.13801, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-10 23:11:36, Epoch : 1, Step : 496, Training Loss : 0.06493, Training Acc : 0.989, Run Time : 0.89
INFO:root:2019-05-10 23:11:43, Epoch : 1, Step : 497, Training Loss : 0.12985, Training Acc : 0.956, Run Time : 7.22
INFO:root:2019-05-10 23:11:44, Epoch : 1, Step : 498, Training Loss : 0.06884, Training Acc : 0.983, Run Time : 0.86
INFO:root:2019-05-10 23:11:44, Epoch : 1, Step : 499, Training Loss : 0.06517, Training Acc : 0.978, Run Time : 0.38
INFO:root:2019-05-10 23:11:45, Epoch : 1, Step : 500, Training Loss : 0.25302, Training Acc : 0.878, Run Time : 0.76
INFO:root:2019-05-10 23:11:49, Epoch : 1, Step : 501, Training Loss : 0.25738, Training Acc : 0.889, Run Time : 3.72
INFO:root:2019-05-10 23:11:49, Epoch : 1, Step : 502, Training Loss : 0.33363, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-10 23:11:50, Epoch : 1, Step : 503, Training Loss : 0.41215, Training Acc : 0.861, Run Time : 0.58
INFO:root:2019-05-10 23:11:54, Epoch : 1, Step : 504, Training Loss : 0.24801, Training Acc : 0.878, Run Time : 4.37
INFO:root:2019-05-10 23:11:55, Epoch : 1, Step : 505, Training Loss : 0.31214, Training Acc : 0.867, Run Time : 0.70
INFO:root:2019-05-10 23:11:55, Epoch : 1, Step : 506, Training Loss : 0.25531, Training Acc : 0.900, Run Time : 0.38
INFO:root:2019-05-10 23:11:56, Epoch : 1, Step : 507, Training Loss : 0.19970, Training Acc : 0.933, Run Time : 0.55
INFO:root:2019-05-10 23:11:57, Epoch : 1, Step : 508, Training Loss : 0.15186, Training Acc : 0.950, Run Time : 1.74
INFO:root:2019-05-10 23:12:09, Epoch : 1, Step : 509, Training Loss : 0.20336, Training Acc : 0.939, Run Time : 11.76
INFO:root:2019-05-10 23:12:10, Epoch : 1, Step : 510, Training Loss : 0.29226, Training Acc : 0.889, Run Time : 0.50
INFO:root:2019-05-10 23:12:10, Epoch : 1, Step : 511, Training Loss : 0.17287, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-10 23:12:12, Epoch : 1, Step : 512, Training Loss : 0.18362, Training Acc : 0.928, Run Time : 1.60
INFO:root:2019-05-10 23:12:23, Epoch : 1, Step : 513, Training Loss : 0.20623, Training Acc : 0.889, Run Time : 11.69
INFO:root:2019-05-10 23:12:24, Epoch : 1, Step : 514, Training Loss : 0.16958, Training Acc : 0.917, Run Time : 0.57
INFO:root:2019-05-10 23:12:24, Epoch : 1, Step : 515, Training Loss : 0.16353, Training Acc : 0.928, Run Time : 0.39
INFO:root:2019-05-10 23:12:33, Epoch : 1, Step : 516, Training Loss : 0.29448, Training Acc : 0.883, Run Time : 8.52
INFO:root:2019-05-10 23:12:35, Epoch : 1, Step : 517, Training Loss : 0.16591, Training Acc : 0.911, Run Time : 1.89
INFO:root:2019-05-10 23:12:48, Epoch : 1, Step : 518, Training Loss : 0.08205, Training Acc : 0.972, Run Time : 13.54
INFO:root:2019-05-10 23:12:49, Epoch : 1, Step : 519, Training Loss : 0.12882, Training Acc : 0.939, Run Time : 0.42
INFO:root:2019-05-10 23:12:49, Epoch : 1, Step : 520, Training Loss : 0.60463, Training Acc : 0.778, Run Time : 0.39
INFO:root:2019-05-10 23:13:03, Epoch : 1, Step : 521, Training Loss : 0.11597, Training Acc : 0.967, Run Time : 13.80
INFO:root:2019-05-10 23:13:06, Epoch : 1, Step : 522, Training Loss : 0.09312, Training Acc : 0.967, Run Time : 3.33
INFO:root:2019-05-10 23:13:06, Epoch : 1, Step : 523, Training Loss : 0.12132, Training Acc : 0.950, Run Time : 0.39
INFO:root:2019-05-10 23:13:07, Epoch : 1, Step : 524, Training Loss : 0.27492, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-10 23:13:08, Epoch : 1, Step : 525, Training Loss : 0.13435, Training Acc : 0.956, Run Time : 1.29
INFO:root:2019-05-10 23:13:16, Epoch : 1, Step : 526, Training Loss : 0.26543, Training Acc : 0.894, Run Time : 8.21
INFO:root:2019-05-10 23:13:17, Epoch : 1, Step : 527, Training Loss : 0.15290, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-10 23:13:17, Epoch : 1, Step : 528, Training Loss : 0.30191, Training Acc : 0.844, Run Time : 0.56
INFO:root:2019-05-10 23:13:18, Epoch : 1, Step : 529, Training Loss : 0.32694, Training Acc : 0.850, Run Time : 0.40
INFO:root:2019-05-10 23:13:26, Epoch : 1, Step : 530, Training Loss : 0.79681, Training Acc : 0.617, Run Time : 7.79
INFO:root:2019-05-10 23:13:26, Epoch : 1, Step : 531, Training Loss : 0.60895, Training Acc : 0.733, Run Time : 0.78
INFO:root:2019-05-10 23:13:27, Epoch : 1, Step : 532, Training Loss : 0.09648, Training Acc : 0.956, Run Time : 0.40
INFO:root:2019-05-10 23:13:33, Epoch : 1, Step : 533, Training Loss : 0.14973, Training Acc : 0.944, Run Time : 6.13
INFO:root:2019-05-10 23:13:34, Epoch : 1, Step : 534, Training Loss : 0.29280, Training Acc : 0.906, Run Time : 0.68
INFO:root:2019-05-10 23:13:34, Epoch : 1, Step : 535, Training Loss : 0.14068, Training Acc : 0.967, Run Time : 0.42
INFO:root:2019-05-10 23:13:35, Epoch : 1, Step : 536, Training Loss : 0.12761, Training Acc : 0.961, Run Time : 1.07
INFO:root:2019-05-10 23:13:47, Epoch : 1, Step : 537, Training Loss : 0.24108, Training Acc : 0.906, Run Time : 12.25
INFO:root:2019-05-10 23:13:52, Epoch : 1, Step : 538, Training Loss : 0.18375, Training Acc : 0.944, Run Time : 4.38
INFO:root:2019-05-10 23:14:08, Epoch : 1, Step : 539, Training Loss : 0.32190, Training Acc : 0.867, Run Time : 16.40
INFO:root:2019-05-10 23:14:11, Epoch : 1, Step : 540, Training Loss : 0.11188, Training Acc : 0.950, Run Time : 3.02
INFO:root:2019-05-10 23:14:11, Epoch : 1, Step : 541, Training Loss : 0.27508, Training Acc : 0.894, Run Time : 0.41
INFO:root:2019-05-10 23:14:12, Epoch : 1, Step : 542, Training Loss : 0.14909, Training Acc : 0.956, Run Time : 0.43
INFO:root:2019-05-10 23:14:12, Epoch : 1, Step : 543, Training Loss : 0.13965, Training Acc : 0.967, Run Time : 0.38
INFO:root:2019-05-10 23:14:13, Epoch : 1, Step : 544, Training Loss : 0.10923, Training Acc : 0.978, Run Time : 1.10
INFO:root:2019-05-10 23:14:28, Epoch : 1, Step : 545, Training Loss : 0.18652, Training Acc : 0.900, Run Time : 14.35
INFO:root:2019-05-10 23:14:40, Epoch : 1, Step : 546, Training Loss : 0.19662, Training Acc : 0.928, Run Time : 12.66
INFO:root:2019-05-10 23:14:42, Epoch : 1, Step : 547, Training Loss : 0.11223, Training Acc : 0.961, Run Time : 1.77
INFO:root:2019-05-10 23:14:43, Epoch : 1, Step : 548, Training Loss : 0.29081, Training Acc : 0.861, Run Time : 0.51
INFO:root:2019-05-10 23:14:43, Epoch : 1, Step : 549, Training Loss : 0.28683, Training Acc : 0.861, Run Time : 0.53
INFO:root:2019-05-10 23:14:44, Epoch : 1, Step : 550, Training Loss : 0.50549, Training Acc : 0.711, Run Time : 0.39
INFO:root:2019-05-10 23:14:44, Epoch : 1, Step : 551, Training Loss : 0.23470, Training Acc : 0.900, Run Time : 0.39
INFO:root:2019-05-10 23:14:44, Epoch : 1, Step : 552, Training Loss : 0.16702, Training Acc : 0.939, Run Time : 0.40
INFO:root:2019-05-10 23:14:45, Epoch : 1, Step : 553, Training Loss : 0.22745, Training Acc : 0.917, Run Time : 0.40
INFO:root:2019-05-10 23:14:46, Epoch : 1, Step : 554, Training Loss : 0.22547, Training Acc : 0.900, Run Time : 0.90
INFO:root:2019-05-10 23:14:55, Epoch : 1, Step : 555, Training Loss : 0.13530, Training Acc : 0.944, Run Time : 9.22
INFO:root:2019-05-10 23:14:55, Epoch : 1, Step : 556, Training Loss : 0.19178, Training Acc : 0.950, Run Time : 0.41
INFO:root:2019-05-10 23:14:56, Epoch : 1, Step : 557, Training Loss : 0.15624, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-10 23:14:57, Epoch : 1, Step : 558, Training Loss : 0.14285, Training Acc : 0.961, Run Time : 0.88
INFO:root:2019-05-10 23:15:03, Epoch : 1, Step : 559, Training Loss : 0.10171, Training Acc : 0.978, Run Time : 6.15
INFO:root:2019-05-10 23:15:03, Epoch : 1, Step : 560, Training Loss : 0.16812, Training Acc : 0.950, Run Time : 0.41
INFO:root:2019-05-10 23:15:04, Epoch : 1, Step : 561, Training Loss : 0.20674, Training Acc : 0.917, Run Time : 0.48
INFO:root:2019-05-10 23:15:05, Epoch : 1, Step : 562, Training Loss : 0.19517, Training Acc : 0.922, Run Time : 1.38
INFO:root:2019-05-10 23:15:20, Epoch : 1, Step : 563, Training Loss : 0.34223, Training Acc : 0.867, Run Time : 15.26
INFO:root:2019-05-10 23:15:22, Epoch : 1, Step : 564, Training Loss : 0.13595, Training Acc : 0.967, Run Time : 1.54
INFO:root:2019-05-10 23:15:22, Epoch : 1, Step : 565, Training Loss : 0.39413, Training Acc : 0.867, Run Time : 0.38
INFO:root:2019-05-10 23:15:27, Epoch : 1, Step : 566, Training Loss : 0.16597, Training Acc : 0.939, Run Time : 4.84
INFO:root:2019-05-10 23:15:27, Epoch : 1, Step : 567, Training Loss : 0.18698, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-10 23:15:28, Epoch : 1, Step : 568, Training Loss : 0.18018, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-10 23:15:28, Epoch : 1, Step : 569, Training Loss : 0.19670, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-10 23:15:36, Epoch : 1, Step : 570, Training Loss : 0.21575, Training Acc : 0.889, Run Time : 7.64
INFO:root:2019-05-10 23:15:45, Epoch : 1, Step : 571, Training Loss : 0.26655, Training Acc : 0.900, Run Time : 9.02
INFO:root:2019-05-10 23:15:46, Epoch : 1, Step : 572, Training Loss : 0.14784, Training Acc : 0.950, Run Time : 1.20
INFO:root:2019-05-10 23:16:06, Epoch : 1, Step : 573, Training Loss : 0.39757, Training Acc : 0.806, Run Time : 19.49
INFO:root:2019-05-10 23:16:06, Epoch : 1, Step : 574, Training Loss : 0.23206, Training Acc : 0.900, Run Time : 0.70
INFO:root:2019-05-10 23:16:07, Epoch : 1, Step : 575, Training Loss : 0.14892, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-10 23:16:07, Epoch : 1, Step : 576, Training Loss : 0.25132, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 23:16:13, Epoch : 1, Step : 577, Training Loss : 0.21705, Training Acc : 0.889, Run Time : 5.68
INFO:root:2019-05-10 23:16:14, Epoch : 1, Step : 578, Training Loss : 0.24914, Training Acc : 0.878, Run Time : 0.68
INFO:root:2019-05-10 23:16:14, Epoch : 1, Step : 579, Training Loss : 0.23632, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-10 23:16:14, Epoch : 1, Step : 580, Training Loss : 0.43090, Training Acc : 0.828, Run Time : 0.47
INFO:root:2019-05-10 23:16:24, Epoch : 1, Step : 581, Training Loss : 0.22161, Training Acc : 0.917, Run Time : 9.11
INFO:root:2019-05-10 23:16:24, Epoch : 1, Step : 582, Training Loss : 0.24760, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-10 23:16:25, Epoch : 1, Step : 583, Training Loss : 0.24936, Training Acc : 0.911, Run Time : 0.61
INFO:root:2019-05-10 23:16:37, Epoch : 1, Step : 584, Training Loss : 0.28834, Training Acc : 0.889, Run Time : 12.77
INFO:root:2019-05-10 23:16:38, Epoch : 1, Step : 585, Training Loss : 0.30739, Training Acc : 0.850, Run Time : 0.49
INFO:root:2019-05-10 23:16:39, Epoch : 1, Step : 586, Training Loss : 0.22896, Training Acc : 0.889, Run Time : 0.86
INFO:root:2019-05-10 23:16:58, Epoch : 1, Step : 587, Training Loss : 0.34504, Training Acc : 0.800, Run Time : 19.01
INFO:root:2019-05-10 23:17:00, Epoch : 1, Step : 588, Training Loss : 0.30200, Training Acc : 0.872, Run Time : 1.95
INFO:root:2019-05-10 23:17:00, Epoch : 1, Step : 589, Training Loss : 0.25038, Training Acc : 0.894, Run Time : 0.43
INFO:root:2019-05-10 23:17:01, Epoch : 1, Step : 590, Training Loss : 0.24837, Training Acc : 0.878, Run Time : 0.69
INFO:root:2019-05-10 23:17:15, Epoch : 1, Step : 591, Training Loss : 0.27279, Training Acc : 0.867, Run Time : 13.97
INFO:root:2019-05-10 23:17:23, Epoch : 1, Step : 592, Training Loss : 0.19576, Training Acc : 0.922, Run Time : 7.98
INFO:root:2019-05-10 23:17:37, Epoch : 1, Step : 593, Training Loss : 0.27910, Training Acc : 0.872, Run Time : 14.38
INFO:root:2019-05-10 23:17:38, Epoch : 1, Step : 594, Training Loss : 0.26229, Training Acc : 0.856, Run Time : 1.21
INFO:root:2019-05-10 23:17:39, Epoch : 1, Step : 595, Training Loss : 0.31667, Training Acc : 0.833, Run Time : 0.44
INFO:root:2019-05-10 23:17:42, Epoch : 1, Step : 596, Training Loss : 0.27897, Training Acc : 0.839, Run Time : 3.06
INFO:root:2019-05-10 23:17:42, Epoch : 1, Step : 597, Training Loss : 0.32377, Training Acc : 0.844, Run Time : 0.53
INFO:root:2019-05-10 23:17:44, Epoch : 1, Step : 598, Training Loss : 0.25838, Training Acc : 0.867, Run Time : 1.88
INFO:root:2019-05-10 23:17:48, Epoch : 1, Step : 599, Training Loss : 0.19640, Training Acc : 0.928, Run Time : 3.27
INFO:root:2019-05-10 23:17:52, Epoch : 1, Step : 600, Training Loss : 0.31146, Training Acc : 0.828, Run Time : 4.94
INFO:root:2019-05-10 23:18:03, Epoch : 1, Step : 601, Training Loss : 0.47525, Training Acc : 0.794, Run Time : 10.84
INFO:root:2019-05-10 23:18:15, Epoch : 1, Step : 602, Training Loss : 0.56201, Training Acc : 0.750, Run Time : 11.50
INFO:root:2019-05-10 23:18:27, Epoch : 1, Step : 603, Training Loss : 0.57542, Training Acc : 0.739, Run Time : 12.56
INFO:root:2019-05-10 23:18:28, Epoch : 1, Step : 604, Training Loss : 0.34021, Training Acc : 0.889, Run Time : 0.62
INFO:root:2019-05-10 23:18:29, Epoch : 1, Step : 605, Training Loss : 0.47220, Training Acc : 0.778, Run Time : 1.34
INFO:root:2019-05-10 23:18:38, Epoch : 1, Step : 606, Training Loss : 0.50498, Training Acc : 0.767, Run Time : 8.22
INFO:root:2019-05-10 23:18:38, Epoch : 1, Step : 607, Training Loss : 0.22321, Training Acc : 0.900, Run Time : 0.60
INFO:root:2019-05-10 23:18:39, Epoch : 1, Step : 608, Training Loss : 0.24962, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-10 23:18:39, Epoch : 1, Step : 609, Training Loss : 0.20325, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-10 23:18:39, Epoch : 1, Step : 610, Training Loss : 0.24944, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-10 23:18:40, Epoch : 1, Step : 611, Training Loss : 0.16354, Training Acc : 0.933, Run Time : 0.39
INFO:root:2019-05-10 23:18:40, Epoch : 1, Step : 612, Training Loss : 0.38486, Training Acc : 0.789, Run Time : 0.39
INFO:root:2019-05-10 23:18:45, Epoch : 1, Step : 613, Training Loss : 0.23512, Training Acc : 0.894, Run Time : 5.32
INFO:root:2019-05-10 23:18:46, Epoch : 1, Step : 614, Training Loss : 0.42957, Training Acc : 0.817, Run Time : 0.42
INFO:root:2019-05-10 23:18:53, Epoch : 1, Step : 615, Training Loss : 0.24138, Training Acc : 0.906, Run Time : 6.85
INFO:root:2019-05-10 23:18:53, Epoch : 1, Step : 616, Training Loss : 0.29513, Training Acc : 0.917, Run Time : 0.63
INFO:root:2019-05-10 23:18:54, Epoch : 1, Step : 617, Training Loss : 0.37065, Training Acc : 0.806, Run Time : 0.38
INFO:root:2019-05-10 23:18:55, Epoch : 1, Step : 618, Training Loss : 0.27876, Training Acc : 0.917, Run Time : 1.10
INFO:root:2019-05-10 23:18:59, Epoch : 1, Step : 619, Training Loss : 0.33017, Training Acc : 0.872, Run Time : 4.20
INFO:root:2019-05-10 23:18:59, Epoch : 1, Step : 620, Training Loss : 0.39247, Training Acc : 0.844, Run Time : 0.42
INFO:root:2019-05-10 23:19:00, Epoch : 1, Step : 621, Training Loss : 0.21660, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-10 23:19:01, Epoch : 1, Step : 622, Training Loss : 0.37674, Training Acc : 0.811, Run Time : 1.50
INFO:root:2019-05-10 23:19:14, Epoch : 1, Step : 623, Training Loss : 0.57887, Training Acc : 0.789, Run Time : 12.77
INFO:root:2019-05-10 23:19:15, Epoch : 1, Step : 624, Training Loss : 0.28284, Training Acc : 0.900, Run Time : 0.75
INFO:root:2019-05-10 23:19:15, Epoch : 1, Step : 625, Training Loss : 0.24507, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-10 23:19:16, Epoch : 1, Step : 626, Training Loss : 0.36799, Training Acc : 0.867, Run Time : 0.43
INFO:root:2019-05-10 23:19:16, Epoch : 1, Step : 627, Training Loss : 0.24058, Training Acc : 0.928, Run Time : 0.71
INFO:root:2019-05-10 23:19:23, Epoch : 1, Step : 628, Training Loss : 0.31815, Training Acc : 0.867, Run Time : 6.23
INFO:root:2019-05-10 23:19:23, Epoch : 1, Step : 629, Training Loss : 0.21600, Training Acc : 0.911, Run Time : 0.69
INFO:root:2019-05-10 23:19:24, Epoch : 1, Step : 630, Training Loss : 0.24975, Training Acc : 0.900, Run Time : 0.38
INFO:root:2019-05-10 23:19:24, Epoch : 1, Step : 631, Training Loss : 0.22089, Training Acc : 0.922, Run Time : 0.39
INFO:root:2019-05-10 23:19:25, Epoch : 1, Step : 632, Training Loss : 0.14986, Training Acc : 0.972, Run Time : 0.54
INFO:root:2019-05-10 23:19:26, Epoch : 1, Step : 633, Training Loss : 0.39472, Training Acc : 0.822, Run Time : 1.45
INFO:root:2019-05-10 23:19:30, Epoch : 1, Step : 634, Training Loss : 0.20863, Training Acc : 0.933, Run Time : 4.23
INFO:root:2019-05-10 23:19:31, Epoch : 1, Step : 635, Training Loss : 0.22762, Training Acc : 0.922, Run Time : 0.66
INFO:root:2019-05-10 23:19:31, Epoch : 1, Step : 636, Training Loss : 0.19651, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-10 23:19:32, Epoch : 1, Step : 637, Training Loss : 0.31975, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-10 23:19:41, Epoch : 1, Step : 638, Training Loss : 0.24643, Training Acc : 0.900, Run Time : 9.67
INFO:root:2019-05-10 23:19:43, Epoch : 1, Step : 639, Training Loss : 0.22710, Training Acc : 0.911, Run Time : 1.21
INFO:root:2019-05-10 23:19:43, Epoch : 1, Step : 640, Training Loss : 0.15967, Training Acc : 0.956, Run Time : 0.42
INFO:root:2019-05-10 23:19:43, Epoch : 1, Step : 641, Training Loss : 0.19079, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-10 23:20:00, Epoch : 1, Step : 642, Training Loss : 0.39607, Training Acc : 0.806, Run Time : 16.44
INFO:root:2019-05-10 23:20:01, Epoch : 1, Step : 643, Training Loss : 0.24688, Training Acc : 0.861, Run Time : 0.80
INFO:root:2019-05-10 23:20:01, Epoch : 1, Step : 644, Training Loss : 0.38149, Training Acc : 0.883, Run Time : 0.41
INFO:root:2019-05-10 23:20:02, Epoch : 1, Step : 645, Training Loss : 0.23271, Training Acc : 0.894, Run Time : 0.65
INFO:root:2019-05-10 23:20:14, Epoch : 1, Step : 646, Training Loss : 0.25577, Training Acc : 0.906, Run Time : 11.94
INFO:root:2019-05-10 23:20:14, Epoch : 1, Step : 647, Training Loss : 0.28014, Training Acc : 0.872, Run Time : 0.65
INFO:root:2019-05-10 23:20:15, Epoch : 1, Step : 648, Training Loss : 0.22359, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-10 23:20:15, Epoch : 1, Step : 649, Training Loss : 0.50089, Training Acc : 0.767, Run Time : 0.40
INFO:root:2019-05-10 23:20:16, Epoch : 1, Step : 650, Training Loss : 0.44751, Training Acc : 0.772, Run Time : 0.46
INFO:root:2019-05-10 23:20:16, Epoch : 1, Step : 651, Training Loss : 0.28641, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-10 23:20:17, Epoch : 1, Step : 652, Training Loss : 0.18615, Training Acc : 0.939, Run Time : 0.56
INFO:root:2019-05-10 23:20:23, Epoch : 1, Step : 653, Training Loss : 0.12712, Training Acc : 0.967, Run Time : 6.14
INFO:root:2019-05-10 23:20:25, Epoch : 1, Step : 654, Training Loss : 0.21017, Training Acc : 0.911, Run Time : 2.31
INFO:root:2019-05-10 23:20:26, Epoch : 1, Step : 655, Training Loss : 0.20227, Training Acc : 0.928, Run Time : 0.55
INFO:root:2019-05-10 23:20:26, Epoch : 1, Step : 656, Training Loss : 0.29146, Training Acc : 0.889, Run Time : 0.57
INFO:root:2019-05-10 23:20:37, Epoch : 1, Step : 657, Training Loss : 0.30292, Training Acc : 0.878, Run Time : 10.65
INFO:root:2019-05-10 23:20:39, Epoch : 1, Step : 658, Training Loss : 0.27649, Training Acc : 0.883, Run Time : 2.40
INFO:root:2019-05-10 23:20:45, Epoch : 1, Step : 659, Training Loss : 0.27802, Training Acc : 0.861, Run Time : 5.45
INFO:root:2019-05-10 23:20:46, Epoch : 1, Step : 660, Training Loss : 0.24053, Training Acc : 0.883, Run Time : 1.37
INFO:root:2019-05-10 23:20:48, Epoch : 1, Step : 661, Training Loss : 0.25477, Training Acc : 0.883, Run Time : 2.05
INFO:root:2019-05-10 23:20:55, Epoch : 1, Step : 662, Training Loss : 0.29807, Training Acc : 0.878, Run Time : 6.88
INFO:root:2019-05-10 23:20:55, Epoch : 1, Step : 663, Training Loss : 0.51931, Training Acc : 0.756, Run Time : 0.48
INFO:root:2019-05-10 23:20:56, Epoch : 1, Step : 664, Training Loss : 0.74027, Training Acc : 0.667, Run Time : 0.42
INFO:root:2019-05-10 23:20:57, Epoch : 1, Step : 665, Training Loss : 0.35960, Training Acc : 0.839, Run Time : 1.09
INFO:root:2019-05-10 23:21:05, Epoch : 1, Step : 666, Training Loss : 0.66944, Training Acc : 0.789, Run Time : 8.36
INFO:root:2019-05-10 23:21:06, Epoch : 1, Step : 667, Training Loss : 0.37477, Training Acc : 0.828, Run Time : 0.41
INFO:root:2019-05-10 23:21:06, Epoch : 1, Step : 668, Training Loss : 0.35190, Training Acc : 0.844, Run Time : 0.59
INFO:root:2019-05-10 23:21:14, Epoch : 1, Step : 669, Training Loss : 0.41765, Training Acc : 0.822, Run Time : 7.18
INFO:root:2019-05-10 23:21:14, Epoch : 1, Step : 670, Training Loss : 0.46994, Training Acc : 0.789, Run Time : 0.53
INFO:root:2019-05-10 23:21:14, Epoch : 1, Step : 671, Training Loss : 0.31857, Training Acc : 0.850, Run Time : 0.44
INFO:root:2019-05-10 23:21:16, Epoch : 1, Step : 672, Training Loss : 0.34680, Training Acc : 0.839, Run Time : 1.54
INFO:root:2019-05-10 23:21:27, Epoch : 1, Step : 673, Training Loss : 0.39571, Training Acc : 0.839, Run Time : 10.65
INFO:root:2019-05-10 23:21:27, Epoch : 1, Step : 674, Training Loss : 0.33468, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-10 23:21:27, Epoch : 1, Step : 675, Training Loss : 0.29873, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-10 23:21:28, Epoch : 1, Step : 676, Training Loss : 0.35694, Training Acc : 0.839, Run Time : 0.69
INFO:root:2019-05-10 23:21:30, Epoch : 1, Step : 677, Training Loss : 0.47415, Training Acc : 0.761, Run Time : 1.58
INFO:root:2019-05-10 23:21:30, Epoch : 1, Step : 678, Training Loss : 0.39965, Training Acc : 0.817, Run Time : 0.41
INFO:root:2019-05-10 23:21:31, Epoch : 1, Step : 679, Training Loss : 0.34096, Training Acc : 0.872, Run Time : 0.46
INFO:root:2019-05-10 23:21:31, Epoch : 1, Step : 680, Training Loss : 0.33570, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-10 23:21:32, Epoch : 1, Step : 681, Training Loss : 0.49368, Training Acc : 0.783, Run Time : 0.87
INFO:root:2019-05-10 23:21:39, Epoch : 1, Step : 682, Training Loss : 0.40470, Training Acc : 0.789, Run Time : 7.50
INFO:root:2019-05-10 23:21:40, Epoch : 1, Step : 683, Training Loss : 0.37355, Training Acc : 0.850, Run Time : 0.41
INFO:root:2019-05-10 23:21:40, Epoch : 1, Step : 684, Training Loss : 0.45059, Training Acc : 0.739, Run Time : 0.38
INFO:root:2019-05-10 23:21:41, Epoch : 1, Step : 685, Training Loss : 0.37301, Training Acc : 0.811, Run Time : 1.18
INFO:root:2019-05-10 23:21:48, Epoch : 1, Step : 686, Training Loss : 0.31143, Training Acc : 0.883, Run Time : 6.42
INFO:root:2019-05-10 23:21:48, Epoch : 1, Step : 687, Training Loss : 0.38842, Training Acc : 0.806, Run Time : 0.41
INFO:root:2019-05-10 23:21:49, Epoch : 1, Step : 688, Training Loss : 0.32825, Training Acc : 0.856, Run Time : 0.38
INFO:root:2019-05-10 23:21:50, Epoch : 1, Step : 689, Training Loss : 0.37500, Training Acc : 0.789, Run Time : 1.56
INFO:root:2019-05-10 23:21:59, Epoch : 1, Step : 690, Training Loss : 0.25897, Training Acc : 0.894, Run Time : 8.96
INFO:root:2019-05-10 23:21:59, Epoch : 1, Step : 691, Training Loss : 0.30533, Training Acc : 0.883, Run Time : 0.41
INFO:root:2019-05-10 23:22:00, Epoch : 1, Step : 692, Training Loss : 0.37213, Training Acc : 0.828, Run Time : 0.39
INFO:root:2019-05-10 23:22:02, Epoch : 1, Step : 693, Training Loss : 0.26959, Training Acc : 0.911, Run Time : 2.20
INFO:root:2019-05-10 23:22:12, Epoch : 1, Step : 694, Training Loss : 0.25606, Training Acc : 0.906, Run Time : 10.29
INFO:root:2019-05-10 23:22:13, Epoch : 1, Step : 695, Training Loss : 0.22295, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-10 23:22:13, Epoch : 1, Step : 696, Training Loss : 0.24455, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-10 23:22:14, Epoch : 1, Step : 697, Training Loss : 0.20817, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-10 23:22:17, Epoch : 1, Step : 698, Training Loss : 0.23656, Training Acc : 0.922, Run Time : 3.25
INFO:root:2019-05-10 23:22:18, Epoch : 1, Step : 699, Training Loss : 0.22835, Training Acc : 0.906, Run Time : 1.08
INFO:root:2019-05-10 23:22:28, Epoch : 1, Step : 700, Training Loss : 0.29793, Training Acc : 0.889, Run Time : 10.31
INFO:root:2019-05-10 23:22:29, Epoch : 1, Step : 701, Training Loss : 0.21629, Training Acc : 0.900, Run Time : 0.80
INFO:root:2019-05-10 23:22:30, Epoch : 1, Step : 702, Training Loss : 0.19450, Training Acc : 0.894, Run Time : 0.93
INFO:root:2019-05-10 23:22:39, Epoch : 1, Step : 703, Training Loss : 0.15568, Training Acc : 0.933, Run Time : 9.16
INFO:root:2019-05-10 23:22:40, Epoch : 1, Step : 704, Training Loss : 0.28013, Training Acc : 0.911, Run Time : 0.42
INFO:root:2019-05-10 23:22:40, Epoch : 1, Step : 705, Training Loss : 0.20890, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-10 23:22:42, Epoch : 1, Step : 706, Training Loss : 0.17364, Training Acc : 0.939, Run Time : 2.48
INFO:root:2019-05-10 23:22:47, Epoch : 1, Step : 707, Training Loss : 0.22821, Training Acc : 0.900, Run Time : 4.93
INFO:root:2019-05-10 23:22:48, Epoch : 1, Step : 708, Training Loss : 0.22166, Training Acc : 0.906, Run Time : 0.40
INFO:root:2019-05-10 23:22:48, Epoch : 1, Step : 709, Training Loss : 0.57308, Training Acc : 0.833, Run Time : 0.38
INFO:root:2019-05-10 23:22:49, Epoch : 1, Step : 710, Training Loss : 0.23925, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-10 23:22:49, Epoch : 1, Step : 711, Training Loss : 0.23093, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-10 23:22:50, Epoch : 1, Step : 712, Training Loss : 0.32767, Training Acc : 0.850, Run Time : 0.83
INFO:root:2019-05-10 23:22:57, Epoch : 1, Step : 713, Training Loss : 0.39391, Training Acc : 0.800, Run Time : 7.30
INFO:root:2019-05-10 23:22:57, Epoch : 1, Step : 714, Training Loss : 0.37566, Training Acc : 0.889, Run Time : 0.43
INFO:root:2019-05-10 23:22:58, Epoch : 1, Step : 715, Training Loss : 0.18806, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-10 23:22:58, Epoch : 1, Step : 716, Training Loss : 0.52647, Training Acc : 0.789, Run Time : 0.38
INFO:root:2019-05-10 23:22:59, Epoch : 1, Step : 717, Training Loss : 0.63530, Training Acc : 0.706, Run Time : 0.86
INFO:root:2019-05-10 23:23:05, Epoch : 1, Step : 718, Training Loss : 0.36143, Training Acc : 0.811, Run Time : 6.07
INFO:root:2019-05-10 23:23:06, Epoch : 1, Step : 719, Training Loss : 0.11265, Training Acc : 0.967, Run Time : 1.24
INFO:root:2019-05-10 23:23:07, Epoch : 1, Step : 720, Training Loss : 0.11693, Training Acc : 0.967, Run Time : 0.41
INFO:root:2019-05-10 23:23:08, Epoch : 1, Step : 721, Training Loss : 0.15278, Training Acc : 0.939, Run Time : 1.00
INFO:root:2019-05-10 23:23:11, Epoch : 1, Step : 722, Training Loss : 0.11507, Training Acc : 0.956, Run Time : 3.68
INFO:root:2019-05-10 23:23:12, Epoch : 1, Step : 723, Training Loss : 0.07308, Training Acc : 0.983, Run Time : 0.75
INFO:root:2019-05-10 23:23:13, Epoch : 1, Step : 724, Training Loss : 0.13077, Training Acc : 0.972, Run Time : 0.38
INFO:root:2019-05-10 23:23:13, Epoch : 1, Step : 725, Training Loss : 0.19447, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-10 23:23:14, Epoch : 1, Step : 726, Training Loss : 0.13235, Training Acc : 0.944, Run Time : 1.30
INFO:root:2019-05-10 23:23:20, Epoch : 1, Step : 727, Training Loss : 0.24206, Training Acc : 0.933, Run Time : 5.95
INFO:root:2019-05-10 23:23:21, Epoch : 1, Step : 728, Training Loss : 0.26361, Training Acc : 0.883, Run Time : 0.84
INFO:root:2019-05-10 23:23:21, Epoch : 1, Step : 729, Training Loss : 0.62073, Training Acc : 0.806, Run Time : 0.38
INFO:root:2019-05-10 23:23:22, Epoch : 1, Step : 730, Training Loss : 0.41994, Training Acc : 0.844, Run Time : 0.49
INFO:root:2019-05-10 23:23:23, Epoch : 1, Step : 731, Training Loss : 0.18201, Training Acc : 0.933, Run Time : 0.86
INFO:root:2019-05-10 23:23:29, Epoch : 1, Step : 732, Training Loss : 0.17886, Training Acc : 0.950, Run Time : 5.74
INFO:root:2019-05-10 23:23:29, Epoch : 1, Step : 733, Training Loss : 0.27428, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-10 23:23:29, Epoch : 1, Step : 734, Training Loss : 0.38753, Training Acc : 0.878, Run Time : 0.39
INFO:root:2019-05-10 23:23:30, Epoch : 1, Step : 735, Training Loss : 0.13789, Training Acc : 0.956, Run Time : 0.53
INFO:root:2019-05-10 23:23:31, Epoch : 1, Step : 736, Training Loss : 0.13838, Training Acc : 0.956, Run Time : 0.86
INFO:root:2019-05-10 23:23:37, Epoch : 1, Step : 737, Training Loss : 0.17924, Training Acc : 0.944, Run Time : 5.95
INFO:root:2019-05-10 23:23:37, Epoch : 1, Step : 738, Training Loss : 0.21390, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-10 23:23:38, Epoch : 1, Step : 739, Training Loss : 0.21137, Training Acc : 0.878, Run Time : 0.39
INFO:root:2019-05-10 23:23:40, Epoch : 1, Step : 740, Training Loss : 0.14648, Training Acc : 0.944, Run Time : 2.97
INFO:root:2019-05-10 23:23:49, Epoch : 1, Step : 741, Training Loss : 0.25177, Training Acc : 0.906, Run Time : 8.62
INFO:root:2019-05-10 23:23:50, Epoch : 1, Step : 742, Training Loss : 1.55246, Training Acc : 0.489, Run Time : 0.72
INFO:root:2019-05-10 23:23:50, Epoch : 1, Step : 743, Training Loss : 0.46438, Training Acc : 0.722, Run Time : 0.41
INFO:root:2019-05-10 23:23:58, Epoch : 1, Step : 744, Training Loss : 0.19670, Training Acc : 0.917, Run Time : 7.91
INFO:root:2019-05-10 23:23:59, Epoch : 1, Step : 745, Training Loss : 0.17432, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-10 23:23:59, Epoch : 1, Step : 746, Training Loss : 0.15207, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-10 23:23:59, Epoch : 1, Step : 747, Training Loss : 0.18456, Training Acc : 0.917, Run Time : 0.40
INFO:root:2019-05-10 23:24:00, Epoch : 1, Step : 748, Training Loss : 0.17152, Training Acc : 0.939, Run Time : 0.69
INFO:root:2019-05-10 23:24:05, Epoch : 1, Step : 749, Training Loss : 0.13737, Training Acc : 0.972, Run Time : 4.63
INFO:root:2019-05-10 23:24:05, Epoch : 1, Step : 750, Training Loss : 0.13594, Training Acc : 0.967, Run Time : 0.50
INFO:root:2019-05-10 23:24:06, Epoch : 1, Step : 751, Training Loss : 0.16004, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-10 23:24:06, Epoch : 1, Step : 752, Training Loss : 0.13325, Training Acc : 0.944, Run Time : 0.76
INFO:root:2019-05-10 23:24:08, Epoch : 1, Step : 753, Training Loss : 0.15767, Training Acc : 0.933, Run Time : 1.40
INFO:root:2019-05-10 23:24:09, Epoch : 1, Step : 754, Training Loss : 0.14739, Training Acc : 0.933, Run Time : 0.98
INFO:root:2019-05-10 23:24:15, Epoch : 1, Step : 755, Training Loss : 0.14391, Training Acc : 0.933, Run Time : 5.91
INFO:root:2019-05-10 23:24:16, Epoch : 1, Step : 756, Training Loss : 0.13441, Training Acc : 0.944, Run Time : 1.06
INFO:root:2019-05-10 23:24:16, Epoch : 1, Step : 757, Training Loss : 0.07043, Training Acc : 0.972, Run Time : 0.41
INFO:root:2019-05-10 23:24:25, Epoch : 1, Step : 758, Training Loss : 0.13472, Training Acc : 0.944, Run Time : 9.16
INFO:root:2019-05-10 23:24:26, Epoch : 1, Step : 759, Training Loss : 0.08968, Training Acc : 0.972, Run Time : 0.62
INFO:root:2019-05-10 23:24:26, Epoch : 1, Step : 760, Training Loss : 0.16012, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-10 23:24:27, Epoch : 1, Step : 761, Training Loss : 0.09169, Training Acc : 0.967, Run Time : 0.46
INFO:root:2019-05-10 23:24:27, Epoch : 1, Step : 762, Training Loss : 0.15895, Training Acc : 0.922, Run Time : 0.40
INFO:root:2019-05-10 23:24:27, Epoch : 1, Step : 763, Training Loss : 0.06440, Training Acc : 0.972, Run Time : 0.38
INFO:root:2019-05-10 23:24:28, Epoch : 1, Step : 764, Training Loss : 0.08586, Training Acc : 0.967, Run Time : 0.42
INFO:root:2019-05-10 23:24:29, Epoch : 1, Step : 765, Training Loss : 0.15988, Training Acc : 0.933, Run Time : 0.76
INFO:root:2019-05-10 23:24:29, Epoch : 1, Step : 766, Training Loss : 0.07736, Training Acc : 0.978, Run Time : 0.54
INFO:root:2019-05-10 23:24:48, Epoch : 1, Step : 767, Training Loss : 0.11790, Training Acc : 0.956, Run Time : 19.17
INFO:root:2019-05-10 23:24:49, Epoch : 1, Step : 768, Training Loss : 0.13052, Training Acc : 0.956, Run Time : 0.42
INFO:root:2019-05-10 23:24:49, Epoch : 1, Step : 769, Training Loss : 0.15667, Training Acc : 0.917, Run Time : 0.68
INFO:root:2019-05-10 23:25:02, Epoch : 1, Step : 770, Training Loss : 0.14867, Training Acc : 0.950, Run Time : 12.29
INFO:root:2019-05-10 23:25:02, Epoch : 1, Step : 771, Training Loss : 0.99039, Training Acc : 0.656, Run Time : 0.42
INFO:root:2019-05-10 23:25:03, Epoch : 1, Step : 772, Training Loss : 0.37539, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-10 23:25:04, Epoch : 1, Step : 773, Training Loss : 0.51372, Training Acc : 0.761, Run Time : 1.06
INFO:root:2019-05-10 23:25:10, Epoch : 1, Step : 774, Training Loss : 0.26526, Training Acc : 0.900, Run Time : 6.37
INFO:root:2019-05-10 23:25:11, Epoch : 1, Step : 775, Training Loss : 0.46699, Training Acc : 0.817, Run Time : 0.60
INFO:root:2019-05-10 23:25:11, Epoch : 1, Step : 776, Training Loss : 0.26145, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-10 23:25:12, Epoch : 1, Step : 777, Training Loss : 0.27595, Training Acc : 0.894, Run Time : 0.83
INFO:root:2019-05-10 23:25:19, Epoch : 1, Step : 778, Training Loss : 0.16913, Training Acc : 0.928, Run Time : 6.69
INFO:root:2019-05-10 23:25:19, Epoch : 1, Step : 779, Training Loss : 0.22131, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-10 23:25:19, Epoch : 1, Step : 780, Training Loss : 0.27713, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-10 23:25:20, Epoch : 1, Step : 781, Training Loss : 0.30520, Training Acc : 0.856, Run Time : 0.60
INFO:root:2019-05-10 23:25:25, Epoch : 1, Step : 782, Training Loss : 0.38045, Training Acc : 0.883, Run Time : 4.57
INFO:root:2019-05-10 23:25:25, Epoch : 1, Step : 783, Training Loss : 0.33340, Training Acc : 0.894, Run Time : 0.52
INFO:root:2019-05-10 23:25:26, Epoch : 1, Step : 784, Training Loss : 0.32014, Training Acc : 0.828, Run Time : 0.41
INFO:root:2019-05-10 23:25:26, Epoch : 1, Step : 785, Training Loss : 0.14589, Training Acc : 0.978, Run Time : 0.38
INFO:root:2019-05-10 23:25:27, Epoch : 1, Step : 786, Training Loss : 0.27444, Training Acc : 0.844, Run Time : 0.88
INFO:root:2019-05-10 23:25:35, Epoch : 1, Step : 787, Training Loss : 0.18676, Training Acc : 0.933, Run Time : 8.43
INFO:root:2019-05-10 23:25:36, Epoch : 1, Step : 788, Training Loss : 0.22733, Training Acc : 0.894, Run Time : 0.42
INFO:root:2019-05-10 23:25:36, Epoch : 1, Step : 789, Training Loss : 0.20697, Training Acc : 0.911, Run Time : 0.44
INFO:root:2019-05-10 23:25:37, Epoch : 1, Step : 790, Training Loss : 0.24527, Training Acc : 0.856, Run Time : 0.91
INFO:root:2019-05-10 23:25:45, Epoch : 1, Step : 791, Training Loss : 0.26804, Training Acc : 0.872, Run Time : 7.93
INFO:root:2019-05-10 23:25:45, Epoch : 1, Step : 792, Training Loss : 0.34361, Training Acc : 0.822, Run Time : 0.46
INFO:root:2019-05-10 23:25:46, Epoch : 1, Step : 793, Training Loss : 0.17012, Training Acc : 0.944, Run Time : 0.43
INFO:root:2019-05-10 23:25:48, Epoch : 1, Step : 794, Training Loss : 0.21166, Training Acc : 0.900, Run Time : 1.81
INFO:root:2019-05-10 23:25:56, Epoch : 1, Step : 795, Training Loss : 0.22011, Training Acc : 0.917, Run Time : 8.30
INFO:root:2019-05-10 23:25:56, Epoch : 1, Step : 796, Training Loss : 0.41650, Training Acc : 0.794, Run Time : 0.43
INFO:root:2019-05-10 23:25:57, Epoch : 1, Step : 797, Training Loss : 0.47657, Training Acc : 0.794, Run Time : 0.44
INFO:root:2019-05-10 23:25:58, Epoch : 1, Step : 798, Training Loss : 0.27956, Training Acc : 0.856, Run Time : 1.01
INFO:root:2019-05-10 23:26:08, Epoch : 1, Step : 799, Training Loss : 0.35880, Training Acc : 0.828, Run Time : 9.80
INFO:root:2019-05-10 23:26:08, Epoch : 1, Step : 800, Training Loss : 0.41605, Training Acc : 0.789, Run Time : 0.48
INFO:root:2019-05-10 23:26:09, Epoch : 1, Step : 801, Training Loss : 0.39948, Training Acc : 0.817, Run Time : 1.03
INFO:root:2019-05-10 23:26:22, Epoch : 1, Step : 802, Training Loss : 0.65602, Training Acc : 0.733, Run Time : 13.12
INFO:root:2019-05-10 23:26:23, Epoch : 1, Step : 803, Training Loss : 0.64485, Training Acc : 0.756, Run Time : 1.16
INFO:root:2019-05-10 23:26:27, Epoch : 1, Step : 804, Training Loss : 0.45894, Training Acc : 0.789, Run Time : 3.66
INFO:root:2019-05-10 23:26:29, Epoch : 1, Step : 805, Training Loss : 0.30229, Training Acc : 0.872, Run Time : 1.99
INFO:root:2019-05-10 23:26:30, Epoch : 1, Step : 806, Training Loss : 0.42307, Training Acc : 0.828, Run Time : 0.45
INFO:root:2019-05-10 23:26:31, Epoch : 1, Step : 807, Training Loss : 0.53051, Training Acc : 0.778, Run Time : 1.24
INFO:root:2019-05-10 23:26:38, Epoch : 1, Step : 808, Training Loss : 0.36112, Training Acc : 0.828, Run Time : 7.57
INFO:root:2019-05-10 23:26:43, Epoch : 1, Step : 809, Training Loss : 0.37410, Training Acc : 0.811, Run Time : 5.12
INFO:root:2019-05-10 23:26:44, Epoch : 1, Step : 810, Training Loss : 0.29309, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-10 23:26:49, Epoch : 1, Step : 811, Training Loss : 0.29052, Training Acc : 0.850, Run Time : 5.60
INFO:root:2019-05-10 23:26:50, Epoch : 1, Step : 812, Training Loss : 0.33557, Training Acc : 0.867, Run Time : 0.62
INFO:root:2019-05-10 23:26:51, Epoch : 1, Step : 813, Training Loss : 0.50976, Training Acc : 0.783, Run Time : 1.38
INFO:root:2019-05-10 23:27:00, Epoch : 1, Step : 814, Training Loss : 0.24834, Training Acc : 0.872, Run Time : 8.51
INFO:root:2019-05-10 23:27:01, Epoch : 1, Step : 815, Training Loss : 0.26348, Training Acc : 0.894, Run Time : 0.82
INFO:root:2019-05-10 23:27:02, Epoch : 1, Step : 816, Training Loss : 0.44424, Training Acc : 0.800, Run Time : 1.47
INFO:root:2019-05-10 23:27:08, Epoch : 1, Step : 817, Training Loss : 0.41365, Training Acc : 0.839, Run Time : 5.93
INFO:root:2019-05-10 23:27:09, Epoch : 1, Step : 818, Training Loss : 0.47925, Training Acc : 0.844, Run Time : 0.41
INFO:root:2019-05-10 23:27:09, Epoch : 1, Step : 819, Training Loss : 0.33829, Training Acc : 0.856, Run Time : 0.38
INFO:root:2019-05-10 23:27:16, Epoch : 1, Step : 820, Training Loss : 0.34423, Training Acc : 0.856, Run Time : 7.12
INFO:root:2019-05-10 23:27:17, Epoch : 1, Step : 821, Training Loss : 0.48640, Training Acc : 0.789, Run Time : 0.44
INFO:root:2019-05-10 23:27:17, Epoch : 1, Step : 822, Training Loss : 0.40214, Training Acc : 0.817, Run Time : 0.38
INFO:root:2019-05-10 23:27:19, Epoch : 1, Step : 823, Training Loss : 0.44185, Training Acc : 0.822, Run Time : 2.18
INFO:root:2019-05-10 23:27:28, Epoch : 1, Step : 824, Training Loss : 0.37363, Training Acc : 0.883, Run Time : 9.13
INFO:root:2019-05-10 23:27:29, Epoch : 1, Step : 825, Training Loss : 0.72208, Training Acc : 0.711, Run Time : 0.95
INFO:root:2019-05-10 23:27:30, Epoch : 1, Step : 826, Training Loss : 0.59410, Training Acc : 0.728, Run Time : 0.38
INFO:root:2019-05-10 23:27:30, Epoch : 1, Step : 827, Training Loss : 0.71482, Training Acc : 0.650, Run Time : 0.42
INFO:root:2019-05-10 23:27:31, Epoch : 1, Step : 828, Training Loss : 0.54518, Training Acc : 0.789, Run Time : 1.07
INFO:root:2019-05-10 23:27:38, Epoch : 1, Step : 829, Training Loss : 0.31671, Training Acc : 0.906, Run Time : 6.67
INFO:root:2019-05-10 23:27:38, Epoch : 1, Step : 830, Training Loss : 0.28724, Training Acc : 0.889, Run Time : 0.42
INFO:root:2019-05-10 23:27:39, Epoch : 1, Step : 831, Training Loss : 0.25705, Training Acc : 0.928, Run Time : 0.72
INFO:root:2019-05-10 23:27:40, Epoch : 1, Step : 832, Training Loss : 0.23803, Training Acc : 0.928, Run Time : 1.03
INFO:root:2019-05-10 23:27:46, Epoch : 1, Step : 833, Training Loss : 0.33851, Training Acc : 0.856, Run Time : 6.17
INFO:root:2019-05-10 23:27:47, Epoch : 1, Step : 834, Training Loss : 0.18925, Training Acc : 0.933, Run Time : 0.67
INFO:root:2019-05-10 23:27:47, Epoch : 1, Step : 835, Training Loss : 0.27748, Training Acc : 0.900, Run Time : 0.38
INFO:root:2019-05-10 23:27:56, Epoch : 1, Step : 836, Training Loss : 0.23113, Training Acc : 0.911, Run Time : 8.95
INFO:root:2019-05-10 23:27:57, Epoch : 1, Step : 837, Training Loss : 0.20755, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-10 23:27:57, Epoch : 1, Step : 838, Training Loss : 0.23492, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-10 23:27:57, Epoch : 1, Step : 839, Training Loss : 0.28598, Training Acc : 0.867, Run Time : 0.38
INFO:root:2019-05-10 23:27:58, Epoch : 1, Step : 840, Training Loss : 0.24895, Training Acc : 0.906, Run Time : 0.58
INFO:root:2019-05-10 23:28:04, Epoch : 1, Step : 841, Training Loss : 0.21420, Training Acc : 0.911, Run Time : 6.37
INFO:root:2019-05-10 23:28:05, Epoch : 1, Step : 842, Training Loss : 0.13940, Training Acc : 0.983, Run Time : 0.51
INFO:root:2019-05-10 23:28:05, Epoch : 1, Step : 843, Training Loss : 0.18763, Training Acc : 0.894, Run Time : 0.42
INFO:root:2019-05-10 23:28:11, Epoch : 1, Step : 844, Training Loss : 0.21989, Training Acc : 0.928, Run Time : 6.18
INFO:root:2019-05-10 23:28:12, Epoch : 1, Step : 845, Training Loss : 0.34899, Training Acc : 0.850, Run Time : 1.00
INFO:root:2019-05-10 23:28:13, Epoch : 1, Step : 846, Training Loss : 0.18840, Training Acc : 0.961, Run Time : 0.46
INFO:root:2019-05-10 23:28:13, Epoch : 1, Step : 847, Training Loss : 0.14028, Training Acc : 0.939, Run Time : 0.41
INFO:root:2019-05-10 23:28:14, Epoch : 1, Step : 848, Training Loss : 0.19309, Training Acc : 0.911, Run Time : 0.43
INFO:root:2019-05-10 23:28:14, Epoch : 1, Step : 849, Training Loss : 0.26727, Training Acc : 0.861, Run Time : 0.48
INFO:root:2019-05-10 23:28:17, Epoch : 1, Step : 850, Training Loss : 0.20286, Training Acc : 0.939, Run Time : 3.15
INFO:root:2019-05-10 23:28:18, Epoch : 1, Step : 851, Training Loss : 0.10559, Training Acc : 0.961, Run Time : 0.40
INFO:root:2019-05-10 23:28:18, Epoch : 1, Step : 852, Training Loss : 0.25811, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-10 23:28:19, Epoch : 1, Step : 853, Training Loss : 0.14775, Training Acc : 0.950, Run Time : 0.57
INFO:root:2019-05-10 23:28:25, Epoch : 1, Step : 854, Training Loss : 0.36111, Training Acc : 0.817, Run Time : 5.95
INFO:root:2019-05-10 23:28:26, Epoch : 1, Step : 855, Training Loss : 0.26445, Training Acc : 0.894, Run Time : 1.57
INFO:root:2019-05-10 23:28:27, Epoch : 1, Step : 856, Training Loss : 0.31707, Training Acc : 0.817, Run Time : 0.41
INFO:root:2019-05-10 23:28:27, Epoch : 1, Step : 857, Training Loss : 0.43670, Training Acc : 0.833, Run Time : 0.80
INFO:root:2019-05-10 23:28:51, Epoch : 1, Step : 858, Training Loss : 0.43060, Training Acc : 0.828, Run Time : 23.50
INFO:root:2019-05-10 23:28:52, Epoch : 1, Step : 859, Training Loss : 0.39595, Training Acc : 0.828, Run Time : 0.94
INFO:root:2019-05-10 23:29:12, Epoch : 1, Step : 860, Training Loss : 0.22117, Training Acc : 0.928, Run Time : 20.13
INFO:root:2019-05-10 23:29:14, Epoch : 1, Step : 861, Training Loss : 0.20126, Training Acc : 0.928, Run Time : 1.95
INFO:root:2019-05-10 23:29:14, Epoch : 1, Step : 862, Training Loss : 0.18735, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-10 23:29:15, Epoch : 1, Step : 863, Training Loss : 0.15200, Training Acc : 0.939, Run Time : 0.41
INFO:root:2019-05-10 23:29:16, Epoch : 1, Step : 864, Training Loss : 0.34312, Training Acc : 0.839, Run Time : 0.82
INFO:root:2019-05-10 23:29:23, Epoch : 1, Step : 865, Training Loss : 0.34518, Training Acc : 0.856, Run Time : 7.39
INFO:root:2019-05-10 23:29:23, Epoch : 1, Step : 866, Training Loss : 0.30356, Training Acc : 0.872, Run Time : 0.41
INFO:root:2019-05-10 23:29:24, Epoch : 1, Step : 867, Training Loss : 0.15687, Training Acc : 0.950, Run Time : 0.41
INFO:root:2019-05-10 23:29:25, Epoch : 1, Step : 868, Training Loss : 0.14945, Training Acc : 0.961, Run Time : 1.00
INFO:root:2019-05-10 23:29:52, Epoch : 1, Step : 869, Training Loss : 0.21777, Training Acc : 0.894, Run Time : 27.19
INFO:root:2019-05-10 23:29:53, Epoch : 1, Step : 870, Training Loss : 0.28073, Training Acc : 0.878, Run Time : 0.86
INFO:root:2019-05-10 23:29:53, Epoch : 1, Step : 871, Training Loss : 0.14414, Training Acc : 0.961, Run Time : 0.39
INFO:root:2019-05-10 23:29:54, Epoch : 1, Step : 872, Training Loss : 0.14889, Training Acc : 0.950, Run Time : 0.94
INFO:root:2019-05-10 23:30:00, Epoch : 1, Step : 873, Training Loss : 0.20934, Training Acc : 0.922, Run Time : 5.42
INFO:root:2019-05-10 23:30:00, Epoch : 1, Step : 874, Training Loss : 0.38814, Training Acc : 0.817, Run Time : 0.40
INFO:root:2019-05-10 23:30:01, Epoch : 1, Step : 875, Training Loss : 0.19261, Training Acc : 0.894, Run Time : 0.65
INFO:root:2019-05-10 23:30:02, Epoch : 1, Step : 876, Training Loss : 0.36304, Training Acc : 0.850, Run Time : 1.34
INFO:root:2019-05-10 23:30:10, Epoch : 1, Step : 877, Training Loss : 0.25733, Training Acc : 0.856, Run Time : 7.86
INFO:root:2019-05-10 23:30:10, Epoch : 1, Step : 878, Training Loss : 0.12090, Training Acc : 0.956, Run Time : 0.50
INFO:root:2019-05-10 23:30:11, Epoch : 1, Step : 879, Training Loss : 0.13807, Training Acc : 0.956, Run Time : 0.45
INFO:root:2019-05-10 23:30:12, Epoch : 1, Step : 880, Training Loss : 0.14222, Training Acc : 0.950, Run Time : 0.82
INFO:root:2019-05-10 23:30:13, Epoch : 1, Step : 881, Training Loss : 0.10484, Training Acc : 0.961, Run Time : 1.06
INFO:root:2019-05-10 23:30:13, Epoch : 1, Step : 882, Training Loss : 0.12308, Training Acc : 0.961, Run Time : 0.40
INFO:root:2019-05-10 23:30:14, Epoch : 1, Step : 883, Training Loss : 0.09705, Training Acc : 0.972, Run Time : 0.39
INFO:root:2019-05-10 23:30:14, Epoch : 1, Step : 884, Training Loss : 0.16976, Training Acc : 0.933, Run Time : 0.39
INFO:root:2019-05-10 23:30:14, Epoch : 1, Step : 885, Training Loss : 0.13641, Training Acc : 0.917, Run Time : 0.50
INFO:root:2019-05-10 23:30:16, Epoch : 1, Step : 886, Training Loss : 0.17536, Training Acc : 0.922, Run Time : 1.21
INFO:root:2019-05-10 23:30:16, Epoch : 1, Step : 887, Training Loss : 0.17433, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-10 23:30:16, Epoch : 1, Step : 888, Training Loss : 0.21859, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-10 23:30:17, Epoch : 1, Step : 889, Training Loss : 0.11926, Training Acc : 0.956, Run Time : 0.46
INFO:root:2019-05-10 23:30:17, Epoch : 1, Step : 890, Training Loss : 0.13406, Training Acc : 0.950, Run Time : 0.55
INFO:root:2019-05-10 23:30:23, Epoch : 1, Step : 891, Training Loss : 0.17109, Training Acc : 0.944, Run Time : 5.35
INFO:root:2019-05-10 23:30:24, Epoch : 1, Step : 892, Training Loss : 0.09344, Training Acc : 0.972, Run Time : 0.91
INFO:root:2019-05-10 23:30:24, Epoch : 1, Step : 893, Training Loss : 0.12481, Training Acc : 0.961, Run Time : 0.39
INFO:root:2019-05-10 23:30:25, Epoch : 1, Step : 894, Training Loss : 0.24562, Training Acc : 0.900, Run Time : 0.92
INFO:root:2019-05-10 23:30:26, Epoch : 1, Step : 895, Training Loss : 0.12820, Training Acc : 0.950, Run Time : 0.80
INFO:root:2019-05-10 23:30:41, Epoch : 1, Step : 896, Training Loss : 0.13582, Training Acc : 0.944, Run Time : 15.36
INFO:root:2019-05-10 23:30:49, Epoch : 1, Step : 897, Training Loss : 0.19858, Training Acc : 0.917, Run Time : 7.74
INFO:root:2019-05-10 23:30:50, Epoch : 1, Step : 898, Training Loss : 0.18438, Training Acc : 0.928, Run Time : 0.74
INFO:root:2019-05-10 23:30:50, Epoch : 1, Step : 899, Training Loss : 0.12845, Training Acc : 0.967, Run Time : 0.40
INFO:root:2019-05-10 23:30:57, Epoch : 1, Step : 900, Training Loss : 0.12858, Training Acc : 0.939, Run Time : 7.43
INFO:root:2019-05-10 23:30:58, Epoch : 1, Step : 901, Training Loss : 0.08860, Training Acc : 0.967, Run Time : 0.92
INFO:root:2019-05-10 23:31:01, Epoch : 1, Step : 902, Training Loss : 0.11604, Training Acc : 0.950, Run Time : 2.84
INFO:root:2019-05-10 23:31:07, Epoch : 1, Step : 903, Training Loss : 0.27177, Training Acc : 0.889, Run Time : 5.35
INFO:root:2019-05-10 23:31:07, Epoch : 1, Step : 904, Training Loss : 0.20699, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-10 23:31:07, Epoch : 1, Step : 905, Training Loss : 0.17615, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-10 23:31:08, Epoch : 1, Step : 906, Training Loss : 0.19619, Training Acc : 0.928, Run Time : 0.94
INFO:root:2019-05-10 23:31:19, Epoch : 1, Step : 907, Training Loss : 0.15196, Training Acc : 0.933, Run Time : 10.95
INFO:root:2019-05-10 23:31:20, Epoch : 1, Step : 908, Training Loss : 0.17592, Training Acc : 0.928, Run Time : 0.82
INFO:root:2019-05-10 23:31:21, Epoch : 1, Step : 909, Training Loss : 0.16569, Training Acc : 0.944, Run Time : 1.04
INFO:root:2019-05-10 23:31:27, Epoch : 1, Step : 910, Training Loss : 0.16184, Training Acc : 0.928, Run Time : 6.27
INFO:root:2019-05-10 23:31:28, Epoch : 1, Step : 911, Training Loss : 0.12231, Training Acc : 0.956, Run Time : 0.42
INFO:root:2019-05-10 23:31:28, Epoch : 1, Step : 912, Training Loss : 0.13530, Training Acc : 0.939, Run Time : 0.37
INFO:root:2019-05-10 23:31:31, Epoch : 1, Step : 913, Training Loss : 0.11645, Training Acc : 0.967, Run Time : 2.67
INFO:root:2019-05-10 23:31:40, Epoch : 1, Step : 914, Training Loss : 0.10361, Training Acc : 0.961, Run Time : 9.02
INFO:root:2019-05-10 23:31:40, Epoch : 1, Step : 915, Training Loss : 0.15988, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-10 23:31:41, Epoch : 1, Step : 916, Training Loss : 0.17703, Training Acc : 0.922, Run Time : 0.39
INFO:root:2019-05-10 23:31:41, Epoch : 1, Step : 917, Training Loss : 0.09674, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-10 23:31:42, Epoch : 1, Step : 918, Training Loss : 0.12805, Training Acc : 0.933, Run Time : 0.53
INFO:root:2019-05-10 23:31:42, Epoch : 1, Step : 919, Training Loss : 0.11278, Training Acc : 0.967, Run Time : 0.38
INFO:root:2019-05-10 23:31:42, Epoch : 1, Step : 920, Training Loss : 0.12924, Training Acc : 0.961, Run Time : 0.38
INFO:root:2019-05-10 23:31:43, Epoch : 1, Step : 921, Training Loss : 0.07784, Training Acc : 0.983, Run Time : 0.87
INFO:root:2019-05-10 23:31:51, Epoch : 1, Step : 922, Training Loss : 0.11656, Training Acc : 0.950, Run Time : 7.44
INFO:root:2019-05-10 23:31:51, Epoch : 1, Step : 923, Training Loss : 0.14021, Training Acc : 0.944, Run Time : 0.44
INFO:root:2019-05-10 23:31:52, Epoch : 1, Step : 924, Training Loss : 0.11715, Training Acc : 0.950, Run Time : 0.51
INFO:root:2019-05-10 23:31:53, Epoch : 1, Step : 925, Training Loss : 0.07573, Training Acc : 0.978, Run Time : 0.85
INFO:root:2019-05-10 23:31:58, Epoch : 1, Step : 926, Training Loss : 0.18119, Training Acc : 0.928, Run Time : 5.22
INFO:root:2019-05-10 23:31:58, Epoch : 1, Step : 927, Training Loss : 0.17585, Training Acc : 0.928, Run Time : 0.63
INFO:root:2019-05-10 23:31:59, Epoch : 1, Step : 928, Training Loss : 0.12324, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-10 23:31:59, Epoch : 1, Step : 929, Training Loss : 0.11093, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-10 23:32:00, Epoch : 1, Step : 930, Training Loss : 0.09584, Training Acc : 0.961, Run Time : 0.88
INFO:root:2019-05-10 23:32:07, Epoch : 1, Step : 931, Training Loss : 0.09911, Training Acc : 0.967, Run Time : 7.12
INFO:root:2019-05-10 23:32:08, Epoch : 1, Step : 932, Training Loss : 0.07405, Training Acc : 0.978, Run Time : 0.65
INFO:root:2019-05-10 23:32:08, Epoch : 1, Step : 933, Training Loss : 0.21861, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-10 23:32:09, Epoch : 1, Step : 934, Training Loss : 0.18826, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-10 23:32:09, Epoch : 1, Step : 935, Training Loss : 0.29386, Training Acc : 0.883, Run Time : 0.53
INFO:root:2019-05-10 23:32:13, Epoch : 1, Step : 936, Training Loss : 0.18198, Training Acc : 0.928, Run Time : 3.82
INFO:root:2019-05-10 23:32:14, Epoch : 1, Step : 937, Training Loss : 0.42160, Training Acc : 0.811, Run Time : 0.85
INFO:root:2019-05-10 23:32:14, Epoch : 1, Step : 938, Training Loss : 0.13334, Training Acc : 0.944, Run Time : 0.39
INFO:root:2019-05-10 23:32:15, Epoch : 1, Step : 939, Training Loss : 0.14617, Training Acc : 0.950, Run Time : 0.90
INFO:root:2019-05-10 23:32:20, Epoch : 1, Step : 940, Training Loss : 0.08887, Training Acc : 0.972, Run Time : 4.85
INFO:root:2019-05-10 23:32:21, Epoch : 1, Step : 941, Training Loss : 0.16392, Training Acc : 0.922, Run Time : 0.55
INFO:root:2019-05-10 23:32:22, Epoch : 1, Step : 942, Training Loss : 0.10255, Training Acc : 0.978, Run Time : 1.03
INFO:root:2019-05-10 23:32:33, Epoch : 1, Step : 943, Training Loss : 0.20512, Training Acc : 0.933, Run Time : 11.30
INFO:root:2019-05-10 23:32:34, Epoch : 1, Step : 944, Training Loss : 0.53294, Training Acc : 0.800, Run Time : 0.85
INFO:root:2019-05-10 23:32:34, Epoch : 1, Step : 945, Training Loss : 0.09592, Training Acc : 0.961, Run Time : 0.43
INFO:root:2019-05-10 23:32:35, Epoch : 1, Step : 946, Training Loss : 0.12003, Training Acc : 0.961, Run Time : 0.44
INFO:root:2019-05-10 23:32:36, Epoch : 1, Step : 947, Training Loss : 0.16147, Training Acc : 0.961, Run Time : 1.42
INFO:root:2019-05-10 23:32:46, Epoch : 1, Step : 948, Training Loss : 0.11359, Training Acc : 0.961, Run Time : 10.15
INFO:root:2019-05-10 23:32:47, Epoch : 1, Step : 949, Training Loss : 0.14248, Training Acc : 0.956, Run Time : 0.64
INFO:root:2019-05-10 23:32:47, Epoch : 1, Step : 950, Training Loss : 0.22216, Training Acc : 0.922, Run Time : 0.43
INFO:root:2019-05-10 23:32:48, Epoch : 1, Step : 951, Training Loss : 0.20905, Training Acc : 0.939, Run Time : 0.53
INFO:root:2019-05-10 23:32:56, Epoch : 1, Step : 952, Training Loss : 0.24599, Training Acc : 0.906, Run Time : 8.71
INFO:root:2019-05-10 23:32:57, Epoch : 1, Step : 953, Training Loss : 0.29663, Training Acc : 0.894, Run Time : 0.88
INFO:root:2019-05-10 23:32:58, Epoch : 1, Step : 954, Training Loss : 0.31041, Training Acc : 0.889, Run Time : 0.43
INFO:root:2019-05-10 23:33:05, Epoch : 1, Step : 955, Training Loss : 0.17969, Training Acc : 0.928, Run Time : 7.37
INFO:root:2019-05-10 23:33:06, Epoch : 1, Step : 956, Training Loss : 0.17862, Training Acc : 0.939, Run Time : 1.33
INFO:root:2019-05-10 23:33:07, Epoch : 1, Step : 957, Training Loss : 0.17087, Training Acc : 0.922, Run Time : 0.43
INFO:root:2019-05-10 23:33:08, Epoch : 1, Step : 958, Training Loss : 0.23354, Training Acc : 0.917, Run Time : 0.78
INFO:root:2019-05-10 23:33:18, Epoch : 1, Step : 959, Training Loss : 0.26453, Training Acc : 0.894, Run Time : 9.90
INFO:root:2019-05-10 23:33:18, Epoch : 1, Step : 960, Training Loss : 0.19141, Training Acc : 0.917, Run Time : 0.74
INFO:root:2019-05-10 23:33:19, Epoch : 1, Step : 961, Training Loss : 0.24242, Training Acc : 0.878, Run Time : 1.16
INFO:root:2019-05-10 23:33:27, Epoch : 1, Step : 962, Training Loss : 0.47335, Training Acc : 0.822, Run Time : 7.20
INFO:root:2019-05-10 23:33:27, Epoch : 1, Step : 963, Training Loss : 0.47252, Training Acc : 0.794, Run Time : 0.42
INFO:root:2019-05-10 23:33:28, Epoch : 1, Step : 964, Training Loss : 0.29406, Training Acc : 0.878, Run Time : 0.49
INFO:root:2019-05-10 23:33:29, Epoch : 1, Step : 965, Training Loss : 0.29039, Training Acc : 0.867, Run Time : 1.39
INFO:root:2019-05-10 23:33:38, Epoch : 1, Step : 966, Training Loss : 0.36203, Training Acc : 0.872, Run Time : 9.16
INFO:root:2019-05-10 23:33:39, Epoch : 1, Step : 967, Training Loss : 0.36876, Training Acc : 0.833, Run Time : 0.52
INFO:root:2019-05-10 23:33:39, Epoch : 1, Step : 968, Training Loss : 0.26013, Training Acc : 0.883, Run Time : 0.42
INFO:root:2019-05-10 23:33:40, Epoch : 1, Step : 969, Training Loss : 0.14496, Training Acc : 0.950, Run Time : 0.79
INFO:root:2019-05-10 23:33:47, Epoch : 1, Step : 970, Training Loss : 0.27221, Training Acc : 0.856, Run Time : 7.08
INFO:root:2019-05-10 23:33:47, Epoch : 1, Step : 971, Training Loss : 0.16106, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-10 23:33:48, Epoch : 1, Step : 972, Training Loss : 0.24728, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-10 23:33:49, Epoch : 1, Step : 973, Training Loss : 0.34465, Training Acc : 0.850, Run Time : 1.34
INFO:root:2019-05-10 23:33:59, Epoch : 1, Step : 974, Training Loss : 0.28896, Training Acc : 0.906, Run Time : 9.49
INFO:root:2019-05-10 23:33:59, Epoch : 1, Step : 975, Training Loss : 0.20673, Training Acc : 0.917, Run Time : 0.53
INFO:root:2019-05-10 23:33:59, Epoch : 1, Step : 976, Training Loss : 0.23182, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-10 23:34:00, Epoch : 1, Step : 977, Training Loss : 0.22885, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-10 23:34:08, Epoch : 1, Step : 978, Training Loss : 0.23513, Training Acc : 0.883, Run Time : 7.65
INFO:root:2019-05-10 23:34:08, Epoch : 1, Step : 979, Training Loss : 0.21638, Training Acc : 0.894, Run Time : 0.64
INFO:root:2019-05-10 23:34:09, Epoch : 1, Step : 980, Training Loss : 0.12333, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-10 23:34:17, Epoch : 1, Step : 981, Training Loss : 0.16594, Training Acc : 0.950, Run Time : 8.87
INFO:root:2019-05-10 23:34:18, Epoch : 1, Step : 982, Training Loss : 0.11800, Training Acc : 0.961, Run Time : 0.80
INFO:root:2019-05-10 23:34:19, Epoch : 1, Step : 983, Training Loss : 0.15556, Training Acc : 0.950, Run Time : 0.37
INFO:root:2019-05-10 23:34:19, Epoch : 1, Step : 984, Training Loss : 0.19293, Training Acc : 0.894, Run Time : 0.79
INFO:root:2019-05-10 23:34:30, Epoch : 1, Step : 985, Training Loss : 0.13837, Training Acc : 0.944, Run Time : 10.64
INFO:root:2019-05-10 23:34:39, Epoch : 1, Step : 986, Training Loss : 0.18391, Training Acc : 0.933, Run Time : 9.11
INFO:root:2019-05-10 23:34:40, Epoch : 1, Step : 987, Training Loss : 0.19562, Training Acc : 0.900, Run Time : 0.61
INFO:root:2019-05-10 23:34:40, Epoch : 1, Step : 988, Training Loss : 0.15829, Training Acc : 0.922, Run Time : 0.40
INFO:root:2019-05-10 23:34:42, Epoch : 1, Step : 989, Training Loss : 0.17080, Training Acc : 0.939, Run Time : 1.55
INFO:root:2019-05-10 23:34:50, Epoch : 1, Step : 990, Training Loss : 0.21947, Training Acc : 0.911, Run Time : 8.65
INFO:root:2019-05-10 23:34:51, Epoch : 1, Step : 991, Training Loss : 0.28560, Training Acc : 0.883, Run Time : 0.42
INFO:root:2019-05-10 23:34:51, Epoch : 1, Step : 992, Training Loss : 0.35881, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-10 23:34:52, Epoch : 1, Step : 993, Training Loss : 0.23019, Training Acc : 0.911, Run Time : 1.17
INFO:root:2019-05-10 23:34:59, Epoch : 1, Step : 994, Training Loss : 0.27551, Training Acc : 0.906, Run Time : 6.52
INFO:root:2019-05-10 23:34:59, Epoch : 1, Step : 995, Training Loss : 0.38272, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-10 23:35:00, Epoch : 1, Step : 996, Training Loss : 0.25705, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-10 23:35:10, Epoch : 1, Step : 997, Training Loss : 0.29966, Training Acc : 0.883, Run Time : 9.89
INFO:root:2019-05-10 23:35:10, Epoch : 1, Step : 998, Training Loss : 0.35262, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-10 23:35:11, Epoch : 1, Step : 999, Training Loss : 0.16914, Training Acc : 0.939, Run Time : 0.80
INFO:root:2019-05-10 23:35:18, Epoch : 1, Step : 1000, Training Loss : 0.34527, Training Acc : 0.900, Run Time : 7.47
INFO:root:2019-05-10 23:35:19, Epoch : 1, Step : 1001, Training Loss : 1.11373, Training Acc : 0.717, Run Time : 1.10
INFO:root:2019-05-10 23:35:20, Epoch : 1, Step : 1002, Training Loss : 1.16213, Training Acc : 0.711, Run Time : 0.49
INFO:root:2019-05-10 23:35:26, Epoch : 1, Step : 1003, Training Loss : 0.97728, Training Acc : 0.722, Run Time : 6.14
INFO:root:2019-05-10 23:35:27, Epoch : 1, Step : 1004, Training Loss : 1.05282, Training Acc : 0.717, Run Time : 1.03
INFO:root:2019-05-10 23:35:28, Epoch : 1, Step : 1005, Training Loss : 1.04983, Training Acc : 0.750, Run Time : 1.36
INFO:root:2019-05-10 23:35:38, Epoch : 1, Step : 1006, Training Loss : 0.57807, Training Acc : 0.778, Run Time : 9.54
INFO:root:2019-05-10 23:35:40, Epoch : 1, Step : 1007, Training Loss : 0.57428, Training Acc : 0.806, Run Time : 2.28
INFO:root:2019-05-10 23:35:41, Epoch : 1, Step : 1008, Training Loss : 0.53300, Training Acc : 0.800, Run Time : 0.72
INFO:root:2019-05-10 23:35:43, Epoch : 1, Step : 1009, Training Loss : 0.56047, Training Acc : 0.728, Run Time : 2.07
INFO:root:2019-05-10 23:35:50, Epoch : 1, Step : 1010, Training Loss : 0.65221, Training Acc : 0.789, Run Time : 7.32
INFO:root:2019-05-10 23:35:51, Epoch : 1, Step : 1011, Training Loss : 0.84945, Training Acc : 0.683, Run Time : 1.25
INFO:root:2019-05-10 23:35:57, Epoch : 1, Step : 1012, Training Loss : 0.73855, Training Acc : 0.639, Run Time : 5.42
INFO:root:2019-05-10 23:35:57, Epoch : 1, Step : 1013, Training Loss : 0.44824, Training Acc : 0.778, Run Time : 0.58
INFO:root:2019-05-10 23:35:58, Epoch : 1, Step : 1014, Training Loss : 0.30449, Training Acc : 0.856, Run Time : 0.49
INFO:root:2019-05-10 23:36:05, Epoch : 1, Step : 1015, Training Loss : 0.28732, Training Acc : 0.883, Run Time : 7.47
INFO:root:2019-05-10 23:36:06, Epoch : 1, Step : 1016, Training Loss : 0.36468, Training Acc : 0.856, Run Time : 0.59
INFO:root:2019-05-10 23:36:06, Epoch : 1, Step : 1017, Training Loss : 0.31884, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-10 23:36:08, Epoch : 1, Step : 1018, Training Loss : 0.26899, Training Acc : 0.900, Run Time : 1.53
INFO:root:2019-05-10 23:36:08, Epoch : 1, Step : 1019, Training Loss : 0.38850, Training Acc : 0.828, Run Time : 0.41
INFO:root:2019-05-10 23:36:09, Epoch : 1, Step : 1020, Training Loss : 0.35351, Training Acc : 0.839, Run Time : 0.39
INFO:root:2019-05-10 23:36:09, Epoch : 1, Step : 1021, Training Loss : 0.32915, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-10 23:36:11, Epoch : 1, Step : 1022, Training Loss : 0.43306, Training Acc : 0.789, Run Time : 1.88
INFO:root:2019-05-10 23:36:11, Epoch : 1, Step : 1023, Training Loss : 0.33846, Training Acc : 0.861, Run Time : 0.42
INFO:root:2019-05-10 23:36:12, Epoch : 1, Step : 1024, Training Loss : 0.31634, Training Acc : 0.850, Run Time : 0.37
INFO:root:2019-05-10 23:36:12, Epoch : 1, Step : 1025, Training Loss : 0.31480, Training Acc : 0.878, Run Time : 0.37
INFO:root:2019-05-10 23:36:13, Epoch : 1, Step : 1026, Training Loss : 0.26104, Training Acc : 0.922, Run Time : 0.51
INFO:root:2019-05-10 23:36:14, Epoch : 1, Step : 1027, Training Loss : 0.29922, Training Acc : 0.867, Run Time : 1.15
INFO:root:2019-05-10 23:36:14, Epoch : 1, Step : 1028, Training Loss : 0.34223, Training Acc : 0.794, Run Time : 0.39
INFO:root:2019-05-10 23:36:15, Epoch : 1, Step : 1029, Training Loss : 0.27592, Training Acc : 0.889, Run Time : 0.37
INFO:root:2019-05-10 23:36:21, Epoch : 1, Step : 1030, Training Loss : 0.29235, Training Acc : 0.844, Run Time : 5.87
INFO:root:2019-05-10 23:36:21, Epoch : 1, Step : 1031, Training Loss : 0.37769, Training Acc : 0.822, Run Time : 0.79
INFO:root:2019-05-10 23:36:22, Epoch : 1, Step : 1032, Training Loss : 0.44393, Training Acc : 0.783, Run Time : 0.38
INFO:root:2019-05-10 23:36:23, Epoch : 1, Step : 1033, Training Loss : 0.25473, Training Acc : 0.883, Run Time : 1.06
INFO:root:2019-05-10 23:36:27, Epoch : 1, Step : 1034, Training Loss : 0.31102, Training Acc : 0.867, Run Time : 3.90
INFO:root:2019-05-10 23:36:27, Epoch : 1, Step : 1035, Training Loss : 0.40472, Training Acc : 0.783, Run Time : 0.40
INFO:root:2019-05-10 23:36:27, Epoch : 1, Step : 1036, Training Loss : 0.41671, Training Acc : 0.783, Run Time : 0.42
INFO:root:2019-05-10 23:36:28, Epoch : 1, Step : 1037, Training Loss : 0.26255, Training Acc : 0.889, Run Time : 0.39
INFO:root:2019-05-10 23:36:28, Epoch : 1, Step : 1038, Training Loss : 0.29919, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-10 23:36:29, Epoch : 1, Step : 1039, Training Loss : 0.37451, Training Acc : 0.833, Run Time : 0.54
INFO:root:2019-05-10 23:36:39, Epoch : 1, Step : 1040, Training Loss : 0.27178, Training Acc : 0.856, Run Time : 9.90
INFO:root:2019-05-10 23:36:39, Epoch : 1, Step : 1041, Training Loss : 0.30660, Training Acc : 0.839, Run Time : 0.75
INFO:root:2019-05-10 23:36:40, Epoch : 1, Step : 1042, Training Loss : 0.39307, Training Acc : 0.844, Run Time : 0.52
INFO:root:2019-05-10 23:36:41, Epoch : 1, Step : 1043, Training Loss : 0.22191, Training Acc : 0.922, Run Time : 1.18
INFO:root:2019-05-10 23:36:47, Epoch : 1, Step : 1044, Training Loss : 0.31795, Training Acc : 0.889, Run Time : 5.78
INFO:root:2019-05-10 23:36:47, Epoch : 1, Step : 1045, Training Loss : 0.29119, Training Acc : 0.883, Run Time : 0.40
INFO:root:2019-05-10 23:36:48, Epoch : 1, Step : 1046, Training Loss : 0.46509, Training Acc : 0.756, Run Time : 0.37
INFO:root:2019-05-10 23:36:48, Epoch : 1, Step : 1047, Training Loss : 0.68135, Training Acc : 0.639, Run Time : 0.60
INFO:root:2019-05-10 23:36:52, Epoch : 1, Step : 1048, Training Loss : 0.96743, Training Acc : 0.522, Run Time : 4.20
INFO:root:2019-05-10 23:36:53, Epoch : 1, Step : 1049, Training Loss : 0.65244, Training Acc : 0.711, Run Time : 0.41
INFO:root:2019-05-10 23:36:53, Epoch : 1, Step : 1050, Training Loss : 0.41962, Training Acc : 0.806, Run Time : 0.41
INFO:root:2019-05-10 23:36:54, Epoch : 1, Step : 1051, Training Loss : 0.47661, Training Acc : 0.767, Run Time : 0.51
INFO:root:2019-05-10 23:36:55, Epoch : 1, Step : 1052, Training Loss : 0.43498, Training Acc : 0.756, Run Time : 1.07
INFO:root:2019-05-10 23:37:03, Epoch : 1, Step : 1053, Training Loss : 0.56318, Training Acc : 0.711, Run Time : 8.22
INFO:root:2019-05-10 23:37:04, Epoch : 1, Step : 1054, Training Loss : 0.46979, Training Acc : 0.750, Run Time : 0.52
INFO:root:2019-05-10 23:37:04, Epoch : 1, Step : 1055, Training Loss : 0.49925, Training Acc : 0.728, Run Time : 0.38
INFO:root:2019-05-10 23:37:05, Epoch : 1, Step : 1056, Training Loss : 0.40534, Training Acc : 0.833, Run Time : 0.55
INFO:root:2019-05-10 23:37:08, Epoch : 1, Step : 1057, Training Loss : 0.45184, Training Acc : 0.767, Run Time : 3.21
INFO:root:2019-05-10 23:37:08, Epoch : 1, Step : 1058, Training Loss : 0.55148, Training Acc : 0.733, Run Time : 0.38
INFO:root:2019-05-10 23:37:08, Epoch : 1, Step : 1059, Training Loss : 0.63596, Training Acc : 0.728, Run Time : 0.38
INFO:root:2019-05-10 23:37:09, Epoch : 1, Step : 1060, Training Loss : 0.52142, Training Acc : 0.772, Run Time : 0.42
INFO:root:2019-05-10 23:37:15, Epoch : 1, Step : 1061, Training Loss : 0.51575, Training Acc : 0.761, Run Time : 5.74
INFO:root:2019-05-10 23:37:15, Epoch : 1, Step : 1062, Training Loss : 0.43675, Training Acc : 0.811, Run Time : 0.76
INFO:root:2019-05-10 23:37:16, Epoch : 1, Step : 1063, Training Loss : 0.43868, Training Acc : 0.794, Run Time : 0.37
INFO:root:2019-05-10 23:37:16, Epoch : 1, Step : 1064, Training Loss : 0.42869, Training Acc : 0.844, Run Time : 0.39
INFO:root:2019-05-10 23:37:17, Epoch : 1, Step : 1065, Training Loss : 0.41805, Training Acc : 0.839, Run Time : 0.37
INFO:root:2019-05-10 23:37:17, Epoch : 1, Step : 1066, Training Loss : 0.46815, Training Acc : 0.767, Run Time : 0.44
INFO:root:2019-05-10 23:37:24, Epoch : 1, Step : 1067, Training Loss : 0.38914, Training Acc : 0.850, Run Time : 6.85
INFO:root:2019-05-10 23:37:24, Epoch : 1, Step : 1068, Training Loss : 0.38573, Training Acc : 0.822, Run Time : 0.62
INFO:root:2019-05-10 23:37:25, Epoch : 1, Step : 1069, Training Loss : 0.37958, Training Acc : 0.833, Run Time : 0.37
INFO:root:2019-05-10 23:37:26, Epoch : 1, Step : 1070, Training Loss : 0.54828, Training Acc : 0.772, Run Time : 0.94
INFO:root:2019-05-10 23:37:34, Epoch : 1, Step : 1071, Training Loss : 0.32136, Training Acc : 0.894, Run Time : 7.96
INFO:root:2019-05-10 23:37:35, Epoch : 1, Step : 1072, Training Loss : 0.38157, Training Acc : 0.833, Run Time : 0.89
INFO:root:2019-05-10 23:37:35, Epoch : 1, Step : 1073, Training Loss : 0.45205, Training Acc : 0.800, Run Time : 0.41
INFO:root:2019-05-10 23:37:48, Epoch : 1, Step : 1074, Training Loss : 0.42633, Training Acc : 0.794, Run Time : 12.57
INFO:root:2019-05-10 23:37:49, Epoch : 1, Step : 1075, Training Loss : 0.29946, Training Acc : 0.900, Run Time : 1.65
INFO:root:2019-05-10 23:37:50, Epoch : 1, Step : 1076, Training Loss : 0.33066, Training Acc : 0.850, Run Time : 0.40
INFO:root:2019-05-10 23:37:51, Epoch : 1, Step : 1077, Training Loss : 0.32317, Training Acc : 0.861, Run Time : 1.20
INFO:root:2019-05-10 23:37:58, Epoch : 1, Step : 1078, Training Loss : 0.32481, Training Acc : 0.889, Run Time : 6.91
INFO:root:2019-05-10 23:37:58, Epoch : 1, Step : 1079, Training Loss : 0.38563, Training Acc : 0.811, Run Time : 0.41
INFO:root:2019-05-10 23:37:59, Epoch : 1, Step : 1080, Training Loss : 0.34499, Training Acc : 0.817, Run Time : 0.96
INFO:root:2019-05-10 23:38:16, Epoch : 1, Step : 1081, Training Loss : 0.37404, Training Acc : 0.767, Run Time : 16.98
INFO:root:2019-05-10 23:38:17, Epoch : 1, Step : 1082, Training Loss : 0.30780, Training Acc : 0.839, Run Time : 0.46
INFO:root:2019-05-10 23:38:17, Epoch : 1, Step : 1083, Training Loss : 0.28761, Training Acc : 0.850, Run Time : 0.40
INFO:root:2019-05-10 23:38:19, Epoch : 1, Step : 1084, Training Loss : 0.27379, Training Acc : 0.889, Run Time : 1.62
INFO:root:2019-05-10 23:38:30, Epoch : 1, Step : 1085, Training Loss : 0.26409, Training Acc : 0.889, Run Time : 11.83
INFO:root:2019-05-10 23:38:31, Epoch : 1, Step : 1086, Training Loss : 0.30107, Training Acc : 0.850, Run Time : 0.42
INFO:root:2019-05-10 23:38:31, Epoch : 1, Step : 1087, Training Loss : 0.25387, Training Acc : 0.889, Run Time : 0.48
INFO:root:2019-05-10 23:38:32, Epoch : 1, Step : 1088, Training Loss : 0.30391, Training Acc : 0.850, Run Time : 0.49
INFO:root:2019-05-10 23:38:37, Epoch : 1, Step : 1089, Training Loss : 0.34055, Training Acc : 0.867, Run Time : 5.60
INFO:root:2019-05-10 23:38:38, Epoch : 1, Step : 1090, Training Loss : 0.28315, Training Acc : 0.839, Run Time : 0.94
INFO:root:2019-05-10 23:38:39, Epoch : 1, Step : 1091, Training Loss : 0.32439, Training Acc : 0.839, Run Time : 1.11
INFO:root:2019-05-10 23:38:49, Epoch : 1, Step : 1092, Training Loss : 0.33024, Training Acc : 0.833, Run Time : 9.44
INFO:root:2019-05-10 23:38:49, Epoch : 1, Step : 1093, Training Loss : 0.33355, Training Acc : 0.856, Run Time : 0.43
INFO:root:2019-05-10 23:38:50, Epoch : 1, Step : 1094, Training Loss : 0.28321, Training Acc : 0.889, Run Time : 0.37
INFO:root:2019-05-10 23:38:51, Epoch : 1, Step : 1095, Training Loss : 0.24065, Training Acc : 0.889, Run Time : 1.44
INFO:root:2019-05-10 23:38:58, Epoch : 1, Step : 1096, Training Loss : 0.28004, Training Acc : 0.872, Run Time : 6.47
INFO:root:2019-05-10 23:39:05, Epoch : 1, Step : 1097, Training Loss : 0.29829, Training Acc : 0.856, Run Time : 7.62
INFO:root:2019-05-10 23:39:08, Epoch : 1, Step : 1098, Training Loss : 0.30678, Training Acc : 0.867, Run Time : 2.96
INFO:root:2019-05-10 23:39:09, Epoch : 1, Step : 1099, Training Loss : 0.51122, Training Acc : 0.800, Run Time : 0.38
INFO:root:2019-05-10 23:39:09, Epoch : 1, Step : 1100, Training Loss : 0.81542, Training Acc : 0.683, Run Time : 0.37
INFO:root:2019-05-10 23:39:17, Epoch : 1, Step : 1101, Training Loss : 0.49603, Training Acc : 0.783, Run Time : 7.58
INFO:root:2019-05-10 23:39:17, Epoch : 1, Step : 1102, Training Loss : 0.40582, Training Acc : 0.811, Run Time : 0.41
INFO:root:2019-05-10 23:39:18, Epoch : 1, Step : 1103, Training Loss : 0.28142, Training Acc : 0.878, Run Time : 1.31
INFO:root:2019-05-10 23:39:25, Epoch : 1, Step : 1104, Training Loss : 0.23894, Training Acc : 0.894, Run Time : 6.96
INFO:root:2019-05-10 23:39:27, Epoch : 1, Step : 1105, Training Loss : 0.22728, Training Acc : 0.911, Run Time : 1.57
INFO:root:2019-05-10 23:39:27, Epoch : 1, Step : 1106, Training Loss : 0.36642, Training Acc : 0.833, Run Time : 0.49
INFO:root:2019-05-10 23:39:34, Epoch : 1, Step : 1107, Training Loss : 0.38699, Training Acc : 0.800, Run Time : 7.20
INFO:root:2019-05-10 23:39:35, Epoch : 1, Step : 1108, Training Loss : 0.41743, Training Acc : 0.806, Run Time : 0.43
INFO:root:2019-05-10 23:39:35, Epoch : 1, Step : 1109, Training Loss : 0.47703, Training Acc : 0.761, Run Time : 0.38
INFO:root:2019-05-10 23:39:37, Epoch : 1, Step : 1110, Training Loss : 0.52335, Training Acc : 0.733, Run Time : 1.49
INFO:root:2019-05-10 23:39:43, Epoch : 1, Step : 1111, Training Loss : 0.46471, Training Acc : 0.750, Run Time : 6.74
INFO:root:2019-05-10 23:39:44, Epoch : 1, Step : 1112, Training Loss : 0.30970, Training Acc : 0.828, Run Time : 0.41
INFO:root:2019-05-10 23:39:45, Epoch : 1, Step : 1113, Training Loss : 0.42133, Training Acc : 0.756, Run Time : 1.55
INFO:root:2019-05-10 23:39:51, Epoch : 1, Step : 1114, Training Loss : 0.40736, Training Acc : 0.761, Run Time : 5.20
INFO:root:2019-05-10 23:39:51, Epoch : 1, Step : 1115, Training Loss : 0.40114, Training Acc : 0.800, Run Time : 0.40
INFO:root:2019-05-10 23:39:51, Epoch : 1, Step : 1116, Training Loss : 0.43437, Training Acc : 0.772, Run Time : 0.37
INFO:root:2019-05-10 23:39:52, Epoch : 1, Step : 1117, Training Loss : 0.41802, Training Acc : 0.783, Run Time : 0.38
INFO:root:2019-05-10 23:39:53, Epoch : 1, Step : 1118, Training Loss : 0.36847, Training Acc : 0.828, Run Time : 0.77
INFO:root:2019-05-10 23:40:02, Epoch : 1, Step : 1119, Training Loss : 0.54836, Training Acc : 0.694, Run Time : 9.54
INFO:root:2019-05-10 23:40:03, Epoch : 1, Step : 1120, Training Loss : 0.33269, Training Acc : 0.844, Run Time : 0.75
INFO:root:2019-05-10 23:40:03, Epoch : 1, Step : 1121, Training Loss : 0.40279, Training Acc : 0.822, Run Time : 0.38
INFO:root:2019-05-10 23:40:04, Epoch : 1, Step : 1122, Training Loss : 0.41372, Training Acc : 0.767, Run Time : 0.38
INFO:root:2019-05-10 23:40:11, Epoch : 1, Step : 1123, Training Loss : 0.35723, Training Acc : 0.828, Run Time : 7.59
INFO:root:2019-05-10 23:40:12, Epoch : 1, Step : 1124, Training Loss : 0.30416, Training Acc : 0.861, Run Time : 0.42
INFO:root:2019-05-10 23:40:12, Epoch : 1, Step : 1125, Training Loss : 0.42096, Training Acc : 0.806, Run Time : 0.37
INFO:root:2019-05-10 23:40:14, Epoch : 1, Step : 1126, Training Loss : 0.30826, Training Acc : 0.872, Run Time : 1.98
INFO:root:2019-05-10 23:40:20, Epoch : 1, Step : 1127, Training Loss : 0.30985, Training Acc : 0.850, Run Time : 6.33
INFO:root:2019-05-10 23:40:21, Epoch : 1, Step : 1128, Training Loss : 0.39935, Training Acc : 0.789, Run Time : 0.62
INFO:root:2019-05-10 23:40:22, Epoch : 1, Step : 1129, Training Loss : 0.34616, Training Acc : 0.828, Run Time : 1.00
INFO:root:2019-05-10 23:40:36, Epoch : 1, Step : 1130, Training Loss : 0.23358, Training Acc : 0.944, Run Time : 14.59
INFO:root:2019-05-10 23:40:37, Epoch : 1, Step : 1131, Training Loss : 0.28492, Training Acc : 0.889, Run Time : 0.43
INFO:root:2019-05-10 23:40:37, Epoch : 1, Step : 1132, Training Loss : 0.26919, Training Acc : 0.878, Run Time : 0.37
INFO:root:2019-05-10 23:40:38, Epoch : 1, Step : 1133, Training Loss : 0.24796, Training Acc : 0.922, Run Time : 0.99
INFO:root:2019-05-10 23:40:44, Epoch : 1, Step : 1134, Training Loss : 0.25802, Training Acc : 0.922, Run Time : 5.32
INFO:root:2019-05-10 23:40:44, Epoch : 1, Step : 1135, Training Loss : 0.20985, Training Acc : 0.939, Run Time : 0.53
INFO:root:2019-05-10 23:40:45, Epoch : 1, Step : 1136, Training Loss : 0.20912, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-10 23:40:45, Epoch : 1, Step : 1137, Training Loss : 0.29514, Training Acc : 0.878, Run Time : 0.95
INFO:root:2019-05-10 23:40:50, Epoch : 1, Step : 1138, Training Loss : 0.23063, Training Acc : 0.928, Run Time : 4.78
INFO:root:2019-05-10 23:40:51, Epoch : 1, Step : 1139, Training Loss : 0.24475, Training Acc : 0.894, Run Time : 0.50
INFO:root:2019-05-10 23:40:51, Epoch : 1, Step : 1140, Training Loss : 0.18516, Training Acc : 0.939, Run Time : 0.37
INFO:root:2019-05-10 23:40:52, Epoch : 1, Step : 1141, Training Loss : 0.29196, Training Acc : 0.878, Run Time : 0.58
INFO:root:2019-05-10 23:40:52, Epoch : 1, Step : 1142, Training Loss : 0.35961, Training Acc : 0.839, Run Time : 0.38
INFO:root:2019-05-10 23:40:52, Epoch : 1, Step : 1143, Training Loss : 0.20548, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-10 23:40:53, Epoch : 1, Step : 1144, Training Loss : 0.31342, Training Acc : 0.828, Run Time : 0.70
INFO:root:2019-05-10 23:40:58, Epoch : 1, Step : 1145, Training Loss : 0.18866, Training Acc : 0.950, Run Time : 5.26
INFO:root:2019-05-10 23:40:59, Epoch : 1, Step : 1146, Training Loss : 0.18011, Training Acc : 0.961, Run Time : 0.66
INFO:root:2019-05-10 23:41:00, Epoch : 1, Step : 1147, Training Loss : 0.21003, Training Acc : 0.922, Run Time : 0.88
INFO:root:2019-05-10 23:41:09, Epoch : 1, Step : 1148, Training Loss : 0.19895, Training Acc : 0.928, Run Time : 9.22
INFO:root:2019-05-10 23:41:10, Epoch : 1, Step : 1149, Training Loss : 0.20397, Training Acc : 0.922, Run Time : 0.61
INFO:root:2019-05-10 23:41:10, Epoch : 1, Step : 1150, Training Loss : 0.18055, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-10 23:41:18, Epoch : 1, Step : 1151, Training Loss : 0.20704, Training Acc : 0.939, Run Time : 8.14
INFO:root:2019-05-10 23:41:19, Epoch : 1, Step : 1152, Training Loss : 0.21953, Training Acc : 0.906, Run Time : 0.84
INFO:root:2019-05-10 23:41:19, Epoch : 1, Step : 1153, Training Loss : 0.48111, Training Acc : 0.800, Run Time : 0.37
INFO:root:2019-05-10 23:41:20, Epoch : 1, Step : 1154, Training Loss : 0.81270, Training Acc : 0.700, Run Time : 0.44
INFO:root:2019-05-10 23:41:25, Epoch : 1, Step : 1155, Training Loss : 0.30433, Training Acc : 0.850, Run Time : 4.58
INFO:root:2019-05-10 23:41:25, Epoch : 1, Step : 1156, Training Loss : 0.29797, Training Acc : 0.889, Run Time : 0.80
INFO:root:2019-05-10 23:41:32, Epoch : 1, Step : 1157, Training Loss : 0.31384, Training Acc : 0.867, Run Time : 6.76
INFO:root:2019-05-10 23:41:33, Epoch : 1, Step : 1158, Training Loss : 0.34789, Training Acc : 0.856, Run Time : 1.24
INFO:root:2019-05-10 23:41:34, Epoch : 1, Step : 1159, Training Loss : 0.57029, Training Acc : 0.739, Run Time : 0.38
INFO:root:2019-05-10 23:41:34, Epoch : 1, Step : 1160, Training Loss : 0.43470, Training Acc : 0.806, Run Time : 0.38
INFO:root:2019-05-10 23:41:35, Epoch : 1, Step : 1161, Training Loss : 0.68351, Training Acc : 0.667, Run Time : 0.58
INFO:root:2019-05-10 23:41:39, Epoch : 1, Step : 1162, Training Loss : 0.48943, Training Acc : 0.750, Run Time : 4.21
INFO:root:2019-05-10 23:41:41, Epoch : 1, Step : 1163, Training Loss : 0.35838, Training Acc : 0.833, Run Time : 2.44
INFO:root:2019-05-10 23:41:48, Epoch : 1, Step : 1164, Training Loss : 0.49303, Training Acc : 0.772, Run Time : 6.84
INFO:root:2019-05-10 23:41:49, Epoch : 1, Step : 1165, Training Loss : 0.36955, Training Acc : 0.817, Run Time : 0.41
INFO:root:2019-05-10 23:41:49, Epoch : 1, Step : 1166, Training Loss : 0.25948, Training Acc : 0.861, Run Time : 0.42
INFO:root:2019-05-10 23:41:50, Epoch : 1, Step : 1167, Training Loss : 0.45599, Training Acc : 0.772, Run Time : 0.64
INFO:root:2019-05-10 23:41:59, Epoch : 1, Step : 1168, Training Loss : 0.38562, Training Acc : 0.844, Run Time : 9.20
INFO:root:2019-05-10 23:41:59, Epoch : 1, Step : 1169, Training Loss : 0.31724, Training Acc : 0.850, Run Time : 0.44
INFO:root:2019-05-10 23:42:00, Epoch : 1, Step : 1170, Training Loss : 0.27900, Training Acc : 0.872, Run Time : 0.40
INFO:root:2019-05-10 23:42:00, Epoch : 1, Step : 1171, Training Loss : 0.42417, Training Acc : 0.767, Run Time : 0.54
INFO:root:2019-05-10 23:42:04, Epoch : 1, Step : 1172, Training Loss : 0.36073, Training Acc : 0.844, Run Time : 3.94
INFO:root:2019-05-10 23:42:05, Epoch : 1, Step : 1173, Training Loss : 0.37942, Training Acc : 0.828, Run Time : 0.55
INFO:root:2019-05-10 23:42:06, Epoch : 1, Step : 1174, Training Loss : 0.47847, Training Acc : 0.761, Run Time : 1.09
INFO:root:2019-05-10 23:42:15, Epoch : 1, Step : 1175, Training Loss : 0.36985, Training Acc : 0.833, Run Time : 9.72
INFO:root:2019-05-10 23:42:16, Epoch : 1, Step : 1176, Training Loss : 0.35131, Training Acc : 0.811, Run Time : 0.45
INFO:root:2019-05-10 23:42:16, Epoch : 1, Step : 1177, Training Loss : 0.35338, Training Acc : 0.839, Run Time : 0.46
INFO:root:2019-05-10 23:42:17, Epoch : 1, Step : 1178, Training Loss : 0.33465, Training Acc : 0.856, Run Time : 0.39
INFO:root:2019-05-10 23:42:17, Epoch : 1, Step : 1179, Training Loss : 0.35967, Training Acc : 0.822, Run Time : 0.55
INFO:root:2019-05-10 23:42:30, Epoch : 1, Step : 1180, Training Loss : 0.45614, Training Acc : 0.822, Run Time : 12.68
INFO:root:2019-05-10 23:42:31, Epoch : 1, Step : 1181, Training Loss : 0.38108, Training Acc : 0.872, Run Time : 0.93
INFO:root:2019-05-10 23:42:31, Epoch : 1, Step : 1182, Training Loss : 0.40476, Training Acc : 0.839, Run Time : 0.38
INFO:root:2019-05-10 23:42:43, Epoch : 1, Step : 1183, Training Loss : 0.41679, Training Acc : 0.806, Run Time : 11.20
INFO:root:2019-05-10 23:42:44, Epoch : 1, Step : 1184, Training Loss : 0.34581, Training Acc : 0.850, Run Time : 1.35
INFO:root:2019-05-10 23:42:44, Epoch : 1, Step : 1185, Training Loss : 0.36225, Training Acc : 0.844, Run Time : 0.37
INFO:root:2019-05-10 23:42:46, Epoch : 1, Step : 1186, Training Loss : 0.36089, Training Acc : 0.828, Run Time : 1.37
INFO:root:2019-05-10 23:42:47, Epoch : 1, Step : 1187, Training Loss : 0.30058, Training Acc : 0.833, Run Time : 1.50
INFO:root:2019-05-10 23:42:48, Epoch : 1, Step : 1188, Training Loss : 0.34345, Training Acc : 0.856, Run Time : 0.74
INFO:root:2019-05-10 23:42:55, Epoch : 1, Step : 1189, Training Loss : 0.33334, Training Acc : 0.839, Run Time : 7.12
INFO:root:2019-05-10 23:42:56, Epoch : 1, Step : 1190, Training Loss : 0.31395, Training Acc : 0.856, Run Time : 1.20
INFO:root:2019-05-10 23:42:57, Epoch : 1, Step : 1191, Training Loss : 0.31210, Training Acc : 0.872, Run Time : 0.61
INFO:root:2019-05-10 23:43:01, Epoch : 1, Step : 1192, Training Loss : 0.30177, Training Acc : 0.872, Run Time : 4.14
INFO:root:2019-05-10 23:43:01, Epoch : 1, Step : 1193, Training Loss : 0.31222, Training Acc : 0.861, Run Time : 0.52
INFO:root:2019-05-10 23:43:02, Epoch : 1, Step : 1194, Training Loss : 0.26722, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-10 23:43:02, Epoch : 1, Step : 1195, Training Loss : 0.31927, Training Acc : 0.878, Run Time : 0.42
INFO:root:2019-05-10 23:43:07, Epoch : 1, Step : 1196, Training Loss : 0.44288, Training Acc : 0.833, Run Time : 4.51
INFO:root:2019-05-10 23:43:07, Epoch : 1, Step : 1197, Training Loss : 0.30291, Training Acc : 0.856, Run Time : 0.45
INFO:root:2019-05-10 23:43:08, Epoch : 1, Step : 1198, Training Loss : 0.35524, Training Acc : 0.833, Run Time : 0.79
INFO:root:2019-05-10 23:43:09, Epoch : 1, Step : 1199, Training Loss : 0.30726, Training Acc : 0.867, Run Time : 1.26
INFO:root:2019-05-10 23:43:21, Epoch : 1, Step : 1200, Training Loss : 0.32160, Training Acc : 0.867, Run Time : 11.52
INFO:root:2019-05-10 23:43:23, Epoch : 1, Step : 1201, Training Loss : 0.44377, Training Acc : 0.839, Run Time : 1.98
INFO:root:2019-05-10 23:43:24, Epoch : 1, Step : 1202, Training Loss : 0.32326, Training Acc : 0.878, Run Time : 0.77
INFO:root:2019-05-10 23:43:25, Epoch : 1, Step : 1203, Training Loss : 0.32503, Training Acc : 0.878, Run Time : 1.12
INFO:root:2019-05-10 23:43:25, Epoch : 1, Step : 1204, Training Loss : 0.33332, Training Acc : 0.861, Run Time : 0.65
INFO:root:2019-05-10 23:43:26, Epoch : 1, Step : 1205, Training Loss : 0.53178, Training Acc : 0.772, Run Time : 0.38
INFO:root:2019-05-10 23:43:26, Epoch : 1, Step : 1206, Training Loss : 0.33866, Training Acc : 0.761, Run Time : 0.37
INFO:root:2019-05-10 23:43:27, Epoch : 1, Step : 1207, Training Loss : 0.32700, Training Acc : 0.828, Run Time : 0.78
INFO:root:2019-05-10 23:43:28, Epoch : 1, Step : 1208, Training Loss : 0.59625, Training Acc : 0.733, Run Time : 0.60
INFO:root:2019-05-10 23:43:28, Epoch : 1, Step : 1209, Training Loss : 0.31743, Training Acc : 0.806, Run Time : 0.38
INFO:root:2019-05-10 23:43:28, Epoch : 1, Step : 1210, Training Loss : 0.24486, Training Acc : 0.906, Run Time : 0.52
INFO:root:2019-05-10 23:43:30, Epoch : 1, Step : 1211, Training Loss : 0.26957, Training Acc : 0.900, Run Time : 1.64
INFO:root:2019-05-10 23:43:31, Epoch : 1, Step : 1212, Training Loss : 0.42818, Training Acc : 0.789, Run Time : 0.67
INFO:root:2019-05-10 23:43:31, Epoch : 1, Step : 1213, Training Loss : 0.18924, Training Acc : 0.956, Run Time : 0.59
INFO:root:2019-05-10 23:43:37, Epoch : 1, Step : 1214, Training Loss : 0.19692, Training Acc : 0.967, Run Time : 5.25
INFO:root:2019-05-10 23:43:37, Epoch : 1, Step : 1215, Training Loss : 0.25949, Training Acc : 0.928, Run Time : 0.43
INFO:root:2019-05-10 23:43:37, Epoch : 1, Step : 1216, Training Loss : 0.31782, Training Acc : 0.850, Run Time : 0.40
INFO:root:2019-05-10 23:43:43, Epoch : 1, Step : 1217, Training Loss : 0.16714, Training Acc : 0.956, Run Time : 5.86
INFO:root:2019-05-10 23:43:44, Epoch : 1, Step : 1218, Training Loss : 0.16248, Training Acc : 0.956, Run Time : 0.69
INFO:root:2019-05-10 23:43:44, Epoch : 1, Step : 1219, Training Loss : 0.21101, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-10 23:43:45, Epoch : 1, Step : 1220, Training Loss : 0.18727, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-10 23:43:45, Epoch : 1, Step : 1221, Training Loss : 0.22110, Training Acc : 0.922, Run Time : 0.56
INFO:root:2019-05-10 23:43:46, Epoch : 1, Step : 1222, Training Loss : 0.23741, Training Acc : 0.922, Run Time : 0.70
INFO:root:2019-05-10 23:43:56, Epoch : 1, Step : 1223, Training Loss : 0.17459, Training Acc : 0.944, Run Time : 10.30
INFO:root:2019-05-10 23:43:57, Epoch : 1, Step : 1224, Training Loss : 0.20383, Training Acc : 0.894, Run Time : 0.76
INFO:root:2019-05-10 23:43:57, Epoch : 1, Step : 1225, Training Loss : 0.17683, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-10 23:44:03, Epoch : 1, Step : 1226, Training Loss : 0.16162, Training Acc : 0.939, Run Time : 5.95
INFO:root:2019-05-10 23:44:13, Epoch : 1, Step : 1227, Training Loss : 0.28407, Training Acc : 0.883, Run Time : 9.91
INFO:root:2019-05-10 23:44:14, Epoch : 1, Step : 1228, Training Loss : 0.18825, Training Acc : 0.922, Run Time : 0.40
INFO:root:2019-05-10 23:44:14, Epoch : 1, Step : 1229, Training Loss : 0.17359, Training Acc : 0.944, Run Time : 0.37
INFO:root:2019-05-10 23:44:15, Epoch : 1, Step : 1230, Training Loss : 0.12615, Training Acc : 0.967, Run Time : 0.84
INFO:root:2019-05-10 23:44:23, Epoch : 1, Step : 1231, Training Loss : 0.14174, Training Acc : 0.956, Run Time : 7.76
INFO:root:2019-05-10 23:44:23, Epoch : 1, Step : 1232, Training Loss : 0.22326, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-10 23:44:23, Epoch : 1, Step : 1233, Training Loss : 0.17574, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-10 23:44:24, Epoch : 1, Step : 1234, Training Loss : 0.17933, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-10 23:44:25, Epoch : 1, Step : 1235, Training Loss : 0.18071, Training Acc : 0.939, Run Time : 0.84
INFO:root:2019-05-10 23:44:27, Epoch : 1, Step : 1236, Training Loss : 0.19292, Training Acc : 0.928, Run Time : 2.56
INFO:root:2019-05-10 23:44:40, Epoch : 1, Step : 1237, Training Loss : 0.16873, Training Acc : 0.956, Run Time : 12.40
INFO:root:2019-05-10 23:44:41, Epoch : 1, Step : 1238, Training Loss : 0.23248, Training Acc : 0.922, Run Time : 1.14
INFO:root:2019-05-10 23:44:42, Epoch : 1, Step : 1239, Training Loss : 0.21385, Training Acc : 0.917, Run Time : 0.78
INFO:root:2019-05-10 23:44:53, Epoch : 1, Step : 1240, Training Loss : 0.28327, Training Acc : 0.894, Run Time : 11.24
INFO:root:2019-05-10 23:44:54, Epoch : 1, Step : 1241, Training Loss : 0.27043, Training Acc : 0.867, Run Time : 1.28
INFO:root:2019-05-10 23:45:07, Epoch : 1, Step : 1242, Training Loss : 0.25198, Training Acc : 0.894, Run Time : 12.72
INFO:root:2019-05-10 23:45:08, Epoch : 1, Step : 1243, Training Loss : 0.17270, Training Acc : 0.956, Run Time : 1.06
INFO:root:2019-05-10 23:45:09, Epoch : 1, Step : 1244, Training Loss : 0.19000, Training Acc : 0.933, Run Time : 1.22
INFO:root:2019-05-10 23:45:19, Epoch : 1, Step : 1245, Training Loss : 0.14463, Training Acc : 0.950, Run Time : 10.15
INFO:root:2019-05-10 23:45:20, Epoch : 1, Step : 1246, Training Loss : 0.28838, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-10 23:45:20, Epoch : 1, Step : 1247, Training Loss : 0.24103, Training Acc : 0.911, Run Time : 0.40
INFO:root:2019-05-10 23:45:21, Epoch : 1, Step : 1248, Training Loss : 0.27904, Training Acc : 0.889, Run Time : 1.19
INFO:root:2019-05-10 23:45:30, Epoch : 1, Step : 1249, Training Loss : 0.24937, Training Acc : 0.911, Run Time : 9.31
INFO:root:2019-05-10 23:45:31, Epoch : 1, Step : 1250, Training Loss : 0.23940, Training Acc : 0.906, Run Time : 0.66
INFO:root:2019-05-10 23:45:32, Epoch : 1, Step : 1251, Training Loss : 0.22385, Training Acc : 0.911, Run Time : 1.17
INFO:root:2019-05-10 23:45:38, Epoch : 1, Step : 1252, Training Loss : 0.38024, Training Acc : 0.850, Run Time : 5.52
INFO:root:2019-05-10 23:45:38, Epoch : 1, Step : 1253, Training Loss : 0.28337, Training Acc : 0.867, Run Time : 0.40
INFO:root:2019-05-10 23:45:39, Epoch : 1, Step : 1254, Training Loss : 0.28525, Training Acc : 0.889, Run Time : 0.39
INFO:root:2019-05-10 23:45:39, Epoch : 1, Step : 1255, Training Loss : 0.36016, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-10 23:45:52, Epoch : 1, Step : 1256, Training Loss : 0.22516, Training Acc : 0.883, Run Time : 12.44
INFO:root:2019-05-10 23:45:52, Epoch : 1, Step : 1257, Training Loss : 0.19930, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-10 23:45:52, Epoch : 1, Step : 1258, Training Loss : 0.24482, Training Acc : 0.883, Run Time : 0.39
INFO:root:2019-05-10 23:45:54, Epoch : 1, Step : 1259, Training Loss : 0.22837, Training Acc : 0.894, Run Time : 1.26
INFO:root:2019-05-10 23:45:54, Epoch : 1, Step : 1260, Training Loss : 0.28352, Training Acc : 0.878, Run Time : 0.42
INFO:root:2019-05-10 23:46:03, Epoch : 1, Step : 1261, Training Loss : 0.92642, Training Acc : 0.678, Run Time : 8.63
INFO:root:2019-05-10 23:46:04, Epoch : 1, Step : 1262, Training Loss : 0.97228, Training Acc : 0.644, Run Time : 0.83
INFO:root:2019-05-10 23:46:04, Epoch : 1, Step : 1263, Training Loss : 0.84619, Training Acc : 0.744, Run Time : 0.38
INFO:root:2019-05-10 23:46:04, Epoch : 1, Step : 1264, Training Loss : 0.40621, Training Acc : 0.817, Run Time : 0.37
INFO:root:2019-05-10 23:46:05, Epoch : 1, Step : 1265, Training Loss : 0.29293, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-10 23:46:06, Epoch : 1, Step : 1266, Training Loss : 0.33705, Training Acc : 0.844, Run Time : 1.23
INFO:root:2019-05-10 23:46:17, Epoch : 1, Step : 1267, Training Loss : 0.34643, Training Acc : 0.861, Run Time : 10.80
INFO:root:2019-05-10 23:46:17, Epoch : 1, Step : 1268, Training Loss : 0.40926, Training Acc : 0.817, Run Time : 0.57
INFO:root:2019-05-10 23:46:18, Epoch : 1, Step : 1269, Training Loss : 0.78429, Training Acc : 0.628, Run Time : 0.39
INFO:root:2019-05-10 23:46:18, Epoch : 1, Step : 1270, Training Loss : 0.41525, Training Acc : 0.856, Run Time : 0.38
INFO:root:2019-05-10 23:46:20, Epoch : 1, Step : 1271, Training Loss : 0.31960, Training Acc : 0.861, Run Time : 1.69
INFO:root:2019-05-10 23:46:34, Epoch : 1, Step : 1272, Training Loss : 0.32337, Training Acc : 0.872, Run Time : 13.86
INFO:root:2019-05-10 23:46:34, Epoch : 1, Step : 1273, Training Loss : 0.38666, Training Acc : 0.783, Run Time : 0.67
INFO:root:2019-05-10 23:46:35, Epoch : 1, Step : 1274, Training Loss : 0.26955, Training Acc : 0.883, Run Time : 0.43
INFO:root:2019-05-10 23:46:35, Epoch : 1, Step : 1275, Training Loss : 0.23085, Training Acc : 0.878, Run Time : 0.39
INFO:root:2019-05-10 23:46:35, Epoch : 1, Step : 1276, Training Loss : 0.36327, Training Acc : 0.811, Run Time : 0.39
INFO:root:2019-05-10 23:46:36, Epoch : 1, Step : 1277, Training Loss : 0.30550, Training Acc : 0.844, Run Time : 0.70
INFO:root:2019-05-10 23:46:47, Epoch : 1, Step : 1278, Training Loss : 0.48694, Training Acc : 0.783, Run Time : 10.53
INFO:root:2019-05-10 23:46:47, Epoch : 1, Step : 1279, Training Loss : 0.31914, Training Acc : 0.861, Run Time : 0.45
INFO:root:2019-05-10 23:46:48, Epoch : 1, Step : 1280, Training Loss : 0.39989, Training Acc : 0.811, Run Time : 0.52
INFO:root:2019-05-10 23:46:49, Epoch : 1, Step : 1281, Training Loss : 0.39676, Training Acc : 0.833, Run Time : 0.89
INFO:root:2019-05-10 23:46:50, Epoch : 1, Step : 1282, Training Loss : 0.34702, Training Acc : 0.872, Run Time : 1.34
INFO:root:2019-05-10 23:46:58, Epoch : 1, Step : 1283, Training Loss : 0.41038, Training Acc : 0.811, Run Time : 8.53
INFO:root:2019-05-10 23:46:59, Epoch : 1, Step : 1284, Training Loss : 0.26119, Training Acc : 0.900, Run Time : 0.50
INFO:root:2019-05-10 23:46:59, Epoch : 1, Step : 1285, Training Loss : 0.38004, Training Acc : 0.806, Run Time : 0.47
INFO:root:2019-05-10 23:47:00, Epoch : 1, Step : 1286, Training Loss : 0.28152, Training Acc : 0.867, Run Time : 0.56
INFO:root:2019-05-10 23:47:09, Epoch : 1, Step : 1287, Training Loss : 0.41783, Training Acc : 0.783, Run Time : 8.93
INFO:root:2019-05-10 23:47:09, Epoch : 1, Step : 1288, Training Loss : 0.33231, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-10 23:47:10, Epoch : 1, Step : 1289, Training Loss : 0.38750, Training Acc : 0.822, Run Time : 0.52
INFO:root:2019-05-10 23:47:11, Epoch : 1, Step : 1290, Training Loss : 0.32513, Training Acc : 0.828, Run Time : 1.15
INFO:root:2019-05-10 23:47:12, Epoch : 1, Step : 1291, Training Loss : 0.29841, Training Acc : 0.867, Run Time : 1.36
INFO:root:2019-05-10 23:47:13, Epoch : 1, Step : 1292, Training Loss : 0.30617, Training Acc : 0.861, Run Time : 0.47
INFO:root:2019-05-10 23:47:13, Epoch : 1, Step : 1293, Training Loss : 0.27383, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-10 23:47:14, Epoch : 1, Step : 1294, Training Loss : 0.33589, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-10 23:47:20, Epoch : 1, Step : 1295, Training Loss : 0.31894, Training Acc : 0.911, Run Time : 5.96
INFO:root:2019-05-10 23:47:20, Epoch : 1, Step : 1296, Training Loss : 0.33530, Training Acc : 0.833, Run Time : 0.61
INFO:root:2019-05-10 23:47:21, Epoch : 1, Step : 1297, Training Loss : 0.30194, Training Acc : 0.894, Run Time : 0.52
INFO:root:2019-05-10 23:47:21, Epoch : 1, Step : 1298, Training Loss : 0.45208, Training Acc : 0.772, Run Time : 0.37
INFO:root:2019-05-10 23:47:22, Epoch : 1, Step : 1299, Training Loss : 0.32586, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-10 23:47:22, Epoch : 1, Step : 1300, Training Loss : 0.26323, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-10 23:47:31, Epoch : 1, Step : 1301, Training Loss : 0.31243, Training Acc : 0.883, Run Time : 8.92
INFO:root:2019-05-10 23:47:32, Epoch : 1, Step : 1302, Training Loss : 0.26049, Training Acc : 0.894, Run Time : 0.76
INFO:root:2019-05-10 23:47:32, Epoch : 1, Step : 1303, Training Loss : 0.27730, Training Acc : 0.867, Run Time : 0.42
INFO:root:2019-05-10 23:47:32, Epoch : 1, Step : 1304, Training Loss : 0.24531, Training Acc : 0.928, Run Time : 0.42
INFO:root:2019-05-10 23:47:33, Epoch : 1, Step : 1305, Training Loss : 0.28854, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-10 23:47:43, Epoch : 1, Step : 1306, Training Loss : 0.22230, Training Acc : 0.944, Run Time : 10.55
INFO:root:2019-05-10 23:47:44, Epoch : 1, Step : 1307, Training Loss : 0.32857, Training Acc : 0.872, Run Time : 0.90
INFO:root:2019-05-10 23:47:45, Epoch : 1, Step : 1308, Training Loss : 0.28325, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-10 23:47:51, Epoch : 1, Step : 1309, Training Loss : 0.27089, Training Acc : 0.917, Run Time : 6.20
INFO:root:2019-05-10 23:47:51, Epoch : 1, Step : 1310, Training Loss : 0.27296, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 23:47:52, Epoch : 1, Step : 1311, Training Loss : 0.29314, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-10 23:47:52, Epoch : 1, Step : 1312, Training Loss : 0.34478, Training Acc : 0.828, Run Time : 0.37
INFO:root:2019-05-10 23:47:54, Epoch : 1, Step : 1313, Training Loss : 0.33984, Training Acc : 0.833, Run Time : 1.52
INFO:root:2019-05-10 23:47:56, Epoch : 1, Step : 1314, Training Loss : 0.78409, Training Acc : 0.650, Run Time : 2.17
INFO:root:2019-05-10 23:48:06, Epoch : 1, Step : 1315, Training Loss : 0.64506, Training Acc : 0.728, Run Time : 10.45
INFO:root:2019-05-10 23:48:07, Epoch : 1, Step : 1316, Training Loss : 0.98853, Training Acc : 0.622, Run Time : 0.43
INFO:root:2019-05-10 23:48:07, Epoch : 1, Step : 1317, Training Loss : 0.30369, Training Acc : 0.856, Run Time : 0.40
INFO:root:2019-05-10 23:48:07, Epoch : 1, Step : 1318, Training Loss : 0.35922, Training Acc : 0.828, Run Time : 0.37
INFO:root:2019-05-10 23:48:08, Epoch : 1, Step : 1319, Training Loss : 0.42190, Training Acc : 0.811, Run Time : 1.08
INFO:root:2019-05-10 23:48:14, Epoch : 1, Step : 1320, Training Loss : 0.35070, Training Acc : 0.850, Run Time : 5.80
INFO:root:2019-05-10 23:48:15, Epoch : 1, Step : 1321, Training Loss : 0.28768, Training Acc : 0.867, Run Time : 0.51
INFO:root:2019-05-10 23:48:15, Epoch : 1, Step : 1322, Training Loss : 0.24041, Training Acc : 0.894, Run Time : 0.51
INFO:root:2019-05-10 23:48:16, Epoch : 1, Step : 1323, Training Loss : 0.28117, Training Acc : 0.911, Run Time : 0.60
INFO:root:2019-05-10 23:48:24, Epoch : 1, Step : 1324, Training Loss : 0.27777, Training Acc : 0.894, Run Time : 8.30
INFO:root:2019-05-10 23:48:25, Epoch : 1, Step : 1325, Training Loss : 0.46672, Training Acc : 0.739, Run Time : 0.67
INFO:root:2019-05-10 23:48:25, Epoch : 1, Step : 1326, Training Loss : 0.34002, Training Acc : 0.844, Run Time : 0.38
INFO:root:2019-05-10 23:48:26, Epoch : 1, Step : 1327, Training Loss : 0.29669, Training Acc : 0.861, Run Time : 0.80
INFO:root:2019-05-10 23:48:35, Epoch : 1, Step : 1328, Training Loss : 0.50483, Training Acc : 0.744, Run Time : 9.46
INFO:root:2019-05-10 23:48:36, Epoch : 1, Step : 1329, Training Loss : 0.38906, Training Acc : 0.794, Run Time : 0.68
INFO:root:2019-05-10 23:48:37, Epoch : 1, Step : 1330, Training Loss : 0.40057, Training Acc : 0.822, Run Time : 0.37
INFO:root:2019-05-10 23:48:38, Epoch : 1, Step : 1331, Training Loss : 0.57747, Training Acc : 0.744, Run Time : 1.04
INFO:root:2019-05-10 23:48:49, Epoch : 1, Step : 1332, Training Loss : 0.48835, Training Acc : 0.783, Run Time : 11.12
INFO:root:2019-05-10 23:48:49, Epoch : 1, Step : 1333, Training Loss : 0.39748, Training Acc : 0.789, Run Time : 0.68
INFO:root:2019-05-10 23:48:50, Epoch : 1, Step : 1334, Training Loss : 0.39551, Training Acc : 0.833, Run Time : 0.37
INFO:root:2019-05-10 23:48:52, Epoch : 1, Step : 1335, Training Loss : 0.40161, Training Acc : 0.806, Run Time : 2.09
INFO:root:2019-05-10 23:48:59, Epoch : 1, Step : 1336, Training Loss : 0.37044, Training Acc : 0.839, Run Time : 6.86
INFO:root:2019-05-10 23:48:59, Epoch : 1, Step : 1337, Training Loss : 0.40367, Training Acc : 0.839, Run Time : 0.57
INFO:root:2019-05-10 23:49:00, Epoch : 1, Step : 1338, Training Loss : 0.41931, Training Acc : 0.778, Run Time : 0.43
INFO:root:2019-05-10 23:49:01, Epoch : 1, Step : 1339, Training Loss : 0.31700, Training Acc : 0.806, Run Time : 1.19
INFO:root:2019-05-10 23:49:18, Epoch : 1, Step : 1340, Training Loss : 0.51097, Training Acc : 0.789, Run Time : 17.12
INFO:root:2019-05-10 23:49:19, Epoch : 1, Step : 1341, Training Loss : 0.36432, Training Acc : 0.822, Run Time : 0.88
INFO:root:2019-05-10 23:49:19, Epoch : 1, Step : 1342, Training Loss : 0.39941, Training Acc : 0.817, Run Time : 0.50
INFO:root:2019-05-10 23:49:32, Epoch : 1, Step : 1343, Training Loss : 0.44549, Training Acc : 0.800, Run Time : 12.31
INFO:root:2019-05-10 23:49:32, Epoch : 1, Step : 1344, Training Loss : 0.39793, Training Acc : 0.856, Run Time : 0.54
INFO:root:2019-05-10 23:49:33, Epoch : 1, Step : 1345, Training Loss : 0.28400, Training Acc : 0.867, Run Time : 0.45
INFO:root:2019-05-10 23:49:33, Epoch : 1, Step : 1346, Training Loss : 0.30597, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-10 23:49:34, Epoch : 1, Step : 1347, Training Loss : 0.31166, Training Acc : 0.861, Run Time : 0.58
INFO:root:2019-05-10 23:49:37, Epoch : 1, Step : 1348, Training Loss : 0.28523, Training Acc : 0.883, Run Time : 3.28
INFO:root:2019-05-10 23:49:38, Epoch : 1, Step : 1349, Training Loss : 0.29151, Training Acc : 0.872, Run Time : 0.86
INFO:root:2019-05-10 23:49:38, Epoch : 1, Step : 1350, Training Loss : 0.24984, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-10 23:49:39, Epoch : 1, Step : 1351, Training Loss : 0.27779, Training Acc : 0.889, Run Time : 0.60
INFO:root:2019-05-10 23:49:48, Epoch : 1, Step : 1352, Training Loss : 0.41328, Training Acc : 0.856, Run Time : 8.74
INFO:root:2019-05-10 23:49:48, Epoch : 1, Step : 1353, Training Loss : 0.37501, Training Acc : 0.844, Run Time : 0.50
INFO:root:2019-05-10 23:49:49, Epoch : 1, Step : 1354, Training Loss : 0.38229, Training Acc : 0.833, Run Time : 1.16
INFO:root:2019-05-10 23:49:56, Epoch : 1, Step : 1355, Training Loss : 0.33257, Training Acc : 0.844, Run Time : 6.73
INFO:root:2019-05-10 23:49:57, Epoch : 1, Step : 1356, Training Loss : 0.31034, Training Acc : 0.822, Run Time : 0.60
INFO:root:2019-05-10 23:49:57, Epoch : 1, Step : 1357, Training Loss : 0.31771, Training Acc : 0.811, Run Time : 0.37
INFO:root:2019-05-10 23:49:59, Epoch : 1, Step : 1358, Training Loss : 0.32261, Training Acc : 0.839, Run Time : 1.81
INFO:root:2019-05-10 23:50:05, Epoch : 1, Step : 1359, Training Loss : 0.29878, Training Acc : 0.861, Run Time : 5.77
INFO:root:2019-05-10 23:50:05, Epoch : 1, Step : 1360, Training Loss : 0.39323, Training Acc : 0.828, Run Time : 0.48
INFO:root:2019-05-10 23:50:05, Epoch : 1, Step : 1361, Training Loss : 0.37969, Training Acc : 0.817, Run Time : 0.37
INFO:root:2019-05-10 23:50:06, Epoch : 1, Step : 1362, Training Loss : 0.33049, Training Acc : 0.817, Run Time : 0.71
INFO:root:2019-05-10 23:50:12, Epoch : 1, Step : 1363, Training Loss : 0.38675, Training Acc : 0.828, Run Time : 6.03
INFO:root:2019-05-10 23:50:13, Epoch : 1, Step : 1364, Training Loss : 0.36848, Training Acc : 0.811, Run Time : 0.59
INFO:root:2019-05-10 23:50:13, Epoch : 1, Step : 1365, Training Loss : 0.35000, Training Acc : 0.811, Run Time : 0.39
INFO:root:2019-05-10 23:50:14, Epoch : 1, Step : 1366, Training Loss : 0.32087, Training Acc : 0.856, Run Time : 0.47
INFO:root:2019-05-10 23:50:15, Epoch : 1, Step : 1367, Training Loss : 0.33076, Training Acc : 0.844, Run Time : 1.23
INFO:root:2019-05-10 23:50:20, Epoch : 1, Step : 1368, Training Loss : 0.36171, Training Acc : 0.794, Run Time : 4.85
INFO:root:2019-05-10 23:50:20, Epoch : 1, Step : 1369, Training Loss : 0.30587, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-10 23:50:21, Epoch : 1, Step : 1370, Training Loss : 0.48058, Training Acc : 0.783, Run Time : 0.68
INFO:root:2019-05-10 23:50:22, Epoch : 1, Step : 1371, Training Loss : 0.30713, Training Acc : 0.883, Run Time : 1.69
INFO:root:2019-05-10 23:50:23, Epoch : 1, Step : 1372, Training Loss : 0.41246, Training Acc : 0.761, Run Time : 0.47
INFO:root:2019-05-10 23:50:23, Epoch : 1, Step : 1373, Training Loss : 0.32231, Training Acc : 0.850, Run Time : 0.41
INFO:root:2019-05-10 23:50:31, Epoch : 1, Step : 1374, Training Loss : 0.34464, Training Acc : 0.828, Run Time : 7.23
INFO:root:2019-05-10 23:50:31, Epoch : 1, Step : 1375, Training Loss : 0.31468, Training Acc : 0.844, Run Time : 0.49
INFO:root:2019-05-10 23:50:31, Epoch : 1, Step : 1376, Training Loss : 0.31143, Training Acc : 0.839, Run Time : 0.38
INFO:root:2019-05-10 23:50:33, Epoch : 1, Step : 1377, Training Loss : 0.32931, Training Acc : 0.833, Run Time : 1.23
INFO:root:2019-05-10 23:50:39, Epoch : 1, Step : 1378, Training Loss : 0.32610, Training Acc : 0.844, Run Time : 6.76
INFO:root:2019-05-10 23:50:40, Epoch : 1, Step : 1379, Training Loss : 0.33943, Training Acc : 0.822, Run Time : 0.43
INFO:root:2019-05-10 23:50:40, Epoch : 1, Step : 1380, Training Loss : 0.27256, Training Acc : 0.867, Run Time : 0.37
INFO:root:2019-05-10 23:50:41, Epoch : 1, Step : 1381, Training Loss : 0.34111, Training Acc : 0.850, Run Time : 1.06
INFO:root:2019-05-10 23:50:42, Epoch : 1, Step : 1382, Training Loss : 0.31345, Training Acc : 0.822, Run Time : 0.39
INFO:root:2019-05-10 23:50:42, Epoch : 1, Step : 1383, Training Loss : 0.32957, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-10 23:50:43, Epoch : 1, Step : 1384, Training Loss : 0.26438, Training Acc : 0.894, Run Time : 0.69
INFO:root:2019-05-10 23:50:54, Epoch : 1, Step : 1385, Training Loss : 0.29251, Training Acc : 0.878, Run Time : 11.29
INFO:root:2019-05-10 23:50:55, Epoch : 1, Step : 1386, Training Loss : 0.22632, Training Acc : 0.911, Run Time : 0.66
INFO:root:2019-05-10 23:50:57, Epoch : 1, Step : 1387, Training Loss : 0.20577, Training Acc : 0.928, Run Time : 2.68
INFO:root:2019-05-10 23:51:05, Epoch : 1, Step : 1388, Training Loss : 0.30441, Training Acc : 0.883, Run Time : 7.21
INFO:root:2019-05-10 23:51:05, Epoch : 1, Step : 1389, Training Loss : 0.25779, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-10 23:51:05, Epoch : 1, Step : 1390, Training Loss : 0.26159, Training Acc : 0.872, Run Time : 0.37
INFO:root:2019-05-10 23:51:06, Epoch : 1, Step : 1391, Training Loss : 0.19451, Training Acc : 0.928, Run Time : 0.98
INFO:root:2019-05-10 23:51:10, Epoch : 1, Step : 1392, Training Loss : 0.20485, Training Acc : 0.928, Run Time : 3.96
INFO:root:2019-05-10 23:51:11, Epoch : 1, Step : 1393, Training Loss : 0.21639, Training Acc : 0.889, Run Time : 0.92
INFO:root:2019-05-10 23:51:12, Epoch : 1, Step : 1394, Training Loss : 0.19655, Training Acc : 0.911, Run Time : 0.42
INFO:root:2019-05-10 23:51:12, Epoch : 1, Step : 1395, Training Loss : 0.22815, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-10 23:51:13, Epoch : 1, Step : 1396, Training Loss : 0.21616, Training Acc : 0.906, Run Time : 0.55
INFO:root:2019-05-10 23:51:13, Epoch : 1, Step : 1397, Training Loss : 0.25863, Training Acc : 0.872, Run Time : 0.37
INFO:root:2019-05-10 23:51:14, Epoch : 1, Step : 1398, Training Loss : 0.23375, Training Acc : 0.933, Run Time : 0.95
INFO:root:2019-05-10 23:51:20, Epoch : 1, Step : 1399, Training Loss : 0.23247, Training Acc : 0.894, Run Time : 6.44
INFO:root:2019-05-10 23:51:21, Epoch : 1, Step : 1400, Training Loss : 0.17853, Training Acc : 0.939, Run Time : 0.39
INFO:root:2019-05-10 23:51:22, Epoch : 1, Step : 1401, Training Loss : 0.34807, Training Acc : 0.844, Run Time : 0.80
INFO:root:2019-05-10 23:51:32, Epoch : 1, Step : 1402, Training Loss : 0.31405, Training Acc : 0.856, Run Time : 10.90
INFO:root:2019-05-10 23:51:33, Epoch : 1, Step : 1403, Training Loss : 0.33294, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-10 23:51:34, Epoch : 1, Step : 1404, Training Loss : 0.23824, Training Acc : 0.867, Run Time : 0.68
INFO:root:2019-05-10 23:51:35, Epoch : 1, Step : 1405, Training Loss : 0.37287, Training Acc : 0.844, Run Time : 1.95
INFO:root:2019-05-10 23:51:44, Epoch : 1, Step : 1406, Training Loss : 0.24300, Training Acc : 0.872, Run Time : 8.13
INFO:root:2019-05-10 23:51:44, Epoch : 1, Step : 1407, Training Loss : 0.22622, Training Acc : 0.889, Run Time : 0.40
INFO:root:2019-05-10 23:51:45, Epoch : 1, Step : 1408, Training Loss : 0.21814, Training Acc : 0.911, Run Time : 0.50
INFO:root:2019-05-10 23:51:46, Epoch : 1, Step : 1409, Training Loss : 0.18062, Training Acc : 0.900, Run Time : 1.27
INFO:root:2019-05-10 23:51:53, Epoch : 1, Step : 1410, Training Loss : 0.21496, Training Acc : 0.906, Run Time : 7.27
INFO:root:2019-05-10 23:51:54, Epoch : 1, Step : 1411, Training Loss : 0.19763, Training Acc : 0.906, Run Time : 0.52
INFO:root:2019-05-10 23:51:54, Epoch : 1, Step : 1412, Training Loss : 0.20946, Training Acc : 0.928, Run Time : 0.37
INFO:root:2019-05-10 23:51:54, Epoch : 1, Step : 1413, Training Loss : 0.23595, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-10 23:51:55, Epoch : 1, Step : 1414, Training Loss : 0.33701, Training Acc : 0.850, Run Time : 0.39
INFO:root:2019-05-10 23:51:56, Epoch : 1, Step : 1415, Training Loss : 0.19995, Training Acc : 0.922, Run Time : 1.27
INFO:root:2019-05-10 23:52:09, Epoch : 1, Step : 1416, Training Loss : 0.18447, Training Acc : 0.928, Run Time : 13.28
INFO:root:2019-05-10 23:52:10, Epoch : 1, Step : 1417, Training Loss : 0.16004, Training Acc : 0.928, Run Time : 0.81
INFO:root:2019-05-10 23:52:11, Epoch : 1, Step : 1418, Training Loss : 0.18320, Training Acc : 0.917, Run Time : 1.40
INFO:root:2019-05-10 23:52:22, Epoch : 1, Step : 1419, Training Loss : 0.32438, Training Acc : 0.822, Run Time : 10.36
INFO:root:2019-05-10 23:52:22, Epoch : 1, Step : 1420, Training Loss : 0.19589, Training Acc : 0.922, Run Time : 0.51
INFO:root:2019-05-10 23:52:23, Epoch : 1, Step : 1421, Training Loss : 0.21504, Training Acc : 0.889, Run Time : 0.39
INFO:root:2019-05-10 23:52:24, Epoch : 1, Step : 1422, Training Loss : 0.25988, Training Acc : 0.872, Run Time : 0.89
INFO:root:2019-05-10 23:52:30, Epoch : 1, Step : 1423, Training Loss : 0.19865, Training Acc : 0.894, Run Time : 5.98
INFO:root:2019-05-10 23:52:46, Epoch : 1, Step : 1424, Training Loss : 0.37806, Training Acc : 0.839, Run Time : 16.60
INFO:root:2019-05-10 23:52:47, Epoch : 1, Step : 1425, Training Loss : 0.22612, Training Acc : 0.889, Run Time : 1.19
INFO:root:2019-05-10 23:52:48, Epoch : 1, Step : 1426, Training Loss : 0.41394, Training Acc : 0.856, Run Time : 0.90
INFO:root:2019-05-10 23:52:49, Epoch : 1, Step : 1427, Training Loss : 0.16812, Training Acc : 0.917, Run Time : 1.12
INFO:root:2019-05-10 23:53:04, Epoch : 1, Step : 1428, Training Loss : 0.27563, Training Acc : 0.889, Run Time : 14.28
INFO:root:2019-05-10 23:53:04, Epoch : 1, Step : 1429, Training Loss : 0.37626, Training Acc : 0.833, Run Time : 0.67
INFO:root:2019-05-10 23:53:05, Epoch : 1, Step : 1430, Training Loss : 0.26962, Training Acc : 0.872, Run Time : 0.41
INFO:root:2019-05-10 23:53:05, Epoch : 1, Step : 1431, Training Loss : 0.38894, Training Acc : 0.839, Run Time : 0.43
INFO:root:2019-05-10 23:53:13, Epoch : 1, Step : 1432, Training Loss : 0.34986, Training Acc : 0.839, Run Time : 7.33
INFO:root:2019-05-10 23:53:14, Epoch : 1, Step : 1433, Training Loss : 0.31183, Training Acc : 0.867, Run Time : 1.39
INFO:root:2019-05-10 23:53:14, Epoch : 1, Step : 1434, Training Loss : 0.30181, Training Acc : 0.878, Run Time : 0.37
INFO:root:2019-05-10 23:53:28, Epoch : 1, Step : 1435, Training Loss : 0.35612, Training Acc : 0.861, Run Time : 13.65
INFO:root:2019-05-10 23:53:30, Epoch : 1, Step : 1436, Training Loss : 0.25124, Training Acc : 0.894, Run Time : 1.81
INFO:root:2019-05-10 23:53:30, Epoch : 1, Step : 1437, Training Loss : 0.25956, Training Acc : 0.917, Run Time : 0.72
INFO:root:2019-05-10 23:53:31, Epoch : 1, Step : 1438, Training Loss : 0.31870, Training Acc : 0.872, Run Time : 0.42
INFO:root:2019-05-10 23:53:31, Epoch : 1, Step : 1439, Training Loss : 0.23215, Training Acc : 0.906, Run Time : 0.37
INFO:root:2019-05-10 23:53:38, Epoch : 1, Step : 1440, Training Loss : 0.33143, Training Acc : 0.872, Run Time : 6.36
INFO:root:2019-05-10 23:53:38, Epoch : 1, Step : 1441, Training Loss : 0.20682, Training Acc : 0.917, Run Time : 0.56
INFO:root:2019-05-10 23:53:46, Epoch : 1, Step : 1442, Training Loss : 0.24717, Training Acc : 0.911, Run Time : 8.11
INFO:root:2019-05-10 23:53:47, Epoch : 1, Step : 1443, Training Loss : 0.30080, Training Acc : 0.867, Run Time : 0.52
INFO:root:2019-05-10 23:53:47, Epoch : 1, Step : 1444, Training Loss : 0.31122, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-10 23:53:48, Epoch : 1, Step : 1445, Training Loss : 0.33768, Training Acc : 0.839, Run Time : 0.49
INFO:root:2019-05-10 23:53:49, Epoch : 1, Step : 1446, Training Loss : 0.24976, Training Acc : 0.883, Run Time : 0.88
INFO:root:2019-05-10 23:53:49, Epoch : 1, Step : 1447, Training Loss : 0.27332, Training Acc : 0.883, Run Time : 0.64
INFO:root:2019-05-10 23:53:55, Epoch : 1, Step : 1448, Training Loss : 0.25254, Training Acc : 0.889, Run Time : 6.10
INFO:root:2019-05-10 23:53:57, Epoch : 1, Step : 1449, Training Loss : 0.31666, Training Acc : 0.850, Run Time : 1.31
INFO:root:2019-05-10 23:54:02, Epoch : 1, Step : 1450, Training Loss : 0.27755, Training Acc : 0.867, Run Time : 5.05
INFO:root:2019-05-10 23:54:02, Epoch : 1, Step : 1451, Training Loss : 0.19995, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-10 23:54:02, Epoch : 1, Step : 1452, Training Loss : 0.23247, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-10 23:54:04, Epoch : 1, Step : 1453, Training Loss : 0.21506, Training Acc : 0.906, Run Time : 1.66
INFO:root:2019-05-10 23:54:11, Epoch : 1, Step : 1454, Training Loss : 0.20407, Training Acc : 0.922, Run Time : 6.57
INFO:root:2019-05-10 23:54:11, Epoch : 1, Step : 1455, Training Loss : 0.23907, Training Acc : 0.906, Run Time : 0.40
INFO:root:2019-05-10 23:54:11, Epoch : 1, Step : 1456, Training Loss : 0.20799, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-10 23:54:13, Epoch : 1, Step : 1457, Training Loss : 0.18958, Training Acc : 0.928, Run Time : 1.12
INFO:root:2019-05-10 23:54:20, Epoch : 1, Step : 1458, Training Loss : 0.17503, Training Acc : 0.922, Run Time : 7.45
INFO:root:2019-05-10 23:54:21, Epoch : 1, Step : 1459, Training Loss : 0.26098, Training Acc : 0.872, Run Time : 0.71
INFO:root:2019-05-10 23:54:21, Epoch : 1, Step : 1460, Training Loss : 0.22043, Training Acc : 0.889, Run Time : 0.37
INFO:root:2019-05-10 23:54:22, Epoch : 1, Step : 1461, Training Loss : 0.22262, Training Acc : 0.900, Run Time : 1.06
INFO:root:2019-05-10 23:54:28, Epoch : 1, Step : 1462, Training Loss : 0.33582, Training Acc : 0.828, Run Time : 5.73
INFO:root:2019-05-10 23:54:28, Epoch : 1, Step : 1463, Training Loss : 0.30022, Training Acc : 0.872, Run Time : 0.40
INFO:root:2019-05-10 23:54:29, Epoch : 1, Step : 1464, Training Loss : 0.28339, Training Acc : 0.883, Run Time : 0.37
INFO:root:2019-05-10 23:54:29, Epoch : 1, Step : 1465, Training Loss : 0.27233, Training Acc : 0.883, Run Time : 0.40
INFO:root:2019-05-10 23:54:30, Epoch : 1, Step : 1466, Training Loss : 0.23695, Training Acc : 0.900, Run Time : 0.87
INFO:root:2019-05-10 23:54:37, Epoch : 1, Step : 1467, Training Loss : 0.20611, Training Acc : 0.900, Run Time : 7.13
INFO:root:2019-05-10 23:54:38, Epoch : 1, Step : 1468, Training Loss : 0.24731, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-10 23:54:38, Epoch : 1, Step : 1469, Training Loss : 0.22680, Training Acc : 0.894, Run Time : 0.53
INFO:root:2019-05-10 23:54:44, Epoch : 1, Step : 1470, Training Loss : 0.28452, Training Acc : 0.911, Run Time : 6.08
INFO:root:2019-05-10 23:54:45, Epoch : 1, Step : 1471, Training Loss : 0.23756, Training Acc : 0.900, Run Time : 0.56
INFO:root:2019-05-10 23:54:52, Epoch : 1, Step : 1472, Training Loss : 0.28270, Training Acc : 0.872, Run Time : 6.96
INFO:root:2019-05-10 23:54:52, Epoch : 1, Step : 1473, Training Loss : 0.25842, Training Acc : 0.894, Run Time : 0.50
INFO:root:2019-05-10 23:54:53, Epoch : 1, Step : 1474, Training Loss : 0.22458, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-10 23:54:53, Epoch : 1, Step : 1475, Training Loss : 0.15170, Training Acc : 0.961, Run Time : 0.37
INFO:root:2019-05-10 23:54:54, Epoch : 1, Step : 1476, Training Loss : 0.18658, Training Acc : 0.961, Run Time : 0.81
INFO:root:2019-05-10 23:55:03, Epoch : 1, Step : 1477, Training Loss : 0.17264, Training Acc : 0.928, Run Time : 9.50
INFO:root:2019-05-10 23:55:04, Epoch : 1, Step : 1478, Training Loss : 0.17886, Training Acc : 0.939, Run Time : 0.86
INFO:root:2019-05-10 23:55:05, Epoch : 1, Step : 1479, Training Loss : 0.19524, Training Acc : 0.928, Run Time : 0.53
INFO:root:2019-05-10 23:55:06, Epoch : 1, Step : 1480, Training Loss : 0.20174, Training Acc : 0.900, Run Time : 1.67
INFO:root:2019-05-10 23:55:20, Epoch : 1, Step : 1481, Training Loss : 0.21024, Training Acc : 0.900, Run Time : 13.27
INFO:root:2019-05-10 23:55:21, Epoch : 1, Step : 1482, Training Loss : 0.16158, Training Acc : 0.944, Run Time : 0.95
INFO:root:2019-05-10 23:55:21, Epoch : 1, Step : 1483, Training Loss : 0.19571, Training Acc : 0.894, Run Time : 0.42
INFO:root:2019-05-10 23:55:40, Epoch : 1, Step : 1484, Training Loss : 0.47888, Training Acc : 0.839, Run Time : 18.50
INFO:root:2019-05-10 23:55:47, Epoch : 1, Step : 1485, Training Loss : 0.30231, Training Acc : 0.889, Run Time : 7.78
INFO:root:2019-05-10 23:55:50, Epoch : 1, Step : 1486, Training Loss : 0.16751, Training Acc : 0.928, Run Time : 2.89
INFO:root:2019-05-10 23:55:51, Epoch : 1, Step : 1487, Training Loss : 0.20472, Training Acc : 0.911, Run Time : 0.58
INFO:root:2019-05-10 23:55:51, Epoch : 1, Step : 1488, Training Loss : 0.13007, Training Acc : 0.956, Run Time : 0.37
INFO:root:2019-05-10 23:55:52, Epoch : 1, Step : 1489, Training Loss : 0.26299, Training Acc : 0.917, Run Time : 0.37
INFO:root:2019-05-10 23:55:52, Epoch : 1, Step : 1490, Training Loss : 0.30468, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-10 23:55:52, Epoch : 1, Step : 1491, Training Loss : 0.22544, Training Acc : 0.889, Run Time : 0.53
INFO:root:2019-05-10 23:55:58, Epoch : 1, Step : 1492, Training Loss : 0.18704, Training Acc : 0.928, Run Time : 5.58
INFO:root:2019-05-10 23:55:59, Epoch : 1, Step : 1493, Training Loss : 0.17880, Training Acc : 0.950, Run Time : 0.56
INFO:root:2019-05-10 23:55:59, Epoch : 1, Step : 1494, Training Loss : 0.15403, Training Acc : 0.917, Run Time : 0.40
INFO:root:2019-05-10 23:55:59, Epoch : 1, Step : 1495, Training Loss : 0.42702, Training Acc : 0.828, Run Time : 0.37
INFO:root:2019-05-10 23:56:00, Epoch : 1, Step : 1496, Training Loss : 0.27032, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-10 23:56:00, Epoch : 1, Step : 1497, Training Loss : 0.31594, Training Acc : 0.856, Run Time : 0.42
INFO:root:2019-05-10 23:56:01, Epoch : 1, Step : 1498, Training Loss : 0.35932, Training Acc : 0.833, Run Time : 0.73
INFO:root:2019-05-10 23:56:09, Epoch : 1, Step : 1499, Training Loss : 0.19118, Training Acc : 0.906, Run Time : 8.33
INFO:root:2019-05-10 23:56:10, Epoch : 1, Step : 1500, Training Loss : 0.22513, Training Acc : 0.900, Run Time : 0.54
INFO:root:2019-05-10 23:56:18, Epoch : 1, Step : 1501, Training Loss : 0.31774, Training Acc : 0.889, Run Time : 7.95
INFO:root:2019-05-10 23:56:20, Epoch : 1, Step : 1502, Training Loss : 0.46698, Training Acc : 0.761, Run Time : 2.78
INFO:root:2019-05-10 23:56:21, Epoch : 1, Step : 1503, Training Loss : 0.17350, Training Acc : 0.928, Run Time : 0.37
INFO:root:2019-05-10 23:56:21, Epoch : 1, Step : 1504, Training Loss : 0.22762, Training Acc : 0.889, Run Time : 0.37
INFO:root:2019-05-10 23:56:22, Epoch : 1, Step : 1505, Training Loss : 0.18168, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-10 23:56:32, Epoch : 1, Step : 1506, Training Loss : 0.24505, Training Acc : 0.906, Run Time : 10.79
INFO:root:2019-05-10 23:56:33, Epoch : 1, Step : 1507, Training Loss : 0.20237, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-10 23:56:33, Epoch : 1, Step : 1508, Training Loss : 0.37286, Training Acc : 0.861, Run Time : 0.57
INFO:root:2019-05-10 23:56:34, Epoch : 1, Step : 1509, Training Loss : 0.23794, Training Acc : 0.911, Run Time : 0.78
INFO:root:2019-05-10 23:56:41, Epoch : 1, Step : 1510, Training Loss : 0.18250, Training Acc : 0.906, Run Time : 6.42
INFO:root:2019-05-10 23:56:41, Epoch : 1, Step : 1511, Training Loss : 0.22537, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-10 23:56:41, Epoch : 1, Step : 1512, Training Loss : 0.22745, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-10 23:56:42, Epoch : 1, Step : 1513, Training Loss : 0.21356, Training Acc : 0.922, Run Time : 0.73
INFO:root:2019-05-10 23:56:51, Epoch : 1, Step : 1514, Training Loss : 0.21536, Training Acc : 0.900, Run Time : 8.89
INFO:root:2019-05-10 23:56:51, Epoch : 1, Step : 1515, Training Loss : 0.17991, Training Acc : 0.933, Run Time : 0.48
INFO:root:2019-05-10 23:56:52, Epoch : 1, Step : 1516, Training Loss : 0.17000, Training Acc : 0.961, Run Time : 0.40
INFO:root:2019-05-10 23:56:52, Epoch : 1, Step : 1517, Training Loss : 0.19139, Training Acc : 0.911, Run Time : 0.57
INFO:root:2019-05-10 23:56:54, Epoch : 1, Step : 1518, Training Loss : 0.19189, Training Acc : 0.922, Run Time : 1.94
INFO:root:2019-05-10 23:57:03, Epoch : 1, Step : 1519, Training Loss : 0.23765, Training Acc : 0.928, Run Time : 8.90
INFO:root:2019-05-10 23:57:04, Epoch : 1, Step : 1520, Training Loss : 0.20483, Training Acc : 0.900, Run Time : 0.59
INFO:root:2019-05-10 23:57:04, Epoch : 1, Step : 1521, Training Loss : 0.24051, Training Acc : 0.894, Run Time : 0.39
INFO:root:2019-05-10 23:57:11, Epoch : 1, Step : 1522, Training Loss : 0.19305, Training Acc : 0.922, Run Time : 6.57
INFO:root:2019-05-10 23:57:11, Epoch : 1, Step : 1523, Training Loss : 0.25486, Training Acc : 0.872, Run Time : 0.40
INFO:root:2019-05-10 23:57:12, Epoch : 1, Step : 1524, Training Loss : 0.24094, Training Acc : 0.900, Run Time : 0.48
INFO:root:2019-05-10 23:57:12, Epoch : 1, Step : 1525, Training Loss : 0.32324, Training Acc : 0.856, Run Time : 0.63
INFO:root:2019-05-10 23:57:13, Epoch : 1, Step : 1526, Training Loss : 0.24331, Training Acc : 0.883, Run Time : 0.83
INFO:root:2019-05-10 23:57:20, Epoch : 1, Step : 1527, Training Loss : 0.28758, Training Acc : 0.867, Run Time : 7.05
INFO:root:2019-05-10 23:57:21, Epoch : 1, Step : 1528, Training Loss : 0.24001, Training Acc : 0.911, Run Time : 1.27
INFO:root:2019-05-10 23:57:22, Epoch : 1, Step : 1529, Training Loss : 0.18481, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-10 23:57:28, Epoch : 1, Step : 1530, Training Loss : 0.15101, Training Acc : 0.956, Run Time : 5.58
INFO:root:2019-05-10 23:57:28, Epoch : 1, Step : 1531, Training Loss : 0.17368, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-10 23:57:29, Epoch : 1, Step : 1532, Training Loss : 0.13887, Training Acc : 0.956, Run Time : 0.85
INFO:root:2019-05-10 23:57:29, Epoch : 1, Step : 1533, Training Loss : 0.21336, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-10 23:57:30, Epoch : 1, Step : 1534, Training Loss : 0.17945, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-10 23:57:37, Epoch : 1, Step : 1535, Training Loss : 0.19277, Training Acc : 0.917, Run Time : 7.69
INFO:root:2019-05-10 23:57:39, Epoch : 1, Step : 1536, Training Loss : 0.17350, Training Acc : 0.928, Run Time : 1.45
INFO:root:2019-05-10 23:57:39, Epoch : 1, Step : 1537, Training Loss : 0.17171, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-10 23:57:40, Epoch : 1, Step : 1538, Training Loss : 0.31101, Training Acc : 0.867, Run Time : 0.37
INFO:root:2019-05-10 23:57:40, Epoch : 1, Step : 1539, Training Loss : 0.27920, Training Acc : 0.861, Run Time : 0.55
INFO:root:2019-05-10 23:57:44, Epoch : 1, Step : 1540, Training Loss : 0.31401, Training Acc : 0.856, Run Time : 3.38
INFO:root:2019-05-10 23:57:44, Epoch : 1, Step : 1541, Training Loss : 0.26174, Training Acc : 0.878, Run Time : 0.78
INFO:root:2019-05-10 23:57:52, Epoch : 1, Step : 1542, Training Loss : 0.19522, Training Acc : 0.917, Run Time : 8.04
INFO:root:2019-05-10 23:57:53, Epoch : 1, Step : 1543, Training Loss : 0.22954, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-10 23:57:53, Epoch : 1, Step : 1544, Training Loss : 0.29287, Training Acc : 0.867, Run Time : 0.52
INFO:root:2019-05-10 23:57:54, Epoch : 1, Step : 1545, Training Loss : 0.26248, Training Acc : 0.911, Run Time : 0.84
INFO:root:2019-05-10 23:57:55, Epoch : 1, Step : 1546, Training Loss : 0.26197, Training Acc : 0.889, Run Time : 1.22
INFO:root:2019-05-10 23:57:56, Epoch : 1, Step : 1547, Training Loss : 0.23549, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-10 23:57:56, Epoch : 1, Step : 1548, Training Loss : 0.20821, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-10 23:57:57, Epoch : 1, Step : 1549, Training Loss : 0.29201, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-10 23:57:57, Epoch : 1, Step : 1550, Training Loss : 0.25134, Training Acc : 0.883, Run Time : 0.37
INFO:root:2019-05-10 23:57:57, Epoch : 1, Step : 1551, Training Loss : 0.31414, Training Acc : 0.861, Run Time : 0.43
INFO:root:2019-05-10 23:58:06, Epoch : 1, Step : 1552, Training Loss : 0.23379, Training Acc : 0.911, Run Time : 9.09
INFO:root:2019-05-10 23:58:07, Epoch : 1, Step : 1553, Training Loss : 0.27877, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-10 23:58:07, Epoch : 1, Step : 1554, Training Loss : 0.25437, Training Acc : 0.894, Run Time : 0.37
INFO:root:2019-05-10 23:58:09, Epoch : 1, Step : 1555, Training Loss : 0.39309, Training Acc : 0.828, Run Time : 1.71
INFO:root:2019-05-10 23:58:24, Epoch : 1, Step : 1556, Training Loss : 0.17743, Training Acc : 0.928, Run Time : 14.79
INFO:root:2019-05-10 23:58:24, Epoch : 1, Step : 1557, Training Loss : 0.19313, Training Acc : 0.911, Run Time : 0.68
INFO:root:2019-05-10 23:58:25, Epoch : 1, Step : 1558, Training Loss : 0.21524, Training Acc : 0.911, Run Time : 0.39
INFO:root:2019-05-10 23:58:26, Epoch : 1, Step : 1559, Training Loss : 0.21994, Training Acc : 0.906, Run Time : 1.38
INFO:root:2019-05-10 23:58:39, Epoch : 1, Step : 1560, Training Loss : 0.19786, Training Acc : 0.917, Run Time : 13.24
INFO:root:2019-05-10 23:58:40, Epoch : 1, Step : 1561, Training Loss : 0.15619, Training Acc : 0.933, Run Time : 0.73
INFO:root:2019-05-10 23:58:50, Epoch : 1, Step : 1562, Training Loss : 0.16859, Training Acc : 0.928, Run Time : 9.97
INFO:root:2019-05-10 23:58:51, Epoch : 1, Step : 1563, Training Loss : 0.19541, Training Acc : 0.922, Run Time : 1.20
INFO:root:2019-05-10 23:58:52, Epoch : 1, Step : 1564, Training Loss : 0.16312, Training Acc : 0.939, Run Time : 0.37
INFO:root:2019-05-10 23:58:52, Epoch : 1, Step : 1565, Training Loss : 0.17772, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-10 23:59:00, Epoch : 1, Step : 1566, Training Loss : 0.20904, Training Acc : 0.906, Run Time : 7.56
INFO:root:2019-05-10 23:59:01, Epoch : 1, Step : 1567, Training Loss : 0.20232, Training Acc : 0.894, Run Time : 0.84
INFO:root:2019-05-10 23:59:02, Epoch : 1, Step : 1568, Training Loss : 0.23607, Training Acc : 0.889, Run Time : 1.13
INFO:root:2019-05-10 23:59:09, Epoch : 1, Step : 1569, Training Loss : 0.38474, Training Acc : 0.833, Run Time : 7.13
INFO:root:2019-05-10 23:59:09, Epoch : 1, Step : 1570, Training Loss : 0.19901, Training Acc : 0.906, Run Time : 0.53
INFO:root:2019-05-10 23:59:10, Epoch : 1, Step : 1571, Training Loss : 0.27219, Training Acc : 0.872, Run Time : 0.40
INFO:root:2019-05-10 23:59:20, Epoch : 1, Step : 1572, Training Loss : 0.27934, Training Acc : 0.856, Run Time : 10.66
INFO:root:2019-05-10 23:59:21, Epoch : 1, Step : 1573, Training Loss : 0.20080, Training Acc : 0.906, Run Time : 0.40
INFO:root:2019-05-10 23:59:21, Epoch : 1, Step : 1574, Training Loss : 0.21998, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-10 23:59:22, Epoch : 1, Step : 1575, Training Loss : 0.19328, Training Acc : 0.889, Run Time : 0.42
INFO:root:2019-05-10 23:59:23, Epoch : 1, Step : 1576, Training Loss : 0.20047, Training Acc : 0.911, Run Time : 1.07
INFO:root:2019-05-10 23:59:30, Epoch : 1, Step : 1577, Training Loss : 0.24675, Training Acc : 0.883, Run Time : 7.73
INFO:root:2019-05-10 23:59:31, Epoch : 1, Step : 1578, Training Loss : 0.23310, Training Acc : 0.900, Run Time : 0.97
INFO:root:2019-05-10 23:59:32, Epoch : 1, Step : 1579, Training Loss : 0.30123, Training Acc : 0.889, Run Time : 0.44
INFO:root:2019-05-10 23:59:32, Epoch : 1, Step : 1580, Training Loss : 0.31264, Training Acc : 0.867, Run Time : 0.40
INFO:root:2019-05-10 23:59:38, Epoch : 1, Step : 1581, Training Loss : 0.22357, Training Acc : 0.917, Run Time : 6.00
INFO:root:2019-05-10 23:59:43, Epoch : 1, Step : 1582, Training Loss : 0.27156, Training Acc : 0.883, Run Time : 4.60
INFO:root:2019-05-10 23:59:44, Epoch : 1, Step : 1583, Training Loss : 0.20884, Training Acc : 0.933, Run Time : 0.85
INFO:root:2019-05-10 23:59:45, Epoch : 1, Step : 1584, Training Loss : 0.19452, Training Acc : 0.928, Run Time : 1.68
INFO:root:2019-05-10 23:59:53, Epoch : 1, Step : 1585, Training Loss : 0.25771, Training Acc : 0.922, Run Time : 7.75
INFO:root:2019-05-10 23:59:54, Epoch : 1, Step : 1586, Training Loss : 0.20546, Training Acc : 0.928, Run Time : 0.67
INFO:root:2019-05-10 23:59:54, Epoch : 1, Step : 1587, Training Loss : 0.24426, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-10 23:59:56, Epoch : 1, Step : 1588, Training Loss : 0.31154, Training Acc : 0.900, Run Time : 1.65
INFO:root:2019-05-11 00:00:08, Epoch : 1, Step : 1589, Training Loss : 0.28367, Training Acc : 0.917, Run Time : 11.86
INFO:root:2019-05-11 00:00:08, Epoch : 1, Step : 1590, Training Loss : 0.24709, Training Acc : 0.911, Run Time : 0.40
INFO:root:2019-05-11 00:00:08, Epoch : 1, Step : 1591, Training Loss : 0.23837, Training Acc : 0.911, Run Time : 0.44
INFO:root:2019-05-11 00:00:09, Epoch : 1, Step : 1592, Training Loss : 0.25389, Training Acc : 0.917, Run Time : 0.40
INFO:root:2019-05-11 00:00:09, Epoch : 1, Step : 1593, Training Loss : 0.16801, Training Acc : 0.917, Run Time : 0.39
INFO:root:2019-05-11 00:00:10, Epoch : 1, Step : 1594, Training Loss : 0.20057, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 00:00:10, Epoch : 1, Step : 1595, Training Loss : 0.19334, Training Acc : 0.933, Run Time : 0.83
INFO:root:2019-05-11 00:00:14, Epoch : 1, Step : 1596, Training Loss : 0.21383, Training Acc : 0.928, Run Time : 3.46
INFO:root:2019-05-11 00:00:14, Epoch : 1, Step : 1597, Training Loss : 0.28798, Training Acc : 0.894, Run Time : 0.46
INFO:root:2019-05-11 00:00:15, Epoch : 1, Step : 1598, Training Loss : 0.27548, Training Acc : 0.889, Run Time : 0.37
INFO:root:2019-05-11 00:00:15, Epoch : 1, Step : 1599, Training Loss : 0.36597, Training Acc : 0.856, Run Time : 0.66
INFO:root:2019-05-11 00:00:21, Epoch : 1, Step : 1600, Training Loss : 0.25678, Training Acc : 0.900, Run Time : 5.66
INFO:root:2019-05-11 00:00:33, Epoch : 1, Step : 1601, Training Loss : 1.02269, Training Acc : 0.633, Run Time : 11.95
INFO:root:2019-05-11 00:00:34, Epoch : 1, Step : 1602, Training Loss : 1.17703, Training Acc : 0.594, Run Time : 0.47
INFO:root:2019-05-11 00:00:34, Epoch : 1, Step : 1603, Training Loss : 0.98511, Training Acc : 0.617, Run Time : 0.39
INFO:root:2019-05-11 00:00:35, Epoch : 1, Step : 1604, Training Loss : 0.83038, Training Acc : 0.656, Run Time : 1.33
INFO:root:2019-05-11 00:00:42, Epoch : 1, Step : 1605, Training Loss : 0.68197, Training Acc : 0.656, Run Time : 7.15
INFO:root:2019-05-11 00:00:43, Epoch : 1, Step : 1606, Training Loss : 0.88240, Training Acc : 0.667, Run Time : 0.41
INFO:root:2019-05-11 00:00:43, Epoch : 1, Step : 1607, Training Loss : 0.45662, Training Acc : 0.772, Run Time : 0.38
INFO:root:2019-05-11 00:00:44, Epoch : 1, Step : 1608, Training Loss : 0.38034, Training Acc : 0.833, Run Time : 0.95
INFO:root:2019-05-11 00:00:52, Epoch : 1, Step : 1609, Training Loss : 0.50785, Training Acc : 0.689, Run Time : 7.82
INFO:root:2019-05-11 00:00:52, Epoch : 1, Step : 1610, Training Loss : 0.21429, Training Acc : 0.883, Run Time : 0.54
INFO:root:2019-05-11 00:00:53, Epoch : 1, Step : 1611, Training Loss : 0.21174, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 00:00:53, Epoch : 1, Step : 1612, Training Loss : 0.39175, Training Acc : 0.800, Run Time : 0.54
INFO:root:2019-05-11 00:00:59, Epoch : 1, Step : 1613, Training Loss : 0.63385, Training Acc : 0.711, Run Time : 5.70
INFO:root:2019-05-11 00:01:00, Epoch : 1, Step : 1614, Training Loss : 0.40161, Training Acc : 0.828, Run Time : 0.41
INFO:root:2019-05-11 00:01:00, Epoch : 1, Step : 1615, Training Loss : 0.59046, Training Acc : 0.717, Run Time : 0.37
INFO:root:2019-05-11 00:01:01, Epoch : 1, Step : 1616, Training Loss : 0.44467, Training Acc : 0.811, Run Time : 1.08
INFO:root:2019-05-11 00:01:06, Epoch : 1, Step : 1617, Training Loss : 0.33890, Training Acc : 0.833, Run Time : 4.88
INFO:root:2019-05-11 00:01:06, Epoch : 1, Step : 1618, Training Loss : 0.24167, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-11 00:01:07, Epoch : 1, Step : 1619, Training Loss : 0.53886, Training Acc : 0.722, Run Time : 0.38
INFO:root:2019-05-11 00:01:07, Epoch : 1, Step : 1620, Training Loss : 0.39357, Training Acc : 0.828, Run Time : 0.74
INFO:root:2019-05-11 00:01:08, Epoch : 1, Step : 1621, Training Loss : 0.65010, Training Acc : 0.722, Run Time : 0.77
INFO:root:2019-05-11 00:01:16, Epoch : 1, Step : 1622, Training Loss : 0.33130, Training Acc : 0.911, Run Time : 7.83
INFO:root:2019-05-11 00:01:16, Epoch : 1, Step : 1623, Training Loss : 0.18046, Training Acc : 0.922, Run Time : 0.52
INFO:root:2019-05-11 00:01:17, Epoch : 1, Step : 1624, Training Loss : 0.26039, Training Acc : 0.872, Run Time : 0.37
INFO:root:2019-05-11 00:01:17, Epoch : 1, Step : 1625, Training Loss : 0.44249, Training Acc : 0.811, Run Time : 0.39
INFO:root:2019-05-11 00:01:21, Epoch : 1, Step : 1626, Training Loss : 0.08671, Training Acc : 0.983, Run Time : 3.72
INFO:root:2019-05-11 00:01:22, Epoch : 1, Step : 1627, Training Loss : 0.35444, Training Acc : 0.867, Run Time : 0.68
INFO:root:2019-05-11 00:01:22, Epoch : 1, Step : 1628, Training Loss : 0.56521, Training Acc : 0.789, Run Time : 0.53
INFO:root:2019-05-11 00:01:23, Epoch : 1, Step : 1629, Training Loss : 0.35928, Training Acc : 0.833, Run Time : 0.84
INFO:root:2019-05-11 00:01:23, Epoch : 1, Step : 1630, Training Loss : 0.21523, Training Acc : 0.900, Run Time : 0.37
INFO:root:2019-05-11 00:01:24, Epoch : 1, Step : 1631, Training Loss : 0.76664, Training Acc : 0.683, Run Time : 0.85
INFO:root:2019-05-11 00:01:31, Epoch : 1, Step : 1632, Training Loss : 0.52217, Training Acc : 0.722, Run Time : 6.98
INFO:root:2019-05-11 00:01:32, Epoch : 1, Step : 1633, Training Loss : 0.29160, Training Acc : 0.844, Run Time : 0.95
INFO:root:2019-05-11 00:01:34, Epoch : 1, Step : 1634, Training Loss : 0.18866, Training Acc : 0.917, Run Time : 1.62
INFO:root:2019-05-11 00:01:44, Epoch : 1, Step : 1635, Training Loss : 0.29883, Training Acc : 0.867, Run Time : 10.21
INFO:root:2019-05-11 00:01:52, Epoch : 1, Step : 1636, Training Loss : 0.28469, Training Acc : 0.911, Run Time : 7.77
INFO:root:2019-05-11 00:01:53, Epoch : 1, Step : 1637, Training Loss : 0.27396, Training Acc : 0.883, Run Time : 0.99
INFO:root:2019-05-11 00:01:53, Epoch : 1, Step : 1638, Training Loss : 0.34618, Training Acc : 0.856, Run Time : 0.39
INFO:root:2019-05-11 00:01:54, Epoch : 1, Step : 1639, Training Loss : 0.11084, Training Acc : 0.983, Run Time : 0.39
INFO:root:2019-05-11 00:01:54, Epoch : 1, Step : 1640, Training Loss : 0.12362, Training Acc : 0.978, Run Time : 0.73
INFO:root:2019-05-11 00:02:02, Epoch : 1, Step : 1641, Training Loss : 0.14100, Training Acc : 0.939, Run Time : 8.10
INFO:root:2019-05-11 00:02:03, Epoch : 1, Step : 1642, Training Loss : 0.18570, Training Acc : 0.928, Run Time : 0.39
INFO:root:2019-05-11 00:02:03, Epoch : 1, Step : 1643, Training Loss : 0.09034, Training Acc : 0.989, Run Time : 0.37
INFO:root:2019-05-11 00:02:04, Epoch : 1, Step : 1644, Training Loss : 0.23242, Training Acc : 0.900, Run Time : 1.36
INFO:root:2019-05-11 00:02:13, Epoch : 1, Step : 1645, Training Loss : 0.28446, Training Acc : 0.883, Run Time : 8.08
INFO:root:2019-05-11 00:02:13, Epoch : 1, Step : 1646, Training Loss : 0.20355, Training Acc : 0.917, Run Time : 0.61
INFO:root:2019-05-11 00:02:14, Epoch : 1, Step : 1647, Training Loss : 0.24353, Training Acc : 0.922, Run Time : 0.52
INFO:root:2019-05-11 00:02:15, Epoch : 1, Step : 1648, Training Loss : 0.13560, Training Acc : 0.989, Run Time : 0.97
INFO:root:2019-05-11 00:02:20, Epoch : 1, Step : 1649, Training Loss : 0.16009, Training Acc : 0.950, Run Time : 5.49
INFO:root:2019-05-11 00:02:21, Epoch : 1, Step : 1650, Training Loss : 0.14869, Training Acc : 0.939, Run Time : 0.47
INFO:root:2019-05-11 00:02:21, Epoch : 1, Step : 1651, Training Loss : 0.12884, Training Acc : 0.983, Run Time : 0.53
INFO:root:2019-05-11 00:02:22, Epoch : 1, Step : 1652, Training Loss : 0.27833, Training Acc : 0.867, Run Time : 0.52
INFO:root:2019-05-11 00:02:23, Epoch : 1, Step : 1653, Training Loss : 0.23931, Training Acc : 0.889, Run Time : 1.02
INFO:root:2019-05-11 00:02:28, Epoch : 1, Step : 1654, Training Loss : 0.17369, Training Acc : 0.950, Run Time : 5.50
INFO:root:2019-05-11 00:02:29, Epoch : 1, Step : 1655, Training Loss : 0.14014, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-11 00:02:29, Epoch : 1, Step : 1656, Training Loss : 0.14461, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 00:02:30, Epoch : 1, Step : 1657, Training Loss : 0.19825, Training Acc : 0.911, Run Time : 0.88
INFO:root:2019-05-11 00:02:41, Epoch : 1, Step : 1658, Training Loss : 0.19094, Training Acc : 0.933, Run Time : 11.14
INFO:root:2019-05-11 00:02:42, Epoch : 1, Step : 1659, Training Loss : 0.24650, Training Acc : 0.872, Run Time : 0.45
INFO:root:2019-05-11 00:02:42, Epoch : 1, Step : 1660, Training Loss : 0.42969, Training Acc : 0.772, Run Time : 0.37
INFO:root:2019-05-11 00:02:42, Epoch : 1, Step : 1661, Training Loss : 0.16661, Training Acc : 0.911, Run Time : 0.51
INFO:root:2019-05-11 00:02:44, Epoch : 1, Step : 1662, Training Loss : 0.12977, Training Acc : 0.928, Run Time : 1.14
INFO:root:2019-05-11 00:02:51, Epoch : 1, Step : 1663, Training Loss : 0.06722, Training Acc : 0.989, Run Time : 7.47
INFO:root:2019-05-11 00:02:51, Epoch : 1, Step : 1664, Training Loss : 0.39407, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-11 00:02:52, Epoch : 1, Step : 1665, Training Loss : 0.74535, Training Acc : 0.661, Run Time : 0.37
INFO:root:2019-05-11 00:02:56, Epoch : 1, Step : 1666, Training Loss : 0.26577, Training Acc : 0.889, Run Time : 3.73
INFO:root:2019-05-11 00:02:59, Epoch : 1, Step : 1667, Training Loss : 0.22137, Training Acc : 0.900, Run Time : 3.28
INFO:root:2019-05-11 00:03:02, Epoch : 1, Step : 1668, Training Loss : 0.28990, Training Acc : 0.856, Run Time : 3.40
INFO:root:2019-05-11 00:03:03, Epoch : 1, Step : 1669, Training Loss : 0.26552, Training Acc : 0.906, Run Time : 0.58
INFO:root:2019-05-11 00:03:03, Epoch : 1, Step : 1670, Training Loss : 0.15541, Training Acc : 0.956, Run Time : 0.38
INFO:root:2019-05-11 00:03:04, Epoch : 1, Step : 1671, Training Loss : 0.14805, Training Acc : 0.961, Run Time : 1.26
INFO:root:2019-05-11 00:03:17, Epoch : 1, Step : 1672, Training Loss : 0.20767, Training Acc : 0.900, Run Time : 13.02
INFO:root:2019-05-11 00:03:19, Epoch : 1, Step : 1673, Training Loss : 0.46077, Training Acc : 0.883, Run Time : 1.12
INFO:root:2019-05-11 00:03:19, Epoch : 1, Step : 1674, Training Loss : 0.21714, Training Acc : 0.867, Run Time : 0.38
INFO:root:2019-05-11 00:03:20, Epoch : 1, Step : 1675, Training Loss : 0.19255, Training Acc : 0.906, Run Time : 1.00
INFO:root:2019-05-11 00:03:29, Epoch : 1, Step : 1676, Training Loss : 0.16501, Training Acc : 0.961, Run Time : 8.86
INFO:root:2019-05-11 00:03:29, Epoch : 1, Step : 1677, Training Loss : 0.12031, Training Acc : 0.928, Run Time : 0.42
INFO:root:2019-05-11 00:03:30, Epoch : 1, Step : 1678, Training Loss : 0.22044, Training Acc : 0.922, Run Time : 0.40
INFO:root:2019-05-11 00:03:30, Epoch : 1, Step : 1679, Training Loss : 0.04406, Training Acc : 1.000, Run Time : 0.50
INFO:root:2019-05-11 00:03:37, Epoch : 1, Step : 1680, Training Loss : 0.18991, Training Acc : 0.944, Run Time : 6.85
INFO:root:2019-05-11 00:03:38, Epoch : 1, Step : 1681, Training Loss : 0.30620, Training Acc : 0.878, Run Time : 0.72
INFO:root:2019-05-11 00:03:38, Epoch : 1, Step : 1682, Training Loss : 0.10204, Training Acc : 0.967, Run Time : 0.40
INFO:root:2019-05-11 00:03:39, Epoch : 1, Step : 1683, Training Loss : 0.07386, Training Acc : 0.983, Run Time : 0.45
INFO:root:2019-05-11 00:03:39, Epoch : 1, Step : 1684, Training Loss : 0.11815, Training Acc : 0.967, Run Time : 0.73
INFO:root:2019-05-11 00:03:47, Epoch : 1, Step : 1685, Training Loss : 0.11915, Training Acc : 0.950, Run Time : 8.17
INFO:root:2019-05-11 00:03:48, Epoch : 1, Step : 1686, Training Loss : 0.10188, Training Acc : 0.950, Run Time : 0.95
INFO:root:2019-05-11 00:03:49, Epoch : 1, Step : 1687, Training Loss : 0.18341, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-11 00:03:56, Epoch : 1, Step : 1688, Training Loss : 0.11352, Training Acc : 0.978, Run Time : 6.97
INFO:root:2019-05-11 00:03:58, Epoch : 1, Step : 1689, Training Loss : 0.17843, Training Acc : 0.939, Run Time : 2.28
INFO:root:2019-05-11 00:03:59, Epoch : 1, Step : 1690, Training Loss : 0.13646, Training Acc : 0.939, Run Time : 0.63
INFO:root:2019-05-11 00:04:14, Epoch : 1, Step : 1691, Training Loss : 0.26053, Training Acc : 0.878, Run Time : 15.28
INFO:root:2019-05-11 00:04:16, Epoch : 1, Step : 1692, Training Loss : 0.13611, Training Acc : 0.956, Run Time : 2.32
INFO:root:2019-05-11 00:04:17, Epoch : 1, Step : 1693, Training Loss : 0.15715, Training Acc : 0.950, Run Time : 0.37
INFO:root:2019-05-11 00:04:17, Epoch : 1, Step : 1694, Training Loss : 0.10831, Training Acc : 0.967, Run Time : 0.49
INFO:root:2019-05-11 00:04:18, Epoch : 1, Step : 1695, Training Loss : 0.18463, Training Acc : 0.928, Run Time : 0.84
INFO:root:2019-05-11 00:04:19, Epoch : 1, Step : 1696, Training Loss : 0.09900, Training Acc : 0.978, Run Time : 0.67
INFO:root:2019-05-11 00:04:20, Epoch : 1, Step : 1697, Training Loss : 0.58276, Training Acc : 0.789, Run Time : 1.22
INFO:root:2019-05-11 00:04:20, Epoch : 1, Step : 1698, Training Loss : 0.35479, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-11 00:04:26, Epoch : 1, Step : 1699, Training Loss : 0.21155, Training Acc : 0.906, Run Time : 6.17
INFO:root:2019-05-11 00:04:27, Epoch : 1, Step : 1700, Training Loss : 0.14407, Training Acc : 0.978, Run Time : 0.57
INFO:root:2019-05-11 00:04:28, Epoch : 1, Step : 1701, Training Loss : 0.27331, Training Acc : 0.878, Run Time : 0.91
INFO:root:2019-05-11 00:04:35, Epoch : 1, Step : 1702, Training Loss : 0.35532, Training Acc : 0.850, Run Time : 7.01
INFO:root:2019-05-11 00:04:36, Epoch : 1, Step : 1703, Training Loss : 0.31378, Training Acc : 0.900, Run Time : 0.70
INFO:root:2019-05-11 00:04:36, Epoch : 1, Step : 1704, Training Loss : 0.30788, Training Acc : 0.867, Run Time : 0.40
INFO:root:2019-05-11 00:04:36, Epoch : 1, Step : 1705, Training Loss : 0.32345, Training Acc : 0.867, Run Time : 0.38
INFO:root:2019-05-11 00:04:37, Epoch : 1, Step : 1706, Training Loss : 0.08110, Training Acc : 0.978, Run Time : 0.65
INFO:root:2019-05-11 00:04:37, Epoch : 1, Step : 1707, Training Loss : 0.16592, Training Acc : 0.928, Run Time : 0.39
INFO:root:2019-05-11 00:04:38, Epoch : 1, Step : 1708, Training Loss : 0.26429, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 00:04:42, Epoch : 1, Step : 1709, Training Loss : 0.26335, Training Acc : 0.878, Run Time : 4.42
INFO:root:2019-05-11 00:04:43, Epoch : 1, Step : 1710, Training Loss : 0.30333, Training Acc : 0.872, Run Time : 0.70
INFO:root:2019-05-11 00:04:43, Epoch : 1, Step : 1711, Training Loss : 0.37334, Training Acc : 0.828, Run Time : 0.54
INFO:root:2019-05-11 00:04:44, Epoch : 1, Step : 1712, Training Loss : 0.43177, Training Acc : 0.800, Run Time : 0.38
INFO:root:2019-05-11 00:04:44, Epoch : 1, Step : 1713, Training Loss : 0.55165, Training Acc : 0.739, Run Time : 0.40
INFO:root:2019-05-11 00:04:45, Epoch : 1, Step : 1714, Training Loss : 0.60861, Training Acc : 0.783, Run Time : 0.38
INFO:root:2019-05-11 00:04:45, Epoch : 1, Step : 1715, Training Loss : 0.20789, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-11 00:04:45, Epoch : 1, Step : 1716, Training Loss : 0.22838, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-11 00:04:46, Epoch : 1, Step : 1717, Training Loss : 0.17100, Training Acc : 0.939, Run Time : 0.41
INFO:root:2019-05-11 00:04:46, Epoch : 1, Step : 1718, Training Loss : 0.08118, Training Acc : 0.983, Run Time : 0.44
INFO:root:2019-05-11 00:04:47, Epoch : 1, Step : 1719, Training Loss : 0.14632, Training Acc : 0.950, Run Time : 0.41
INFO:root:2019-05-11 00:04:56, Epoch : 1, Step : 1720, Training Loss : 0.14965, Training Acc : 0.917, Run Time : 8.93
INFO:root:2019-05-11 00:04:56, Epoch : 1, Step : 1721, Training Loss : 0.12193, Training Acc : 0.961, Run Time : 0.79
INFO:root:2019-05-11 00:04:57, Epoch : 1, Step : 1722, Training Loss : 0.17172, Training Acc : 0.944, Run Time : 0.37
INFO:root:2019-05-11 00:04:58, Epoch : 1, Step : 1723, Training Loss : 0.09068, Training Acc : 0.989, Run Time : 1.08
INFO:root:2019-05-11 00:05:06, Epoch : 1, Step : 1724, Training Loss : 0.14910, Training Acc : 0.933, Run Time : 7.77
INFO:root:2019-05-11 00:05:06, Epoch : 1, Step : 1725, Training Loss : 0.18105, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-11 00:05:06, Epoch : 1, Step : 1726, Training Loss : 0.15433, Training Acc : 0.950, Run Time : 0.42
INFO:root:2019-05-11 00:05:07, Epoch : 1, Step : 1727, Training Loss : 0.14154, Training Acc : 0.956, Run Time : 0.80
INFO:root:2019-05-11 00:05:08, Epoch : 1, Step : 1728, Training Loss : 0.12998, Training Acc : 0.961, Run Time : 1.08
INFO:root:2019-05-11 00:05:09, Epoch : 1, Step : 1729, Training Loss : 0.11564, Training Acc : 0.967, Run Time : 0.37
INFO:root:2019-05-11 00:05:11, Epoch : 1, Step : 1730, Training Loss : 0.12524, Training Acc : 0.956, Run Time : 1.85
INFO:root:2019-05-11 00:05:18, Epoch : 1, Step : 1731, Training Loss : 0.10847, Training Acc : 0.956, Run Time : 6.94
INFO:root:2019-05-11 00:05:18, Epoch : 1, Step : 1732, Training Loss : 0.19979, Training Acc : 0.906, Run Time : 0.40
INFO:root:2019-05-11 00:05:18, Epoch : 1, Step : 1733, Training Loss : 0.14651, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 00:05:19, Epoch : 1, Step : 1734, Training Loss : 0.16660, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 00:05:27, Epoch : 1, Step : 1735, Training Loss : 0.32629, Training Acc : 0.889, Run Time : 8.10
INFO:root:2019-05-11 00:05:28, Epoch : 1, Step : 1736, Training Loss : 0.32240, Training Acc : 0.856, Run Time : 0.76
INFO:root:2019-05-11 00:05:28, Epoch : 1, Step : 1737, Training Loss : 0.20819, Training Acc : 0.917, Run Time : 0.52
INFO:root:2019-05-11 00:05:29, Epoch : 1, Step : 1738, Training Loss : 0.30735, Training Acc : 0.850, Run Time : 0.89
INFO:root:2019-05-11 00:05:29, Epoch : 1, Step : 1739, Training Loss : 0.23779, Training Acc : 0.894, Run Time : 0.42
INFO:root:2019-05-11 00:05:34, Epoch : 1, Step : 1740, Training Loss : 0.15271, Training Acc : 0.933, Run Time : 4.73
INFO:root:2019-05-11 00:05:35, Epoch : 1, Step : 1741, Training Loss : 0.13340, Training Acc : 0.961, Run Time : 0.72
INFO:root:2019-05-11 00:05:35, Epoch : 1, Step : 1742, Training Loss : 0.05180, Training Acc : 1.000, Run Time : 0.37
INFO:root:2019-05-11 00:05:45, Epoch : 1, Step : 1743, Training Loss : 0.15004, Training Acc : 0.933, Run Time : 9.88
INFO:root:2019-05-11 00:05:46, Epoch : 1, Step : 1744, Training Loss : 0.23044, Training Acc : 0.900, Run Time : 0.43
INFO:root:2019-05-11 00:05:46, Epoch : 1, Step : 1745, Training Loss : 0.16944, Training Acc : 0.900, Run Time : 0.37
INFO:root:2019-05-11 00:05:47, Epoch : 1, Step : 1746, Training Loss : 0.11085, Training Acc : 0.950, Run Time : 1.15
INFO:root:2019-05-11 00:05:54, Epoch : 1, Step : 1747, Training Loss : 0.15074, Training Acc : 0.933, Run Time : 6.68
INFO:root:2019-05-11 00:05:54, Epoch : 1, Step : 1748, Training Loss : 0.50453, Training Acc : 0.783, Run Time : 0.60
INFO:root:2019-05-11 00:05:55, Epoch : 1, Step : 1749, Training Loss : 0.12106, Training Acc : 0.928, Run Time : 0.39
INFO:root:2019-05-11 00:06:00, Epoch : 1, Step : 1750, Training Loss : 1.11133, Training Acc : 0.639, Run Time : 5.63
INFO:root:2019-05-11 00:06:01, Epoch : 1, Step : 1751, Training Loss : 0.43004, Training Acc : 0.833, Run Time : 0.40
INFO:root:2019-05-11 00:06:01, Epoch : 1, Step : 1752, Training Loss : 0.10960, Training Acc : 0.983, Run Time : 0.37
INFO:root:2019-05-11 00:06:01, Epoch : 1, Step : 1753, Training Loss : 0.24686, Training Acc : 0.894, Run Time : 0.37
INFO:root:2019-05-11 00:06:10, Epoch : 1, Step : 1754, Training Loss : 0.18736, Training Acc : 0.928, Run Time : 8.42
INFO:root:2019-05-11 00:06:12, Epoch : 1, Step : 1755, Training Loss : 0.25746, Training Acc : 0.933, Run Time : 2.03
INFO:root:2019-05-11 00:06:22, Epoch : 1, Step : 1756, Training Loss : 0.11409, Training Acc : 0.994, Run Time : 10.35
INFO:root:2019-05-11 00:06:23, Epoch : 1, Step : 1757, Training Loss : 0.12665, Training Acc : 0.978, Run Time : 0.43
INFO:root:2019-05-11 00:06:23, Epoch : 1, Step : 1758, Training Loss : 0.08531, Training Acc : 0.994, Run Time : 0.37
INFO:root:2019-05-11 00:06:24, Epoch : 1, Step : 1759, Training Loss : 0.17006, Training Acc : 0.933, Run Time : 0.94
INFO:root:2019-05-11 00:06:31, Epoch : 1, Step : 1760, Training Loss : 0.19373, Training Acc : 0.928, Run Time : 7.41
INFO:root:2019-05-11 00:06:33, Epoch : 1, Step : 1761, Training Loss : 0.09762, Training Acc : 0.967, Run Time : 1.15
INFO:root:2019-05-11 00:06:33, Epoch : 1, Step : 1762, Training Loss : 0.11543, Training Acc : 0.994, Run Time : 0.52
INFO:root:2019-05-11 00:06:42, Epoch : 1, Step : 1763, Training Loss : 0.12854, Training Acc : 0.972, Run Time : 8.65
INFO:root:2019-05-11 00:06:42, Epoch : 1, Step : 1764, Training Loss : 0.16521, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-11 00:06:43, Epoch : 1, Step : 1765, Training Loss : 0.18755, Training Acc : 0.928, Run Time : 0.63
INFO:root:2019-05-11 00:06:43, Epoch : 1, Step : 1766, Training Loss : 0.15385, Training Acc : 0.956, Run Time : 0.38
INFO:root:2019-05-11 00:06:53, Epoch : 1, Step : 1767, Training Loss : 0.11322, Training Acc : 0.978, Run Time : 9.96
INFO:root:2019-05-11 00:06:54, Epoch : 1, Step : 1768, Training Loss : 0.12211, Training Acc : 0.989, Run Time : 0.74
INFO:root:2019-05-11 00:06:54, Epoch : 1, Step : 1769, Training Loss : 0.09056, Training Acc : 0.989, Run Time : 0.42
INFO:root:2019-05-11 00:06:55, Epoch : 1, Step : 1770, Training Loss : 0.24981, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-11 00:06:55, Epoch : 1, Step : 1771, Training Loss : 0.11895, Training Acc : 0.972, Run Time : 0.37
INFO:root:2019-05-11 00:06:56, Epoch : 1, Step : 1772, Training Loss : 0.12067, Training Acc : 0.961, Run Time : 0.57
INFO:root:2019-05-11 00:06:59, Epoch : 1, Step : 1773, Training Loss : 0.17524, Training Acc : 0.956, Run Time : 3.32
INFO:root:2019-05-11 00:07:00, Epoch : 1, Step : 1774, Training Loss : 0.11246, Training Acc : 0.961, Run Time : 0.67
INFO:root:2019-05-11 00:07:01, Epoch : 1, Step : 1775, Training Loss : 0.06500, Training Acc : 0.983, Run Time : 1.05
INFO:root:2019-05-11 00:07:07, Epoch : 1, Step : 1776, Training Loss : 0.37311, Training Acc : 0.833, Run Time : 6.38
INFO:root:2019-05-11 00:07:08, Epoch : 1, Step : 1777, Training Loss : 0.16416, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-11 00:07:08, Epoch : 1, Step : 1778, Training Loss : 0.12102, Training Acc : 0.939, Run Time : 0.39
INFO:root:2019-05-11 00:07:08, Epoch : 1, Step : 1779, Training Loss : 0.21023, Training Acc : 0.889, Run Time : 0.39
INFO:root:2019-05-11 00:07:14, Epoch : 1, Step : 1780, Training Loss : 0.17056, Training Acc : 0.933, Run Time : 5.30
INFO:root:2019-05-11 00:07:14, Epoch : 1, Step : 1781, Training Loss : 0.12728, Training Acc : 0.939, Run Time : 0.51
INFO:root:2019-05-11 00:07:15, Epoch : 1, Step : 1782, Training Loss : 0.09390, Training Acc : 0.972, Run Time : 0.44
INFO:root:2019-05-11 00:07:15, Epoch : 1, Step : 1783, Training Loss : 0.25286, Training Acc : 0.883, Run Time : 0.65
INFO:root:2019-05-11 00:07:16, Epoch : 1, Step : 1784, Training Loss : 0.06837, Training Acc : 0.994, Run Time : 0.48
INFO:root:2019-05-11 00:07:24, Epoch : 1, Step : 1785, Training Loss : 0.11620, Training Acc : 0.967, Run Time : 8.31
INFO:root:2019-05-11 00:07:25, Epoch : 1, Step : 1786, Training Loss : 0.17679, Training Acc : 0.928, Run Time : 0.51
INFO:root:2019-05-11 00:07:25, Epoch : 1, Step : 1787, Training Loss : 0.11767, Training Acc : 0.956, Run Time : 0.55
INFO:root:2019-05-11 00:07:33, Epoch : 1, Step : 1788, Training Loss : 0.23169, Training Acc : 0.889, Run Time : 7.69
INFO:root:2019-05-11 00:07:33, Epoch : 1, Step : 1789, Training Loss : 0.18125, Training Acc : 0.911, Run Time : 0.69
INFO:root:2019-05-11 00:07:34, Epoch : 1, Step : 1790, Training Loss : 0.06775, Training Acc : 0.989, Run Time : 0.40
INFO:root:2019-05-11 00:07:34, Epoch : 1, Step : 1791, Training Loss : 0.11976, Training Acc : 0.961, Run Time : 0.58
INFO:root:2019-05-11 00:07:42, Epoch : 1, Step : 1792, Training Loss : 0.08507, Training Acc : 0.989, Run Time : 7.98
INFO:root:2019-05-11 00:07:43, Epoch : 1, Step : 1793, Training Loss : 0.26691, Training Acc : 0.894, Run Time : 0.61
INFO:root:2019-05-11 00:07:43, Epoch : 1, Step : 1794, Training Loss : 0.06653, Training Acc : 1.000, Run Time : 0.37
INFO:root:2019-05-11 00:07:45, Epoch : 1, Step : 1795, Training Loss : 0.20670, Training Acc : 0.917, Run Time : 1.41
INFO:root:2019-05-11 00:07:51, Epoch : 1, Step : 1796, Training Loss : 0.15512, Training Acc : 0.944, Run Time : 6.60
INFO:root:2019-05-11 00:07:52, Epoch : 1, Step : 1797, Training Loss : 0.21407, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-11 00:07:52, Epoch : 1, Step : 1798, Training Loss : 0.18104, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-11 00:07:53, Epoch : 1, Step : 1799, Training Loss : 0.15380, Training Acc : 0.944, Run Time : 0.39
INFO:root:2019-05-11 00:07:54, Epoch : 1, Step : 1800, Training Loss : 0.43528, Training Acc : 0.861, Run Time : 1.14
INFO:root:2019-05-11 00:08:02, Epoch : 1, Step : 1801, Training Loss : 1.00013, Training Acc : 0.622, Run Time : 7.98
INFO:root:2019-05-11 00:08:02, Epoch : 1, Step : 1802, Training Loss : 0.87261, Training Acc : 0.700, Run Time : 0.44
INFO:root:2019-05-11 00:08:03, Epoch : 1, Step : 1803, Training Loss : 0.88468, Training Acc : 0.633, Run Time : 0.51
INFO:root:2019-05-11 00:08:11, Epoch : 1, Step : 1804, Training Loss : 0.88253, Training Acc : 0.661, Run Time : 8.18
INFO:root:2019-05-11 00:08:11, Epoch : 1, Step : 1805, Training Loss : 0.76141, Training Acc : 0.722, Run Time : 0.47
INFO:root:2019-05-11 00:08:12, Epoch : 1, Step : 1806, Training Loss : 0.55619, Training Acc : 0.767, Run Time : 0.43
INFO:root:2019-05-11 00:08:12, Epoch : 1, Step : 1807, Training Loss : 0.42282, Training Acc : 0.828, Run Time : 0.62
INFO:root:2019-05-11 00:08:18, Epoch : 1, Step : 1808, Training Loss : 0.27115, Training Acc : 0.839, Run Time : 5.85
INFO:root:2019-05-11 00:08:19, Epoch : 1, Step : 1809, Training Loss : 0.33380, Training Acc : 0.856, Run Time : 0.40
INFO:root:2019-05-11 00:08:19, Epoch : 1, Step : 1810, Training Loss : 0.16865, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-11 00:08:19, Epoch : 1, Step : 1811, Training Loss : 0.14994, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 00:08:21, Epoch : 1, Step : 1812, Training Loss : 0.19248, Training Acc : 0.933, Run Time : 1.21
INFO:root:2019-05-11 00:08:30, Epoch : 1, Step : 1813, Training Loss : 0.19663, Training Acc : 0.939, Run Time : 9.83
INFO:root:2019-05-11 00:08:31, Epoch : 1, Step : 1814, Training Loss : 0.17256, Training Acc : 0.944, Run Time : 0.59
INFO:root:2019-05-11 00:08:32, Epoch : 1, Step : 1815, Training Loss : 0.25454, Training Acc : 0.917, Run Time : 0.60
INFO:root:2019-05-11 00:08:33, Epoch : 1, Step : 1816, Training Loss : 0.20843, Training Acc : 0.922, Run Time : 1.09
INFO:root:2019-05-11 00:08:41, Epoch : 1, Step : 1817, Training Loss : 0.22606, Training Acc : 0.922, Run Time : 8.66
INFO:root:2019-05-11 00:08:42, Epoch : 1, Step : 1818, Training Loss : 0.19182, Training Acc : 0.922, Run Time : 0.82
INFO:root:2019-05-11 00:08:43, Epoch : 1, Step : 1819, Training Loss : 0.14782, Training Acc : 0.928, Run Time : 0.54
INFO:root:2019-05-11 00:08:46, Epoch : 1, Step : 1820, Training Loss : 0.20305, Training Acc : 0.917, Run Time : 3.62
INFO:root:2019-05-11 00:08:48, Epoch : 1, Step : 1821, Training Loss : 0.18673, Training Acc : 0.917, Run Time : 1.21
INFO:root:2019-05-11 00:08:48, Epoch : 1, Step : 1822, Training Loss : 0.15004, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-11 00:08:48, Epoch : 1, Step : 1823, Training Loss : 0.19457, Training Acc : 0.917, Run Time : 0.39
INFO:root:2019-05-11 00:08:49, Epoch : 1, Step : 1824, Training Loss : 0.15127, Training Acc : 0.939, Run Time : 0.85
INFO:root:2019-05-11 00:08:55, Epoch : 1, Step : 1825, Training Loss : 0.10321, Training Acc : 0.944, Run Time : 5.57
INFO:root:2019-05-11 00:08:55, Epoch : 1, Step : 1826, Training Loss : 0.14934, Training Acc : 0.928, Run Time : 0.60
INFO:root:2019-05-11 00:08:56, Epoch : 1, Step : 1827, Training Loss : 0.15019, Training Acc : 0.922, Run Time : 0.94
INFO:root:2019-05-11 00:08:58, Epoch : 1, Step : 1828, Training Loss : 0.13472, Training Acc : 0.939, Run Time : 1.86
INFO:root:2019-05-11 00:08:59, Epoch : 1, Step : 1829, Training Loss : 0.12376, Training Acc : 0.944, Run Time : 0.41
INFO:root:2019-05-11 00:08:59, Epoch : 1, Step : 1830, Training Loss : 0.07414, Training Acc : 0.972, Run Time : 0.38
INFO:root:2019-05-11 00:08:59, Epoch : 1, Step : 1831, Training Loss : 0.10237, Training Acc : 0.956, Run Time : 0.38
INFO:root:2019-05-11 00:09:00, Epoch : 1, Step : 1832, Training Loss : 0.08204, Training Acc : 0.961, Run Time : 0.50
INFO:root:2019-05-11 00:09:01, Epoch : 1, Step : 1833, Training Loss : 0.08580, Training Acc : 0.944, Run Time : 1.14
INFO:root:2019-05-11 00:09:03, Epoch : 1, Step : 1834, Training Loss : 0.08180, Training Acc : 0.961, Run Time : 2.18
INFO:root:2019-05-11 00:09:04, Epoch : 1, Step : 1835, Training Loss : 0.09694, Training Acc : 0.956, Run Time : 0.67
INFO:root:2019-05-11 00:09:09, Epoch : 1, Step : 1836, Training Loss : 0.11814, Training Acc : 0.961, Run Time : 5.23
INFO:root:2019-05-11 00:09:11, Epoch : 1, Step : 1837, Training Loss : 0.17768, Training Acc : 0.928, Run Time : 1.73
INFO:root:2019-05-11 00:09:11, Epoch : 1, Step : 1838, Training Loss : 0.09975, Training Acc : 0.956, Run Time : 0.38
INFO:root:2019-05-11 00:09:12, Epoch : 1, Step : 1839, Training Loss : 0.23606, Training Acc : 0.917, Run Time : 1.12
INFO:root:2019-05-11 00:09:21, Epoch : 1, Step : 1840, Training Loss : 0.22334, Training Acc : 0.911, Run Time : 8.46
INFO:root:2019-05-11 00:09:21, Epoch : 1, Step : 1841, Training Loss : 0.47441, Training Acc : 0.822, Run Time : 0.42
INFO:root:2019-05-11 00:09:22, Epoch : 1, Step : 1842, Training Loss : 0.38647, Training Acc : 0.844, Run Time : 0.85
INFO:root:2019-05-11 00:09:30, Epoch : 1, Step : 1843, Training Loss : 0.22477, Training Acc : 0.922, Run Time : 7.61
INFO:root:2019-05-11 00:09:30, Epoch : 1, Step : 1844, Training Loss : 0.22159, Training Acc : 0.894, Run Time : 0.42
INFO:root:2019-05-11 00:09:31, Epoch : 1, Step : 1845, Training Loss : 0.16116, Training Acc : 0.917, Run Time : 0.39
INFO:root:2019-05-11 00:09:31, Epoch : 1, Step : 1846, Training Loss : 0.26301, Training Acc : 0.878, Run Time : 0.75
INFO:root:2019-05-11 00:09:36, Epoch : 1, Step : 1847, Training Loss : 0.24416, Training Acc : 0.894, Run Time : 4.22
INFO:root:2019-05-11 00:09:36, Epoch : 1, Step : 1848, Training Loss : 0.23547, Training Acc : 0.889, Run Time : 0.72
INFO:root:2019-05-11 00:09:37, Epoch : 1, Step : 1849, Training Loss : 0.18739, Training Acc : 0.906, Run Time : 0.37
INFO:root:2019-05-11 00:09:37, Epoch : 1, Step : 1850, Training Loss : 0.18770, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-11 00:09:38, Epoch : 1, Step : 1851, Training Loss : 0.11664, Training Acc : 0.967, Run Time : 0.60
INFO:root:2019-05-11 00:09:43, Epoch : 1, Step : 1852, Training Loss : 0.17822, Training Acc : 0.922, Run Time : 5.42
INFO:root:2019-05-11 00:09:44, Epoch : 1, Step : 1853, Training Loss : 0.11681, Training Acc : 0.956, Run Time : 0.84
INFO:root:2019-05-11 00:09:44, Epoch : 1, Step : 1854, Training Loss : 0.11709, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-11 00:09:45, Epoch : 1, Step : 1855, Training Loss : 0.16899, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 00:09:45, Epoch : 1, Step : 1856, Training Loss : 0.22613, Training Acc : 0.900, Run Time : 0.38
INFO:root:2019-05-11 00:09:46, Epoch : 1, Step : 1857, Training Loss : 0.15292, Training Acc : 0.917, Run Time : 0.78
INFO:root:2019-05-11 00:09:53, Epoch : 1, Step : 1858, Training Loss : 0.24276, Training Acc : 0.878, Run Time : 7.21
INFO:root:2019-05-11 00:09:54, Epoch : 1, Step : 1859, Training Loss : 0.18442, Training Acc : 0.906, Run Time : 0.85
INFO:root:2019-05-11 00:09:55, Epoch : 1, Step : 1860, Training Loss : 0.20557, Training Acc : 0.883, Run Time : 1.04
INFO:root:2019-05-11 00:10:03, Epoch : 1, Step : 1861, Training Loss : 0.69897, Training Acc : 0.739, Run Time : 7.78
INFO:root:2019-05-11 00:10:04, Epoch : 1, Step : 1862, Training Loss : 0.47763, Training Acc : 0.756, Run Time : 1.25
INFO:root:2019-05-11 00:10:05, Epoch : 1, Step : 1863, Training Loss : 0.50050, Training Acc : 0.789, Run Time : 0.97
INFO:root:2019-05-11 00:10:13, Epoch : 1, Step : 1864, Training Loss : 0.81169, Training Acc : 0.706, Run Time : 7.79
INFO:root:2019-05-11 00:10:13, Epoch : 1, Step : 1865, Training Loss : 0.56379, Training Acc : 0.789, Run Time : 0.41
INFO:root:2019-05-11 00:10:14, Epoch : 1, Step : 1866, Training Loss : 0.38420, Training Acc : 0.861, Run Time : 0.59
INFO:root:2019-05-11 00:10:15, Epoch : 1, Step : 1867, Training Loss : 0.57026, Training Acc : 0.789, Run Time : 1.25
INFO:root:2019-05-11 00:10:23, Epoch : 1, Step : 1868, Training Loss : 0.37522, Training Acc : 0.828, Run Time : 7.68
INFO:root:2019-05-11 00:10:23, Epoch : 1, Step : 1869, Training Loss : 0.34967, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-11 00:10:23, Epoch : 1, Step : 1870, Training Loss : 0.23578, Training Acc : 0.911, Run Time : 0.39
INFO:root:2019-05-11 00:10:32, Epoch : 1, Step : 1871, Training Loss : 0.25829, Training Acc : 0.889, Run Time : 8.55
INFO:root:2019-05-11 00:10:33, Epoch : 1, Step : 1872, Training Loss : 0.29936, Training Acc : 0.867, Run Time : 0.64
INFO:root:2019-05-11 00:10:33, Epoch : 1, Step : 1873, Training Loss : 0.42811, Training Acc : 0.839, Run Time : 0.42
INFO:root:2019-05-11 00:10:34, Epoch : 1, Step : 1874, Training Loss : 0.53948, Training Acc : 0.778, Run Time : 0.79
INFO:root:2019-05-11 00:10:43, Epoch : 1, Step : 1875, Training Loss : 0.45076, Training Acc : 0.850, Run Time : 9.31
INFO:root:2019-05-11 00:10:44, Epoch : 1, Step : 1876, Training Loss : 0.60295, Training Acc : 0.767, Run Time : 0.96
INFO:root:2019-05-11 00:10:45, Epoch : 1, Step : 1877, Training Loss : 0.28790, Training Acc : 0.883, Run Time : 0.37
INFO:root:2019-05-11 00:10:46, Epoch : 1, Step : 1878, Training Loss : 0.32482, Training Acc : 0.900, Run Time : 1.02
INFO:root:2019-05-11 00:10:49, Epoch : 1, Step : 1879, Training Loss : 0.27746, Training Acc : 0.889, Run Time : 3.10
INFO:root:2019-05-11 00:10:49, Epoch : 1, Step : 1880, Training Loss : 0.22627, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 00:10:49, Epoch : 1, Step : 1881, Training Loss : 0.37931, Training Acc : 0.856, Run Time : 0.37
INFO:root:2019-05-11 00:10:51, Epoch : 1, Step : 1882, Training Loss : 0.28931, Training Acc : 0.889, Run Time : 1.17
INFO:root:2019-05-11 00:10:56, Epoch : 1, Step : 1883, Training Loss : 0.19658, Training Acc : 0.922, Run Time : 5.30
INFO:root:2019-05-11 00:10:56, Epoch : 1, Step : 1884, Training Loss : 0.30325, Training Acc : 0.894, Run Time : 0.41
INFO:root:2019-05-11 00:10:57, Epoch : 1, Step : 1885, Training Loss : 0.24325, Training Acc : 0.894, Run Time : 0.44
INFO:root:2019-05-11 00:10:58, Epoch : 1, Step : 1886, Training Loss : 0.18936, Training Acc : 0.911, Run Time : 0.89
INFO:root:2019-05-11 00:11:09, Epoch : 1, Step : 1887, Training Loss : 0.20591, Training Acc : 0.894, Run Time : 11.22
INFO:root:2019-05-11 00:11:09, Epoch : 1, Step : 1888, Training Loss : 0.19413, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-11 00:11:10, Epoch : 1, Step : 1889, Training Loss : 0.24808, Training Acc : 0.861, Run Time : 0.78
INFO:root:2019-05-11 00:11:17, Epoch : 1, Step : 1890, Training Loss : 0.22992, Training Acc : 0.878, Run Time : 6.65
INFO:root:2019-05-11 00:11:18, Epoch : 1, Step : 1891, Training Loss : 0.20135, Training Acc : 0.928, Run Time : 0.87
INFO:root:2019-05-11 00:11:18, Epoch : 1, Step : 1892, Training Loss : 0.18680, Training Acc : 0.911, Run Time : 0.79
INFO:root:2019-05-11 00:11:26, Epoch : 1, Step : 1893, Training Loss : 0.23310, Training Acc : 0.872, Run Time : 7.48
INFO:root:2019-05-11 00:11:26, Epoch : 1, Step : 1894, Training Loss : 0.22657, Training Acc : 0.872, Run Time : 0.44
INFO:root:2019-05-11 00:11:27, Epoch : 1, Step : 1895, Training Loss : 0.29554, Training Acc : 0.817, Run Time : 0.37
INFO:root:2019-05-11 00:11:28, Epoch : 1, Step : 1896, Training Loss : 0.30756, Training Acc : 0.811, Run Time : 1.60
INFO:root:2019-05-11 00:11:29, Epoch : 1, Step : 1897, Training Loss : 0.23207, Training Acc : 0.911, Run Time : 0.40
INFO:root:2019-05-11 00:11:29, Epoch : 1, Step : 1898, Training Loss : 0.21136, Training Acc : 0.900, Run Time : 0.41
INFO:root:2019-05-11 00:11:29, Epoch : 1, Step : 1899, Training Loss : 0.24643, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-11 00:11:30, Epoch : 1, Step : 1900, Training Loss : 0.22040, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-11 00:11:38, Epoch : 1, Step : 1901, Training Loss : 0.16881, Training Acc : 0.950, Run Time : 7.86
INFO:root:2019-05-11 00:11:38, Epoch : 1, Step : 1902, Training Loss : 0.18517, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 00:11:39, Epoch : 1, Step : 1903, Training Loss : 0.24847, Training Acc : 0.889, Run Time : 0.39
INFO:root:2019-05-11 00:11:39, Epoch : 1, Step : 1904, Training Loss : 0.25128, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-11 00:11:40, Epoch : 1, Step : 1905, Training Loss : 0.26641, Training Acc : 0.894, Run Time : 0.87
INFO:root:2019-05-11 00:11:48, Epoch : 1, Step : 1906, Training Loss : 0.21214, Training Acc : 0.928, Run Time : 7.85
INFO:root:2019-05-11 00:11:48, Epoch : 1, Step : 1907, Training Loss : 0.22617, Training Acc : 0.894, Run Time : 0.42
INFO:root:2019-05-11 00:11:48, Epoch : 1, Step : 1908, Training Loss : 0.28567, Training Acc : 0.872, Run Time : 0.37
INFO:root:2019-05-11 00:11:49, Epoch : 1, Step : 1909, Training Loss : 0.20796, Training Acc : 0.928, Run Time : 0.42
INFO:root:2019-05-11 00:11:50, Epoch : 1, Step : 1910, Training Loss : 0.31750, Training Acc : 0.872, Run Time : 0.72
INFO:root:2019-05-11 00:11:55, Epoch : 1, Step : 1911, Training Loss : 0.33714, Training Acc : 0.844, Run Time : 5.15
INFO:root:2019-05-11 00:11:55, Epoch : 1, Step : 1912, Training Loss : 0.30074, Training Acc : 0.872, Run Time : 0.57
INFO:root:2019-05-11 00:11:56, Epoch : 1, Step : 1913, Training Loss : 0.23563, Training Acc : 0.861, Run Time : 0.55
INFO:root:2019-05-11 00:11:57, Epoch : 1, Step : 1914, Training Loss : 0.17103, Training Acc : 0.933, Run Time : 1.58
INFO:root:2019-05-11 00:12:05, Epoch : 1, Step : 1915, Training Loss : 0.21665, Training Acc : 0.894, Run Time : 7.57
INFO:root:2019-05-11 00:12:06, Epoch : 1, Step : 1916, Training Loss : 0.24540, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-11 00:12:06, Epoch : 1, Step : 1917, Training Loss : 0.15256, Training Acc : 0.928, Run Time : 0.39
INFO:root:2019-05-11 00:12:07, Epoch : 1, Step : 1918, Training Loss : 0.15820, Training Acc : 0.928, Run Time : 1.22
INFO:root:2019-05-11 00:12:15, Epoch : 1, Step : 1919, Training Loss : 0.16447, Training Acc : 0.939, Run Time : 8.23
INFO:root:2019-05-11 00:12:16, Epoch : 1, Step : 1920, Training Loss : 0.32108, Training Acc : 0.861, Run Time : 0.44
INFO:root:2019-05-11 00:12:16, Epoch : 1, Step : 1921, Training Loss : 0.14327, Training Acc : 0.961, Run Time : 0.38
INFO:root:2019-05-11 00:12:17, Epoch : 1, Step : 1922, Training Loss : 0.19734, Training Acc : 0.911, Run Time : 0.90
INFO:root:2019-05-11 00:12:23, Epoch : 1, Step : 1923, Training Loss : 0.23429, Training Acc : 0.883, Run Time : 5.58
INFO:root:2019-05-11 00:12:23, Epoch : 1, Step : 1924, Training Loss : 0.19622, Training Acc : 0.928, Run Time : 0.53
INFO:root:2019-05-11 00:12:24, Epoch : 1, Step : 1925, Training Loss : 0.22366, Training Acc : 0.911, Run Time : 0.40
INFO:root:2019-05-11 00:12:25, Epoch : 1, Step : 1926, Training Loss : 0.21891, Training Acc : 0.917, Run Time : 0.99
INFO:root:2019-05-11 00:12:31, Epoch : 1, Step : 1927, Training Loss : 0.21190, Training Acc : 0.894, Run Time : 6.52
INFO:root:2019-05-11 00:12:32, Epoch : 1, Step : 1928, Training Loss : 0.21778, Training Acc : 0.872, Run Time : 0.60
INFO:root:2019-05-11 00:12:32, Epoch : 1, Step : 1929, Training Loss : 0.15241, Training Acc : 0.939, Run Time : 0.37
INFO:root:2019-05-11 00:12:38, Epoch : 1, Step : 1930, Training Loss : 0.19307, Training Acc : 0.917, Run Time : 6.17
INFO:root:2019-05-11 00:12:39, Epoch : 1, Step : 1931, Training Loss : 0.19108, Training Acc : 0.928, Run Time : 0.98
INFO:root:2019-05-11 00:12:40, Epoch : 1, Step : 1932, Training Loss : 0.21621, Training Acc : 0.878, Run Time : 0.37
INFO:root:2019-05-11 00:12:44, Epoch : 1, Step : 1933, Training Loss : 0.18045, Training Acc : 0.917, Run Time : 4.23
INFO:root:2019-05-11 00:12:44, Epoch : 1, Step : 1934, Training Loss : 0.12343, Training Acc : 0.961, Run Time : 0.58
INFO:root:2019-05-11 00:12:45, Epoch : 1, Step : 1935, Training Loss : 0.15494, Training Acc : 0.917, Run Time : 0.40
INFO:root:2019-05-11 00:12:46, Epoch : 1, Step : 1936, Training Loss : 0.20208, Training Acc : 0.894, Run Time : 1.16
INFO:root:2019-05-11 00:12:54, Epoch : 1, Step : 1937, Training Loss : 0.20786, Training Acc : 0.906, Run Time : 7.59
INFO:root:2019-05-11 00:12:54, Epoch : 1, Step : 1938, Training Loss : 0.14117, Training Acc : 0.939, Run Time : 0.60
INFO:root:2019-05-11 00:12:55, Epoch : 1, Step : 1939, Training Loss : 0.15971, Training Acc : 0.928, Run Time : 1.19
INFO:root:2019-05-11 00:13:02, Epoch : 1, Step : 1940, Training Loss : 0.15167, Training Acc : 0.944, Run Time : 6.36
INFO:root:2019-05-11 00:13:02, Epoch : 1, Step : 1941, Training Loss : 0.16121, Training Acc : 0.911, Run Time : 0.52
INFO:root:2019-05-11 00:13:03, Epoch : 1, Step : 1942, Training Loss : 0.12639, Training Acc : 0.950, Run Time : 0.41
INFO:root:2019-05-11 00:13:03, Epoch : 1, Step : 1943, Training Loss : 0.15844, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 00:13:11, Epoch : 1, Step : 1944, Training Loss : 0.18118, Training Acc : 0.928, Run Time : 8.22
INFO:root:2019-05-11 00:13:12, Epoch : 1, Step : 1945, Training Loss : 0.15471, Training Acc : 0.933, Run Time : 0.52
INFO:root:2019-05-11 00:13:12, Epoch : 1, Step : 1946, Training Loss : 0.11831, Training Acc : 0.967, Run Time : 0.49
INFO:root:2019-05-11 00:13:13, Epoch : 1, Step : 1947, Training Loss : 0.14379, Training Acc : 0.939, Run Time : 0.42
INFO:root:2019-05-11 00:13:14, Epoch : 1, Step : 1948, Training Loss : 0.15363, Training Acc : 0.922, Run Time : 1.14
INFO:root:2019-05-11 00:13:20, Epoch : 1, Step : 1949, Training Loss : 0.14553, Training Acc : 0.928, Run Time : 6.64
INFO:root:2019-05-11 00:13:21, Epoch : 1, Step : 1950, Training Loss : 0.12432, Training Acc : 0.956, Run Time : 0.43
INFO:root:2019-05-11 00:13:21, Epoch : 1, Step : 1951, Training Loss : 0.19730, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-11 00:13:22, Epoch : 1, Step : 1952, Training Loss : 0.10607, Training Acc : 0.967, Run Time : 0.37
INFO:root:2019-05-11 00:13:22, Epoch : 1, Step : 1953, Training Loss : 0.11138, Training Acc : 0.967, Run Time : 0.70
INFO:root:2019-05-11 00:13:30, Epoch : 1, Step : 1954, Training Loss : 0.09645, Training Acc : 0.972, Run Time : 7.87
INFO:root:2019-05-11 00:13:31, Epoch : 1, Step : 1955, Training Loss : 0.10738, Training Acc : 0.967, Run Time : 0.66
INFO:root:2019-05-11 00:13:31, Epoch : 1, Step : 1956, Training Loss : 0.11961, Training Acc : 0.967, Run Time : 0.41
INFO:root:2019-05-11 00:13:32, Epoch : 1, Step : 1957, Training Loss : 0.14182, Training Acc : 0.944, Run Time : 1.13
INFO:root:2019-05-11 00:13:39, Epoch : 1, Step : 1958, Training Loss : 0.24443, Training Acc : 0.878, Run Time : 6.68
INFO:root:2019-05-11 00:13:39, Epoch : 1, Step : 1959, Training Loss : 0.12526, Training Acc : 0.950, Run Time : 0.44
INFO:root:2019-05-11 00:13:40, Epoch : 1, Step : 1960, Training Loss : 0.17724, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 00:13:41, Epoch : 1, Step : 1961, Training Loss : 0.13372, Training Acc : 0.933, Run Time : 0.88
INFO:root:2019-05-11 00:13:47, Epoch : 1, Step : 1962, Training Loss : 0.16207, Training Acc : 0.933, Run Time : 6.36
INFO:root:2019-05-11 00:13:48, Epoch : 1, Step : 1963, Training Loss : 0.19781, Training Acc : 0.906, Run Time : 0.40
INFO:root:2019-05-11 00:13:48, Epoch : 1, Step : 1964, Training Loss : 0.15902, Training Acc : 0.922, Run Time : 0.74
INFO:root:2019-05-11 00:13:49, Epoch : 1, Step : 1965, Training Loss : 0.13010, Training Acc : 0.944, Run Time : 0.37
INFO:root:2019-05-11 00:13:50, Epoch : 1, Step : 1966, Training Loss : 0.15418, Training Acc : 0.928, Run Time : 1.14
INFO:root:2019-05-11 00:13:55, Epoch : 1, Step : 1967, Training Loss : 0.21579, Training Acc : 0.889, Run Time : 5.15
INFO:root:2019-05-11 00:13:55, Epoch : 1, Step : 1968, Training Loss : 0.16713, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-11 00:13:56, Epoch : 1, Step : 1969, Training Loss : 0.10254, Training Acc : 0.950, Run Time : 0.40
INFO:root:2019-05-11 00:13:56, Epoch : 1, Step : 1970, Training Loss : 0.15932, Training Acc : 0.933, Run Time : 0.37
INFO:root:2019-05-11 00:13:56, Epoch : 1, Step : 1971, Training Loss : 0.09850, Training Acc : 0.967, Run Time : 0.39
INFO:root:2019-05-11 00:13:59, Epoch : 1, Step : 1972, Training Loss : 0.17323, Training Acc : 0.933, Run Time : 2.19
INFO:root:2019-05-11 00:13:59, Epoch : 1, Step : 1973, Training Loss : 0.07665, Training Acc : 0.989, Run Time : 0.37
INFO:root:2019-05-11 00:13:59, Epoch : 1, Step : 1974, Training Loss : 0.13252, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 00:14:00, Epoch : 1, Step : 1975, Training Loss : 0.15580, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 00:14:00, Epoch : 1, Step : 1976, Training Loss : 0.08859, Training Acc : 0.978, Run Time : 0.38
INFO:root:2019-05-11 00:14:01, Epoch : 1, Step : 1977, Training Loss : 0.19163, Training Acc : 0.906, Run Time : 0.62
INFO:root:2019-05-11 00:14:05, Epoch : 1, Step : 1978, Training Loss : 0.16068, Training Acc : 0.939, Run Time : 3.79
INFO:root:2019-05-11 00:14:05, Epoch : 1, Step : 1979, Training Loss : 0.18851, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-11 00:14:05, Epoch : 1, Step : 1980, Training Loss : 0.14710, Training Acc : 0.928, Run Time : 0.40
INFO:root:2019-05-11 00:14:06, Epoch : 1, Step : 1981, Training Loss : 0.22733, Training Acc : 0.889, Run Time : 0.55
INFO:root:2019-05-11 00:14:11, Epoch : 1, Step : 1982, Training Loss : 0.16412, Training Acc : 0.928, Run Time : 4.56
INFO:root:2019-05-11 00:14:11, Epoch : 1, Step : 1983, Training Loss : 0.10502, Training Acc : 0.961, Run Time : 0.39
INFO:root:2019-05-11 00:14:11, Epoch : 1, Step : 1984, Training Loss : 0.09766, Training Acc : 0.978, Run Time : 0.37
INFO:root:2019-05-11 00:14:12, Epoch : 1, Step : 1985, Training Loss : 0.08677, Training Acc : 0.961, Run Time : 0.59
INFO:root:2019-05-11 00:14:12, Epoch : 1, Step : 1986, Training Loss : 0.07788, Training Acc : 0.972, Run Time : 0.41
INFO:root:2019-05-11 00:14:13, Epoch : 1, Step : 1987, Training Loss : 0.06842, Training Acc : 0.983, Run Time : 0.73
INFO:root:2019-05-11 00:14:14, Epoch : 1, Step : 1988, Training Loss : 0.06688, Training Acc : 0.983, Run Time : 1.02
INFO:root:2019-05-11 00:14:14, Epoch : 1, Step : 1989, Training Loss : 0.06725, Training Acc : 0.978, Run Time : 0.39
INFO:root:2019-05-11 00:14:15, Epoch : 1, Step : 1990, Training Loss : 0.09437, Training Acc : 0.961, Run Time : 0.38
INFO:root:2019-05-11 00:14:16, Epoch : 1, Step : 1991, Training Loss : 0.09030, Training Acc : 0.978, Run Time : 0.71
INFO:root:2019-05-11 00:14:20, Epoch : 1, Step : 1992, Training Loss : 0.06174, Training Acc : 0.972, Run Time : 4.69
INFO:root:2019-05-11 00:14:26, Epoch : 1, Step : 1993, Training Loss : 0.06426, Training Acc : 0.983, Run Time : 5.90
INFO:root:2019-05-11 00:14:27, Epoch : 1, Step : 1994, Training Loss : 0.08242, Training Acc : 0.978, Run Time : 0.64
INFO:root:2019-05-11 00:14:27, Epoch : 1, Step : 1995, Training Loss : 0.06305, Training Acc : 0.972, Run Time : 0.38
INFO:root:2019-05-11 00:14:28, Epoch : 1, Step : 1996, Training Loss : 0.06029, Training Acc : 0.978, Run Time : 0.50
INFO:root:2019-05-11 00:14:35, Epoch : 1, Step : 1997, Training Loss : 0.07905, Training Acc : 0.972, Run Time : 7.55
INFO:root:2019-05-11 00:14:36, Epoch : 1, Step : 1998, Training Loss : 0.08177, Training Acc : 0.967, Run Time : 0.42
INFO:root:2019-05-11 00:14:36, Epoch : 1, Step : 1999, Training Loss : 0.06513, Training Acc : 0.972, Run Time : 0.38
INFO:root:2019-05-11 00:14:37, Epoch : 1, Step : 2000, Training Loss : 0.09068, Training Acc : 0.950, Run Time : 0.78
INFO:root:2019-05-11 00:14:42, Epoch : 1, Step : 2001, Training Loss : 0.91767, Training Acc : 0.672, Run Time : 5.66
INFO:root:2019-05-11 00:14:43, Epoch : 1, Step : 2002, Training Loss : 1.57725, Training Acc : 0.589, Run Time : 0.66
INFO:root:2019-05-11 00:14:44, Epoch : 1, Step : 2003, Training Loss : 1.44661, Training Acc : 0.633, Run Time : 1.11
INFO:root:2019-05-11 00:14:52, Epoch : 1, Step : 2004, Training Loss : 1.47055, Training Acc : 0.583, Run Time : 7.71
INFO:root:2019-05-11 00:14:52, Epoch : 1, Step : 2005, Training Loss : 1.14090, Training Acc : 0.639, Run Time : 0.42
INFO:root:2019-05-11 00:14:53, Epoch : 1, Step : 2006, Training Loss : 0.88247, Training Acc : 0.667, Run Time : 0.38
INFO:root:2019-05-11 00:14:53, Epoch : 1, Step : 2007, Training Loss : 0.72110, Training Acc : 0.700, Run Time : 0.38
INFO:root:2019-05-11 00:14:56, Epoch : 1, Step : 2008, Training Loss : 0.54981, Training Acc : 0.744, Run Time : 3.32
INFO:root:2019-05-11 00:15:00, Epoch : 1, Step : 2009, Training Loss : 0.56896, Training Acc : 0.756, Run Time : 3.34
INFO:root:2019-05-11 00:15:00, Epoch : 1, Step : 2010, Training Loss : 0.31325, Training Acc : 0.867, Run Time : 0.38
INFO:root:2019-05-11 00:15:05, Epoch : 1, Step : 2011, Training Loss : 0.33833, Training Acc : 0.839, Run Time : 5.14
INFO:root:2019-05-11 00:15:06, Epoch : 1, Step : 2012, Training Loss : 0.26815, Training Acc : 0.850, Run Time : 0.99
INFO:root:2019-05-11 00:15:12, Epoch : 1, Step : 2013, Training Loss : 0.17246, Training Acc : 0.906, Run Time : 5.85
INFO:root:2019-05-11 00:15:13, Epoch : 1, Step : 2014, Training Loss : 0.15283, Training Acc : 0.939, Run Time : 0.64
INFO:root:2019-05-11 00:15:13, Epoch : 1, Step : 2015, Training Loss : 0.20082, Training Acc : 0.900, Run Time : 0.73
INFO:root:2019-05-11 00:15:19, Epoch : 1, Step : 2016, Training Loss : 0.18889, Training Acc : 0.922, Run Time : 5.94
INFO:root:2019-05-11 00:15:20, Epoch : 1, Step : 2017, Training Loss : 0.36510, Training Acc : 0.828, Run Time : 0.69
INFO:root:2019-05-11 00:15:21, Epoch : 1, Step : 2018, Training Loss : 0.15723, Training Acc : 0.961, Run Time : 0.54
INFO:root:2019-05-11 00:15:27, Epoch : 1, Step : 2019, Training Loss : 0.22265, Training Acc : 0.900, Run Time : 5.87
INFO:root:2019-05-11 00:15:27, Epoch : 1, Step : 2020, Training Loss : 0.63027, Training Acc : 0.800, Run Time : 0.60
INFO:root:2019-05-11 00:15:28, Epoch : 1, Step : 2021, Training Loss : 0.78691, Training Acc : 0.711, Run Time : 0.38
INFO:root:2019-05-11 00:15:28, Epoch : 1, Step : 2022, Training Loss : 0.54124, Training Acc : 0.733, Run Time : 0.86
INFO:root:2019-05-11 00:15:37, Epoch : 1, Step : 2023, Training Loss : 0.55202, Training Acc : 0.756, Run Time : 9.08
INFO:root:2019-05-11 00:15:38, Epoch : 1, Step : 2024, Training Loss : 0.47478, Training Acc : 0.794, Run Time : 0.67
INFO:root:2019-05-11 00:15:38, Epoch : 1, Step : 2025, Training Loss : 0.74333, Training Acc : 0.706, Run Time : 0.38
INFO:root:2019-05-11 00:15:48, Epoch : 1, Step : 2026, Training Loss : 0.73471, Training Acc : 0.750, Run Time : 9.50
INFO:root:2019-05-11 00:15:49, Epoch : 1, Step : 2027, Training Loss : 0.61261, Training Acc : 0.811, Run Time : 0.94
INFO:root:2019-05-11 00:15:49, Epoch : 1, Step : 2028, Training Loss : 0.31422, Training Acc : 0.867, Run Time : 0.39
INFO:root:2019-05-11 00:15:50, Epoch : 1, Step : 2029, Training Loss : 0.51324, Training Acc : 0.767, Run Time : 0.38
INFO:root:2019-05-11 00:15:50, Epoch : 1, Step : 2030, Training Loss : 0.45257, Training Acc : 0.828, Run Time : 0.40
INFO:root:2019-05-11 00:15:51, Epoch : 1, Step : 2031, Training Loss : 0.22965, Training Acc : 0.911, Run Time : 0.51
INFO:root:2019-05-11 00:15:55, Epoch : 1, Step : 2032, Training Loss : 0.24676, Training Acc : 0.900, Run Time : 4.00
INFO:root:2019-05-11 00:15:55, Epoch : 1, Step : 2033, Training Loss : 0.34745, Training Acc : 0.861, Run Time : 0.44
INFO:root:2019-05-11 00:15:55, Epoch : 1, Step : 2034, Training Loss : 0.34658, Training Acc : 0.861, Run Time : 0.39
INFO:root:2019-05-11 00:15:56, Epoch : 1, Step : 2035, Training Loss : 0.49454, Training Acc : 0.778, Run Time : 0.76
INFO:root:2019-05-11 00:15:58, Epoch : 1, Step : 2036, Training Loss : 0.45613, Training Acc : 0.811, Run Time : 1.90
INFO:root:2019-05-11 00:15:58, Epoch : 1, Step : 2037, Training Loss : 0.13737, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-11 00:15:59, Epoch : 1, Step : 2038, Training Loss : 0.29767, Training Acc : 0.844, Run Time : 0.57
INFO:root:2019-05-11 00:16:04, Epoch : 1, Step : 2039, Training Loss : 0.53455, Training Acc : 0.739, Run Time : 4.88
INFO:root:2019-05-11 00:16:04, Epoch : 1, Step : 2040, Training Loss : 0.43800, Training Acc : 0.822, Run Time : 0.56
INFO:root:2019-05-11 00:16:05, Epoch : 1, Step : 2041, Training Loss : 0.40269, Training Acc : 0.817, Run Time : 0.56
INFO:root:2019-05-11 00:16:05, Epoch : 1, Step : 2042, Training Loss : 0.31088, Training Acc : 0.856, Run Time : 0.39
INFO:root:2019-05-11 00:16:07, Epoch : 1, Step : 2043, Training Loss : 0.42565, Training Acc : 0.822, Run Time : 1.13
INFO:root:2019-05-11 00:16:12, Epoch : 1, Step : 2044, Training Loss : 0.30091, Training Acc : 0.850, Run Time : 5.22
INFO:root:2019-05-11 00:16:12, Epoch : 1, Step : 2045, Training Loss : 0.47278, Training Acc : 0.778, Run Time : 0.70
INFO:root:2019-05-11 00:16:13, Epoch : 1, Step : 2046, Training Loss : 0.29410, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-11 00:16:20, Epoch : 1, Step : 2047, Training Loss : 0.28873, Training Acc : 0.894, Run Time : 7.40
INFO:root:2019-05-11 00:16:21, Epoch : 1, Step : 2048, Training Loss : 0.31708, Training Acc : 0.900, Run Time : 0.49
INFO:root:2019-05-11 00:16:21, Epoch : 1, Step : 2049, Training Loss : 0.36430, Training Acc : 0.822, Run Time : 0.46
INFO:root:2019-05-11 00:16:22, Epoch : 1, Step : 2050, Training Loss : 0.45793, Training Acc : 0.794, Run Time : 0.87
INFO:root:2019-05-11 00:16:24, Epoch : 1, Step : 2051, Training Loss : 0.35106, Training Acc : 0.872, Run Time : 2.23
INFO:root:2019-05-11 00:16:26, Epoch : 1, Step : 2052, Training Loss : 0.43266, Training Acc : 0.833, Run Time : 1.46
INFO:root:2019-05-11 00:16:26, Epoch : 1, Step : 2053, Training Loss : 0.26684, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 00:16:27, Epoch : 1, Step : 2054, Training Loss : 0.34812, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-11 00:16:34, Epoch : 1, Step : 2055, Training Loss : 0.24073, Training Acc : 0.922, Run Time : 7.61
INFO:root:2019-05-11 00:16:46, Epoch : 1, Step : 2056, Training Loss : 0.34816, Training Acc : 0.872, Run Time : 11.51
INFO:root:2019-05-11 00:16:46, Epoch : 1, Step : 2057, Training Loss : 0.27391, Training Acc : 0.900, Run Time : 0.63
INFO:root:2019-05-11 00:16:47, Epoch : 1, Step : 2058, Training Loss : 0.34219, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-11 00:16:47, Epoch : 1, Step : 2059, Training Loss : 0.32288, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 00:16:55, Epoch : 1, Step : 2060, Training Loss : 0.34661, Training Acc : 0.883, Run Time : 7.96
INFO:root:2019-05-11 00:16:56, Epoch : 1, Step : 2061, Training Loss : 0.31726, Training Acc : 0.861, Run Time : 0.61
INFO:root:2019-05-11 00:16:56, Epoch : 1, Step : 2062, Training Loss : 0.33826, Training Acc : 0.861, Run Time : 0.37
INFO:root:2019-05-11 00:16:56, Epoch : 1, Step : 2063, Training Loss : 0.28338, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-11 00:16:57, Epoch : 1, Step : 2064, Training Loss : 0.24544, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 00:16:58, Epoch : 1, Step : 2065, Training Loss : 0.25312, Training Acc : 0.944, Run Time : 1.04
INFO:root:2019-05-11 00:17:04, Epoch : 1, Step : 2066, Training Loss : 0.22118, Training Acc : 0.906, Run Time : 6.15
INFO:root:2019-05-11 00:17:04, Epoch : 1, Step : 2067, Training Loss : 0.37880, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-11 00:17:05, Epoch : 1, Step : 2068, Training Loss : 0.16040, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 00:17:06, Epoch : 1, Step : 2069, Training Loss : 0.32848, Training Acc : 0.889, Run Time : 0.86
INFO:root:2019-05-11 00:17:14, Epoch : 1, Step : 2070, Training Loss : 0.32874, Training Acc : 0.889, Run Time : 8.49
INFO:root:2019-05-11 00:17:15, Epoch : 1, Step : 2071, Training Loss : 0.30927, Training Acc : 0.872, Run Time : 0.40
INFO:root:2019-05-11 00:17:15, Epoch : 1, Step : 2072, Training Loss : 0.16624, Training Acc : 0.922, Run Time : 0.51
INFO:root:2019-05-11 00:17:16, Epoch : 1, Step : 2073, Training Loss : 0.24555, Training Acc : 0.878, Run Time : 1.04
INFO:root:2019-05-11 00:17:19, Epoch : 1, Step : 2074, Training Loss : 0.14746, Training Acc : 0.956, Run Time : 2.46
INFO:root:2019-05-11 00:17:19, Epoch : 1, Step : 2075, Training Loss : 0.25326, Training Acc : 0.867, Run Time : 0.50
INFO:root:2019-05-11 00:17:20, Epoch : 1, Step : 2076, Training Loss : 0.91548, Training Acc : 0.656, Run Time : 0.37
INFO:root:2019-05-11 00:17:20, Epoch : 1, Step : 2077, Training Loss : 1.48384, Training Acc : 0.550, Run Time : 0.76
INFO:root:2019-05-11 00:17:31, Epoch : 1, Step : 2078, Training Loss : 0.91346, Training Acc : 0.694, Run Time : 10.95
INFO:root:2019-05-11 00:17:32, Epoch : 1, Step : 2079, Training Loss : 0.62553, Training Acc : 0.744, Run Time : 0.42
INFO:root:2019-05-11 00:17:32, Epoch : 1, Step : 2080, Training Loss : 0.83376, Training Acc : 0.783, Run Time : 0.38
INFO:root:2019-05-11 00:17:33, Epoch : 1, Step : 2081, Training Loss : 0.53989, Training Acc : 0.806, Run Time : 0.49
INFO:root:2019-05-11 00:17:34, Epoch : 1, Step : 2082, Training Loss : 0.65859, Training Acc : 0.733, Run Time : 1.66
INFO:root:2019-05-11 00:17:35, Epoch : 1, Step : 2083, Training Loss : 0.52648, Training Acc : 0.833, Run Time : 0.45
INFO:root:2019-05-11 00:17:38, Epoch : 1, Step : 2084, Training Loss : 0.44209, Training Acc : 0.828, Run Time : 3.04
INFO:root:2019-05-11 00:17:43, Epoch : 1, Step : 2085, Training Loss : 0.20493, Training Acc : 0.933, Run Time : 5.81
INFO:root:2019-05-11 00:17:44, Epoch : 1, Step : 2086, Training Loss : 0.40402, Training Acc : 0.794, Run Time : 0.49
INFO:root:2019-05-11 00:17:45, Epoch : 1, Step : 2087, Training Loss : 0.42213, Training Acc : 0.800, Run Time : 0.56
INFO:root:2019-05-11 00:17:46, Epoch : 1, Step : 2088, Training Loss : 0.33163, Training Acc : 0.850, Run Time : 1.02
INFO:root:2019-05-11 00:17:53, Epoch : 1, Step : 2089, Training Loss : 0.42010, Training Acc : 0.822, Run Time : 7.58
INFO:root:2019-05-11 00:17:54, Epoch : 1, Step : 2090, Training Loss : 0.56459, Training Acc : 0.689, Run Time : 0.41
INFO:root:2019-05-11 00:17:54, Epoch : 1, Step : 2091, Training Loss : 0.63353, Training Acc : 0.717, Run Time : 0.38
INFO:root:2019-05-11 00:17:54, Epoch : 1, Step : 2092, Training Loss : 0.57944, Training Acc : 0.800, Run Time : 0.38
INFO:root:2019-05-11 00:17:55, Epoch : 1, Step : 2093, Training Loss : 0.61232, Training Acc : 0.778, Run Time : 0.41
INFO:root:2019-05-11 00:17:56, Epoch : 1, Step : 2094, Training Loss : 0.31731, Training Acc : 0.878, Run Time : 0.99
INFO:root:2019-05-11 00:18:04, Epoch : 1, Step : 2095, Training Loss : 0.32076, Training Acc : 0.872, Run Time : 8.56
INFO:root:2019-05-11 00:18:05, Epoch : 1, Step : 2096, Training Loss : 0.46491, Training Acc : 0.756, Run Time : 0.68
INFO:root:2019-05-11 00:18:05, Epoch : 1, Step : 2097, Training Loss : 0.34902, Training Acc : 0.872, Run Time : 0.38
INFO:root:2019-05-11 00:18:07, Epoch : 1, Step : 2098, Training Loss : 0.38408, Training Acc : 0.794, Run Time : 1.30
INFO:root:2019-05-11 00:18:15, Epoch : 1, Step : 2099, Training Loss : 0.30707, Training Acc : 0.867, Run Time : 7.98
INFO:root:2019-05-11 00:18:15, Epoch : 1, Step : 2100, Training Loss : 0.27208, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-11 00:18:17, Epoch : 1, Step : 2101, Training Loss : 0.33585, Training Acc : 0.861, Run Time : 1.68
INFO:root:2019-05-11 00:18:17, Epoch : 1, Step : 2102, Training Loss : 0.42829, Training Acc : 0.778, Run Time : 0.57
INFO:root:2019-05-11 00:18:23, Epoch : 1, Step : 2103, Training Loss : 0.39427, Training Acc : 0.850, Run Time : 5.93
INFO:root:2019-05-11 00:18:24, Epoch : 1, Step : 2104, Training Loss : 0.47935, Training Acc : 0.800, Run Time : 0.55
INFO:root:2019-05-11 00:18:24, Epoch : 1, Step : 2105, Training Loss : 0.38349, Training Acc : 0.817, Run Time : 0.57
INFO:root:2019-05-11 00:18:25, Epoch : 1, Step : 2106, Training Loss : 0.37803, Training Acc : 0.817, Run Time : 0.49
INFO:root:2019-05-11 00:18:30, Epoch : 1, Step : 2107, Training Loss : 0.33336, Training Acc : 0.872, Run Time : 5.16
INFO:root:2019-05-11 00:18:31, Epoch : 1, Step : 2108, Training Loss : 0.38817, Training Acc : 0.794, Run Time : 1.14
INFO:root:2019-05-11 00:18:31, Epoch : 1, Step : 2109, Training Loss : 0.36772, Training Acc : 0.839, Run Time : 0.38
INFO:root:2019-05-11 00:18:32, Epoch : 1, Step : 2110, Training Loss : 0.55802, Training Acc : 0.761, Run Time : 1.00
INFO:root:2019-05-11 00:18:47, Epoch : 1, Step : 2111, Training Loss : 0.48890, Training Acc : 0.733, Run Time : 15.01
INFO:root:2019-05-11 00:18:55, Epoch : 1, Step : 2112, Training Loss : 0.31018, Training Acc : 0.872, Run Time : 7.55
INFO:root:2019-05-11 00:18:56, Epoch : 1, Step : 2113, Training Loss : 0.29379, Training Acc : 0.828, Run Time : 0.52
INFO:root:2019-05-11 00:18:56, Epoch : 1, Step : 2114, Training Loss : 0.37481, Training Acc : 0.822, Run Time : 0.41
INFO:root:2019-05-11 00:18:57, Epoch : 1, Step : 2115, Training Loss : 0.48574, Training Acc : 0.733, Run Time : 1.28
INFO:root:2019-05-11 00:19:04, Epoch : 1, Step : 2116, Training Loss : 0.30267, Training Acc : 0.833, Run Time : 7.22
INFO:root:2019-05-11 00:19:05, Epoch : 1, Step : 2117, Training Loss : 0.34821, Training Acc : 0.794, Run Time : 0.45
INFO:root:2019-05-11 00:19:05, Epoch : 1, Step : 2118, Training Loss : 0.35939, Training Acc : 0.817, Run Time : 0.41
INFO:root:2019-05-11 00:19:06, Epoch : 1, Step : 2119, Training Loss : 0.55721, Training Acc : 0.661, Run Time : 0.37
INFO:root:2019-05-11 00:19:06, Epoch : 1, Step : 2120, Training Loss : 0.45907, Training Acc : 0.750, Run Time : 0.44
INFO:root:2019-05-11 00:19:07, Epoch : 1, Step : 2121, Training Loss : 0.36455, Training Acc : 0.794, Run Time : 0.93
INFO:root:2019-05-11 00:19:16, Epoch : 1, Step : 2122, Training Loss : 0.46610, Training Acc : 0.817, Run Time : 9.46
INFO:root:2019-05-11 00:19:17, Epoch : 1, Step : 2123, Training Loss : 0.39996, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-11 00:19:18, Epoch : 1, Step : 2124, Training Loss : 0.52106, Training Acc : 0.767, Run Time : 0.70
INFO:root:2019-05-11 00:19:20, Epoch : 1, Step : 2125, Training Loss : 0.35907, Training Acc : 0.850, Run Time : 1.96
INFO:root:2019-05-11 00:19:27, Epoch : 1, Step : 2126, Training Loss : 0.49109, Training Acc : 0.756, Run Time : 7.88
INFO:root:2019-05-11 00:19:28, Epoch : 1, Step : 2127, Training Loss : 0.29525, Training Acc : 0.894, Run Time : 0.44
INFO:root:2019-05-11 00:19:28, Epoch : 1, Step : 2128, Training Loss : 0.33833, Training Acc : 0.850, Run Time : 0.37
INFO:root:2019-05-11 00:19:29, Epoch : 1, Step : 2129, Training Loss : 0.32323, Training Acc : 0.883, Run Time : 0.98
INFO:root:2019-05-11 00:19:39, Epoch : 1, Step : 2130, Training Loss : 0.26101, Training Acc : 0.883, Run Time : 9.70
INFO:root:2019-05-11 00:19:39, Epoch : 1, Step : 2131, Training Loss : 0.28962, Training Acc : 0.911, Run Time : 0.47
INFO:root:2019-05-11 00:19:40, Epoch : 1, Step : 2132, Training Loss : 0.27939, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-11 00:19:41, Epoch : 1, Step : 2133, Training Loss : 0.27259, Training Acc : 0.900, Run Time : 1.35
INFO:root:2019-05-11 00:19:46, Epoch : 1, Step : 2134, Training Loss : 0.20058, Training Acc : 0.967, Run Time : 4.84
INFO:root:2019-05-11 00:19:46, Epoch : 1, Step : 2135, Training Loss : 0.23719, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 00:19:47, Epoch : 1, Step : 2136, Training Loss : 0.18846, Training Acc : 0.967, Run Time : 0.65
INFO:root:2019-05-11 00:19:48, Epoch : 1, Step : 2137, Training Loss : 0.33560, Training Acc : 0.844, Run Time : 0.54
INFO:root:2019-05-11 00:19:58, Epoch : 1, Step : 2138, Training Loss : 0.28982, Training Acc : 0.856, Run Time : 10.52
INFO:root:2019-05-11 00:19:59, Epoch : 1, Step : 2139, Training Loss : 0.23587, Training Acc : 0.900, Run Time : 0.41
INFO:root:2019-05-11 00:19:59, Epoch : 1, Step : 2140, Training Loss : 0.25787, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 00:20:00, Epoch : 1, Step : 2141, Training Loss : 0.22676, Training Acc : 0.928, Run Time : 0.53
INFO:root:2019-05-11 00:20:10, Epoch : 1, Step : 2142, Training Loss : 0.39111, Training Acc : 0.839, Run Time : 10.10
INFO:root:2019-05-11 00:20:10, Epoch : 1, Step : 2143, Training Loss : 0.28045, Training Acc : 0.872, Run Time : 0.64
INFO:root:2019-05-11 00:20:11, Epoch : 1, Step : 2144, Training Loss : 0.28865, Training Acc : 0.850, Run Time : 0.48
INFO:root:2019-05-11 00:20:13, Epoch : 1, Step : 2145, Training Loss : 0.15570, Training Acc : 0.956, Run Time : 1.99
INFO:root:2019-05-11 00:20:14, Epoch : 1, Step : 2146, Training Loss : 0.19254, Training Acc : 0.922, Run Time : 1.18
INFO:root:2019-05-11 00:20:14, Epoch : 1, Step : 2147, Training Loss : 0.20865, Training Acc : 0.956, Run Time : 0.43
INFO:root:2019-05-11 00:20:15, Epoch : 1, Step : 2148, Training Loss : 0.32700, Training Acc : 0.844, Run Time : 0.38
INFO:root:2019-05-11 00:20:25, Epoch : 1, Step : 2149, Training Loss : 0.14280, Training Acc : 0.950, Run Time : 10.30
INFO:root:2019-05-11 00:20:26, Epoch : 1, Step : 2150, Training Loss : 0.15589, Training Acc : 0.956, Run Time : 0.54
INFO:root:2019-05-11 00:20:26, Epoch : 1, Step : 2151, Training Loss : 0.22593, Training Acc : 0.900, Run Time : 0.37
INFO:root:2019-05-11 00:20:27, Epoch : 1, Step : 2152, Training Loss : 0.19583, Training Acc : 0.922, Run Time : 1.43
INFO:root:2019-05-11 00:20:33, Epoch : 1, Step : 2153, Training Loss : 0.14664, Training Acc : 0.956, Run Time : 6.06
INFO:root:2019-05-11 00:20:34, Epoch : 1, Step : 2154, Training Loss : 0.17065, Training Acc : 0.922, Run Time : 0.40
INFO:root:2019-05-11 00:20:34, Epoch : 1, Step : 2155, Training Loss : 0.21355, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-11 00:20:35, Epoch : 1, Step : 2156, Training Loss : 0.11163, Training Acc : 0.956, Run Time : 0.45
INFO:root:2019-05-11 00:20:35, Epoch : 1, Step : 2157, Training Loss : 0.28082, Training Acc : 0.856, Run Time : 0.55
INFO:root:2019-05-11 00:20:45, Epoch : 1, Step : 2158, Training Loss : 0.12298, Training Acc : 0.972, Run Time : 9.92
INFO:root:2019-05-11 00:20:46, Epoch : 1, Step : 2159, Training Loss : 0.25586, Training Acc : 0.867, Run Time : 0.53
INFO:root:2019-05-11 00:20:46, Epoch : 1, Step : 2160, Training Loss : 0.13039, Training Acc : 0.956, Run Time : 0.38
INFO:root:2019-05-11 00:20:48, Epoch : 1, Step : 2161, Training Loss : 0.26777, Training Acc : 0.872, Run Time : 1.99
INFO:root:2019-05-11 00:20:58, Epoch : 1, Step : 2162, Training Loss : 0.22862, Training Acc : 0.911, Run Time : 10.18
INFO:root:2019-05-11 00:20:59, Epoch : 1, Step : 2163, Training Loss : 0.06702, Training Acc : 0.989, Run Time : 0.47
INFO:root:2019-05-11 00:20:59, Epoch : 1, Step : 2164, Training Loss : 0.26836, Training Acc : 0.878, Run Time : 0.51
INFO:root:2019-05-11 00:21:00, Epoch : 1, Step : 2165, Training Loss : 0.29330, Training Acc : 0.917, Run Time : 0.81
INFO:root:2019-05-11 00:21:11, Epoch : 1, Step : 2166, Training Loss : 0.27163, Training Acc : 0.911, Run Time : 10.59
INFO:root:2019-05-11 00:21:11, Epoch : 1, Step : 2167, Training Loss : 0.39351, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-11 00:21:11, Epoch : 1, Step : 2168, Training Loss : 0.08405, Training Acc : 0.983, Run Time : 0.39
INFO:root:2019-05-11 00:21:24, Epoch : 1, Step : 2169, Training Loss : 0.14945, Training Acc : 0.922, Run Time : 12.10
INFO:root:2019-05-11 00:21:24, Epoch : 1, Step : 2170, Training Loss : 0.10632, Training Acc : 0.967, Run Time : 0.75
INFO:root:2019-05-11 00:21:25, Epoch : 1, Step : 2171, Training Loss : 0.19757, Training Acc : 0.917, Run Time : 0.59
INFO:root:2019-05-11 00:21:25, Epoch : 1, Step : 2172, Training Loss : 0.11727, Training Acc : 0.961, Run Time : 0.40
INFO:root:2019-05-11 00:21:26, Epoch : 1, Step : 2173, Training Loss : 0.13965, Training Acc : 0.961, Run Time : 0.38
INFO:root:2019-05-11 00:21:26, Epoch : 1, Step : 2174, Training Loss : 0.13428, Training Acc : 0.967, Run Time : 0.38
INFO:root:2019-05-11 00:21:28, Epoch : 1, Step : 2175, Training Loss : 0.07256, Training Acc : 1.000, Run Time : 1.74
INFO:root:2019-05-11 00:21:28, Epoch : 1, Step : 2176, Training Loss : 0.10338, Training Acc : 0.972, Run Time : 0.43
INFO:root:2019-05-11 00:21:29, Epoch : 1, Step : 2177, Training Loss : 0.17428, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 00:21:31, Epoch : 1, Step : 2178, Training Loss : 0.08915, Training Acc : 0.983, Run Time : 2.16
INFO:root:2019-05-11 00:21:35, Epoch : 1, Step : 2179, Training Loss : 0.12917, Training Acc : 0.961, Run Time : 3.81
INFO:root:2019-05-11 00:21:35, Epoch : 1, Step : 2180, Training Loss : 0.23764, Training Acc : 0.883, Run Time : 0.40
INFO:root:2019-05-11 00:21:35, Epoch : 1, Step : 2181, Training Loss : 0.22329, Training Acc : 0.911, Run Time : 0.49
INFO:root:2019-05-11 00:21:36, Epoch : 1, Step : 2182, Training Loss : 0.25453, Training Acc : 0.889, Run Time : 0.50
INFO:root:2019-05-11 00:21:45, Epoch : 1, Step : 2183, Training Loss : 0.09021, Training Acc : 0.978, Run Time : 8.89
INFO:root:2019-05-11 00:21:45, Epoch : 1, Step : 2184, Training Loss : 0.09257, Training Acc : 0.989, Run Time : 0.60
INFO:root:2019-05-11 00:21:46, Epoch : 1, Step : 2185, Training Loss : 0.13631, Training Acc : 0.950, Run Time : 0.73
INFO:root:2019-05-11 00:21:55, Epoch : 1, Step : 2186, Training Loss : 0.19936, Training Acc : 0.922, Run Time : 8.65
INFO:root:2019-05-11 00:21:55, Epoch : 1, Step : 2187, Training Loss : 0.09653, Training Acc : 0.978, Run Time : 0.55
INFO:root:2019-05-11 00:21:56, Epoch : 1, Step : 2188, Training Loss : 0.11341, Training Acc : 0.967, Run Time : 0.50
INFO:root:2019-05-11 00:21:56, Epoch : 1, Step : 2189, Training Loss : 0.10342, Training Acc : 0.978, Run Time : 0.47
INFO:root:2019-05-11 00:22:05, Epoch : 1, Step : 2190, Training Loss : 0.09925, Training Acc : 0.972, Run Time : 8.96
INFO:root:2019-05-11 00:22:06, Epoch : 1, Step : 2191, Training Loss : 0.22309, Training Acc : 0.894, Run Time : 0.95
INFO:root:2019-05-11 00:22:07, Epoch : 1, Step : 2192, Training Loss : 0.14351, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 00:22:08, Epoch : 1, Step : 2193, Training Loss : 0.04493, Training Acc : 1.000, Run Time : 1.84
INFO:root:2019-05-11 00:22:19, Epoch : 1, Step : 2194, Training Loss : 0.11461, Training Acc : 0.961, Run Time : 10.54
INFO:root:2019-05-11 00:22:19, Epoch : 1, Step : 2195, Training Loss : 0.15473, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-11 00:22:20, Epoch : 1, Step : 2196, Training Loss : 0.06107, Training Acc : 0.989, Run Time : 0.53
INFO:root:2019-05-11 00:22:21, Epoch : 1, Step : 2197, Training Loss : 0.18420, Training Acc : 0.911, Run Time : 1.14
INFO:root:2019-05-11 00:22:29, Epoch : 1, Step : 2198, Training Loss : 0.14910, Training Acc : 0.933, Run Time : 8.28
INFO:root:2019-05-11 00:22:30, Epoch : 1, Step : 2199, Training Loss : 0.10121, Training Acc : 0.972, Run Time : 0.42
INFO:root:2019-05-11 00:22:30, Epoch : 1, Step : 2200, Training Loss : 0.27161, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-11 00:22:41, Epoch : 1, Step : 2201, Training Loss : 1.33261, Training Acc : 0.517, Run Time : 10.78
INFO:root:2019-05-11 00:22:41, Epoch : 1, Step : 2202, Training Loss : 1.16497, Training Acc : 0.622, Run Time : 0.47
INFO:root:2019-05-11 00:22:42, Epoch : 1, Step : 2203, Training Loss : 1.02123, Training Acc : 0.656, Run Time : 0.37
INFO:root:2019-05-11 00:22:43, Epoch : 1, Step : 2204, Training Loss : 1.00333, Training Acc : 0.644, Run Time : 1.04
INFO:root:2019-05-11 00:22:45, Epoch : 1, Step : 2205, Training Loss : 0.71869, Training Acc : 0.717, Run Time : 1.91
INFO:root:2019-05-11 00:22:45, Epoch : 1, Step : 2206, Training Loss : 0.64106, Training Acc : 0.711, Run Time : 0.37
INFO:root:2019-05-11 00:22:46, Epoch : 1, Step : 2207, Training Loss : 0.58790, Training Acc : 0.733, Run Time : 0.56
INFO:root:2019-05-11 00:22:49, Epoch : 1, Step : 2208, Training Loss : 0.78703, Training Acc : 0.678, Run Time : 3.05
INFO:root:2019-05-11 00:22:49, Epoch : 1, Step : 2209, Training Loss : 0.41686, Training Acc : 0.828, Run Time : 0.51
INFO:root:2019-05-11 00:22:58, Epoch : 1, Step : 2210, Training Loss : 0.38073, Training Acc : 0.844, Run Time : 8.47
INFO:root:2019-05-11 00:22:59, Epoch : 1, Step : 2211, Training Loss : 0.53657, Training Acc : 0.794, Run Time : 0.85
INFO:root:2019-05-11 00:22:59, Epoch : 1, Step : 2212, Training Loss : 0.55293, Training Acc : 0.789, Run Time : 0.61
INFO:root:2019-05-11 00:23:00, Epoch : 1, Step : 2213, Training Loss : 0.51166, Training Acc : 0.767, Run Time : 0.38
INFO:root:2019-05-11 00:23:06, Epoch : 1, Step : 2214, Training Loss : 0.75930, Training Acc : 0.744, Run Time : 6.87
INFO:root:2019-05-11 00:23:07, Epoch : 1, Step : 2215, Training Loss : 0.62037, Training Acc : 0.744, Run Time : 0.73
INFO:root:2019-05-11 00:23:08, Epoch : 1, Step : 2216, Training Loss : 0.47779, Training Acc : 0.767, Run Time : 0.37
INFO:root:2019-05-11 00:23:08, Epoch : 1, Step : 2217, Training Loss : 0.52598, Training Acc : 0.728, Run Time : 0.40
INFO:root:2019-05-11 00:23:09, Epoch : 1, Step : 2218, Training Loss : 0.64935, Training Acc : 0.700, Run Time : 0.61
INFO:root:2019-05-11 00:23:17, Epoch : 1, Step : 2219, Training Loss : 0.63803, Training Acc : 0.739, Run Time : 8.61
INFO:root:2019-05-11 00:23:18, Epoch : 1, Step : 2220, Training Loss : 0.54082, Training Acc : 0.750, Run Time : 1.33
INFO:root:2019-05-11 00:23:19, Epoch : 1, Step : 2221, Training Loss : 0.47284, Training Acc : 0.739, Run Time : 0.42
INFO:root:2019-05-11 00:23:19, Epoch : 1, Step : 2222, Training Loss : 0.44107, Training Acc : 0.744, Run Time : 0.42
INFO:root:2019-05-11 00:23:20, Epoch : 1, Step : 2223, Training Loss : 0.42257, Training Acc : 0.789, Run Time : 0.75
INFO:root:2019-05-11 00:23:26, Epoch : 1, Step : 2224, Training Loss : 0.33557, Training Acc : 0.828, Run Time : 6.25
INFO:root:2019-05-11 00:23:27, Epoch : 1, Step : 2225, Training Loss : 0.53437, Training Acc : 0.667, Run Time : 0.41
INFO:root:2019-05-11 00:23:27, Epoch : 1, Step : 2226, Training Loss : 0.31968, Training Acc : 0.839, Run Time : 0.59
INFO:root:2019-05-11 00:23:28, Epoch : 1, Step : 2227, Training Loss : 0.25117, Training Acc : 0.894, Run Time : 0.39
INFO:root:2019-05-11 00:23:28, Epoch : 1, Step : 2228, Training Loss : 0.36295, Training Acc : 0.833, Run Time : 0.60
INFO:root:2019-05-11 00:23:36, Epoch : 1, Step : 2229, Training Loss : 0.34744, Training Acc : 0.833, Run Time : 7.92
INFO:root:2019-05-11 00:23:37, Epoch : 1, Step : 2230, Training Loss : 0.35872, Training Acc : 0.856, Run Time : 0.57
INFO:root:2019-05-11 00:23:37, Epoch : 1, Step : 2231, Training Loss : 0.41532, Training Acc : 0.800, Run Time : 0.37
INFO:root:2019-05-11 00:23:38, Epoch : 1, Step : 2232, Training Loss : 0.40617, Training Acc : 0.822, Run Time : 0.54
INFO:root:2019-05-11 00:23:42, Epoch : 1, Step : 2233, Training Loss : 0.48861, Training Acc : 0.783, Run Time : 4.51
INFO:root:2019-05-11 00:23:43, Epoch : 1, Step : 2234, Training Loss : 0.60253, Training Acc : 0.717, Run Time : 0.40
INFO:root:2019-05-11 00:23:43, Epoch : 1, Step : 2235, Training Loss : 0.41878, Training Acc : 0.828, Run Time : 0.38
INFO:root:2019-05-11 00:23:44, Epoch : 1, Step : 2236, Training Loss : 0.40018, Training Acc : 0.806, Run Time : 1.47
INFO:root:2019-05-11 00:23:52, Epoch : 1, Step : 2237, Training Loss : 0.37183, Training Acc : 0.850, Run Time : 7.44
INFO:root:2019-05-11 00:23:52, Epoch : 1, Step : 2238, Training Loss : 0.40230, Training Acc : 0.811, Run Time : 0.48
INFO:root:2019-05-11 00:23:53, Epoch : 1, Step : 2239, Training Loss : 0.93555, Training Acc : 0.589, Run Time : 0.39
INFO:root:2019-05-11 00:23:58, Epoch : 1, Step : 2240, Training Loss : 0.73157, Training Acc : 0.594, Run Time : 4.94
INFO:root:2019-05-11 00:23:58, Epoch : 1, Step : 2241, Training Loss : 0.63771, Training Acc : 0.644, Run Time : 0.74
INFO:root:2019-05-11 00:23:59, Epoch : 1, Step : 2242, Training Loss : 0.45164, Training Acc : 0.783, Run Time : 0.54
INFO:root:2019-05-11 00:23:59, Epoch : 1, Step : 2243, Training Loss : 0.37602, Training Acc : 0.828, Run Time : 0.39
INFO:root:2019-05-11 00:24:00, Epoch : 1, Step : 2244, Training Loss : 0.36593, Training Acc : 0.839, Run Time : 0.38
INFO:root:2019-05-11 00:24:07, Epoch : 1, Step : 2245, Training Loss : 0.31670, Training Acc : 0.894, Run Time : 6.84
INFO:root:2019-05-11 00:24:08, Epoch : 1, Step : 2246, Training Loss : 0.36509, Training Acc : 0.828, Run Time : 1.29
INFO:root:2019-05-11 00:24:08, Epoch : 1, Step : 2247, Training Loss : 0.43837, Training Acc : 0.772, Run Time : 0.41
INFO:root:2019-05-11 00:24:16, Epoch : 1, Step : 2248, Training Loss : 0.36916, Training Acc : 0.850, Run Time : 8.09
INFO:root:2019-05-11 00:24:17, Epoch : 1, Step : 2249, Training Loss : 0.59412, Training Acc : 0.661, Run Time : 0.41
INFO:root:2019-05-11 00:24:17, Epoch : 1, Step : 2250, Training Loss : 0.40607, Training Acc : 0.811, Run Time : 0.67
INFO:root:2019-05-11 00:24:30, Epoch : 1, Step : 2251, Training Loss : 0.31347, Training Acc : 0.883, Run Time : 12.78
INFO:root:2019-05-11 00:24:31, Epoch : 1, Step : 2252, Training Loss : 0.39465, Training Acc : 0.839, Run Time : 0.80
INFO:root:2019-05-11 00:24:31, Epoch : 1, Step : 2253, Training Loss : 0.28352, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-11 00:24:32, Epoch : 1, Step : 2254, Training Loss : 0.30375, Training Acc : 0.883, Run Time : 0.87
INFO:root:2019-05-11 00:24:40, Epoch : 1, Step : 2255, Training Loss : 0.48315, Training Acc : 0.800, Run Time : 7.71
INFO:root:2019-05-11 00:24:41, Epoch : 1, Step : 2256, Training Loss : 0.46720, Training Acc : 0.761, Run Time : 0.69
INFO:root:2019-05-11 00:24:41, Epoch : 1, Step : 2257, Training Loss : 0.43301, Training Acc : 0.767, Run Time : 0.40
INFO:root:2019-05-11 00:24:42, Epoch : 1, Step : 2258, Training Loss : 0.39729, Training Acc : 0.800, Run Time : 0.83
INFO:root:2019-05-11 00:24:48, Epoch : 1, Step : 2259, Training Loss : 0.45738, Training Acc : 0.767, Run Time : 6.48
INFO:root:2019-05-11 00:24:49, Epoch : 1, Step : 2260, Training Loss : 0.39672, Training Acc : 0.811, Run Time : 0.60
INFO:root:2019-05-11 00:24:49, Epoch : 1, Step : 2261, Training Loss : 0.45425, Training Acc : 0.756, Run Time : 0.39
INFO:root:2019-05-11 00:24:50, Epoch : 1, Step : 2262, Training Loss : 0.40974, Training Acc : 0.778, Run Time : 0.79
INFO:root:2019-05-11 00:24:59, Epoch : 1, Step : 2263, Training Loss : 0.42452, Training Acc : 0.811, Run Time : 8.77
INFO:root:2019-05-11 00:25:00, Epoch : 1, Step : 2264, Training Loss : 0.34785, Training Acc : 0.911, Run Time : 0.55
INFO:root:2019-05-11 00:25:00, Epoch : 1, Step : 2265, Training Loss : 0.36659, Training Acc : 0.861, Run Time : 0.39
INFO:root:2019-05-11 00:25:05, Epoch : 1, Step : 2266, Training Loss : 0.43974, Training Acc : 0.772, Run Time : 5.55
INFO:root:2019-05-11 00:25:06, Epoch : 1, Step : 2267, Training Loss : 0.31060, Training Acc : 0.856, Run Time : 0.77
INFO:root:2019-05-11 00:25:07, Epoch : 1, Step : 2268, Training Loss : 0.40474, Training Acc : 0.767, Run Time : 0.59
INFO:root:2019-05-11 00:25:08, Epoch : 1, Step : 2269, Training Loss : 0.38918, Training Acc : 0.778, Run Time : 1.01
INFO:root:2019-05-11 00:25:17, Epoch : 1, Step : 2270, Training Loss : 0.31690, Training Acc : 0.872, Run Time : 8.79
INFO:root:2019-05-11 00:25:17, Epoch : 1, Step : 2271, Training Loss : 0.40461, Training Acc : 0.794, Run Time : 0.41
INFO:root:2019-05-11 00:25:17, Epoch : 1, Step : 2272, Training Loss : 0.30647, Training Acc : 0.872, Run Time : 0.38
INFO:root:2019-05-11 00:25:18, Epoch : 1, Step : 2273, Training Loss : 0.42833, Training Acc : 0.789, Run Time : 0.38
INFO:root:2019-05-11 00:25:18, Epoch : 1, Step : 2274, Training Loss : 0.36815, Training Acc : 0.817, Run Time : 0.61
INFO:root:2019-05-11 00:25:26, Epoch : 1, Step : 2275, Training Loss : 0.30035, Training Acc : 0.883, Run Time : 7.85
INFO:root:2019-05-11 00:25:27, Epoch : 1, Step : 2276, Training Loss : 0.54050, Training Acc : 0.767, Run Time : 0.44
INFO:root:2019-05-11 00:25:27, Epoch : 1, Step : 2277, Training Loss : 0.30235, Training Acc : 0.889, Run Time : 0.39
INFO:root:2019-05-11 00:25:28, Epoch : 1, Step : 2278, Training Loss : 0.26781, Training Acc : 0.933, Run Time : 0.50
INFO:root:2019-05-11 00:25:35, Epoch : 1, Step : 2279, Training Loss : 0.33420, Training Acc : 0.844, Run Time : 7.18
INFO:root:2019-05-11 00:25:35, Epoch : 1, Step : 2280, Training Loss : 0.32676, Training Acc : 0.856, Run Time : 0.51
INFO:root:2019-05-11 00:25:36, Epoch : 1, Step : 2281, Training Loss : 0.23244, Training Acc : 0.917, Run Time : 0.39
INFO:root:2019-05-11 00:25:36, Epoch : 1, Step : 2282, Training Loss : 0.39731, Training Acc : 0.800, Run Time : 0.48
INFO:root:2019-05-11 00:25:37, Epoch : 1, Step : 2283, Training Loss : 0.34501, Training Acc : 0.822, Run Time : 0.40
INFO:root:2019-05-11 00:25:38, Epoch : 1, Step : 2284, Training Loss : 0.33448, Training Acc : 0.850, Run Time : 0.96
INFO:root:2019-05-11 00:25:48, Epoch : 1, Step : 2285, Training Loss : 0.24159, Training Acc : 0.922, Run Time : 10.77
INFO:root:2019-05-11 00:25:49, Epoch : 1, Step : 2286, Training Loss : 0.24892, Training Acc : 0.900, Run Time : 0.44
INFO:root:2019-05-11 00:25:49, Epoch : 1, Step : 2287, Training Loss : 0.20210, Training Acc : 0.928, Run Time : 0.44
INFO:root:2019-05-11 00:25:59, Epoch : 1, Step : 2288, Training Loss : 0.23452, Training Acc : 0.922, Run Time : 9.46
INFO:root:2019-05-11 00:25:59, Epoch : 1, Step : 2289, Training Loss : 0.40679, Training Acc : 0.778, Run Time : 0.41
INFO:root:2019-05-11 00:25:59, Epoch : 1, Step : 2290, Training Loss : 0.34818, Training Acc : 0.839, Run Time : 0.38
INFO:root:2019-05-11 00:26:00, Epoch : 1, Step : 2291, Training Loss : 0.40449, Training Acc : 0.828, Run Time : 0.38
INFO:root:2019-05-11 00:26:01, Epoch : 1, Step : 2292, Training Loss : 0.26687, Training Acc : 0.900, Run Time : 1.36
INFO:root:2019-05-11 00:26:07, Epoch : 1, Step : 2293, Training Loss : 0.33270, Training Acc : 0.828, Run Time : 5.62
INFO:root:2019-05-11 00:26:07, Epoch : 1, Step : 2294, Training Loss : 0.38050, Training Acc : 0.811, Run Time : 0.40
INFO:root:2019-05-11 00:26:08, Epoch : 1, Step : 2295, Training Loss : 0.43349, Training Acc : 0.794, Run Time : 0.40
INFO:root:2019-05-11 00:26:09, Epoch : 1, Step : 2296, Training Loss : 0.39186, Training Acc : 0.794, Run Time : 1.87
INFO:root:2019-05-11 00:26:17, Epoch : 1, Step : 2297, Training Loss : 0.33857, Training Acc : 0.844, Run Time : 8.05
INFO:root:2019-05-11 00:26:18, Epoch : 1, Step : 2298, Training Loss : 0.27245, Training Acc : 0.900, Run Time : 0.54
INFO:root:2019-05-11 00:26:19, Epoch : 1, Step : 2299, Training Loss : 0.47434, Training Acc : 0.761, Run Time : 0.58
INFO:root:2019-05-11 00:26:27, Epoch : 1, Step : 2300, Training Loss : 0.48277, Training Acc : 0.761, Run Time : 8.87
INFO:root:2019-05-11 00:26:29, Epoch : 1, Step : 2301, Training Loss : 0.39602, Training Acc : 0.778, Run Time : 1.51
INFO:root:2019-05-11 00:26:32, Epoch : 1, Step : 2302, Training Loss : 0.35391, Training Acc : 0.850, Run Time : 3.33
INFO:root:2019-05-11 00:26:33, Epoch : 1, Step : 2303, Training Loss : 0.37000, Training Acc : 0.856, Run Time : 0.89
INFO:root:2019-05-11 00:26:37, Epoch : 1, Step : 2304, Training Loss : 0.36053, Training Acc : 0.811, Run Time : 3.75
INFO:root:2019-05-11 00:26:45, Epoch : 1, Step : 2305, Training Loss : 0.37272, Training Acc : 0.800, Run Time : 8.23
INFO:root:2019-05-11 00:26:46, Epoch : 1, Step : 2306, Training Loss : 0.39354, Training Acc : 0.817, Run Time : 0.75
INFO:root:2019-05-11 00:26:46, Epoch : 1, Step : 2307, Training Loss : 0.61187, Training Acc : 0.756, Run Time : 0.54
INFO:root:2019-05-11 00:26:47, Epoch : 1, Step : 2308, Training Loss : 0.27370, Training Acc : 0.883, Run Time : 0.97
INFO:root:2019-05-11 00:26:57, Epoch : 1, Step : 2309, Training Loss : 0.33156, Training Acc : 0.844, Run Time : 9.39
INFO:root:2019-05-11 00:26:57, Epoch : 1, Step : 2310, Training Loss : 0.29217, Training Acc : 0.878, Run Time : 0.43
INFO:root:2019-05-11 00:26:58, Epoch : 1, Step : 2311, Training Loss : 0.40951, Training Acc : 0.817, Run Time : 0.42
INFO:root:2019-05-11 00:27:09, Epoch : 1, Step : 2312, Training Loss : 0.38352, Training Acc : 0.789, Run Time : 10.87
INFO:root:2019-05-11 00:27:09, Epoch : 1, Step : 2313, Training Loss : 0.43730, Training Acc : 0.800, Run Time : 0.40
INFO:root:2019-05-11 00:27:10, Epoch : 1, Step : 2314, Training Loss : 0.37926, Training Acc : 0.839, Run Time : 0.55
INFO:root:2019-05-11 00:27:21, Epoch : 1, Step : 2315, Training Loss : 0.22290, Training Acc : 0.928, Run Time : 11.50
INFO:root:2019-05-11 00:27:21, Epoch : 1, Step : 2316, Training Loss : 0.33342, Training Acc : 0.856, Run Time : 0.40
INFO:root:2019-05-11 00:27:22, Epoch : 1, Step : 2317, Training Loss : 0.31210, Training Acc : 0.856, Run Time : 0.38
INFO:root:2019-05-11 00:27:23, Epoch : 1, Step : 2318, Training Loss : 0.47320, Training Acc : 0.739, Run Time : 1.04
INFO:root:2019-05-11 00:27:30, Epoch : 1, Step : 2319, Training Loss : 0.66052, Training Acc : 0.639, Run Time : 7.41
INFO:root:2019-05-11 00:27:31, Epoch : 1, Step : 2320, Training Loss : 0.50840, Training Acc : 0.739, Run Time : 1.20
INFO:root:2019-05-11 00:27:32, Epoch : 1, Step : 2321, Training Loss : 0.35826, Training Acc : 0.833, Run Time : 0.82
INFO:root:2019-05-11 00:27:40, Epoch : 1, Step : 2322, Training Loss : 0.39189, Training Acc : 0.817, Run Time : 7.38
INFO:root:2019-05-11 00:27:40, Epoch : 1, Step : 2323, Training Loss : 0.38167, Training Acc : 0.789, Run Time : 0.64
INFO:root:2019-05-11 00:27:42, Epoch : 1, Step : 2324, Training Loss : 0.28994, Training Acc : 0.861, Run Time : 1.25
INFO:root:2019-05-11 00:27:42, Epoch : 1, Step : 2325, Training Loss : 0.28293, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 00:27:46, Epoch : 1, Step : 2326, Training Loss : 0.29954, Training Acc : 0.867, Run Time : 3.85
INFO:root:2019-05-11 00:27:46, Epoch : 1, Step : 2327, Training Loss : 0.28706, Training Acc : 0.878, Run Time : 0.64
INFO:root:2019-05-11 00:27:47, Epoch : 1, Step : 2328, Training Loss : 0.36039, Training Acc : 0.817, Run Time : 0.43
INFO:root:2019-05-11 00:27:47, Epoch : 1, Step : 2329, Training Loss : 0.32613, Training Acc : 0.828, Run Time : 0.37
INFO:root:2019-05-11 00:27:48, Epoch : 1, Step : 2330, Training Loss : 0.32275, Training Acc : 0.833, Run Time : 0.39
INFO:root:2019-05-11 00:27:48, Epoch : 1, Step : 2331, Training Loss : 0.28495, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-11 00:27:54, Epoch : 1, Step : 2332, Training Loss : 0.25317, Training Acc : 0.939, Run Time : 6.13
INFO:root:2019-05-11 00:27:55, Epoch : 1, Step : 2333, Training Loss : 0.27768, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 00:27:55, Epoch : 1, Step : 2334, Training Loss : 0.16104, Training Acc : 0.956, Run Time : 0.37
INFO:root:2019-05-11 00:27:56, Epoch : 1, Step : 2335, Training Loss : 0.25627, Training Acc : 0.872, Run Time : 1.32
INFO:root:2019-05-11 00:28:04, Epoch : 1, Step : 2336, Training Loss : 0.27341, Training Acc : 0.928, Run Time : 7.57
INFO:root:2019-05-11 00:28:04, Epoch : 1, Step : 2337, Training Loss : 0.25877, Training Acc : 0.861, Run Time : 0.60
INFO:root:2019-05-11 00:28:05, Epoch : 1, Step : 2338, Training Loss : 0.20826, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 00:28:06, Epoch : 1, Step : 2339, Training Loss : 0.16806, Training Acc : 0.961, Run Time : 1.35
INFO:root:2019-05-11 00:28:13, Epoch : 1, Step : 2340, Training Loss : 0.25868, Training Acc : 0.889, Run Time : 7.18
INFO:root:2019-05-11 00:28:14, Epoch : 1, Step : 2341, Training Loss : 0.20439, Training Acc : 0.944, Run Time : 0.59
INFO:root:2019-05-11 00:28:16, Epoch : 1, Step : 2342, Training Loss : 0.25722, Training Acc : 0.894, Run Time : 1.80
INFO:root:2019-05-11 00:28:22, Epoch : 1, Step : 2343, Training Loss : 0.38887, Training Acc : 0.844, Run Time : 5.89
INFO:root:2019-05-11 00:28:23, Epoch : 1, Step : 2344, Training Loss : 0.30606, Training Acc : 0.878, Run Time : 1.54
INFO:root:2019-05-11 00:28:24, Epoch : 1, Step : 2345, Training Loss : 0.51203, Training Acc : 0.778, Run Time : 0.41
INFO:root:2019-05-11 00:28:24, Epoch : 1, Step : 2346, Training Loss : 0.60865, Training Acc : 0.744, Run Time : 0.78
INFO:root:2019-05-11 00:28:31, Epoch : 1, Step : 2347, Training Loss : 0.49422, Training Acc : 0.783, Run Time : 6.86
INFO:root:2019-05-11 00:28:33, Epoch : 1, Step : 2348, Training Loss : 0.53325, Training Acc : 0.733, Run Time : 1.79
INFO:root:2019-05-11 00:28:38, Epoch : 1, Step : 2349, Training Loss : 0.34475, Training Acc : 0.894, Run Time : 4.78
INFO:root:2019-05-11 00:28:38, Epoch : 1, Step : 2350, Training Loss : 0.26478, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-11 00:28:39, Epoch : 1, Step : 2351, Training Loss : 0.46068, Training Acc : 0.744, Run Time : 0.38
INFO:root:2019-05-11 00:28:39, Epoch : 1, Step : 2352, Training Loss : 0.36805, Training Acc : 0.800, Run Time : 0.54
INFO:root:2019-05-11 00:28:43, Epoch : 1, Step : 2353, Training Loss : 0.34716, Training Acc : 0.844, Run Time : 4.05
INFO:root:2019-05-11 00:28:44, Epoch : 1, Step : 2354, Training Loss : 0.41889, Training Acc : 0.767, Run Time : 0.75
INFO:root:2019-05-11 00:28:44, Epoch : 1, Step : 2355, Training Loss : 0.37459, Training Acc : 0.794, Run Time : 0.53
INFO:root:2019-05-11 00:28:52, Epoch : 1, Step : 2356, Training Loss : 0.54688, Training Acc : 0.733, Run Time : 7.82
INFO:root:2019-05-11 00:28:53, Epoch : 1, Step : 2357, Training Loss : 0.51438, Training Acc : 0.733, Run Time : 0.57
INFO:root:2019-05-11 00:28:53, Epoch : 1, Step : 2358, Training Loss : 0.91564, Training Acc : 0.589, Run Time : 0.38
INFO:root:2019-05-11 00:28:54, Epoch : 1, Step : 2359, Training Loss : 0.43050, Training Acc : 0.783, Run Time : 0.38
INFO:root:2019-05-11 00:28:55, Epoch : 1, Step : 2360, Training Loss : 0.57933, Training Acc : 0.689, Run Time : 1.14
INFO:root:2019-05-11 00:29:05, Epoch : 1, Step : 2361, Training Loss : 0.40285, Training Acc : 0.794, Run Time : 10.07
INFO:root:2019-05-11 00:29:05, Epoch : 1, Step : 2362, Training Loss : 0.53965, Training Acc : 0.717, Run Time : 0.59
INFO:root:2019-05-11 00:29:06, Epoch : 1, Step : 2363, Training Loss : 0.68944, Training Acc : 0.594, Run Time : 0.39
INFO:root:2019-05-11 00:29:08, Epoch : 1, Step : 2364, Training Loss : 0.35437, Training Acc : 0.839, Run Time : 2.01
INFO:root:2019-05-11 00:29:20, Epoch : 1, Step : 2365, Training Loss : 0.37160, Training Acc : 0.850, Run Time : 12.45
INFO:root:2019-05-11 00:29:21, Epoch : 1, Step : 2366, Training Loss : 0.43354, Training Acc : 0.822, Run Time : 0.48
INFO:root:2019-05-11 00:29:21, Epoch : 1, Step : 2367, Training Loss : 0.32137, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-11 00:29:22, Epoch : 1, Step : 2368, Training Loss : 0.50176, Training Acc : 0.794, Run Time : 0.65
INFO:root:2019-05-11 00:29:26, Epoch : 1, Step : 2369, Training Loss : 0.36139, Training Acc : 0.800, Run Time : 4.26
INFO:root:2019-05-11 00:29:26, Epoch : 1, Step : 2370, Training Loss : 0.41256, Training Acc : 0.806, Run Time : 0.40
INFO:root:2019-05-11 00:29:27, Epoch : 1, Step : 2371, Training Loss : 0.29282, Training Acc : 0.889, Run Time : 0.81
INFO:root:2019-05-11 00:29:35, Epoch : 1, Step : 2372, Training Loss : 0.44065, Training Acc : 0.778, Run Time : 7.38
INFO:root:2019-05-11 00:29:35, Epoch : 1, Step : 2373, Training Loss : 0.34763, Training Acc : 0.872, Run Time : 0.40
INFO:root:2019-05-11 00:29:36, Epoch : 1, Step : 2374, Training Loss : 0.44038, Training Acc : 0.761, Run Time : 0.51
INFO:root:2019-05-11 00:29:37, Epoch : 1, Step : 2375, Training Loss : 0.32192, Training Acc : 0.844, Run Time : 1.11
INFO:root:2019-05-11 00:29:44, Epoch : 1, Step : 2376, Training Loss : 0.30090, Training Acc : 0.894, Run Time : 7.33
INFO:root:2019-05-11 00:29:44, Epoch : 1, Step : 2377, Training Loss : 0.34862, Training Acc : 0.844, Run Time : 0.41
INFO:root:2019-05-11 00:29:45, Epoch : 1, Step : 2378, Training Loss : 0.35554, Training Acc : 0.856, Run Time : 0.48
INFO:root:2019-05-11 00:29:49, Epoch : 1, Step : 2379, Training Loss : 0.30284, Training Acc : 0.883, Run Time : 4.03
INFO:root:2019-05-11 00:29:50, Epoch : 1, Step : 2380, Training Loss : 0.27172, Training Acc : 0.872, Run Time : 0.82
INFO:root:2019-05-11 00:29:50, Epoch : 1, Step : 2381, Training Loss : 0.23624, Training Acc : 0.911, Run Time : 0.54
INFO:root:2019-05-11 00:30:00, Epoch : 1, Step : 2382, Training Loss : 0.28245, Training Acc : 0.906, Run Time : 9.29
INFO:root:2019-05-11 00:30:00, Epoch : 1, Step : 2383, Training Loss : 0.28368, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-11 00:30:00, Epoch : 1, Step : 2384, Training Loss : 0.30951, Training Acc : 0.878, Run Time : 0.43
INFO:root:2019-05-11 00:30:01, Epoch : 1, Step : 2385, Training Loss : 0.29299, Training Acc : 0.867, Run Time : 0.40
INFO:root:2019-05-11 00:30:01, Epoch : 1, Step : 2386, Training Loss : 0.43515, Training Acc : 0.828, Run Time : 0.52
INFO:root:2019-05-11 00:30:07, Epoch : 1, Step : 2387, Training Loss : 0.45578, Training Acc : 0.750, Run Time : 5.51
INFO:root:2019-05-11 00:30:07, Epoch : 1, Step : 2388, Training Loss : 0.41469, Training Acc : 0.800, Run Time : 0.40
INFO:root:2019-05-11 00:30:08, Epoch : 1, Step : 2389, Training Loss : 0.48863, Training Acc : 0.756, Run Time : 0.44
INFO:root:2019-05-11 00:30:09, Epoch : 1, Step : 2390, Training Loss : 0.43994, Training Acc : 0.811, Run Time : 1.11
INFO:root:2019-05-11 00:30:17, Epoch : 1, Step : 2391, Training Loss : 0.41392, Training Acc : 0.806, Run Time : 7.72
INFO:root:2019-05-11 00:30:17, Epoch : 1, Step : 2392, Training Loss : 0.37615, Training Acc : 0.817, Run Time : 0.46
INFO:root:2019-05-11 00:30:18, Epoch : 1, Step : 2393, Training Loss : 0.42602, Training Acc : 0.783, Run Time : 0.61
INFO:root:2019-05-11 00:30:25, Epoch : 1, Step : 2394, Training Loss : 0.41454, Training Acc : 0.811, Run Time : 7.79
INFO:root:2019-05-11 00:30:26, Epoch : 1, Step : 2395, Training Loss : 0.35995, Training Acc : 0.800, Run Time : 0.50
INFO:root:2019-05-11 00:30:26, Epoch : 1, Step : 2396, Training Loss : 0.32958, Training Acc : 0.839, Run Time : 0.59
INFO:root:2019-05-11 00:30:29, Epoch : 1, Step : 2397, Training Loss : 0.37080, Training Acc : 0.811, Run Time : 2.48
INFO:root:2019-05-11 00:30:33, Epoch : 1, Step : 2398, Training Loss : 0.27437, Training Acc : 0.828, Run Time : 3.94
INFO:root:2019-05-11 00:30:35, Epoch : 1, Step : 2399, Training Loss : 0.24125, Training Acc : 0.906, Run Time : 1.77
INFO:root:2019-05-11 00:30:43, Epoch : 1, Step : 2400, Training Loss : 0.25575, Training Acc : 0.839, Run Time : 8.28
INFO:root:2019-05-11 00:30:44, Epoch : 1, Step : 2401, Training Loss : 0.25552, Training Acc : 0.861, Run Time : 0.87
INFO:root:2019-05-11 00:30:45, Epoch : 1, Step : 2402, Training Loss : 0.41179, Training Acc : 0.789, Run Time : 1.51
INFO:root:2019-05-11 00:30:52, Epoch : 1, Step : 2403, Training Loss : 0.28830, Training Acc : 0.828, Run Time : 6.59
INFO:root:2019-05-11 00:30:52, Epoch : 1, Step : 2404, Training Loss : 0.25165, Training Acc : 0.878, Run Time : 0.43
INFO:root:2019-05-11 00:30:53, Epoch : 1, Step : 2405, Training Loss : 0.29866, Training Acc : 0.839, Run Time : 0.77
INFO:root:2019-05-11 00:30:54, Epoch : 1, Step : 2406, Training Loss : 0.39024, Training Acc : 0.794, Run Time : 1.31
INFO:root:2019-05-11 00:31:02, Epoch : 1, Step : 2407, Training Loss : 0.35617, Training Acc : 0.828, Run Time : 7.10
INFO:root:2019-05-11 00:31:02, Epoch : 1, Step : 2408, Training Loss : 0.48419, Training Acc : 0.767, Run Time : 0.71
INFO:root:2019-05-11 00:31:03, Epoch : 1, Step : 2409, Training Loss : 0.42069, Training Acc : 0.783, Run Time : 0.40
INFO:root:2019-05-11 00:31:03, Epoch : 1, Step : 2410, Training Loss : 0.53621, Training Acc : 0.750, Run Time : 0.69
INFO:root:2019-05-11 00:31:09, Epoch : 1, Step : 2411, Training Loss : 0.39717, Training Acc : 0.783, Run Time : 5.26
INFO:root:2019-05-11 00:31:10, Epoch : 1, Step : 2412, Training Loss : 0.57688, Training Acc : 0.744, Run Time : 0.98
INFO:root:2019-05-11 00:31:10, Epoch : 1, Step : 2413, Training Loss : 0.31509, Training Acc : 0.839, Run Time : 0.67
INFO:root:2019-05-11 00:31:17, Epoch : 1, Step : 2414, Training Loss : 0.26841, Training Acc : 0.867, Run Time : 6.85
INFO:root:2019-05-11 00:31:18, Epoch : 1, Step : 2415, Training Loss : 0.35919, Training Acc : 0.828, Run Time : 1.08
INFO:root:2019-05-11 00:31:19, Epoch : 1, Step : 2416, Training Loss : 0.28662, Training Acc : 0.867, Run Time : 0.42
INFO:root:2019-05-11 00:31:28, Epoch : 1, Step : 2417, Training Loss : 0.29952, Training Acc : 0.894, Run Time : 9.29
INFO:root:2019-05-11 00:31:30, Epoch : 1, Step : 2418, Training Loss : 0.51431, Training Acc : 0.750, Run Time : 2.29
INFO:root:2019-05-11 00:31:31, Epoch : 1, Step : 2419, Training Loss : 0.55994, Training Acc : 0.717, Run Time : 0.42
INFO:root:2019-05-11 00:31:31, Epoch : 1, Step : 2420, Training Loss : 0.29696, Training Acc : 0.844, Run Time : 0.41
INFO:root:2019-05-11 00:31:31, Epoch : 1, Step : 2421, Training Loss : 0.25600, Training Acc : 0.894, Run Time : 0.44
INFO:root:2019-05-11 00:31:37, Epoch : 1, Step : 2422, Training Loss : 0.43607, Training Acc : 0.789, Run Time : 5.54
INFO:root:2019-05-11 00:31:37, Epoch : 1, Step : 2423, Training Loss : 0.17670, Training Acc : 0.928, Run Time : 0.52
INFO:root:2019-05-11 00:31:38, Epoch : 1, Step : 2424, Training Loss : 0.21004, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-11 00:31:39, Epoch : 1, Step : 2425, Training Loss : 0.32986, Training Acc : 0.844, Run Time : 0.83
INFO:root:2019-05-11 00:31:44, Epoch : 1, Step : 2426, Training Loss : 0.42208, Training Acc : 0.767, Run Time : 5.10
INFO:root:2019-05-11 00:31:45, Epoch : 1, Step : 2427, Training Loss : 0.13644, Training Acc : 0.956, Run Time : 0.73
INFO:root:2019-05-11 00:31:45, Epoch : 1, Step : 2428, Training Loss : 0.19437, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-11 00:31:45, Epoch : 1, Step : 2429, Training Loss : 0.42862, Training Acc : 0.811, Run Time : 0.53
INFO:root:2019-05-11 00:31:46, Epoch : 1, Step : 2430, Training Loss : 0.19915, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 00:31:47, Epoch : 1, Step : 2431, Training Loss : 0.36045, Training Acc : 0.850, Run Time : 0.89
INFO:root:2019-05-11 00:31:52, Epoch : 1, Step : 2432, Training Loss : 0.23488, Training Acc : 0.917, Run Time : 5.17
INFO:root:2019-05-11 00:31:52, Epoch : 1, Step : 2433, Training Loss : 0.24971, Training Acc : 0.922, Run Time : 0.57
INFO:root:2019-05-11 00:31:53, Epoch : 1, Step : 2434, Training Loss : 0.15369, Training Acc : 0.956, Run Time : 0.45
INFO:root:2019-05-11 00:32:01, Epoch : 1, Step : 2435, Training Loss : 0.29097, Training Acc : 0.900, Run Time : 8.27
INFO:root:2019-05-11 00:32:02, Epoch : 1, Step : 2436, Training Loss : 0.33052, Training Acc : 0.900, Run Time : 0.80
INFO:root:2019-05-11 00:32:02, Epoch : 1, Step : 2437, Training Loss : 0.29462, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-11 00:32:03, Epoch : 1, Step : 2438, Training Loss : 0.29046, Training Acc : 0.889, Run Time : 0.86
INFO:root:2019-05-11 00:32:10, Epoch : 1, Step : 2439, Training Loss : 0.23208, Training Acc : 0.922, Run Time : 6.69
INFO:root:2019-05-11 00:32:11, Epoch : 1, Step : 2440, Training Loss : 0.39826, Training Acc : 0.889, Run Time : 0.58
INFO:root:2019-05-11 00:32:11, Epoch : 1, Step : 2441, Training Loss : 0.28641, Training Acc : 0.883, Run Time : 0.43
INFO:root:2019-05-11 00:32:16, Epoch : 1, Step : 2442, Training Loss : 0.24111, Training Acc : 0.911, Run Time : 5.49
INFO:root:2019-05-11 00:32:17, Epoch : 1, Step : 2443, Training Loss : 0.25736, Training Acc : 0.900, Run Time : 0.86
INFO:root:2019-05-11 00:32:18, Epoch : 1, Step : 2444, Training Loss : 0.32685, Training Acc : 0.878, Run Time : 0.70
INFO:root:2019-05-11 00:32:18, Epoch : 1, Step : 2445, Training Loss : 0.24660, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-11 00:32:19, Epoch : 1, Step : 2446, Training Loss : 0.25630, Training Acc : 0.889, Run Time : 0.85
INFO:root:2019-05-11 00:32:20, Epoch : 1, Step : 2447, Training Loss : 0.20866, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-11 00:32:20, Epoch : 1, Step : 2448, Training Loss : 0.33842, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 00:32:21, Epoch : 1, Step : 2449, Training Loss : 0.32216, Training Acc : 0.867, Run Time : 0.82
INFO:root:2019-05-11 00:32:29, Epoch : 1, Step : 2450, Training Loss : 0.50974, Training Acc : 0.783, Run Time : 8.08
INFO:root:2019-05-11 00:32:30, Epoch : 1, Step : 2451, Training Loss : 0.22293, Training Acc : 0.900, Run Time : 0.54
INFO:root:2019-05-11 00:32:30, Epoch : 1, Step : 2452, Training Loss : 0.21240, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-11 00:32:38, Epoch : 1, Step : 2453, Training Loss : 0.20796, Training Acc : 0.917, Run Time : 8.37
INFO:root:2019-05-11 00:32:39, Epoch : 1, Step : 2454, Training Loss : 0.22909, Training Acc : 0.950, Run Time : 0.66
INFO:root:2019-05-11 00:32:39, Epoch : 1, Step : 2455, Training Loss : 0.21348, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-11 00:32:40, Epoch : 1, Step : 2456, Training Loss : 0.23465, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-11 00:32:44, Epoch : 1, Step : 2457, Training Loss : 0.26519, Training Acc : 0.906, Run Time : 4.10
INFO:root:2019-05-11 00:32:44, Epoch : 1, Step : 2458, Training Loss : 0.26564, Training Acc : 0.894, Run Time : 0.41
INFO:root:2019-05-11 00:32:45, Epoch : 1, Step : 2459, Training Loss : 0.20951, Training Acc : 0.922, Run Time : 0.40
INFO:root:2019-05-11 00:32:45, Epoch : 1, Step : 2460, Training Loss : 0.19258, Training Acc : 0.939, Run Time : 0.53
INFO:root:2019-05-11 00:32:54, Epoch : 1, Step : 2461, Training Loss : 0.57500, Training Acc : 0.783, Run Time : 9.24
INFO:root:2019-05-11 00:32:55, Epoch : 1, Step : 2462, Training Loss : 0.90552, Training Acc : 0.683, Run Time : 0.56
INFO:root:2019-05-11 00:32:56, Epoch : 1, Step : 2463, Training Loss : 0.93850, Training Acc : 0.717, Run Time : 0.87
INFO:root:2019-05-11 00:33:05, Epoch : 1, Step : 2464, Training Loss : 0.93017, Training Acc : 0.633, Run Time : 9.22
INFO:root:2019-05-11 00:33:06, Epoch : 1, Step : 2465, Training Loss : 0.78154, Training Acc : 0.728, Run Time : 1.11
INFO:root:2019-05-11 00:33:07, Epoch : 1, Step : 2466, Training Loss : 0.57555, Training Acc : 0.789, Run Time : 0.56
INFO:root:2019-05-11 00:33:15, Epoch : 1, Step : 2467, Training Loss : 0.48411, Training Acc : 0.783, Run Time : 7.78
INFO:root:2019-05-11 00:33:15, Epoch : 1, Step : 2468, Training Loss : 0.57308, Training Acc : 0.778, Run Time : 0.71
INFO:root:2019-05-11 00:33:16, Epoch : 1, Step : 2469, Training Loss : 0.37621, Training Acc : 0.833, Run Time : 0.38
INFO:root:2019-05-11 00:33:16, Epoch : 1, Step : 2470, Training Loss : 0.33988, Training Acc : 0.817, Run Time : 0.74
INFO:root:2019-05-11 00:33:26, Epoch : 1, Step : 2471, Training Loss : 0.23882, Training Acc : 0.917, Run Time : 9.59
INFO:root:2019-05-11 00:33:26, Epoch : 1, Step : 2472, Training Loss : 0.22372, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-11 00:33:27, Epoch : 1, Step : 2473, Training Loss : 0.26957, Training Acc : 0.917, Run Time : 0.47
INFO:root:2019-05-11 00:33:28, Epoch : 1, Step : 2474, Training Loss : 0.21306, Training Acc : 0.911, Run Time : 1.21
INFO:root:2019-05-11 00:33:34, Epoch : 1, Step : 2475, Training Loss : 0.39704, Training Acc : 0.844, Run Time : 6.44
INFO:root:2019-05-11 00:33:35, Epoch : 1, Step : 2476, Training Loss : 0.43774, Training Acc : 0.767, Run Time : 0.40
INFO:root:2019-05-11 00:33:36, Epoch : 1, Step : 2477, Training Loss : 0.43425, Training Acc : 0.783, Run Time : 0.81
INFO:root:2019-05-11 00:33:37, Epoch : 1, Step : 2478, Training Loss : 0.23652, Training Acc : 0.900, Run Time : 0.81
INFO:root:2019-05-11 00:33:38, Epoch : 1, Step : 2479, Training Loss : 0.38979, Training Acc : 0.817, Run Time : 1.01
INFO:root:2019-05-11 00:33:39, Epoch : 1, Step : 2480, Training Loss : 0.33978, Training Acc : 0.822, Run Time : 0.97
INFO:root:2019-05-11 00:33:39, Epoch : 1, Step : 2481, Training Loss : 0.33041, Training Acc : 0.839, Run Time : 0.38
INFO:root:2019-05-11 00:33:44, Epoch : 1, Step : 2482, Training Loss : 0.39544, Training Acc : 0.789, Run Time : 5.22
INFO:root:2019-05-11 00:33:45, Epoch : 1, Step : 2483, Training Loss : 0.35682, Training Acc : 0.850, Run Time : 0.80
INFO:root:2019-05-11 00:33:45, Epoch : 1, Step : 2484, Training Loss : 0.24310, Training Acc : 0.850, Run Time : 0.37
INFO:root:2019-05-11 00:33:47, Epoch : 1, Step : 2485, Training Loss : 0.26887, Training Acc : 0.883, Run Time : 1.86
INFO:root:2019-05-11 00:33:56, Epoch : 1, Step : 2486, Training Loss : 0.33615, Training Acc : 0.844, Run Time : 8.62
INFO:root:2019-05-11 00:33:57, Epoch : 1, Step : 2487, Training Loss : 1.05209, Training Acc : 0.561, Run Time : 0.85
INFO:root:2019-05-11 00:33:57, Epoch : 1, Step : 2488, Training Loss : 0.52083, Training Acc : 0.678, Run Time : 0.38
INFO:root:2019-05-11 00:33:57, Epoch : 1, Step : 2489, Training Loss : 0.24466, Training Acc : 0.911, Run Time : 0.40
INFO:root:2019-05-11 00:33:58, Epoch : 1, Step : 2490, Training Loss : 0.26536, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-11 00:33:59, Epoch : 1, Step : 2491, Training Loss : 0.23736, Training Acc : 0.922, Run Time : 1.45
INFO:root:2019-05-11 00:34:08, Epoch : 1, Step : 2492, Training Loss : 0.38386, Training Acc : 0.817, Run Time : 8.46
INFO:root:2019-05-11 00:34:09, Epoch : 1, Step : 2493, Training Loss : 0.21191, Training Acc : 0.922, Run Time : 1.54
INFO:root:2019-05-11 00:34:20, Epoch : 1, Step : 2494, Training Loss : 0.30442, Training Acc : 0.878, Run Time : 10.97
INFO:root:2019-05-11 00:34:21, Epoch : 1, Step : 2495, Training Loss : 0.38593, Training Acc : 0.800, Run Time : 0.93
INFO:root:2019-05-11 00:34:22, Epoch : 1, Step : 2496, Training Loss : 0.37566, Training Acc : 0.811, Run Time : 0.58
INFO:root:2019-05-11 00:34:27, Epoch : 1, Step : 2497, Training Loss : 0.36341, Training Acc : 0.822, Run Time : 5.00
INFO:root:2019-05-11 00:34:27, Epoch : 1, Step : 2498, Training Loss : 0.29768, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-11 00:34:28, Epoch : 1, Step : 2499, Training Loss : 0.34471, Training Acc : 0.833, Run Time : 0.41
INFO:root:2019-05-11 00:34:28, Epoch : 1, Step : 2500, Training Loss : 0.24053, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-11 00:34:40, Epoch : 1, Step : 2501, Training Loss : 0.38401, Training Acc : 0.828, Run Time : 11.88
INFO:root:2019-05-11 00:34:42, Epoch : 1, Step : 2502, Training Loss : 0.34409, Training Acc : 0.839, Run Time : 1.96
INFO:root:2019-05-11 00:34:48, Epoch : 1, Step : 2503, Training Loss : 0.25823, Training Acc : 0.922, Run Time : 6.16
INFO:root:2019-05-11 00:34:49, Epoch : 1, Step : 2504, Training Loss : 0.17307, Training Acc : 0.956, Run Time : 1.15
INFO:root:2019-05-11 00:34:50, Epoch : 1, Step : 2505, Training Loss : 0.22785, Training Acc : 0.917, Run Time : 0.49
INFO:root:2019-05-11 00:34:50, Epoch : 1, Step : 2506, Training Loss : 0.24573, Training Acc : 0.894, Run Time : 0.58
INFO:root:2019-05-11 00:34:56, Epoch : 1, Step : 2507, Training Loss : 0.21921, Training Acc : 0.911, Run Time : 6.31
INFO:root:2019-05-11 00:34:57, Epoch : 1, Step : 2508, Training Loss : 0.27645, Training Acc : 0.867, Run Time : 0.40
INFO:root:2019-05-11 00:34:57, Epoch : 1, Step : 2509, Training Loss : 0.33905, Training Acc : 0.867, Run Time : 0.38
INFO:root:2019-05-11 00:34:59, Epoch : 1, Step : 2510, Training Loss : 0.33498, Training Acc : 0.872, Run Time : 1.37
INFO:root:2019-05-11 00:35:06, Epoch : 1, Step : 2511, Training Loss : 0.23701, Training Acc : 0.922, Run Time : 7.29
INFO:root:2019-05-11 00:35:06, Epoch : 1, Step : 2512, Training Loss : 0.30319, Training Acc : 0.861, Run Time : 0.53
INFO:root:2019-05-11 00:35:07, Epoch : 1, Step : 2513, Training Loss : 0.32304, Training Acc : 0.811, Run Time : 0.39
INFO:root:2019-05-11 00:35:08, Epoch : 1, Step : 2514, Training Loss : 0.19356, Training Acc : 0.911, Run Time : 0.92
INFO:root:2019-05-11 00:35:13, Epoch : 1, Step : 2515, Training Loss : 0.28852, Training Acc : 0.906, Run Time : 5.06
INFO:root:2019-05-11 00:35:13, Epoch : 1, Step : 2516, Training Loss : 0.16188, Training Acc : 0.933, Run Time : 0.60
INFO:root:2019-05-11 00:35:14, Epoch : 1, Step : 2517, Training Loss : 0.18396, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 00:35:14, Epoch : 1, Step : 2518, Training Loss : 0.18135, Training Acc : 0.928, Run Time : 0.40
INFO:root:2019-05-11 00:35:15, Epoch : 1, Step : 2519, Training Loss : 0.16830, Training Acc : 0.950, Run Time : 0.39
INFO:root:2019-05-11 00:35:16, Epoch : 1, Step : 2520, Training Loss : 0.24612, Training Acc : 0.878, Run Time : 1.14
INFO:root:2019-05-11 00:35:22, Epoch : 1, Step : 2521, Training Loss : 0.25685, Training Acc : 0.883, Run Time : 6.29
INFO:root:2019-05-11 00:35:22, Epoch : 1, Step : 2522, Training Loss : 0.18586, Training Acc : 0.939, Run Time : 0.41
INFO:root:2019-05-11 00:35:23, Epoch : 1, Step : 2523, Training Loss : 0.20191, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 00:35:23, Epoch : 1, Step : 2524, Training Loss : 0.20783, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 00:35:24, Epoch : 1, Step : 2525, Training Loss : 0.19294, Training Acc : 0.928, Run Time : 0.86
INFO:root:2019-05-11 00:35:33, Epoch : 1, Step : 2526, Training Loss : 0.17174, Training Acc : 0.944, Run Time : 9.24
INFO:root:2019-05-11 00:35:34, Epoch : 1, Step : 2527, Training Loss : 0.27485, Training Acc : 0.867, Run Time : 0.57
INFO:root:2019-05-11 00:35:34, Epoch : 1, Step : 2528, Training Loss : 0.21577, Training Acc : 0.917, Run Time : 0.37
INFO:root:2019-05-11 00:35:35, Epoch : 1, Step : 2529, Training Loss : 0.19933, Training Acc : 0.928, Run Time : 0.37
INFO:root:2019-05-11 00:35:36, Epoch : 1, Step : 2530, Training Loss : 0.14711, Training Acc : 0.933, Run Time : 0.90
INFO:root:2019-05-11 00:35:41, Epoch : 1, Step : 2531, Training Loss : 0.16364, Training Acc : 0.944, Run Time : 5.60
INFO:root:2019-05-11 00:35:42, Epoch : 1, Step : 2532, Training Loss : 0.16713, Training Acc : 0.967, Run Time : 0.40
INFO:root:2019-05-11 00:35:42, Epoch : 1, Step : 2533, Training Loss : 0.15819, Training Acc : 0.944, Run Time : 0.40
INFO:root:2019-05-11 00:35:44, Epoch : 1, Step : 2534, Training Loss : 0.17713, Training Acc : 0.928, Run Time : 1.93
INFO:root:2019-05-11 00:35:53, Epoch : 1, Step : 2535, Training Loss : 0.12318, Training Acc : 0.961, Run Time : 9.13
INFO:root:2019-05-11 00:35:53, Epoch : 1, Step : 2536, Training Loss : 0.13566, Training Acc : 0.950, Run Time : 0.39
INFO:root:2019-05-11 00:35:54, Epoch : 1, Step : 2537, Training Loss : 0.15297, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 00:35:54, Epoch : 1, Step : 2538, Training Loss : 0.16343, Training Acc : 0.933, Run Time : 0.71
INFO:root:2019-05-11 00:36:05, Epoch : 1, Step : 2539, Training Loss : 0.15633, Training Acc : 0.950, Run Time : 10.16
INFO:root:2019-05-11 00:36:05, Epoch : 1, Step : 2540, Training Loss : 0.13039, Training Acc : 0.944, Run Time : 0.60
INFO:root:2019-05-11 00:36:06, Epoch : 1, Step : 2541, Training Loss : 0.19421, Training Acc : 0.917, Run Time : 0.93
INFO:root:2019-05-11 00:36:10, Epoch : 1, Step : 2542, Training Loss : 0.14294, Training Acc : 0.944, Run Time : 3.78
INFO:root:2019-05-11 00:36:14, Epoch : 1, Step : 2543, Training Loss : 0.20280, Training Acc : 0.906, Run Time : 3.87
INFO:root:2019-05-11 00:36:14, Epoch : 1, Step : 2544, Training Loss : 0.14553, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-11 00:36:16, Epoch : 1, Step : 2545, Training Loss : 0.20708, Training Acc : 0.911, Run Time : 2.21
INFO:root:2019-05-11 00:36:22, Epoch : 1, Step : 2546, Training Loss : 0.13940, Training Acc : 0.950, Run Time : 5.81
INFO:root:2019-05-11 00:36:23, Epoch : 1, Step : 2547, Training Loss : 0.16439, Training Acc : 0.933, Run Time : 0.44
INFO:root:2019-05-11 00:36:23, Epoch : 1, Step : 2548, Training Loss : 0.16453, Training Acc : 0.939, Run Time : 0.37
INFO:root:2019-05-11 00:36:29, Epoch : 1, Step : 2549, Training Loss : 0.10564, Training Acc : 0.978, Run Time : 6.37
INFO:root:2019-05-11 00:36:30, Epoch : 1, Step : 2550, Training Loss : 0.17152, Training Acc : 0.944, Run Time : 1.00
INFO:root:2019-05-11 00:36:31, Epoch : 1, Step : 2551, Training Loss : 0.10367, Training Acc : 0.989, Run Time : 0.41
INFO:root:2019-05-11 00:36:32, Epoch : 1, Step : 2552, Training Loss : 0.16757, Training Acc : 0.944, Run Time : 1.06
INFO:root:2019-05-11 00:36:40, Epoch : 1, Step : 2553, Training Loss : 0.18399, Training Acc : 0.922, Run Time : 8.25
INFO:root:2019-05-11 00:36:41, Epoch : 1, Step : 2554, Training Loss : 0.17332, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-11 00:36:41, Epoch : 1, Step : 2555, Training Loss : 0.24468, Training Acc : 0.878, Run Time : 0.39
INFO:root:2019-05-11 00:36:42, Epoch : 1, Step : 2556, Training Loss : 0.30596, Training Acc : 0.872, Run Time : 0.90
INFO:root:2019-05-11 00:36:51, Epoch : 1, Step : 2557, Training Loss : 0.21572, Training Acc : 0.911, Run Time : 9.60
INFO:root:2019-05-11 00:36:52, Epoch : 1, Step : 2558, Training Loss : 0.23263, Training Acc : 0.872, Run Time : 0.91
INFO:root:2019-05-11 00:36:53, Epoch : 1, Step : 2559, Training Loss : 0.27952, Training Acc : 0.861, Run Time : 0.44
INFO:root:2019-05-11 00:36:54, Epoch : 1, Step : 2560, Training Loss : 0.22309, Training Acc : 0.928, Run Time : 0.80
INFO:root:2019-05-11 00:37:01, Epoch : 1, Step : 2561, Training Loss : 0.23730, Training Acc : 0.906, Run Time : 7.17
INFO:root:2019-05-11 00:37:02, Epoch : 1, Step : 2562, Training Loss : 0.21335, Training Acc : 0.894, Run Time : 0.81
INFO:root:2019-05-11 00:37:02, Epoch : 1, Step : 2563, Training Loss : 0.28375, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 00:37:11, Epoch : 1, Step : 2564, Training Loss : 0.27238, Training Acc : 0.900, Run Time : 9.46
INFO:root:2019-05-11 00:37:12, Epoch : 1, Step : 2565, Training Loss : 0.20248, Training Acc : 0.906, Run Time : 0.47
INFO:root:2019-05-11 00:37:12, Epoch : 1, Step : 2566, Training Loss : 0.13340, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 00:37:13, Epoch : 1, Step : 2567, Training Loss : 0.18053, Training Acc : 0.911, Run Time : 1.20
INFO:root:2019-05-11 00:37:22, Epoch : 1, Step : 2568, Training Loss : 0.18061, Training Acc : 0.922, Run Time : 8.76
INFO:root:2019-05-11 00:37:23, Epoch : 1, Step : 2569, Training Loss : 0.20016, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-11 00:37:23, Epoch : 1, Step : 2570, Training Loss : 0.18858, Training Acc : 0.939, Run Time : 0.37
INFO:root:2019-05-11 00:37:23, Epoch : 1, Step : 2571, Training Loss : 0.22071, Training Acc : 0.894, Run Time : 0.39
INFO:root:2019-05-11 00:37:26, Epoch : 1, Step : 2572, Training Loss : 0.18095, Training Acc : 0.950, Run Time : 2.56
INFO:root:2019-05-11 00:37:27, Epoch : 1, Step : 2573, Training Loss : 0.19854, Training Acc : 0.906, Run Time : 0.68
INFO:root:2019-05-11 00:37:27, Epoch : 1, Step : 2574, Training Loss : 0.25475, Training Acc : 0.878, Run Time : 0.44
INFO:root:2019-05-11 00:37:28, Epoch : 1, Step : 2575, Training Loss : 0.21752, Training Acc : 0.922, Run Time : 1.05
INFO:root:2019-05-11 00:37:35, Epoch : 1, Step : 2576, Training Loss : 0.31795, Training Acc : 0.867, Run Time : 7.20
INFO:root:2019-05-11 00:37:36, Epoch : 1, Step : 2577, Training Loss : 0.43057, Training Acc : 0.822, Run Time : 0.80
INFO:root:2019-05-11 00:37:37, Epoch : 1, Step : 2578, Training Loss : 0.29926, Training Acc : 0.889, Run Time : 0.75
INFO:root:2019-05-11 00:37:45, Epoch : 1, Step : 2579, Training Loss : 0.32941, Training Acc : 0.839, Run Time : 7.89
INFO:root:2019-05-11 00:37:45, Epoch : 1, Step : 2580, Training Loss : 0.21129, Training Acc : 0.900, Run Time : 0.60
INFO:root:2019-05-11 00:37:46, Epoch : 1, Step : 2581, Training Loss : 0.17771, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 00:37:54, Epoch : 1, Step : 2582, Training Loss : 0.28371, Training Acc : 0.878, Run Time : 8.61
INFO:root:2019-05-11 00:37:55, Epoch : 1, Step : 2583, Training Loss : 0.17621, Training Acc : 0.917, Run Time : 0.72
INFO:root:2019-05-11 00:37:55, Epoch : 1, Step : 2584, Training Loss : 0.36640, Training Acc : 0.833, Run Time : 0.38
INFO:root:2019-05-11 00:37:56, Epoch : 1, Step : 2585, Training Loss : 0.23163, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-11 00:37:56, Epoch : 1, Step : 2586, Training Loss : 0.32357, Training Acc : 0.839, Run Time : 0.50
INFO:root:2019-05-11 00:38:05, Epoch : 1, Step : 2587, Training Loss : 0.25006, Training Acc : 0.889, Run Time : 8.32
INFO:root:2019-05-11 00:38:05, Epoch : 1, Step : 2588, Training Loss : 0.44258, Training Acc : 0.789, Run Time : 0.49
INFO:root:2019-05-11 00:38:06, Epoch : 1, Step : 2589, Training Loss : 0.30725, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-11 00:38:06, Epoch : 1, Step : 2590, Training Loss : 0.38896, Training Acc : 0.789, Run Time : 0.38
INFO:root:2019-05-11 00:38:06, Epoch : 1, Step : 2591, Training Loss : 0.24370, Training Acc : 0.872, Run Time : 0.52
INFO:root:2019-05-11 00:38:07, Epoch : 1, Step : 2592, Training Loss : 0.27363, Training Acc : 0.850, Run Time : 0.37
INFO:root:2019-05-11 00:38:07, Epoch : 1, Step : 2593, Training Loss : 0.15801, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 00:38:08, Epoch : 1, Step : 2594, Training Loss : 0.14306, Training Acc : 0.939, Run Time : 0.81
INFO:root:2019-05-11 00:38:15, Epoch : 1, Step : 2595, Training Loss : 0.13722, Training Acc : 0.961, Run Time : 7.49
INFO:root:2019-05-11 00:38:16, Epoch : 1, Step : 2596, Training Loss : 0.20744, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-11 00:38:16, Epoch : 1, Step : 2597, Training Loss : 0.17621, Training Acc : 0.917, Run Time : 0.40
INFO:root:2019-05-11 00:38:18, Epoch : 1, Step : 2598, Training Loss : 0.19147, Training Acc : 0.917, Run Time : 1.28
INFO:root:2019-05-11 00:38:23, Epoch : 1, Step : 2599, Training Loss : 0.26909, Training Acc : 0.889, Run Time : 5.53
INFO:root:2019-05-11 00:38:24, Epoch : 1, Step : 2600, Training Loss : 0.29936, Training Acc : 0.883, Run Time : 0.91
INFO:root:2019-05-11 00:38:25, Epoch : 1, Step : 2601, Training Loss : 1.01920, Training Acc : 0.678, Run Time : 0.74
INFO:root:2019-05-11 00:38:25, Epoch : 1, Step : 2602, Training Loss : 0.75924, Training Acc : 0.711, Run Time : 0.58
INFO:root:2019-05-11 00:38:26, Epoch : 1, Step : 2603, Training Loss : 0.48629, Training Acc : 0.739, Run Time : 1.02
INFO:root:2019-05-11 00:38:34, Epoch : 1, Step : 2604, Training Loss : 0.72266, Training Acc : 0.772, Run Time : 8.04
INFO:root:2019-05-11 00:38:35, Epoch : 1, Step : 2605, Training Loss : 0.58788, Training Acc : 0.694, Run Time : 0.70
INFO:root:2019-05-11 00:38:36, Epoch : 1, Step : 2606, Training Loss : 0.46335, Training Acc : 0.767, Run Time : 1.06
INFO:root:2019-05-11 00:38:45, Epoch : 1, Step : 2607, Training Loss : 0.42571, Training Acc : 0.806, Run Time : 9.07
INFO:root:2019-05-11 00:38:46, Epoch : 1, Step : 2608, Training Loss : 0.46833, Training Acc : 0.772, Run Time : 0.41
INFO:root:2019-05-11 00:38:46, Epoch : 1, Step : 2609, Training Loss : 0.34320, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-11 00:38:46, Epoch : 1, Step : 2610, Training Loss : 0.27931, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-11 00:38:47, Epoch : 1, Step : 2611, Training Loss : 0.16569, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-11 00:38:47, Epoch : 1, Step : 2612, Training Loss : 0.31455, Training Acc : 0.844, Run Time : 0.42
INFO:root:2019-05-11 00:38:48, Epoch : 1, Step : 2613, Training Loss : 0.22201, Training Acc : 0.928, Run Time : 0.94
INFO:root:2019-05-11 00:38:54, Epoch : 1, Step : 2614, Training Loss : 0.14486, Training Acc : 0.939, Run Time : 5.81
INFO:root:2019-05-11 00:38:55, Epoch : 1, Step : 2615, Training Loss : 0.27178, Training Acc : 0.900, Run Time : 0.64
INFO:root:2019-05-11 00:38:55, Epoch : 1, Step : 2616, Training Loss : 0.26816, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-11 00:38:55, Epoch : 1, Step : 2617, Training Loss : 0.07164, Training Acc : 0.978, Run Time : 0.38
INFO:root:2019-05-11 00:38:56, Epoch : 1, Step : 2618, Training Loss : 0.30410, Training Acc : 0.894, Run Time : 0.55
INFO:root:2019-05-11 00:39:03, Epoch : 1, Step : 2619, Training Loss : 0.13680, Training Acc : 0.961, Run Time : 7.42
INFO:root:2019-05-11 00:39:07, Epoch : 1, Step : 2620, Training Loss : 0.15443, Training Acc : 0.961, Run Time : 3.25
INFO:root:2019-05-11 00:39:07, Epoch : 1, Step : 2621, Training Loss : 0.18887, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 00:39:17, Epoch : 1, Step : 2622, Training Loss : 0.22762, Training Acc : 0.894, Run Time : 10.00
INFO:root:2019-05-11 00:39:18, Epoch : 1, Step : 2623, Training Loss : 0.26054, Training Acc : 0.922, Run Time : 0.87
INFO:root:2019-05-11 00:39:19, Epoch : 1, Step : 2624, Training Loss : 0.21776, Training Acc : 0.917, Run Time : 0.66
INFO:root:2019-05-11 00:39:28, Epoch : 1, Step : 2625, Training Loss : 0.34538, Training Acc : 0.889, Run Time : 9.17
INFO:root:2019-05-11 00:39:28, Epoch : 1, Step : 2626, Training Loss : 0.33965, Training Acc : 0.889, Run Time : 0.71
INFO:root:2019-05-11 00:39:29, Epoch : 1, Step : 2627, Training Loss : 0.57324, Training Acc : 0.778, Run Time : 0.37
INFO:root:2019-05-11 00:39:30, Epoch : 1, Step : 2628, Training Loss : 1.69705, Training Acc : 0.506, Run Time : 1.36
INFO:root:2019-05-11 00:39:40, Epoch : 1, Step : 2629, Training Loss : 0.40265, Training Acc : 0.800, Run Time : 10.26
INFO:root:2019-05-11 00:39:41, Epoch : 1, Step : 2630, Training Loss : 0.39115, Training Acc : 0.850, Run Time : 0.43
INFO:root:2019-05-11 00:39:41, Epoch : 1, Step : 2631, Training Loss : 0.30640, Training Acc : 0.867, Run Time : 0.38
INFO:root:2019-05-11 00:39:42, Epoch : 1, Step : 2632, Training Loss : 0.56862, Training Acc : 0.756, Run Time : 0.50
INFO:root:2019-05-11 00:39:42, Epoch : 1, Step : 2633, Training Loss : 0.99049, Training Acc : 0.633, Run Time : 0.38
INFO:root:2019-05-11 00:39:43, Epoch : 1, Step : 2634, Training Loss : 0.41630, Training Acc : 0.800, Run Time : 0.37
INFO:root:2019-05-11 00:39:43, Epoch : 1, Step : 2635, Training Loss : 1.04093, Training Acc : 0.561, Run Time : 0.61
INFO:root:2019-05-11 00:39:51, Epoch : 1, Step : 2636, Training Loss : 0.55273, Training Acc : 0.744, Run Time : 8.17
INFO:root:2019-05-11 00:39:52, Epoch : 1, Step : 2637, Training Loss : 0.64280, Training Acc : 0.761, Run Time : 0.60
INFO:root:2019-05-11 00:39:52, Epoch : 1, Step : 2638, Training Loss : 0.51590, Training Acc : 0.778, Run Time : 0.40
INFO:root:2019-05-11 00:39:53, Epoch : 1, Step : 2639, Training Loss : 0.33563, Training Acc : 0.811, Run Time : 0.39
INFO:root:2019-05-11 00:39:53, Epoch : 1, Step : 2640, Training Loss : 0.47976, Training Acc : 0.789, Run Time : 0.52
INFO:root:2019-05-11 00:39:54, Epoch : 1, Step : 2641, Training Loss : 0.22419, Training Acc : 0.889, Run Time : 0.87
INFO:root:2019-05-11 00:39:55, Epoch : 1, Step : 2642, Training Loss : 0.23515, Training Acc : 0.894, Run Time : 0.48
INFO:root:2019-05-11 00:40:02, Epoch : 1, Step : 2643, Training Loss : 0.29707, Training Acc : 0.883, Run Time : 7.58
INFO:root:2019-05-11 00:40:03, Epoch : 1, Step : 2644, Training Loss : 0.24189, Training Acc : 0.889, Run Time : 1.24
INFO:root:2019-05-11 00:40:10, Epoch : 1, Step : 2645, Training Loss : 0.45207, Training Acc : 0.822, Run Time : 6.44
INFO:root:2019-05-11 00:40:11, Epoch : 1, Step : 2646, Training Loss : 0.32784, Training Acc : 0.817, Run Time : 1.13
INFO:root:2019-05-11 00:40:11, Epoch : 1, Step : 2647, Training Loss : 0.41953, Training Acc : 0.844, Run Time : 0.37
INFO:root:2019-05-11 00:40:13, Epoch : 1, Step : 2648, Training Loss : 0.37205, Training Acc : 0.867, Run Time : 1.31
INFO:root:2019-05-11 00:40:23, Epoch : 1, Step : 2649, Training Loss : 0.29130, Training Acc : 0.911, Run Time : 10.46
INFO:root:2019-05-11 00:40:23, Epoch : 1, Step : 2650, Training Loss : 0.25582, Training Acc : 0.878, Run Time : 0.42
INFO:root:2019-05-11 00:40:24, Epoch : 1, Step : 2651, Training Loss : 0.27064, Training Acc : 0.878, Run Time : 0.37
INFO:root:2019-05-11 00:40:24, Epoch : 1, Step : 2652, Training Loss : 0.18521, Training Acc : 0.950, Run Time : 0.43
INFO:root:2019-05-11 00:40:25, Epoch : 1, Step : 2653, Training Loss : 0.22171, Training Acc : 0.944, Run Time : 0.95
INFO:root:2019-05-11 00:40:31, Epoch : 1, Step : 2654, Training Loss : 0.21614, Training Acc : 0.922, Run Time : 5.30
INFO:root:2019-05-11 00:40:31, Epoch : 1, Step : 2655, Training Loss : 0.31830, Training Acc : 0.861, Run Time : 0.91
INFO:root:2019-05-11 00:40:32, Epoch : 1, Step : 2656, Training Loss : 0.38812, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-11 00:40:32, Epoch : 1, Step : 2657, Training Loss : 0.19952, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-11 00:40:33, Epoch : 1, Step : 2658, Training Loss : 0.18839, Training Acc : 0.933, Run Time : 0.81
INFO:root:2019-05-11 00:40:41, Epoch : 1, Step : 2659, Training Loss : 0.33249, Training Acc : 0.933, Run Time : 7.71
INFO:root:2019-05-11 00:40:41, Epoch : 1, Step : 2660, Training Loss : 0.27048, Training Acc : 0.878, Run Time : 0.56
INFO:root:2019-05-11 00:40:42, Epoch : 1, Step : 2661, Training Loss : 0.17444, Training Acc : 0.978, Run Time : 0.38
INFO:root:2019-05-11 00:40:43, Epoch : 1, Step : 2662, Training Loss : 0.16825, Training Acc : 0.972, Run Time : 1.12
INFO:root:2019-05-11 00:40:51, Epoch : 1, Step : 2663, Training Loss : 0.21604, Training Acc : 0.906, Run Time : 7.81
INFO:root:2019-05-11 00:40:51, Epoch : 1, Step : 2664, Training Loss : 0.15702, Training Acc : 0.961, Run Time : 0.41
INFO:root:2019-05-11 00:40:51, Epoch : 1, Step : 2665, Training Loss : 0.26736, Training Acc : 0.900, Run Time : 0.40
INFO:root:2019-05-11 00:40:52, Epoch : 1, Step : 2666, Training Loss : 0.29984, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-11 00:40:52, Epoch : 1, Step : 2667, Training Loss : 0.21025, Training Acc : 0.906, Run Time : 0.40
INFO:root:2019-05-11 00:40:54, Epoch : 1, Step : 2668, Training Loss : 0.15166, Training Acc : 0.972, Run Time : 1.66
INFO:root:2019-05-11 00:41:04, Epoch : 1, Step : 2669, Training Loss : 0.26581, Training Acc : 0.872, Run Time : 10.22
INFO:root:2019-05-11 00:41:05, Epoch : 1, Step : 2670, Training Loss : 0.31683, Training Acc : 0.911, Run Time : 0.51
INFO:root:2019-05-11 00:41:05, Epoch : 1, Step : 2671, Training Loss : 0.14791, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 00:41:07, Epoch : 1, Step : 2672, Training Loss : 0.25241, Training Acc : 0.883, Run Time : 1.82
INFO:root:2019-05-11 00:41:17, Epoch : 1, Step : 2673, Training Loss : 0.30173, Training Acc : 0.861, Run Time : 10.57
INFO:root:2019-05-11 00:41:18, Epoch : 1, Step : 2674, Training Loss : 0.13011, Training Acc : 0.972, Run Time : 0.42
INFO:root:2019-05-11 00:41:18, Epoch : 1, Step : 2675, Training Loss : 0.23068, Training Acc : 0.900, Run Time : 0.38
INFO:root:2019-05-11 00:41:19, Epoch : 1, Step : 2676, Training Loss : 0.25982, Training Acc : 0.906, Run Time : 1.06
INFO:root:2019-05-11 00:41:25, Epoch : 1, Step : 2677, Training Loss : 0.20952, Training Acc : 0.944, Run Time : 5.99
INFO:root:2019-05-11 00:41:26, Epoch : 1, Step : 2678, Training Loss : 0.13946, Training Acc : 0.961, Run Time : 0.40
INFO:root:2019-05-11 00:41:26, Epoch : 1, Step : 2679, Training Loss : 0.27052, Training Acc : 0.900, Run Time : 0.39
INFO:root:2019-05-11 00:41:28, Epoch : 1, Step : 2680, Training Loss : 0.25216, Training Acc : 0.917, Run Time : 1.85
INFO:root:2019-05-11 00:41:29, Epoch : 1, Step : 2681, Training Loss : 0.26041, Training Acc : 0.889, Run Time : 0.61
INFO:root:2019-05-11 00:41:29, Epoch : 1, Step : 2682, Training Loss : 0.42840, Training Acc : 0.811, Run Time : 0.39
INFO:root:2019-05-11 00:41:29, Epoch : 1, Step : 2683, Training Loss : 0.26701, Training Acc : 0.894, Run Time : 0.54
INFO:root:2019-05-11 00:41:33, Epoch : 1, Step : 2684, Training Loss : 0.45229, Training Acc : 0.783, Run Time : 3.21
INFO:root:2019-05-11 00:41:33, Epoch : 1, Step : 2685, Training Loss : 0.12863, Training Acc : 0.956, Run Time : 0.43
INFO:root:2019-05-11 00:41:34, Epoch : 1, Step : 2686, Training Loss : 0.16572, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 00:41:35, Epoch : 1, Step : 2687, Training Loss : 0.15834, Training Acc : 0.961, Run Time : 1.60
INFO:root:2019-05-11 00:41:43, Epoch : 1, Step : 2688, Training Loss : 0.13060, Training Acc : 0.978, Run Time : 8.37
INFO:root:2019-05-11 00:41:44, Epoch : 1, Step : 2689, Training Loss : 0.13153, Training Acc : 0.967, Run Time : 0.45
INFO:root:2019-05-11 00:41:44, Epoch : 1, Step : 2690, Training Loss : 0.17954, Training Acc : 0.961, Run Time : 0.43
INFO:root:2019-05-11 00:41:45, Epoch : 1, Step : 2691, Training Loss : 0.15548, Training Acc : 0.956, Run Time : 0.52
INFO:root:2019-05-11 00:41:49, Epoch : 1, Step : 2692, Training Loss : 0.11251, Training Acc : 0.972, Run Time : 4.37
INFO:root:2019-05-11 00:41:50, Epoch : 1, Step : 2693, Training Loss : 0.14963, Training Acc : 0.967, Run Time : 0.40
INFO:root:2019-05-11 00:41:50, Epoch : 1, Step : 2694, Training Loss : 0.08983, Training Acc : 0.989, Run Time : 0.56
INFO:root:2019-05-11 00:41:56, Epoch : 1, Step : 2695, Training Loss : 0.16081, Training Acc : 0.967, Run Time : 5.29
INFO:root:2019-05-11 00:41:56, Epoch : 1, Step : 2696, Training Loss : 0.07792, Training Acc : 0.983, Run Time : 0.38
INFO:root:2019-05-11 00:41:56, Epoch : 1, Step : 2697, Training Loss : 0.14709, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-11 00:41:58, Epoch : 1, Step : 2698, Training Loss : 0.23768, Training Acc : 0.911, Run Time : 2.07
INFO:root:2019-05-11 00:42:05, Epoch : 1, Step : 2699, Training Loss : 0.15963, Training Acc : 0.922, Run Time : 6.34
INFO:root:2019-05-11 00:42:05, Epoch : 1, Step : 2700, Training Loss : 0.08459, Training Acc : 0.950, Run Time : 0.77
INFO:root:2019-05-11 00:42:14, Epoch : 1, Step : 2701, Training Loss : 0.06752, Training Acc : 0.978, Run Time : 8.09
INFO:root:2019-05-11 00:42:17, Epoch : 1, Step : 2702, Training Loss : 0.05438, Training Acc : 1.000, Run Time : 3.06
INFO:root:2019-05-11 00:42:25, Epoch : 1, Step : 2703, Training Loss : 0.04072, Training Acc : 1.000, Run Time : 8.23
INFO:root:2019-05-11 00:42:25, Epoch : 1, Step : 2704, Training Loss : 0.04016, Training Acc : 0.994, Run Time : 0.40
INFO:root:2019-05-11 00:42:26, Epoch : 1, Step : 2705, Training Loss : 0.16222, Training Acc : 0.961, Run Time : 0.38
INFO:root:2019-05-11 00:42:27, Epoch : 1, Step : 2706, Training Loss : 0.07893, Training Acc : 0.972, Run Time : 1.27
INFO:root:2019-05-11 00:42:33, Epoch : 1, Step : 2707, Training Loss : 0.04111, Training Acc : 1.000, Run Time : 6.39
INFO:root:2019-05-11 00:42:34, Epoch : 1, Step : 2708, Training Loss : 0.08313, Training Acc : 0.978, Run Time : 0.66
INFO:root:2019-05-11 00:42:35, Epoch : 1, Step : 2709, Training Loss : 0.10655, Training Acc : 0.956, Run Time : 0.85
INFO:root:2019-05-11 00:42:40, Epoch : 1, Step : 2710, Training Loss : 0.14700, Training Acc : 0.972, Run Time : 5.37
INFO:root:2019-05-11 00:42:41, Epoch : 1, Step : 2711, Training Loss : 0.03088, Training Acc : 1.000, Run Time : 0.61
INFO:root:2019-05-11 00:42:41, Epoch : 1, Step : 2712, Training Loss : 0.02615, Training Acc : 1.000, Run Time : 0.38
INFO:root:2019-05-11 00:42:42, Epoch : 1, Step : 2713, Training Loss : 0.03474, Training Acc : 1.000, Run Time : 1.08
INFO:root:2019-05-11 00:42:47, Epoch : 1, Step : 2714, Training Loss : 0.04249, Training Acc : 1.000, Run Time : 4.64
INFO:root:2019-05-11 00:42:47, Epoch : 1, Step : 2715, Training Loss : 0.04979, Training Acc : 1.000, Run Time : 0.41
INFO:root:2019-05-11 00:42:48, Epoch : 1, Step : 2716, Training Loss : 0.04564, Training Acc : 1.000, Run Time : 0.40
INFO:root:2019-05-11 00:42:56, Epoch : 1, Step : 2717, Training Loss : 0.07736, Training Acc : 0.983, Run Time : 8.74
INFO:root:2019-05-11 00:42:57, Epoch : 1, Step : 2718, Training Loss : 0.12417, Training Acc : 0.967, Run Time : 0.43
INFO:root:2019-05-11 00:42:57, Epoch : 1, Step : 2719, Training Loss : 0.02129, Training Acc : 1.000, Run Time : 0.42
INFO:root:2019-05-11 00:42:58, Epoch : 1, Step : 2720, Training Loss : 0.06421, Training Acc : 0.994, Run Time : 0.47
INFO:root:2019-05-11 00:42:59, Epoch : 1, Step : 2721, Training Loss : 0.05894, Training Acc : 0.978, Run Time : 0.84
INFO:root:2019-05-11 00:42:59, Epoch : 1, Step : 2722, Training Loss : 0.09014, Training Acc : 0.956, Run Time : 0.38
INFO:root:2019-05-11 00:42:59, Epoch : 1, Step : 2723, Training Loss : 0.09801, Training Acc : 0.956, Run Time : 0.43
INFO:root:2019-05-11 00:43:00, Epoch : 1, Step : 2724, Training Loss : 0.05691, Training Acc : 0.989, Run Time : 0.52
INFO:root:2019-05-11 00:43:05, Epoch : 1, Step : 2725, Training Loss : 0.02764, Training Acc : 0.994, Run Time : 5.53
INFO:root:2019-05-11 00:43:06, Epoch : 1, Step : 2726, Training Loss : 0.17519, Training Acc : 0.950, Run Time : 0.70
INFO:root:2019-05-11 00:43:07, Epoch : 1, Step : 2727, Training Loss : 0.02305, Training Acc : 1.000, Run Time : 0.52
INFO:root:2019-05-11 00:43:08, Epoch : 1, Step : 2728, Training Loss : 0.04048, Training Acc : 0.994, Run Time : 0.86
INFO:root:2019-05-11 00:43:19, Epoch : 1, Step : 2729, Training Loss : 0.03358, Training Acc : 0.994, Run Time : 11.20
INFO:root:2019-05-11 00:43:19, Epoch : 1, Step : 2730, Training Loss : 0.05263, Training Acc : 0.978, Run Time : 0.74
INFO:root:2019-05-11 00:43:20, Epoch : 1, Step : 2731, Training Loss : 0.05496, Training Acc : 0.989, Run Time : 0.40
INFO:root:2019-05-11 00:43:21, Epoch : 1, Step : 2732, Training Loss : 0.02640, Training Acc : 0.994, Run Time : 1.44
INFO:root:2019-05-11 00:43:28, Epoch : 1, Step : 2733, Training Loss : 0.01712, Training Acc : 1.000, Run Time : 6.50
INFO:root:2019-05-11 00:43:28, Epoch : 1, Step : 2734, Training Loss : 0.04751, Training Acc : 0.994, Run Time : 0.44
INFO:root:2019-05-11 00:43:29, Epoch : 1, Step : 2735, Training Loss : 0.10671, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-11 00:43:37, Epoch : 1, Step : 2736, Training Loss : 0.05680, Training Acc : 0.983, Run Time : 8.65
INFO:root:2019-05-11 00:43:41, Epoch : 1, Step : 2737, Training Loss : 0.04717, Training Acc : 0.994, Run Time : 3.26
INFO:root:2019-05-11 00:43:41, Epoch : 1, Step : 2738, Training Loss : 0.09517, Training Acc : 0.972, Run Time : 0.40
INFO:root:2019-05-11 00:43:41, Epoch : 1, Step : 2739, Training Loss : 0.20184, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 00:43:51, Epoch : 1, Step : 2740, Training Loss : 0.92553, Training Acc : 0.750, Run Time : 9.33
INFO:root:2019-05-11 00:43:51, Epoch : 1, Step : 2741, Training Loss : 0.32004, Training Acc : 0.911, Run Time : 0.43
INFO:root:2019-05-11 00:43:52, Epoch : 1, Step : 2742, Training Loss : 0.13301, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-11 00:43:52, Epoch : 1, Step : 2743, Training Loss : 0.35884, Training Acc : 0.856, Run Time : 0.38
INFO:root:2019-05-11 00:43:58, Epoch : 1, Step : 2744, Training Loss : 0.21320, Training Acc : 0.911, Run Time : 6.34
INFO:root:2019-05-11 00:43:59, Epoch : 1, Step : 2745, Training Loss : 0.37722, Training Acc : 0.883, Run Time : 0.72
INFO:root:2019-05-11 00:44:00, Epoch : 1, Step : 2746, Training Loss : 0.20541, Training Acc : 0.906, Run Time : 0.90
INFO:root:2019-05-11 00:44:07, Epoch : 1, Step : 2747, Training Loss : 0.34218, Training Acc : 0.833, Run Time : 7.30
INFO:root:2019-05-11 00:44:08, Epoch : 1, Step : 2748, Training Loss : 0.22989, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-11 00:44:08, Epoch : 1, Step : 2749, Training Loss : 0.37221, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-11 00:44:09, Epoch : 1, Step : 2750, Training Loss : 0.26715, Training Acc : 0.900, Run Time : 1.22
INFO:root:2019-05-11 00:44:14, Epoch : 1, Step : 2751, Training Loss : 0.35026, Training Acc : 0.872, Run Time : 5.04
INFO:root:2019-05-11 00:44:15, Epoch : 1, Step : 2752, Training Loss : 0.34565, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-11 00:44:15, Epoch : 1, Step : 2753, Training Loss : 0.55710, Training Acc : 0.800, Run Time : 0.50
INFO:root:2019-05-11 00:44:16, Epoch : 1, Step : 2754, Training Loss : 0.36770, Training Acc : 0.856, Run Time : 1.16
INFO:root:2019-05-11 00:44:22, Epoch : 1, Step : 2755, Training Loss : 0.34724, Training Acc : 0.856, Run Time : 5.28
INFO:root:2019-05-11 00:44:22, Epoch : 1, Step : 2756, Training Loss : 0.21737, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-11 00:44:23, Epoch : 1, Step : 2757, Training Loss : 0.29908, Training Acc : 0.889, Run Time : 0.53
INFO:root:2019-05-11 00:44:32, Epoch : 1, Step : 2758, Training Loss : 0.32451, Training Acc : 0.878, Run Time : 9.28
INFO:root:2019-05-11 00:44:32, Epoch : 1, Step : 2759, Training Loss : 0.33763, Training Acc : 0.867, Run Time : 0.40
INFO:root:2019-05-11 00:44:33, Epoch : 1, Step : 2760, Training Loss : 0.24925, Training Acc : 0.889, Run Time : 0.37
INFO:root:2019-05-11 00:44:34, Epoch : 1, Step : 2761, Training Loss : 0.20935, Training Acc : 0.928, Run Time : 0.94
INFO:root:2019-05-11 00:44:44, Epoch : 1, Step : 2762, Training Loss : 0.35587, Training Acc : 0.867, Run Time : 10.06
INFO:root:2019-05-11 00:44:44, Epoch : 1, Step : 2763, Training Loss : 0.19725, Training Acc : 0.911, Run Time : 0.42
INFO:root:2019-05-11 00:44:44, Epoch : 1, Step : 2764, Training Loss : 0.46818, Training Acc : 0.806, Run Time : 0.38
INFO:root:2019-05-11 00:44:46, Epoch : 1, Step : 2765, Training Loss : 0.26071, Training Acc : 0.900, Run Time : 1.35
INFO:root:2019-05-11 00:44:53, Epoch : 1, Step : 2766, Training Loss : 0.13755, Training Acc : 0.944, Run Time : 7.55
INFO:root:2019-05-11 00:44:54, Epoch : 1, Step : 2767, Training Loss : 0.32749, Training Acc : 0.844, Run Time : 0.41
INFO:root:2019-05-11 00:44:54, Epoch : 1, Step : 2768, Training Loss : 0.28636, Training Acc : 0.872, Run Time : 0.40
INFO:root:2019-05-11 00:44:55, Epoch : 1, Step : 2769, Training Loss : 0.25770, Training Acc : 0.928, Run Time : 0.39
INFO:root:2019-05-11 00:44:55, Epoch : 1, Step : 2770, Training Loss : 0.33490, Training Acc : 0.894, Run Time : 0.80
INFO:root:2019-05-11 00:44:56, Epoch : 1, Step : 2771, Training Loss : 0.20717, Training Acc : 0.917, Run Time : 0.53
INFO:root:2019-05-11 00:44:56, Epoch : 1, Step : 2772, Training Loss : 0.20709, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 00:44:57, Epoch : 1, Step : 2773, Training Loss : 0.17512, Training Acc : 0.922, Run Time : 0.90
INFO:root:2019-05-11 00:45:02, Epoch : 1, Step : 2774, Training Loss : 0.13233, Training Acc : 0.950, Run Time : 4.44
INFO:root:2019-05-11 00:45:02, Epoch : 1, Step : 2775, Training Loss : 0.13353, Training Acc : 0.950, Run Time : 0.41
INFO:root:2019-05-11 00:45:02, Epoch : 1, Step : 2776, Training Loss : 0.16275, Training Acc : 0.939, Run Time : 0.47
INFO:root:2019-05-11 00:45:06, Epoch : 1, Step : 2777, Training Loss : 0.30659, Training Acc : 0.844, Run Time : 3.15
INFO:root:2019-05-11 00:45:07, Epoch : 1, Step : 2778, Training Loss : 0.36770, Training Acc : 0.828, Run Time : 1.15
INFO:root:2019-05-11 00:45:07, Epoch : 1, Step : 2779, Training Loss : 0.23222, Training Acc : 0.917, Run Time : 0.56
INFO:root:2019-05-11 00:45:08, Epoch : 1, Step : 2780, Training Loss : 0.23430, Training Acc : 0.922, Run Time : 0.54
INFO:root:2019-05-11 00:45:15, Epoch : 1, Step : 2781, Training Loss : 0.13853, Training Acc : 0.956, Run Time : 7.10
INFO:root:2019-05-11 00:45:16, Epoch : 1, Step : 2782, Training Loss : 0.58110, Training Acc : 0.778, Run Time : 0.83
INFO:root:2019-05-11 00:45:16, Epoch : 1, Step : 2783, Training Loss : 0.20736, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 00:45:17, Epoch : 1, Step : 2784, Training Loss : 0.52407, Training Acc : 0.794, Run Time : 0.48
INFO:root:2019-05-11 00:45:17, Epoch : 1, Step : 2785, Training Loss : 0.82818, Training Acc : 0.661, Run Time : 0.63
INFO:root:2019-05-11 00:45:26, Epoch : 1, Step : 2786, Training Loss : 0.54263, Training Acc : 0.711, Run Time : 8.80
INFO:root:2019-05-11 00:45:27, Epoch : 1, Step : 2787, Training Loss : 0.36092, Training Acc : 0.833, Run Time : 0.61
INFO:root:2019-05-11 00:45:27, Epoch : 1, Step : 2788, Training Loss : 0.22668, Training Acc : 0.917, Run Time : 0.37
INFO:root:2019-05-11 00:45:27, Epoch : 1, Step : 2789, Training Loss : 0.15839, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-11 00:45:28, Epoch : 1, Step : 2790, Training Loss : 0.28692, Training Acc : 0.889, Run Time : 0.72
INFO:root:2019-05-11 00:45:37, Epoch : 1, Step : 2791, Training Loss : 0.19279, Training Acc : 0.939, Run Time : 8.40
INFO:root:2019-05-11 00:45:37, Epoch : 1, Step : 2792, Training Loss : 0.37706, Training Acc : 0.878, Run Time : 0.40
INFO:root:2019-05-11 00:45:37, Epoch : 1, Step : 2793, Training Loss : 0.28084, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-11 00:45:38, Epoch : 1, Step : 2794, Training Loss : 0.36759, Training Acc : 0.839, Run Time : 1.06
INFO:root:2019-05-11 00:45:48, Epoch : 1, Step : 2795, Training Loss : 0.28436, Training Acc : 0.861, Run Time : 9.38
INFO:root:2019-05-11 00:45:48, Epoch : 1, Step : 2796, Training Loss : 0.35999, Training Acc : 0.850, Run Time : 0.45
INFO:root:2019-05-11 00:45:49, Epoch : 1, Step : 2797, Training Loss : 0.39493, Training Acc : 0.822, Run Time : 0.39
INFO:root:2019-05-11 00:45:49, Epoch : 1, Step : 2798, Training Loss : 0.33878, Training Acc : 0.861, Run Time : 0.59
INFO:root:2019-05-11 00:45:56, Epoch : 1, Step : 2799, Training Loss : 0.48995, Training Acc : 0.806, Run Time : 7.04
INFO:root:2019-05-11 00:45:57, Epoch : 1, Step : 2800, Training Loss : 0.69025, Training Acc : 0.606, Run Time : 0.41
INFO:root:2019-05-11 00:46:07, Epoch : 1, Step : 2801, Training Loss : 0.46473, Training Acc : 0.800, Run Time : 10.23
INFO:root:2019-05-11 00:46:07, Epoch : 1, Step : 2802, Training Loss : 0.30800, Training Acc : 0.872, Run Time : 0.52
INFO:root:2019-05-11 00:46:08, Epoch : 1, Step : 2803, Training Loss : 0.27170, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-11 00:46:08, Epoch : 1, Step : 2804, Training Loss : 0.48467, Training Acc : 0.750, Run Time : 0.58
INFO:root:2019-05-11 00:46:09, Epoch : 1, Step : 2805, Training Loss : 0.22850, Training Acc : 0.883, Run Time : 0.82
INFO:root:2019-05-11 00:46:18, Epoch : 1, Step : 2806, Training Loss : 0.24624, Training Acc : 0.889, Run Time : 8.30
INFO:root:2019-05-11 00:46:18, Epoch : 1, Step : 2807, Training Loss : 0.28000, Training Acc : 0.867, Run Time : 0.41
INFO:root:2019-05-11 00:46:18, Epoch : 1, Step : 2808, Training Loss : 0.35394, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-11 00:46:19, Epoch : 1, Step : 2809, Training Loss : 0.25714, Training Acc : 0.917, Run Time : 0.40
INFO:root:2019-05-11 00:46:19, Epoch : 1, Step : 2810, Training Loss : 0.22686, Training Acc : 0.906, Run Time : 0.40
INFO:root:2019-05-11 00:46:20, Epoch : 1, Step : 2811, Training Loss : 0.22336, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 00:46:20, Epoch : 1, Step : 2812, Training Loss : 0.24381, Training Acc : 0.922, Run Time : 0.39
INFO:root:2019-05-11 00:46:21, Epoch : 1, Step : 2813, Training Loss : 0.32650, Training Acc : 0.850, Run Time : 0.61
INFO:root:2019-05-11 00:46:27, Epoch : 1, Step : 2814, Training Loss : 0.26238, Training Acc : 0.911, Run Time : 6.50
INFO:root:2019-05-11 00:46:28, Epoch : 1, Step : 2815, Training Loss : 0.26542, Training Acc : 0.900, Run Time : 0.49
INFO:root:2019-05-11 00:46:28, Epoch : 1, Step : 2816, Training Loss : 0.21007, Training Acc : 0.900, Run Time : 0.40
INFO:root:2019-05-11 00:46:29, Epoch : 1, Step : 2817, Training Loss : 0.21985, Training Acc : 0.911, Run Time : 1.26
INFO:root:2019-05-11 00:46:36, Epoch : 1, Step : 2818, Training Loss : 0.37300, Training Acc : 0.850, Run Time : 6.50
INFO:root:2019-05-11 00:46:36, Epoch : 1, Step : 2819, Training Loss : 0.12347, Training Acc : 0.961, Run Time : 0.42
INFO:root:2019-05-11 00:46:36, Epoch : 1, Step : 2820, Training Loss : 0.13776, Training Acc : 0.961, Run Time : 0.39
INFO:root:2019-05-11 00:46:37, Epoch : 1, Step : 2821, Training Loss : 0.18208, Training Acc : 0.933, Run Time : 0.53
INFO:root:2019-05-11 00:46:38, Epoch : 1, Step : 2822, Training Loss : 0.31035, Training Acc : 0.867, Run Time : 0.55
INFO:root:2019-05-11 00:46:40, Epoch : 1, Step : 2823, Training Loss : 0.18274, Training Acc : 0.900, Run Time : 2.65
INFO:root:2019-05-11 00:46:41, Epoch : 1, Step : 2824, Training Loss : 0.09519, Training Acc : 0.967, Run Time : 0.83
INFO:root:2019-05-11 00:46:42, Epoch : 1, Step : 2825, Training Loss : 0.23338, Training Acc : 0.917, Run Time : 0.78
INFO:root:2019-05-11 00:46:42, Epoch : 1, Step : 2826, Training Loss : 0.14433, Training Acc : 0.961, Run Time : 0.38
INFO:root:2019-05-11 00:46:50, Epoch : 1, Step : 2827, Training Loss : 0.27373, Training Acc : 0.883, Run Time : 8.04
INFO:root:2019-05-11 00:46:51, Epoch : 1, Step : 2828, Training Loss : 0.07899, Training Acc : 0.978, Run Time : 1.05
INFO:root:2019-05-11 00:46:58, Epoch : 1, Step : 2829, Training Loss : 0.14860, Training Acc : 0.933, Run Time : 7.07
INFO:root:2019-05-11 00:46:59, Epoch : 1, Step : 2830, Training Loss : 0.19000, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-11 00:46:59, Epoch : 1, Step : 2831, Training Loss : 0.17166, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-11 00:47:00, Epoch : 1, Step : 2832, Training Loss : 0.22275, Training Acc : 0.889, Run Time : 0.58
INFO:root:2019-05-11 00:47:07, Epoch : 1, Step : 2833, Training Loss : 0.15815, Training Acc : 0.939, Run Time : 7.02
INFO:root:2019-05-11 00:47:08, Epoch : 1, Step : 2834, Training Loss : 0.24984, Training Acc : 0.928, Run Time : 0.93
INFO:root:2019-05-11 00:47:09, Epoch : 1, Step : 2835, Training Loss : 0.13513, Training Acc : 0.950, Run Time : 0.84
INFO:root:2019-05-11 00:47:18, Epoch : 1, Step : 2836, Training Loss : 0.12699, Training Acc : 0.944, Run Time : 8.87
INFO:root:2019-05-11 00:47:19, Epoch : 1, Step : 2837, Training Loss : 0.18914, Training Acc : 0.922, Run Time : 0.98
INFO:root:2019-05-11 00:47:19, Epoch : 1, Step : 2838, Training Loss : 0.13185, Training Acc : 0.933, Run Time : 0.39
INFO:root:2019-05-11 00:47:20, Epoch : 1, Step : 2839, Training Loss : 0.30541, Training Acc : 0.861, Run Time : 0.61
INFO:root:2019-05-11 00:47:20, Epoch : 1, Step : 2840, Training Loss : 0.38062, Training Acc : 0.844, Run Time : 0.73
INFO:root:2019-05-11 00:47:25, Epoch : 1, Step : 2841, Training Loss : 0.14263, Training Acc : 0.950, Run Time : 5.04
INFO:root:2019-05-11 00:47:26, Epoch : 1, Step : 2842, Training Loss : 0.09182, Training Acc : 0.972, Run Time : 0.41
INFO:root:2019-05-11 00:47:26, Epoch : 1, Step : 2843, Training Loss : 0.09538, Training Acc : 0.961, Run Time : 0.37
INFO:root:2019-05-11 00:47:28, Epoch : 1, Step : 2844, Training Loss : 0.17623, Training Acc : 0.906, Run Time : 1.42
INFO:root:2019-05-11 00:47:34, Epoch : 1, Step : 2845, Training Loss : 0.08795, Training Acc : 0.972, Run Time : 6.19
INFO:root:2019-05-11 00:47:34, Epoch : 1, Step : 2846, Training Loss : 0.18733, Training Acc : 0.911, Run Time : 0.74
INFO:root:2019-05-11 00:47:35, Epoch : 1, Step : 2847, Training Loss : 0.22521, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-11 00:47:35, Epoch : 1, Step : 2848, Training Loss : 0.15777, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 00:47:36, Epoch : 1, Step : 2849, Training Loss : 0.25479, Training Acc : 0.900, Run Time : 0.72
INFO:root:2019-05-11 00:47:44, Epoch : 1, Step : 2850, Training Loss : 0.22856, Training Acc : 0.889, Run Time : 7.82
INFO:root:2019-05-11 00:47:45, Epoch : 1, Step : 2851, Training Loss : 0.06171, Training Acc : 0.978, Run Time : 1.00
INFO:root:2019-05-11 00:47:45, Epoch : 1, Step : 2852, Training Loss : 0.16839, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 00:47:45, Epoch : 1, Step : 2853, Training Loss : 0.21849, Training Acc : 0.922, Run Time : 0.39
INFO:root:2019-05-11 00:47:46, Epoch : 1, Step : 2854, Training Loss : 0.16157, Training Acc : 0.961, Run Time : 0.95
INFO:root:2019-05-11 00:47:54, Epoch : 1, Step : 2855, Training Loss : 0.14398, Training Acc : 0.956, Run Time : 7.38
INFO:root:2019-05-11 00:47:55, Epoch : 1, Step : 2856, Training Loss : 0.35297, Training Acc : 0.833, Run Time : 0.76
INFO:root:2019-05-11 00:47:55, Epoch : 1, Step : 2857, Training Loss : 0.17458, Training Acc : 0.922, Run Time : 0.69
INFO:root:2019-05-11 00:47:56, Epoch : 1, Step : 2858, Training Loss : 0.57453, Training Acc : 0.750, Run Time : 0.37
INFO:root:2019-05-11 00:47:56, Epoch : 1, Step : 2859, Training Loss : 0.14171, Training Acc : 0.956, Run Time : 0.70
INFO:root:2019-05-11 00:48:06, Epoch : 1, Step : 2860, Training Loss : 0.29494, Training Acc : 0.900, Run Time : 9.47
INFO:root:2019-05-11 00:48:06, Epoch : 1, Step : 2861, Training Loss : 0.15840, Training Acc : 0.933, Run Time : 0.43
INFO:root:2019-05-11 00:48:07, Epoch : 1, Step : 2862, Training Loss : 0.17548, Training Acc : 0.939, Run Time : 0.43
INFO:root:2019-05-11 00:48:08, Epoch : 1, Step : 2863, Training Loss : 0.08792, Training Acc : 0.983, Run Time : 1.61
INFO:root:2019-05-11 00:48:16, Epoch : 1, Step : 2864, Training Loss : 0.08355, Training Acc : 0.978, Run Time : 8.18
INFO:root:2019-05-11 00:48:17, Epoch : 1, Step : 2865, Training Loss : 0.12045, Training Acc : 0.967, Run Time : 0.42
INFO:root:2019-05-11 00:48:17, Epoch : 1, Step : 2866, Training Loss : 0.06499, Training Acc : 0.989, Run Time : 0.38
INFO:root:2019-05-11 00:48:18, Epoch : 1, Step : 2867, Training Loss : 0.18831, Training Acc : 0.917, Run Time : 0.39
INFO:root:2019-05-11 00:48:19, Epoch : 1, Step : 2868, Training Loss : 0.11511, Training Acc : 0.950, Run Time : 0.85
INFO:root:2019-05-11 00:48:25, Epoch : 1, Step : 2869, Training Loss : 0.06017, Training Acc : 0.994, Run Time : 6.61
INFO:root:2019-05-11 00:48:26, Epoch : 1, Step : 2870, Training Loss : 0.14952, Training Acc : 0.944, Run Time : 0.62
INFO:root:2019-05-11 00:48:26, Epoch : 1, Step : 2871, Training Loss : 0.09411, Training Acc : 0.972, Run Time : 0.58
INFO:root:2019-05-11 00:48:28, Epoch : 1, Step : 2872, Training Loss : 0.25961, Training Acc : 0.861, Run Time : 1.55
INFO:root:2019-05-11 00:48:36, Epoch : 1, Step : 2873, Training Loss : 0.54197, Training Acc : 0.789, Run Time : 8.23
INFO:root:2019-05-11 00:48:37, Epoch : 1, Step : 2874, Training Loss : 0.61583, Training Acc : 0.756, Run Time : 0.42
INFO:root:2019-05-11 00:48:37, Epoch : 1, Step : 2875, Training Loss : 0.21220, Training Acc : 0.939, Run Time : 0.52
INFO:root:2019-05-11 00:48:47, Epoch : 1, Step : 2876, Training Loss : 0.12419, Training Acc : 0.956, Run Time : 9.48
INFO:root:2019-05-11 00:48:47, Epoch : 1, Step : 2877, Training Loss : 0.13967, Training Acc : 0.950, Run Time : 0.80
INFO:root:2019-05-11 00:48:48, Epoch : 1, Step : 2878, Training Loss : 0.26269, Training Acc : 0.906, Run Time : 0.81
INFO:root:2019-05-11 00:48:53, Epoch : 1, Step : 2879, Training Loss : 0.30497, Training Acc : 0.861, Run Time : 4.86
INFO:root:2019-05-11 00:48:54, Epoch : 1, Step : 2880, Training Loss : 0.37011, Training Acc : 0.856, Run Time : 0.58
INFO:root:2019-05-11 00:48:54, Epoch : 1, Step : 2881, Training Loss : 0.55058, Training Acc : 0.789, Run Time : 0.38
INFO:root:2019-05-11 00:48:54, Epoch : 1, Step : 2882, Training Loss : 0.43218, Training Acc : 0.811, Run Time : 0.38
INFO:root:2019-05-11 00:48:55, Epoch : 1, Step : 2883, Training Loss : 0.31953, Training Acc : 0.900, Run Time : 0.38
INFO:root:2019-05-11 00:48:55, Epoch : 1, Step : 2884, Training Loss : 0.40372, Training Acc : 0.828, Run Time : 0.38
INFO:root:2019-05-11 00:48:56, Epoch : 1, Step : 2885, Training Loss : 0.42184, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-11 00:48:57, Epoch : 1, Step : 2886, Training Loss : 0.22442, Training Acc : 0.906, Run Time : 1.17
INFO:root:2019-05-11 00:49:07, Epoch : 1, Step : 2887, Training Loss : 0.12826, Training Acc : 0.972, Run Time : 10.25
INFO:root:2019-05-11 00:49:09, Epoch : 1, Step : 2888, Training Loss : 0.11560, Training Acc : 0.972, Run Time : 1.62
INFO:root:2019-05-11 00:49:09, Epoch : 1, Step : 2889, Training Loss : 0.30241, Training Acc : 0.883, Run Time : 0.37
INFO:root:2019-05-11 00:49:15, Epoch : 1, Step : 2890, Training Loss : 0.28745, Training Acc : 0.889, Run Time : 5.95
INFO:root:2019-05-11 00:49:15, Epoch : 1, Step : 2891, Training Loss : 0.21280, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-11 00:49:16, Epoch : 1, Step : 2892, Training Loss : 0.20492, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-11 00:49:19, Epoch : 1, Step : 2893, Training Loss : 0.16265, Training Acc : 0.944, Run Time : 3.73
INFO:root:2019-05-11 00:49:20, Epoch : 1, Step : 2894, Training Loss : 0.14405, Training Acc : 0.956, Run Time : 0.69
INFO:root:2019-05-11 00:49:21, Epoch : 1, Step : 2895, Training Loss : 0.13642, Training Acc : 0.967, Run Time : 1.04
INFO:root:2019-05-11 00:49:26, Epoch : 1, Step : 2896, Training Loss : 0.15956, Training Acc : 0.944, Run Time : 4.35
INFO:root:2019-05-11 00:49:27, Epoch : 1, Step : 2897, Training Loss : 0.38971, Training Acc : 0.794, Run Time : 1.90
INFO:root:2019-05-11 00:49:28, Epoch : 1, Step : 2898, Training Loss : 0.16262, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-11 00:49:28, Epoch : 1, Step : 2899, Training Loss : 0.17839, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 00:49:29, Epoch : 1, Step : 2900, Training Loss : 0.34808, Training Acc : 0.867, Run Time : 0.65
INFO:root:2019-05-11 00:49:38, Epoch : 1, Step : 2901, Training Loss : 0.23837, Training Acc : 0.911, Run Time : 9.20
INFO:root:2019-05-11 00:49:39, Epoch : 1, Step : 2902, Training Loss : 0.18845, Training Acc : 0.939, Run Time : 0.65
INFO:root:2019-05-11 00:49:39, Epoch : 1, Step : 2903, Training Loss : 0.23027, Training Acc : 0.900, Run Time : 0.44
INFO:root:2019-05-11 00:49:40, Epoch : 1, Step : 2904, Training Loss : 0.29076, Training Acc : 0.856, Run Time : 0.79
INFO:root:2019-05-11 00:49:47, Epoch : 1, Step : 2905, Training Loss : 0.26227, Training Acc : 0.867, Run Time : 7.00
INFO:root:2019-05-11 00:49:47, Epoch : 1, Step : 2906, Training Loss : 0.19598, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 00:49:48, Epoch : 1, Step : 2907, Training Loss : 0.18522, Training Acc : 0.939, Run Time : 0.39
INFO:root:2019-05-11 00:49:48, Epoch : 1, Step : 2908, Training Loss : 0.30373, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-11 00:49:49, Epoch : 1, Step : 2909, Training Loss : 0.22377, Training Acc : 0.900, Run Time : 0.54
INFO:root:2019-05-11 00:49:56, Epoch : 1, Step : 2910, Training Loss : 0.17583, Training Acc : 0.928, Run Time : 6.82
INFO:root:2019-05-11 00:49:56, Epoch : 1, Step : 2911, Training Loss : 0.11681, Training Acc : 0.972, Run Time : 0.41
INFO:root:2019-05-11 00:49:56, Epoch : 1, Step : 2912, Training Loss : 0.16885, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-11 00:49:57, Epoch : 1, Step : 2913, Training Loss : 0.16242, Training Acc : 0.950, Run Time : 1.02
INFO:root:2019-05-11 00:50:05, Epoch : 1, Step : 2914, Training Loss : 0.14253, Training Acc : 0.956, Run Time : 7.67
INFO:root:2019-05-11 00:50:05, Epoch : 1, Step : 2915, Training Loss : 0.18370, Training Acc : 0.939, Run Time : 0.42
INFO:root:2019-05-11 00:50:06, Epoch : 1, Step : 2916, Training Loss : 0.15889, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-11 00:50:06, Epoch : 1, Step : 2917, Training Loss : 0.13920, Training Acc : 0.922, Run Time : 0.56
INFO:root:2019-05-11 00:50:12, Epoch : 1, Step : 2918, Training Loss : 0.13871, Training Acc : 0.933, Run Time : 5.55
INFO:root:2019-05-11 00:50:15, Epoch : 1, Step : 2919, Training Loss : 0.10815, Training Acc : 0.967, Run Time : 3.31
INFO:root:2019-05-11 00:50:16, Epoch : 1, Step : 2920, Training Loss : 0.13482, Training Acc : 0.961, Run Time : 0.60
INFO:root:2019-05-11 00:50:16, Epoch : 1, Step : 2921, Training Loss : 0.28980, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-11 00:50:17, Epoch : 1, Step : 2922, Training Loss : 0.24475, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-11 00:50:18, Epoch : 1, Step : 2923, Training Loss : 0.26437, Training Acc : 0.878, Run Time : 1.25
INFO:root:2019-05-11 00:50:26, Epoch : 1, Step : 2924, Training Loss : 0.24961, Training Acc : 0.906, Run Time : 8.18
INFO:root:2019-05-11 00:50:27, Epoch : 1, Step : 2925, Training Loss : 0.42940, Training Acc : 0.828, Run Time : 0.50
INFO:root:2019-05-11 00:50:27, Epoch : 1, Step : 2926, Training Loss : 0.24202, Training Acc : 0.883, Run Time : 0.51
INFO:root:2019-05-11 00:50:35, Epoch : 1, Step : 2927, Training Loss : 0.24592, Training Acc : 0.894, Run Time : 8.14
INFO:root:2019-05-11 00:50:36, Epoch : 1, Step : 2928, Training Loss : 0.25997, Training Acc : 0.900, Run Time : 0.45
INFO:root:2019-05-11 00:50:37, Epoch : 1, Step : 2929, Training Loss : 0.30521, Training Acc : 0.856, Run Time : 0.97
INFO:root:2019-05-11 00:50:41, Epoch : 1, Step : 2930, Training Loss : 0.31244, Training Acc : 0.878, Run Time : 4.62
INFO:root:2019-05-11 00:50:42, Epoch : 1, Step : 2931, Training Loss : 0.39166, Training Acc : 0.844, Run Time : 1.10
INFO:root:2019-05-11 00:50:43, Epoch : 1, Step : 2932, Training Loss : 0.29235, Training Acc : 0.872, Run Time : 0.37
INFO:root:2019-05-11 00:50:43, Epoch : 1, Step : 2933, Training Loss : 0.25982, Training Acc : 0.906, Run Time : 0.66
INFO:root:2019-05-11 00:50:51, Epoch : 1, Step : 2934, Training Loss : 0.35494, Training Acc : 0.833, Run Time : 7.59
INFO:root:2019-05-11 00:50:51, Epoch : 1, Step : 2935, Training Loss : 0.28977, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-11 00:50:52, Epoch : 1, Step : 2936, Training Loss : 0.23916, Training Acc : 0.883, Run Time : 0.50
INFO:root:2019-05-11 00:50:53, Epoch : 1, Step : 2937, Training Loss : 0.22474, Training Acc : 0.883, Run Time : 0.93
INFO:root:2019-05-11 00:50:56, Epoch : 1, Step : 2938, Training Loss : 0.20608, Training Acc : 0.922, Run Time : 3.50
INFO:root:2019-05-11 00:50:57, Epoch : 1, Step : 2939, Training Loss : 0.14838, Training Acc : 0.928, Run Time : 0.40
INFO:root:2019-05-11 00:50:57, Epoch : 1, Step : 2940, Training Loss : 0.26712, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 00:50:57, Epoch : 1, Step : 2941, Training Loss : 0.17551, Training Acc : 0.917, Run Time : 0.40
INFO:root:2019-05-11 00:51:03, Epoch : 1, Step : 2942, Training Loss : 0.11803, Training Acc : 0.967, Run Time : 5.94
INFO:root:2019-05-11 00:51:04, Epoch : 1, Step : 2943, Training Loss : 0.12842, Training Acc : 0.939, Run Time : 0.56
INFO:root:2019-05-11 00:51:04, Epoch : 1, Step : 2944, Training Loss : 0.16801, Training Acc : 0.939, Run Time : 0.37
INFO:root:2019-05-11 00:51:05, Epoch : 1, Step : 2945, Training Loss : 0.14812, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-11 00:51:06, Epoch : 1, Step : 2946, Training Loss : 0.27128, Training Acc : 0.889, Run Time : 1.39
INFO:root:2019-05-11 00:51:17, Epoch : 1, Step : 2947, Training Loss : 0.17784, Training Acc : 0.939, Run Time : 10.77
INFO:root:2019-05-11 00:51:18, Epoch : 1, Step : 2948, Training Loss : 0.11527, Training Acc : 0.950, Run Time : 0.68
INFO:root:2019-05-11 00:51:18, Epoch : 1, Step : 2949, Training Loss : 0.11670, Training Acc : 0.961, Run Time : 0.40
INFO:root:2019-05-11 00:51:19, Epoch : 1, Step : 2950, Training Loss : 0.06324, Training Acc : 0.983, Run Time : 1.05
INFO:root:2019-05-11 00:51:26, Epoch : 1, Step : 2951, Training Loss : 0.06825, Training Acc : 0.989, Run Time : 7.18
INFO:root:2019-05-11 00:51:27, Epoch : 1, Step : 2952, Training Loss : 0.05192, Training Acc : 1.000, Run Time : 1.02
INFO:root:2019-05-11 00:51:28, Epoch : 1, Step : 2953, Training Loss : 0.12644, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 00:51:29, Epoch : 1, Step : 2954, Training Loss : 0.06834, Training Acc : 0.994, Run Time : 0.91
INFO:root:2019-05-11 00:51:36, Epoch : 1, Step : 2955, Training Loss : 0.06177, Training Acc : 0.972, Run Time : 7.14
INFO:root:2019-05-11 00:51:36, Epoch : 1, Step : 2956, Training Loss : 0.11414, Training Acc : 0.961, Run Time : 0.83
INFO:root:2019-05-11 00:51:37, Epoch : 1, Step : 2957, Training Loss : 0.68810, Training Acc : 0.789, Run Time : 0.50
INFO:root:2019-05-11 00:51:39, Epoch : 1, Step : 2958, Training Loss : 1.23043, Training Acc : 0.606, Run Time : 1.51
INFO:root:2019-05-11 00:51:44, Epoch : 1, Step : 2959, Training Loss : 0.49884, Training Acc : 0.806, Run Time : 5.14
INFO:root:2019-05-11 00:51:44, Epoch : 1, Step : 2960, Training Loss : 0.16856, Training Acc : 0.956, Run Time : 0.43
INFO:root:2019-05-11 00:51:45, Epoch : 1, Step : 2961, Training Loss : 0.17791, Training Acc : 0.928, Run Time : 0.62
INFO:root:2019-05-11 00:51:46, Epoch : 1, Step : 2962, Training Loss : 0.13998, Training Acc : 0.956, Run Time : 0.96
INFO:root:2019-05-11 00:51:47, Epoch : 1, Step : 2963, Training Loss : 0.12612, Training Acc : 0.972, Run Time : 1.01
INFO:root:2019-05-11 00:51:50, Epoch : 1, Step : 2964, Training Loss : 0.21320, Training Acc : 0.922, Run Time : 3.46
INFO:root:2019-05-11 00:51:51, Epoch : 1, Step : 2965, Training Loss : 0.11544, Training Acc : 0.978, Run Time : 1.10
INFO:root:2019-05-11 00:51:52, Epoch : 1, Step : 2966, Training Loss : 0.23857, Training Acc : 0.911, Run Time : 0.79
INFO:root:2019-05-11 00:52:01, Epoch : 1, Step : 2967, Training Loss : 0.14123, Training Acc : 0.967, Run Time : 8.92
INFO:root:2019-05-11 00:52:02, Epoch : 1, Step : 2968, Training Loss : 0.20014, Training Acc : 0.906, Run Time : 1.10
INFO:root:2019-05-11 00:52:02, Epoch : 1, Step : 2969, Training Loss : 0.17131, Training Acc : 0.956, Run Time : 0.38
INFO:root:2019-05-11 00:52:03, Epoch : 1, Step : 2970, Training Loss : 0.17335, Training Acc : 0.950, Run Time : 0.45
INFO:root:2019-05-11 00:52:07, Epoch : 1, Step : 2971, Training Loss : 0.25257, Training Acc : 0.900, Run Time : 4.62
INFO:root:2019-05-11 00:52:08, Epoch : 1, Step : 2972, Training Loss : 0.40796, Training Acc : 0.839, Run Time : 0.40
INFO:root:2019-05-11 00:52:08, Epoch : 1, Step : 2973, Training Loss : 0.29855, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-11 00:52:10, Epoch : 1, Step : 2974, Training Loss : 0.36130, Training Acc : 0.828, Run Time : 1.43
INFO:root:2019-05-11 00:52:17, Epoch : 1, Step : 2975, Training Loss : 0.32356, Training Acc : 0.861, Run Time : 6.86
INFO:root:2019-05-11 00:52:18, Epoch : 1, Step : 2976, Training Loss : 0.20668, Training Acc : 0.889, Run Time : 1.88
INFO:root:2019-05-11 00:52:19, Epoch : 1, Step : 2977, Training Loss : 0.33633, Training Acc : 0.861, Run Time : 0.96
INFO:root:2019-05-11 00:52:26, Epoch : 1, Step : 2978, Training Loss : 0.29189, Training Acc : 0.889, Run Time : 6.17
INFO:root:2019-05-11 00:52:26, Epoch : 1, Step : 2979, Training Loss : 0.36589, Training Acc : 0.850, Run Time : 0.41
INFO:root:2019-05-11 00:52:26, Epoch : 1, Step : 2980, Training Loss : 0.47620, Training Acc : 0.833, Run Time : 0.37
INFO:root:2019-05-11 00:52:27, Epoch : 1, Step : 2981, Training Loss : 0.42356, Training Acc : 0.783, Run Time : 0.49
INFO:root:2019-05-11 00:52:28, Epoch : 1, Step : 2982, Training Loss : 0.28598, Training Acc : 0.872, Run Time : 0.99
INFO:root:2019-05-11 00:52:34, Epoch : 1, Step : 2983, Training Loss : 0.45859, Training Acc : 0.806, Run Time : 6.52
INFO:root:2019-05-11 00:52:35, Epoch : 1, Step : 2984, Training Loss : 0.25615, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 00:52:35, Epoch : 1, Step : 2985, Training Loss : 0.35970, Training Acc : 0.839, Run Time : 0.38
INFO:root:2019-05-11 00:52:36, Epoch : 1, Step : 2986, Training Loss : 0.39200, Training Acc : 0.839, Run Time : 1.37
INFO:root:2019-05-11 00:52:43, Epoch : 1, Step : 2987, Training Loss : 0.36282, Training Acc : 0.822, Run Time : 6.29
INFO:root:2019-05-11 00:52:44, Epoch : 1, Step : 2988, Training Loss : 0.29780, Training Acc : 0.861, Run Time : 0.87
INFO:root:2019-05-11 00:52:45, Epoch : 1, Step : 2989, Training Loss : 0.28969, Training Acc : 0.872, Run Time : 1.38
INFO:root:2019-05-11 00:52:52, Epoch : 1, Step : 2990, Training Loss : 0.16029, Training Acc : 0.939, Run Time : 7.13
INFO:root:2019-05-11 00:52:53, Epoch : 1, Step : 2991, Training Loss : 0.20119, Training Acc : 0.900, Run Time : 0.51
INFO:root:2019-05-11 00:52:53, Epoch : 1, Step : 2992, Training Loss : 0.30026, Training Acc : 0.867, Run Time : 0.37
INFO:root:2019-05-11 00:52:53, Epoch : 1, Step : 2993, Training Loss : 0.26430, Training Acc : 0.872, Run Time : 0.39
INFO:root:2019-05-11 00:52:54, Epoch : 1, Step : 2994, Training Loss : 0.35476, Training Acc : 0.900, Run Time : 0.56
INFO:root:2019-05-11 00:52:55, Epoch : 1, Step : 2995, Training Loss : 0.35080, Training Acc : 0.833, Run Time : 0.67
INFO:root:2019-05-11 00:52:55, Epoch : 1, Step : 2996, Training Loss : 0.28154, Training Acc : 0.867, Run Time : 0.38
INFO:root:2019-05-11 00:52:55, Epoch : 1, Step : 2997, Training Loss : 0.15071, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-11 00:53:01, Epoch : 1, Step : 2998, Training Loss : 0.15852, Training Acc : 0.939, Run Time : 5.11
INFO:root:2019-05-11 00:53:01, Epoch : 1, Step : 2999, Training Loss : 0.20767, Training Acc : 0.922, Run Time : 0.89
INFO:root:2019-05-11 00:53:02, Epoch : 1, Step : 3000, Training Loss : 0.16165, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 00:53:04, Epoch : 1, Step : 3001, Training Loss : 0.56812, Training Acc : 0.783, Run Time : 1.65
INFO:root:2019-05-11 00:53:04, Epoch : 1, Step : 3002, Training Loss : 0.61361, Training Acc : 0.800, Run Time : 0.38
INFO:root:2019-05-11 00:53:04, Epoch : 1, Step : 3003, Training Loss : 0.65182, Training Acc : 0.739, Run Time : 0.38
INFO:root:2019-05-11 00:53:05, Epoch : 1, Step : 3004, Training Loss : 0.55570, Training Acc : 0.728, Run Time : 0.38
INFO:root:2019-05-11 00:53:13, Epoch : 1, Step : 3005, Training Loss : 0.30397, Training Acc : 0.828, Run Time : 8.42
INFO:root:2019-05-11 00:53:14, Epoch : 1, Step : 3006, Training Loss : 0.28631, Training Acc : 0.861, Run Time : 0.61
INFO:root:2019-05-11 00:53:14, Epoch : 1, Step : 3007, Training Loss : 0.28926, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-11 00:53:15, Epoch : 1, Step : 3008, Training Loss : 0.16110, Training Acc : 0.928, Run Time : 0.99
INFO:root:2019-05-11 00:53:21, Epoch : 1, Step : 3009, Training Loss : 0.46799, Training Acc : 0.750, Run Time : 6.37
INFO:root:2019-05-11 00:53:22, Epoch : 1, Step : 3010, Training Loss : 0.34392, Training Acc : 0.844, Run Time : 0.55
INFO:root:2019-05-11 00:53:22, Epoch : 1, Step : 3011, Training Loss : 0.23616, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-11 00:53:23, Epoch : 1, Step : 3012, Training Loss : 0.26822, Training Acc : 0.922, Run Time : 0.50
INFO:root:2019-05-11 00:53:24, Epoch : 1, Step : 3013, Training Loss : 0.18799, Training Acc : 0.928, Run Time : 0.86
INFO:root:2019-05-11 00:53:34, Epoch : 1, Step : 3014, Training Loss : 0.20273, Training Acc : 0.933, Run Time : 9.84
INFO:root:2019-05-11 00:53:34, Epoch : 1, Step : 3015, Training Loss : 0.71762, Training Acc : 0.672, Run Time : 0.78
INFO:root:2019-05-11 00:53:35, Epoch : 1, Step : 3016, Training Loss : 0.33030, Training Acc : 0.878, Run Time : 0.42
INFO:root:2019-05-11 00:53:35, Epoch : 1, Step : 3017, Training Loss : 0.16982, Training Acc : 0.950, Run Time : 0.66
INFO:root:2019-05-11 00:53:39, Epoch : 1, Step : 3018, Training Loss : 0.48665, Training Acc : 0.778, Run Time : 3.44
INFO:root:2019-05-11 00:53:39, Epoch : 1, Step : 3019, Training Loss : 0.45495, Training Acc : 0.789, Run Time : 0.41
INFO:root:2019-05-11 00:53:40, Epoch : 1, Step : 3020, Training Loss : 0.52727, Training Acc : 0.728, Run Time : 0.44
INFO:root:2019-05-11 00:53:41, Epoch : 1, Step : 3021, Training Loss : 0.30900, Training Acc : 0.883, Run Time : 1.02
INFO:root:2019-05-11 00:53:53, Epoch : 1, Step : 3022, Training Loss : 0.27658, Training Acc : 0.883, Run Time : 12.53
INFO:root:2019-05-11 00:53:54, Epoch : 1, Step : 3023, Training Loss : 0.29691, Training Acc : 0.861, Run Time : 0.97
INFO:root:2019-05-11 00:53:55, Epoch : 1, Step : 3024, Training Loss : 0.19907, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 00:53:55, Epoch : 1, Step : 3025, Training Loss : 0.14933, Training Acc : 0.956, Run Time : 0.52
INFO:root:2019-05-11 00:53:56, Epoch : 1, Step : 3026, Training Loss : 0.11177, Training Acc : 0.961, Run Time : 0.76
INFO:root:2019-05-11 00:53:56, Epoch : 1, Step : 3027, Training Loss : 0.36448, Training Acc : 0.817, Run Time : 0.37
INFO:root:2019-05-11 00:53:58, Epoch : 1, Step : 3028, Training Loss : 0.33587, Training Acc : 0.867, Run Time : 1.30
INFO:root:2019-05-11 00:54:07, Epoch : 1, Step : 3029, Training Loss : 0.33673, Training Acc : 0.817, Run Time : 9.69
INFO:root:2019-05-11 00:54:08, Epoch : 1, Step : 3030, Training Loss : 0.31509, Training Acc : 0.850, Run Time : 0.56
INFO:root:2019-05-11 00:54:08, Epoch : 1, Step : 3031, Training Loss : 0.22139, Training Acc : 0.878, Run Time : 0.40
INFO:root:2019-05-11 00:54:09, Epoch : 1, Step : 3032, Training Loss : 0.44653, Training Acc : 0.800, Run Time : 0.37
INFO:root:2019-05-11 00:54:09, Epoch : 1, Step : 3033, Training Loss : 0.30261, Training Acc : 0.889, Run Time : 0.37
INFO:root:2019-05-11 00:54:18, Epoch : 1, Step : 3034, Training Loss : 0.13997, Training Acc : 0.956, Run Time : 8.73
INFO:root:2019-05-11 00:54:18, Epoch : 1, Step : 3035, Training Loss : 0.13948, Training Acc : 0.928, Run Time : 0.58
INFO:root:2019-05-11 00:54:19, Epoch : 1, Step : 3036, Training Loss : 0.24645, Training Acc : 0.917, Run Time : 0.57
INFO:root:2019-05-11 00:54:25, Epoch : 1, Step : 3037, Training Loss : 0.42494, Training Acc : 0.744, Run Time : 6.17
INFO:root:2019-05-11 00:54:26, Epoch : 1, Step : 3038, Training Loss : 0.31219, Training Acc : 0.856, Run Time : 0.70
INFO:root:2019-05-11 00:54:26, Epoch : 1, Step : 3039, Training Loss : 0.36561, Training Acc : 0.833, Run Time : 0.40
INFO:root:2019-05-11 00:54:33, Epoch : 1, Step : 3040, Training Loss : 0.28829, Training Acc : 0.939, Run Time : 7.32
INFO:root:2019-05-11 00:54:34, Epoch : 1, Step : 3041, Training Loss : 0.19280, Training Acc : 0.950, Run Time : 0.94
INFO:root:2019-05-11 00:54:35, Epoch : 1, Step : 3042, Training Loss : 0.08175, Training Acc : 0.989, Run Time : 0.67
INFO:root:2019-05-11 00:54:41, Epoch : 1, Step : 3043, Training Loss : 0.21315, Training Acc : 0.956, Run Time : 6.26
INFO:root:2019-05-11 00:54:42, Epoch : 1, Step : 3044, Training Loss : 0.24053, Training Acc : 0.906, Run Time : 0.62
INFO:root:2019-05-11 00:54:42, Epoch : 1, Step : 3045, Training Loss : 0.17260, Training Acc : 0.956, Run Time : 0.37
INFO:root:2019-05-11 00:54:43, Epoch : 1, Step : 3046, Training Loss : 0.24038, Training Acc : 0.939, Run Time : 0.39
INFO:root:2019-05-11 00:54:49, Epoch : 1, Step : 3047, Training Loss : 0.18495, Training Acc : 0.917, Run Time : 6.29
INFO:root:2019-05-11 00:54:49, Epoch : 1, Step : 3048, Training Loss : 0.21509, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-11 00:54:50, Epoch : 1, Step : 3049, Training Loss : 0.14423, Training Acc : 0.967, Run Time : 0.46
INFO:root:2019-05-11 00:54:51, Epoch : 1, Step : 3050, Training Loss : 0.10382, Training Acc : 0.978, Run Time : 1.41
INFO:root:2019-05-11 00:55:03, Epoch : 1, Step : 3051, Training Loss : 0.16229, Training Acc : 0.911, Run Time : 11.67
INFO:root:2019-05-11 00:55:03, Epoch : 1, Step : 3052, Training Loss : 0.11739, Training Acc : 0.967, Run Time : 0.41
INFO:root:2019-05-11 00:55:04, Epoch : 1, Step : 3053, Training Loss : 0.06357, Training Acc : 0.989, Run Time : 0.39
INFO:root:2019-05-11 00:55:04, Epoch : 1, Step : 3054, Training Loss : 0.12812, Training Acc : 0.967, Run Time : 0.40
INFO:root:2019-05-11 00:55:05, Epoch : 1, Step : 3055, Training Loss : 0.11994, Training Acc : 0.933, Run Time : 0.71
INFO:root:2019-05-11 00:55:06, Epoch : 1, Step : 3056, Training Loss : 0.10516, Training Acc : 0.972, Run Time : 1.48
INFO:root:2019-05-11 00:55:09, Epoch : 1, Step : 3057, Training Loss : 0.09936, Training Acc : 0.961, Run Time : 2.30
INFO:root:2019-05-11 00:55:09, Epoch : 1, Step : 3058, Training Loss : 0.12118, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-11 00:55:10, Epoch : 1, Step : 3059, Training Loss : 0.07896, Training Acc : 0.978, Run Time : 0.56
INFO:root:2019-05-11 00:55:21, Epoch : 1, Step : 3060, Training Loss : 0.15310, Training Acc : 0.978, Run Time : 10.88
INFO:root:2019-05-11 00:55:21, Epoch : 1, Step : 3061, Training Loss : 0.17325, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-11 00:55:21, Epoch : 1, Step : 3062, Training Loss : 0.15859, Training Acc : 0.967, Run Time : 0.42
INFO:root:2019-05-11 00:55:22, Epoch : 1, Step : 3063, Training Loss : 0.13009, Training Acc : 0.956, Run Time : 0.91
INFO:root:2019-05-11 00:55:28, Epoch : 1, Step : 3064, Training Loss : 0.10610, Training Acc : 0.956, Run Time : 6.12
INFO:root:2019-05-11 00:55:29, Epoch : 1, Step : 3065, Training Loss : 0.09919, Training Acc : 0.983, Run Time : 0.62
INFO:root:2019-05-11 00:55:29, Epoch : 1, Step : 3066, Training Loss : 0.11514, Training Acc : 0.983, Run Time : 0.37
INFO:root:2019-05-11 00:55:30, Epoch : 1, Step : 3067, Training Loss : 0.07580, Training Acc : 0.989, Run Time : 0.38
INFO:root:2019-05-11 00:55:31, Epoch : 1, Step : 3068, Training Loss : 0.36719, Training Acc : 0.900, Run Time : 1.38
INFO:root:2019-05-11 00:55:41, Epoch : 1, Step : 3069, Training Loss : 0.15115, Training Acc : 0.928, Run Time : 10.07
INFO:root:2019-05-11 00:55:42, Epoch : 1, Step : 3070, Training Loss : 0.07278, Training Acc : 0.983, Run Time : 0.48
INFO:root:2019-05-11 00:55:43, Epoch : 1, Step : 3071, Training Loss : 0.13599, Training Acc : 0.956, Run Time : 1.21
INFO:root:2019-05-11 00:55:45, Epoch : 1, Step : 3072, Training Loss : 0.08438, Training Acc : 0.983, Run Time : 2.08
INFO:root:2019-05-11 00:55:45, Epoch : 1, Step : 3073, Training Loss : 0.08746, Training Acc : 0.983, Run Time : 0.37
INFO:root:2019-05-11 00:55:46, Epoch : 1, Step : 3074, Training Loss : 0.11194, Training Acc : 0.961, Run Time : 0.38
INFO:root:2019-05-11 00:55:53, Epoch : 1, Step : 3075, Training Loss : 0.14638, Training Acc : 0.961, Run Time : 7.08
INFO:root:2019-05-11 00:55:54, Epoch : 1, Step : 3076, Training Loss : 0.13773, Training Acc : 0.944, Run Time : 0.73
INFO:root:2019-05-11 00:55:54, Epoch : 1, Step : 3077, Training Loss : 0.33938, Training Acc : 0.839, Run Time : 0.38
INFO:root:2019-05-11 00:55:55, Epoch : 1, Step : 3078, Training Loss : 0.16670, Training Acc : 0.956, Run Time : 1.08
INFO:root:2019-05-11 00:56:00, Epoch : 1, Step : 3079, Training Loss : 0.15382, Training Acc : 0.944, Run Time : 4.72
INFO:root:2019-05-11 00:56:00, Epoch : 1, Step : 3080, Training Loss : 0.26877, Training Acc : 0.850, Run Time : 0.47
INFO:root:2019-05-11 00:56:01, Epoch : 1, Step : 3081, Training Loss : 0.10596, Training Acc : 0.983, Run Time : 0.38
INFO:root:2019-05-11 00:56:02, Epoch : 1, Step : 3082, Training Loss : 0.21199, Training Acc : 0.917, Run Time : 1.53
INFO:root:2019-05-11 00:56:11, Epoch : 1, Step : 3083, Training Loss : 0.25065, Training Acc : 0.906, Run Time : 8.49
INFO:root:2019-05-11 00:56:11, Epoch : 1, Step : 3084, Training Loss : 0.25144, Training Acc : 0.872, Run Time : 0.41
INFO:root:2019-05-11 00:56:11, Epoch : 1, Step : 3085, Training Loss : 0.15698, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-11 00:56:12, Epoch : 1, Step : 3086, Training Loss : 0.28046, Training Acc : 0.861, Run Time : 0.39
INFO:root:2019-05-11 00:56:12, Epoch : 1, Step : 3087, Training Loss : 0.13498, Training Acc : 0.933, Run Time : 0.39
INFO:root:2019-05-11 00:56:13, Epoch : 1, Step : 3088, Training Loss : 0.16493, Training Acc : 0.956, Run Time : 0.60
INFO:root:2019-05-11 00:56:19, Epoch : 1, Step : 3089, Training Loss : 0.18058, Training Acc : 0.939, Run Time : 5.70
INFO:root:2019-05-11 00:56:19, Epoch : 1, Step : 3090, Training Loss : 0.18386, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 00:56:19, Epoch : 1, Step : 3091, Training Loss : 0.15947, Training Acc : 0.939, Run Time : 0.40
INFO:root:2019-05-11 00:56:20, Epoch : 1, Step : 3092, Training Loss : 0.19129, Training Acc : 0.906, Run Time : 0.43
INFO:root:2019-05-11 00:56:30, Epoch : 1, Step : 3093, Training Loss : 0.13677, Training Acc : 0.956, Run Time : 10.51
INFO:root:2019-05-11 00:56:31, Epoch : 1, Step : 3094, Training Loss : 0.23765, Training Acc : 0.911, Run Time : 0.54
INFO:root:2019-05-11 00:56:31, Epoch : 1, Step : 3095, Training Loss : 0.27619, Training Acc : 0.872, Run Time : 0.43
INFO:root:2019-05-11 00:56:32, Epoch : 1, Step : 3096, Training Loss : 0.19599, Training Acc : 0.933, Run Time : 1.10
INFO:root:2019-05-11 00:56:38, Epoch : 1, Step : 3097, Training Loss : 0.22201, Training Acc : 0.922, Run Time : 5.49
INFO:root:2019-05-11 00:56:38, Epoch : 1, Step : 3098, Training Loss : 0.32591, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-11 00:56:39, Epoch : 1, Step : 3099, Training Loss : 0.16729, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-11 00:56:40, Epoch : 1, Step : 3100, Training Loss : 0.09581, Training Acc : 0.983, Run Time : 1.29
INFO:root:2019-05-11 00:56:47, Epoch : 1, Step : 3101, Training Loss : 0.21037, Training Acc : 0.900, Run Time : 7.57
INFO:root:2019-05-11 00:56:48, Epoch : 1, Step : 3102, Training Loss : 0.17183, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 00:56:48, Epoch : 1, Step : 3103, Training Loss : 0.09306, Training Acc : 0.978, Run Time : 0.38
INFO:root:2019-05-11 00:56:49, Epoch : 1, Step : 3104, Training Loss : 0.18248, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-11 00:56:54, Epoch : 1, Step : 3105, Training Loss : 0.17136, Training Acc : 0.933, Run Time : 5.08
INFO:root:2019-05-11 00:56:54, Epoch : 1, Step : 3106, Training Loss : 0.08455, Training Acc : 0.972, Run Time : 0.60
INFO:root:2019-05-11 00:56:55, Epoch : 1, Step : 3107, Training Loss : 0.18694, Training Acc : 0.917, Run Time : 0.52
INFO:root:2019-05-11 00:56:56, Epoch : 1, Step : 3108, Training Loss : 0.17069, Training Acc : 0.928, Run Time : 1.31
INFO:root:2019-05-11 00:57:03, Epoch : 1, Step : 3109, Training Loss : 0.18788, Training Acc : 0.928, Run Time : 6.84
INFO:root:2019-05-11 00:57:04, Epoch : 1, Step : 3110, Training Loss : 0.07603, Training Acc : 0.994, Run Time : 0.41
INFO:root:2019-05-11 00:57:04, Epoch : 1, Step : 3111, Training Loss : 0.17594, Training Acc : 0.933, Run Time : 0.49
INFO:root:2019-05-11 00:57:05, Epoch : 1, Step : 3112, Training Loss : 0.14162, Training Acc : 0.939, Run Time : 1.36
INFO:root:2019-05-11 00:57:11, Epoch : 1, Step : 3113, Training Loss : 0.12827, Training Acc : 0.967, Run Time : 5.83
INFO:root:2019-05-11 00:57:12, Epoch : 1, Step : 3114, Training Loss : 0.10706, Training Acc : 0.967, Run Time : 0.40
INFO:root:2019-05-11 00:57:12, Epoch : 1, Step : 3115, Training Loss : 0.17692, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-11 00:57:13, Epoch : 1, Step : 3116, Training Loss : 0.14416, Training Acc : 0.939, Run Time : 1.44
INFO:root:2019-05-11 00:57:21, Epoch : 1, Step : 3117, Training Loss : 0.18459, Training Acc : 0.917, Run Time : 7.26
INFO:root:2019-05-11 00:57:21, Epoch : 1, Step : 3118, Training Loss : 0.11558, Training Acc : 0.961, Run Time : 0.63
INFO:root:2019-05-11 00:57:22, Epoch : 1, Step : 3119, Training Loss : 0.24293, Training Acc : 0.906, Run Time : 0.37
INFO:root:2019-05-11 00:57:23, Epoch : 1, Step : 3120, Training Loss : 0.12281, Training Acc : 0.967, Run Time : 0.91
INFO:root:2019-05-11 00:57:32, Epoch : 1, Step : 3121, Training Loss : 0.10049, Training Acc : 0.972, Run Time : 9.57
INFO:root:2019-05-11 00:57:33, Epoch : 1, Step : 3122, Training Loss : 0.13108, Training Acc : 0.961, Run Time : 0.90
INFO:root:2019-05-11 00:57:34, Epoch : 1, Step : 3123, Training Loss : 0.04311, Training Acc : 0.989, Run Time : 0.70
INFO:root:2019-05-11 00:57:40, Epoch : 1, Step : 3124, Training Loss : 0.10664, Training Acc : 0.961, Run Time : 5.86
INFO:root:2019-05-11 00:57:42, Epoch : 1, Step : 3125, Training Loss : 0.07197, Training Acc : 0.972, Run Time : 2.66
INFO:root:2019-05-11 00:57:43, Epoch : 1, Step : 3126, Training Loss : 0.15144, Training Acc : 0.944, Run Time : 0.53
INFO:root:2019-05-11 00:57:43, Epoch : 1, Step : 3127, Training Loss : 0.07966, Training Acc : 0.950, Run Time : 0.37
INFO:root:2019-05-11 00:57:44, Epoch : 1, Step : 3128, Training Loss : 0.11880, Training Acc : 0.961, Run Time : 1.13
INFO:root:2019-05-11 00:57:50, Epoch : 1, Step : 3129, Training Loss : 0.13211, Training Acc : 0.978, Run Time : 5.22
INFO:root:2019-05-11 00:57:50, Epoch : 1, Step : 3130, Training Loss : 0.15360, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 00:57:50, Epoch : 1, Step : 3131, Training Loss : 0.17604, Training Acc : 0.967, Run Time : 0.43
INFO:root:2019-05-11 00:57:52, Epoch : 1, Step : 3132, Training Loss : 0.17196, Training Acc : 0.939, Run Time : 1.28
INFO:root:2019-05-11 00:58:00, Epoch : 1, Step : 3133, Training Loss : 0.08148, Training Acc : 0.972, Run Time : 8.41
INFO:root:2019-05-11 00:58:01, Epoch : 1, Step : 3134, Training Loss : 0.15792, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-11 00:58:01, Epoch : 1, Step : 3135, Training Loss : 0.38282, Training Acc : 0.900, Run Time : 0.44
INFO:root:2019-05-11 00:58:09, Epoch : 1, Step : 3136, Training Loss : 0.24803, Training Acc : 0.933, Run Time : 8.05
INFO:root:2019-05-11 00:58:10, Epoch : 1, Step : 3137, Training Loss : 0.10256, Training Acc : 0.978, Run Time : 0.50
INFO:root:2019-05-11 00:58:10, Epoch : 1, Step : 3138, Training Loss : 0.19913, Training Acc : 0.950, Run Time : 0.40
INFO:root:2019-05-11 00:58:11, Epoch : 1, Step : 3139, Training Loss : 0.07157, Training Acc : 0.989, Run Time : 1.20
INFO:root:2019-05-11 00:58:21, Epoch : 1, Step : 3140, Training Loss : 0.18549, Training Acc : 0.950, Run Time : 10.35
INFO:root:2019-05-11 00:58:22, Epoch : 1, Step : 3141, Training Loss : 0.17689, Training Acc : 0.944, Run Time : 0.54
INFO:root:2019-05-11 00:58:22, Epoch : 1, Step : 3142, Training Loss : 0.29916, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-11 00:58:23, Epoch : 1, Step : 3143, Training Loss : 0.15022, Training Acc : 0.961, Run Time : 1.02
INFO:root:2019-05-11 00:58:33, Epoch : 1, Step : 3144, Training Loss : 0.23643, Training Acc : 0.922, Run Time : 9.53
INFO:root:2019-05-11 00:58:33, Epoch : 1, Step : 3145, Training Loss : 0.09951, Training Acc : 0.978, Run Time : 0.50
INFO:root:2019-05-11 00:58:34, Epoch : 1, Step : 3146, Training Loss : 0.11866, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-11 00:58:40, Epoch : 1, Step : 3147, Training Loss : 0.04782, Training Acc : 1.000, Run Time : 5.97
INFO:root:2019-05-11 00:58:41, Epoch : 1, Step : 3148, Training Loss : 0.09652, Training Acc : 0.972, Run Time : 1.37
INFO:root:2019-05-11 00:58:42, Epoch : 1, Step : 3149, Training Loss : 0.10307, Training Acc : 0.972, Run Time : 0.76
INFO:root:2019-05-11 00:58:51, Epoch : 1, Step : 3150, Training Loss : 0.06132, Training Acc : 0.989, Run Time : 8.69
INFO:root:2019-05-11 00:58:53, Epoch : 1, Step : 3151, Training Loss : 0.08580, Training Acc : 0.978, Run Time : 2.06
INFO:root:2019-05-11 00:58:54, Epoch : 1, Step : 3152, Training Loss : 0.03926, Training Acc : 0.994, Run Time : 1.36
INFO:root:2019-05-11 00:58:54, Epoch : 1, Step : 3153, Training Loss : 0.12422, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-11 00:58:56, Epoch : 1, Step : 3154, Training Loss : 0.03746, Training Acc : 1.000, Run Time : 1.19
INFO:root:2019-05-11 00:59:05, Epoch : 1, Step : 3155, Training Loss : 0.05949, Training Acc : 0.989, Run Time : 9.14
INFO:root:2019-05-11 00:59:06, Epoch : 1, Step : 3156, Training Loss : 0.04104, Training Acc : 1.000, Run Time : 0.90
INFO:root:2019-05-11 00:59:06, Epoch : 1, Step : 3157, Training Loss : 0.10230, Training Acc : 0.972, Run Time : 0.37
INFO:root:2019-05-11 00:59:07, Epoch : 1, Step : 3158, Training Loss : 0.05106, Training Acc : 0.983, Run Time : 0.73
INFO:root:2019-05-11 00:59:09, Epoch : 1, Step : 3159, Training Loss : 0.06513, Training Acc : 0.983, Run Time : 2.70
INFO:root:2019-05-11 00:59:10, Epoch : 1, Step : 3160, Training Loss : 0.05562, Training Acc : 0.983, Run Time : 0.38
INFO:root:2019-05-11 00:59:10, Epoch : 1, Step : 3161, Training Loss : 0.05190, Training Acc : 0.983, Run Time : 0.37
INFO:root:2019-05-11 00:59:12, Epoch : 1, Step : 3162, Training Loss : 0.04985, Training Acc : 0.989, Run Time : 2.12
INFO:root:2019-05-11 00:59:13, Epoch : 1, Step : 3163, Training Loss : 0.11232, Training Acc : 0.956, Run Time : 0.42
INFO:root:2019-05-11 00:59:13, Epoch : 1, Step : 3164, Training Loss : 0.04588, Training Acc : 0.983, Run Time : 0.41
INFO:root:2019-05-11 00:59:14, Epoch : 1, Step : 3165, Training Loss : 0.08232, Training Acc : 0.967, Run Time : 0.89
INFO:root:2019-05-11 00:59:21, Epoch : 1, Step : 3166, Training Loss : 0.07880, Training Acc : 0.961, Run Time : 6.92
INFO:root:2019-05-11 00:59:29, Epoch : 1, Step : 3167, Training Loss : 0.05052, Training Acc : 0.994, Run Time : 7.61
INFO:root:2019-05-11 00:59:29, Epoch : 1, Step : 3168, Training Loss : 0.02032, Training Acc : 0.994, Run Time : 0.85
INFO:root:2019-05-11 00:59:30, Epoch : 1, Step : 3169, Training Loss : 0.09099, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-11 00:59:31, Epoch : 1, Step : 3170, Training Loss : 0.02719, Training Acc : 0.994, Run Time : 1.28
INFO:root:2019-05-11 00:59:37, Epoch : 1, Step : 3171, Training Loss : 0.07560, Training Acc : 0.978, Run Time : 5.40
INFO:root:2019-05-11 00:59:37, Epoch : 1, Step : 3172, Training Loss : 0.03285, Training Acc : 0.994, Run Time : 0.41
INFO:root:2019-05-11 00:59:37, Epoch : 1, Step : 3173, Training Loss : 0.02168, Training Acc : 1.000, Run Time : 0.45
INFO:root:2019-05-11 00:59:38, Epoch : 1, Step : 3174, Training Loss : 0.08996, Training Acc : 0.983, Run Time : 0.50
INFO:root:2019-05-11 00:59:38, Epoch : 1, Step : 3175, Training Loss : 0.03577, Training Acc : 0.989, Run Time : 0.37
INFO:root:2019-05-11 00:59:39, Epoch : 1, Step : 3176, Training Loss : 0.07529, Training Acc : 0.983, Run Time : 0.37
INFO:root:2019-05-11 00:59:39, Epoch : 1, Step : 3177, Training Loss : 0.11418, Training Acc : 0.972, Run Time : 0.56
INFO:root:2019-05-11 00:59:40, Epoch : 1, Step : 3178, Training Loss : 0.04276, Training Acc : 0.989, Run Time : 0.57
INFO:root:2019-05-11 00:59:41, Epoch : 1, Step : 3179, Training Loss : 0.15689, Training Acc : 0.928, Run Time : 1.12
INFO:root:2019-05-11 00:59:48, Epoch : 1, Step : 3180, Training Loss : 0.07496, Training Acc : 0.972, Run Time : 6.66
INFO:root:2019-05-11 00:59:48, Epoch : 1, Step : 3181, Training Loss : 0.22426, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-11 00:59:48, Epoch : 1, Step : 3182, Training Loss : 0.41310, Training Acc : 0.833, Run Time : 0.40
INFO:root:2019-05-11 00:59:50, Epoch : 1, Step : 3183, Training Loss : 0.24914, Training Acc : 0.894, Run Time : 1.23
INFO:root:2019-05-11 00:59:54, Epoch : 1, Step : 3184, Training Loss : 0.31971, Training Acc : 0.828, Run Time : 4.30
INFO:root:2019-05-11 00:59:54, Epoch : 1, Step : 3185, Training Loss : 0.08758, Training Acc : 0.978, Run Time : 0.40
INFO:root:2019-05-11 00:59:55, Epoch : 1, Step : 3186, Training Loss : 0.07845, Training Acc : 0.978, Run Time : 0.37
INFO:root:2019-05-11 00:59:55, Epoch : 1, Step : 3187, Training Loss : 0.03846, Training Acc : 1.000, Run Time : 0.49
INFO:root:2019-05-11 00:59:56, Epoch : 1, Step : 3188, Training Loss : 0.08826, Training Acc : 0.967, Run Time : 0.53
INFO:root:2019-05-11 01:00:02, Epoch : 1, Step : 3189, Training Loss : 0.28332, Training Acc : 0.917, Run Time : 6.25
INFO:root:2019-05-11 01:00:03, Epoch : 1, Step : 3190, Training Loss : 0.22426, Training Acc : 0.917, Run Time : 0.86
INFO:root:2019-05-11 01:00:03, Epoch : 1, Step : 3191, Training Loss : 0.21597, Training Acc : 0.911, Run Time : 0.51
INFO:root:2019-05-11 01:00:04, Epoch : 1, Step : 3192, Training Loss : 0.34031, Training Acc : 0.894, Run Time : 1.11
INFO:root:2019-05-11 01:00:14, Epoch : 1, Step : 3193, Training Loss : 0.18151, Training Acc : 0.922, Run Time : 9.61
INFO:root:2019-05-11 01:00:14, Epoch : 1, Step : 3194, Training Loss : 0.41909, Training Acc : 0.883, Run Time : 0.40
INFO:root:2019-05-11 01:00:15, Epoch : 1, Step : 3195, Training Loss : 0.34772, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-11 01:00:16, Epoch : 1, Step : 3196, Training Loss : 0.20569, Training Acc : 0.933, Run Time : 1.13
INFO:root:2019-05-11 01:00:24, Epoch : 1, Step : 3197, Training Loss : 0.30802, Training Acc : 0.933, Run Time : 8.11
INFO:root:2019-05-11 01:00:25, Epoch : 1, Step : 3198, Training Loss : 0.29165, Training Acc : 0.939, Run Time : 0.78
INFO:root:2019-05-11 01:00:25, Epoch : 1, Step : 3199, Training Loss : 0.32648, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-11 01:00:26, Epoch : 1, Step : 3200, Training Loss : 0.33481, Training Acc : 0.889, Run Time : 0.50
INFO:root:2019-05-11 01:00:28, Epoch : 1, Step : 3201, Training Loss : 1.08158, Training Acc : 0.661, Run Time : 1.94
INFO:root:2019-05-11 01:00:28, Epoch : 1, Step : 3202, Training Loss : 0.92815, Training Acc : 0.672, Run Time : 0.37
INFO:root:2019-05-11 01:00:29, Epoch : 1, Step : 3203, Training Loss : 0.69179, Training Acc : 0.706, Run Time : 0.37
INFO:root:2019-05-11 01:00:29, Epoch : 1, Step : 3204, Training Loss : 0.73887, Training Acc : 0.678, Run Time : 0.45
INFO:root:2019-05-11 01:00:32, Epoch : 1, Step : 3205, Training Loss : 0.46566, Training Acc : 0.811, Run Time : 2.80
INFO:root:2019-05-11 01:00:33, Epoch : 1, Step : 3206, Training Loss : 0.37821, Training Acc : 0.822, Run Time : 0.74
INFO:root:2019-05-11 01:00:33, Epoch : 1, Step : 3207, Training Loss : 0.32173, Training Acc : 0.850, Run Time : 0.37
INFO:root:2019-05-11 01:00:33, Epoch : 1, Step : 3208, Training Loss : 0.22596, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 01:00:34, Epoch : 1, Step : 3209, Training Loss : 0.25063, Training Acc : 0.861, Run Time : 0.85
INFO:root:2019-05-11 01:00:36, Epoch : 1, Step : 3210, Training Loss : 0.16591, Training Acc : 0.928, Run Time : 1.60
INFO:root:2019-05-11 01:00:37, Epoch : 1, Step : 3211, Training Loss : 0.14045, Training Acc : 0.944, Run Time : 1.17
INFO:root:2019-05-11 01:00:44, Epoch : 1, Step : 3212, Training Loss : 0.17657, Training Acc : 0.939, Run Time : 6.60
INFO:root:2019-05-11 01:00:44, Epoch : 1, Step : 3213, Training Loss : 0.20074, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 01:00:44, Epoch : 1, Step : 3214, Training Loss : 0.21617, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 01:00:45, Epoch : 1, Step : 3215, Training Loss : 0.33120, Training Acc : 0.922, Run Time : 0.39
INFO:root:2019-05-11 01:00:45, Epoch : 1, Step : 3216, Training Loss : 0.22858, Training Acc : 0.922, Run Time : 0.54
INFO:root:2019-05-11 01:00:46, Epoch : 1, Step : 3217, Training Loss : 0.21212, Training Acc : 0.933, Run Time : 0.91
INFO:root:2019-05-11 01:00:58, Epoch : 1, Step : 3218, Training Loss : 0.23999, Training Acc : 0.933, Run Time : 12.07
INFO:root:2019-05-11 01:00:59, Epoch : 1, Step : 3219, Training Loss : 0.30581, Training Acc : 0.911, Run Time : 0.77
INFO:root:2019-05-11 01:00:59, Epoch : 1, Step : 3220, Training Loss : 0.27760, Training Acc : 0.917, Run Time : 0.40
INFO:root:2019-05-11 01:01:03, Epoch : 1, Step : 3221, Training Loss : 0.32446, Training Acc : 0.917, Run Time : 3.19
INFO:root:2019-05-11 01:01:03, Epoch : 1, Step : 3222, Training Loss : 0.22887, Training Acc : 0.917, Run Time : 0.82
INFO:root:2019-05-11 01:01:05, Epoch : 1, Step : 3223, Training Loss : 0.20073, Training Acc : 0.922, Run Time : 1.55
INFO:root:2019-05-11 01:01:05, Epoch : 1, Step : 3224, Training Loss : 0.18058, Training Acc : 0.928, Run Time : 0.54
INFO:root:2019-05-11 01:01:06, Epoch : 1, Step : 3225, Training Loss : 0.22591, Training Acc : 0.911, Run Time : 0.87
INFO:root:2019-05-11 01:01:07, Epoch : 1, Step : 3226, Training Loss : 0.20124, Training Acc : 0.928, Run Time : 0.98
INFO:root:2019-05-11 01:01:08, Epoch : 1, Step : 3227, Training Loss : 0.21985, Training Acc : 0.917, Run Time : 0.39
INFO:root:2019-05-11 01:01:15, Epoch : 1, Step : 3228, Training Loss : 0.19500, Training Acc : 0.922, Run Time : 7.18
INFO:root:2019-05-11 01:01:16, Epoch : 1, Step : 3229, Training Loss : 0.17104, Training Acc : 0.933, Run Time : 0.86
INFO:root:2019-05-11 01:01:16, Epoch : 1, Step : 3230, Training Loss : 0.30883, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-11 01:01:18, Epoch : 1, Step : 3231, Training Loss : 0.24254, Training Acc : 0.900, Run Time : 1.46
INFO:root:2019-05-11 01:01:26, Epoch : 1, Step : 3232, Training Loss : 0.17352, Training Acc : 0.911, Run Time : 8.05
INFO:root:2019-05-11 01:01:26, Epoch : 1, Step : 3233, Training Loss : 0.15959, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-11 01:01:28, Epoch : 1, Step : 3234, Training Loss : 0.14224, Training Acc : 0.922, Run Time : 1.59
INFO:root:2019-05-11 01:01:35, Epoch : 1, Step : 3235, Training Loss : 0.16906, Training Acc : 0.906, Run Time : 7.48
INFO:root:2019-05-11 01:01:36, Epoch : 1, Step : 3236, Training Loss : 0.11984, Training Acc : 0.956, Run Time : 0.62
INFO:root:2019-05-11 01:01:36, Epoch : 1, Step : 3237, Training Loss : 0.13185, Training Acc : 0.939, Run Time : 0.39
INFO:root:2019-05-11 01:01:37, Epoch : 1, Step : 3238, Training Loss : 0.13149, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 01:01:37, Epoch : 1, Step : 3239, Training Loss : 0.09589, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-11 01:01:43, Epoch : 1, Step : 3240, Training Loss : 0.11009, Training Acc : 0.950, Run Time : 5.56
INFO:root:2019-05-11 01:01:43, Epoch : 1, Step : 3241, Training Loss : 0.08746, Training Acc : 0.967, Run Time : 0.79
INFO:root:2019-05-11 01:01:44, Epoch : 1, Step : 3242, Training Loss : 0.16241, Training Acc : 0.928, Run Time : 0.37
INFO:root:2019-05-11 01:01:45, Epoch : 1, Step : 3243, Training Loss : 0.18399, Training Acc : 0.917, Run Time : 1.24
INFO:root:2019-05-11 01:01:51, Epoch : 1, Step : 3244, Training Loss : 0.14953, Training Acc : 0.933, Run Time : 6.44
INFO:root:2019-05-11 01:01:52, Epoch : 1, Step : 3245, Training Loss : 0.09815, Training Acc : 0.967, Run Time : 0.46
INFO:root:2019-05-11 01:01:52, Epoch : 1, Step : 3246, Training Loss : 0.17012, Training Acc : 0.944, Run Time : 0.40
INFO:root:2019-05-11 01:01:53, Epoch : 1, Step : 3247, Training Loss : 0.16406, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 01:01:54, Epoch : 1, Step : 3248, Training Loss : 0.13579, Training Acc : 0.939, Run Time : 1.21
INFO:root:2019-05-11 01:01:56, Epoch : 1, Step : 3249, Training Loss : 0.16707, Training Acc : 0.922, Run Time : 2.33
INFO:root:2019-05-11 01:01:57, Epoch : 1, Step : 3250, Training Loss : 0.13923, Training Acc : 0.933, Run Time : 0.45
INFO:root:2019-05-11 01:01:57, Epoch : 1, Step : 3251, Training Loss : 0.16391, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 01:01:58, Epoch : 1, Step : 3252, Training Loss : 0.16939, Training Acc : 0.922, Run Time : 0.85
INFO:root:2019-05-11 01:02:04, Epoch : 1, Step : 3253, Training Loss : 0.10583, Training Acc : 0.928, Run Time : 6.06
INFO:root:2019-05-11 01:02:04, Epoch : 1, Step : 3254, Training Loss : 0.17174, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-11 01:02:05, Epoch : 1, Step : 3255, Training Loss : 0.15307, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-11 01:02:13, Epoch : 1, Step : 3256, Training Loss : 0.16588, Training Acc : 0.917, Run Time : 8.67
INFO:root:2019-05-11 01:02:14, Epoch : 1, Step : 3257, Training Loss : 0.13703, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-11 01:02:15, Epoch : 1, Step : 3258, Training Loss : 0.16065, Training Acc : 0.933, Run Time : 1.19
INFO:root:2019-05-11 01:02:22, Epoch : 1, Step : 3259, Training Loss : 0.16215, Training Acc : 0.944, Run Time : 7.11
INFO:root:2019-05-11 01:02:23, Epoch : 1, Step : 3260, Training Loss : 0.13488, Training Acc : 0.933, Run Time : 0.67
INFO:root:2019-05-11 01:02:23, Epoch : 1, Step : 3261, Training Loss : 0.17494, Training Acc : 0.939, Run Time : 0.37
INFO:root:2019-05-11 01:02:24, Epoch : 1, Step : 3262, Training Loss : 0.16433, Training Acc : 0.928, Run Time : 0.39
INFO:root:2019-05-11 01:02:24, Epoch : 1, Step : 3263, Training Loss : 0.18674, Training Acc : 0.889, Run Time : 0.89
INFO:root:2019-05-11 01:02:31, Epoch : 1, Step : 3264, Training Loss : 0.21431, Training Acc : 0.889, Run Time : 6.55
INFO:root:2019-05-11 01:02:32, Epoch : 1, Step : 3265, Training Loss : 0.24976, Training Acc : 0.894, Run Time : 0.54
INFO:root:2019-05-11 01:02:32, Epoch : 1, Step : 3266, Training Loss : 0.15769, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-11 01:02:32, Epoch : 1, Step : 3267, Training Loss : 0.16413, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 01:02:33, Epoch : 1, Step : 3268, Training Loss : 0.20116, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 01:02:34, Epoch : 1, Step : 3269, Training Loss : 0.21013, Training Acc : 0.889, Run Time : 0.96
INFO:root:2019-05-11 01:02:43, Epoch : 1, Step : 3270, Training Loss : 0.22472, Training Acc : 0.894, Run Time : 8.95
INFO:root:2019-05-11 01:02:44, Epoch : 1, Step : 3271, Training Loss : 0.17515, Training Acc : 0.933, Run Time : 1.06
INFO:root:2019-05-11 01:02:44, Epoch : 1, Step : 3272, Training Loss : 0.17344, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-11 01:02:46, Epoch : 1, Step : 3273, Training Loss : 0.14540, Training Acc : 0.933, Run Time : 2.19
INFO:root:2019-05-11 01:03:04, Epoch : 1, Step : 3274, Training Loss : 0.16142, Training Acc : 0.900, Run Time : 17.43
INFO:root:2019-05-11 01:03:05, Epoch : 1, Step : 3275, Training Loss : 0.17396, Training Acc : 0.911, Run Time : 1.66
INFO:root:2019-05-11 01:03:06, Epoch : 1, Step : 3276, Training Loss : 0.15237, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-11 01:03:07, Epoch : 1, Step : 3277, Training Loss : 0.22631, Training Acc : 0.883, Run Time : 0.86
INFO:root:2019-05-11 01:03:16, Epoch : 1, Step : 3278, Training Loss : 0.15832, Training Acc : 0.922, Run Time : 9.45
INFO:root:2019-05-11 01:03:18, Epoch : 1, Step : 3279, Training Loss : 0.17011, Training Acc : 0.900, Run Time : 1.56
INFO:root:2019-05-11 01:03:26, Epoch : 1, Step : 3280, Training Loss : 0.18123, Training Acc : 0.917, Run Time : 8.25
INFO:root:2019-05-11 01:03:27, Epoch : 1, Step : 3281, Training Loss : 0.13073, Training Acc : 0.956, Run Time : 0.77
INFO:root:2019-05-11 01:03:27, Epoch : 1, Step : 3282, Training Loss : 0.15004, Training Acc : 0.917, Run Time : 0.75
INFO:root:2019-05-11 01:03:33, Epoch : 1, Step : 3283, Training Loss : 0.14735, Training Acc : 0.939, Run Time : 6.00
INFO:root:2019-05-11 01:03:34, Epoch : 1, Step : 3284, Training Loss : 0.14541, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-11 01:03:34, Epoch : 1, Step : 3285, Training Loss : 0.14444, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 01:03:35, Epoch : 1, Step : 3286, Training Loss : 0.15019, Training Acc : 0.928, Run Time : 0.53
INFO:root:2019-05-11 01:03:40, Epoch : 1, Step : 3287, Training Loss : 0.12983, Training Acc : 0.933, Run Time : 5.42
INFO:root:2019-05-11 01:03:42, Epoch : 1, Step : 3288, Training Loss : 0.12962, Training Acc : 0.956, Run Time : 1.71
INFO:root:2019-05-11 01:03:47, Epoch : 1, Step : 3289, Training Loss : 0.12653, Training Acc : 0.950, Run Time : 5.49
INFO:root:2019-05-11 01:03:48, Epoch : 1, Step : 3290, Training Loss : 0.14638, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-11 01:03:48, Epoch : 1, Step : 3291, Training Loss : 0.14000, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 01:03:54, Epoch : 1, Step : 3292, Training Loss : 0.16387, Training Acc : 0.917, Run Time : 5.37
INFO:root:2019-05-11 01:03:55, Epoch : 1, Step : 3293, Training Loss : 0.12569, Training Acc : 0.944, Run Time : 1.18
INFO:root:2019-05-11 01:03:56, Epoch : 1, Step : 3294, Training Loss : 0.16108, Training Acc : 0.933, Run Time : 1.71
INFO:root:2019-05-11 01:04:03, Epoch : 1, Step : 3295, Training Loss : 0.13782, Training Acc : 0.950, Run Time : 6.82
INFO:root:2019-05-11 01:04:04, Epoch : 1, Step : 3296, Training Loss : 0.11864, Training Acc : 0.922, Run Time : 0.55
INFO:root:2019-05-11 01:04:04, Epoch : 1, Step : 3297, Training Loss : 0.13468, Training Acc : 0.933, Run Time : 0.37
INFO:root:2019-05-11 01:04:06, Epoch : 1, Step : 3298, Training Loss : 0.13591, Training Acc : 0.922, Run Time : 1.56
INFO:root:2019-05-11 01:04:14, Epoch : 1, Step : 3299, Training Loss : 0.10076, Training Acc : 0.950, Run Time : 8.63
INFO:root:2019-05-11 01:04:15, Epoch : 1, Step : 3300, Training Loss : 0.14250, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 01:04:15, Epoch : 1, Step : 3301, Training Loss : 0.10215, Training Acc : 0.944, Run Time : 0.72
INFO:root:2019-05-11 01:04:17, Epoch : 1, Step : 3302, Training Loss : 0.12556, Training Acc : 0.939, Run Time : 1.38
INFO:root:2019-05-11 01:04:24, Epoch : 1, Step : 3303, Training Loss : 0.13808, Training Acc : 0.933, Run Time : 7.43
INFO:root:2019-05-11 01:04:25, Epoch : 1, Step : 3304, Training Loss : 0.11713, Training Acc : 0.939, Run Time : 0.58
INFO:root:2019-05-11 01:04:25, Epoch : 1, Step : 3305, Training Loss : 0.14087, Training Acc : 0.944, Run Time : 0.48
INFO:root:2019-05-11 01:04:26, Epoch : 1, Step : 3306, Training Loss : 0.08554, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-11 01:04:32, Epoch : 1, Step : 3307, Training Loss : 0.11525, Training Acc : 0.956, Run Time : 5.69
INFO:root:2019-05-11 01:04:34, Epoch : 1, Step : 3308, Training Loss : 0.11809, Training Acc : 0.967, Run Time : 2.76
INFO:root:2019-05-11 01:04:35, Epoch : 1, Step : 3309, Training Loss : 0.13053, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 01:04:35, Epoch : 1, Step : 3310, Training Loss : 0.12754, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 01:04:43, Epoch : 1, Step : 3311, Training Loss : 0.11195, Training Acc : 0.961, Run Time : 7.69
INFO:root:2019-05-11 01:04:43, Epoch : 1, Step : 3312, Training Loss : 0.11110, Training Acc : 0.950, Run Time : 0.46
INFO:root:2019-05-11 01:04:44, Epoch : 1, Step : 3313, Training Loss : 0.12224, Training Acc : 0.956, Run Time : 0.76
INFO:root:2019-05-11 01:04:44, Epoch : 1, Step : 3314, Training Loss : 0.11964, Training Acc : 0.967, Run Time : 0.37
INFO:root:2019-05-11 01:04:45, Epoch : 1, Step : 3315, Training Loss : 0.09215, Training Acc : 0.961, Run Time : 0.92
INFO:root:2019-05-11 01:04:52, Epoch : 1, Step : 3316, Training Loss : 0.11440, Training Acc : 0.972, Run Time : 6.57
INFO:root:2019-05-11 01:04:52, Epoch : 1, Step : 3317, Training Loss : 0.10763, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-11 01:04:53, Epoch : 1, Step : 3318, Training Loss : 0.12047, Training Acc : 0.961, Run Time : 0.40
INFO:root:2019-05-11 01:04:53, Epoch : 1, Step : 3319, Training Loss : 0.07572, Training Acc : 0.983, Run Time : 0.52
INFO:root:2019-05-11 01:05:03, Epoch : 1, Step : 3320, Training Loss : 0.22233, Training Acc : 0.900, Run Time : 9.62
INFO:root:2019-05-11 01:05:03, Epoch : 1, Step : 3321, Training Loss : 0.16259, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-11 01:05:04, Epoch : 1, Step : 3322, Training Loss : 0.13040, Training Acc : 0.956, Run Time : 0.42
INFO:root:2019-05-11 01:05:05, Epoch : 1, Step : 3323, Training Loss : 0.12983, Training Acc : 0.950, Run Time : 1.07
INFO:root:2019-05-11 01:05:12, Epoch : 1, Step : 3324, Training Loss : 0.09834, Training Acc : 0.961, Run Time : 7.02
INFO:root:2019-05-11 01:05:12, Epoch : 1, Step : 3325, Training Loss : 0.09356, Training Acc : 0.967, Run Time : 0.41
INFO:root:2019-05-11 01:05:13, Epoch : 1, Step : 3326, Training Loss : 0.12132, Training Acc : 0.956, Run Time : 0.57
INFO:root:2019-05-11 01:05:13, Epoch : 1, Step : 3327, Training Loss : 0.09134, Training Acc : 0.972, Run Time : 0.70
INFO:root:2019-05-11 01:05:18, Epoch : 1, Step : 3328, Training Loss : 0.09955, Training Acc : 0.961, Run Time : 4.55
INFO:root:2019-05-11 01:05:19, Epoch : 1, Step : 3329, Training Loss : 0.10267, Training Acc : 0.956, Run Time : 0.82
INFO:root:2019-05-11 01:05:19, Epoch : 1, Step : 3330, Training Loss : 0.10443, Training Acc : 0.978, Run Time : 0.37
INFO:root:2019-05-11 01:05:20, Epoch : 1, Step : 3331, Training Loss : 0.12509, Training Acc : 0.944, Run Time : 0.65
INFO:root:2019-05-11 01:05:28, Epoch : 1, Step : 3332, Training Loss : 0.12146, Training Acc : 0.950, Run Time : 8.54
INFO:root:2019-05-11 01:05:29, Epoch : 1, Step : 3333, Training Loss : 0.14249, Training Acc : 0.961, Run Time : 0.80
INFO:root:2019-05-11 01:05:30, Epoch : 1, Step : 3334, Training Loss : 0.10350, Training Acc : 0.967, Run Time : 0.38
INFO:root:2019-05-11 01:05:31, Epoch : 1, Step : 3335, Training Loss : 0.11730, Training Acc : 0.961, Run Time : 1.09
INFO:root:2019-05-11 01:05:39, Epoch : 1, Step : 3336, Training Loss : 0.11607, Training Acc : 0.961, Run Time : 8.29
INFO:root:2019-05-11 01:05:39, Epoch : 1, Step : 3337, Training Loss : 0.09578, Training Acc : 0.978, Run Time : 0.42
INFO:root:2019-05-11 01:05:40, Epoch : 1, Step : 3338, Training Loss : 0.10347, Training Acc : 0.967, Run Time : 0.37
INFO:root:2019-05-11 01:05:40, Epoch : 1, Step : 3339, Training Loss : 0.12819, Training Acc : 0.939, Run Time : 0.69
INFO:root:2019-05-11 01:05:48, Epoch : 1, Step : 3340, Training Loss : 0.12607, Training Acc : 0.961, Run Time : 7.77
INFO:root:2019-05-11 01:05:49, Epoch : 1, Step : 3341, Training Loss : 0.15378, Training Acc : 0.917, Run Time : 0.67
INFO:root:2019-05-11 01:05:49, Epoch : 1, Step : 3342, Training Loss : 0.12131, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 01:05:51, Epoch : 1, Step : 3343, Training Loss : 0.13871, Training Acc : 0.944, Run Time : 1.38
INFO:root:2019-05-11 01:06:00, Epoch : 1, Step : 3344, Training Loss : 0.13377, Training Acc : 0.928, Run Time : 9.27
INFO:root:2019-05-11 01:06:00, Epoch : 1, Step : 3345, Training Loss : 0.15414, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-11 01:06:01, Epoch : 1, Step : 3346, Training Loss : 0.17074, Training Acc : 0.922, Run Time : 0.53
INFO:root:2019-05-11 01:06:01, Epoch : 1, Step : 3347, Training Loss : 0.14869, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 01:06:08, Epoch : 1, Step : 3348, Training Loss : 0.15153, Training Acc : 0.939, Run Time : 7.14
INFO:root:2019-05-11 01:06:09, Epoch : 1, Step : 3349, Training Loss : 0.15386, Training Acc : 0.933, Run Time : 1.10
INFO:root:2019-05-11 01:06:10, Epoch : 1, Step : 3350, Training Loss : 0.14157, Training Acc : 0.944, Run Time : 0.37
INFO:root:2019-05-11 01:06:11, Epoch : 1, Step : 3351, Training Loss : 0.16057, Training Acc : 0.939, Run Time : 1.29
INFO:root:2019-05-11 01:06:18, Epoch : 1, Step : 3352, Training Loss : 0.14321, Training Acc : 0.950, Run Time : 7.14
INFO:root:2019-05-11 01:06:19, Epoch : 1, Step : 3353, Training Loss : 0.15961, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-11 01:06:19, Epoch : 1, Step : 3354, Training Loss : 0.14429, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-11 01:06:20, Epoch : 1, Step : 3355, Training Loss : 0.12898, Training Acc : 0.961, Run Time : 0.55
INFO:root:2019-05-11 01:06:26, Epoch : 1, Step : 3356, Training Loss : 0.12480, Training Acc : 0.956, Run Time : 6.43
INFO:root:2019-05-11 01:06:26, Epoch : 1, Step : 3357, Training Loss : 0.16228, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-11 01:06:27, Epoch : 1, Step : 3358, Training Loss : 0.14012, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-11 01:06:27, Epoch : 1, Step : 3359, Training Loss : 0.16099, Training Acc : 0.944, Run Time : 0.57
INFO:root:2019-05-11 01:06:28, Epoch : 1, Step : 3360, Training Loss : 0.17124, Training Acc : 0.922, Run Time : 0.59
INFO:root:2019-05-11 01:06:36, Epoch : 1, Step : 3361, Training Loss : 0.17495, Training Acc : 0.922, Run Time : 7.89
INFO:root:2019-05-11 01:06:37, Epoch : 1, Step : 3362, Training Loss : 0.16457, Training Acc : 0.911, Run Time : 0.79
INFO:root:2019-05-11 01:06:37, Epoch : 1, Step : 3363, Training Loss : 0.13948, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-11 01:06:38, Epoch : 1, Step : 3364, Training Loss : 0.11573, Training Acc : 0.956, Run Time : 1.09
INFO:root:2019-05-11 01:06:45, Epoch : 1, Step : 3365, Training Loss : 0.16709, Training Acc : 0.928, Run Time : 6.61
INFO:root:2019-05-11 01:06:45, Epoch : 1, Step : 3366, Training Loss : 0.14050, Training Acc : 0.928, Run Time : 0.51
INFO:root:2019-05-11 01:06:46, Epoch : 1, Step : 3367, Training Loss : 0.11924, Training Acc : 0.961, Run Time : 0.53
INFO:root:2019-05-11 01:06:54, Epoch : 1, Step : 3368, Training Loss : 0.17969, Training Acc : 0.911, Run Time : 7.70
INFO:root:2019-05-11 01:06:54, Epoch : 1, Step : 3369, Training Loss : 0.12135, Training Acc : 0.956, Run Time : 0.55
INFO:root:2019-05-11 01:06:55, Epoch : 1, Step : 3370, Training Loss : 0.13412, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 01:06:55, Epoch : 1, Step : 3371, Training Loss : 0.19408, Training Acc : 0.889, Run Time : 0.70
INFO:root:2019-05-11 01:06:56, Epoch : 1, Step : 3372, Training Loss : 0.12997, Training Acc : 0.933, Run Time : 0.81
INFO:root:2019-05-11 01:07:01, Epoch : 1, Step : 3373, Training Loss : 0.21950, Training Acc : 0.889, Run Time : 4.91
INFO:root:2019-05-11 01:07:01, Epoch : 1, Step : 3374, Training Loss : 0.22416, Training Acc : 0.900, Run Time : 0.41
INFO:root:2019-05-11 01:07:02, Epoch : 1, Step : 3375, Training Loss : 0.14503, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 01:07:02, Epoch : 1, Step : 3376, Training Loss : 0.16261, Training Acc : 0.922, Run Time : 0.39
INFO:root:2019-05-11 01:07:03, Epoch : 1, Step : 3377, Training Loss : 0.16284, Training Acc : 0.944, Run Time : 0.71
INFO:root:2019-05-11 01:07:08, Epoch : 1, Step : 3378, Training Loss : 0.16206, Training Acc : 0.922, Run Time : 5.19
INFO:root:2019-05-11 01:07:09, Epoch : 1, Step : 3379, Training Loss : 0.15015, Training Acc : 0.933, Run Time : 0.60
INFO:root:2019-05-11 01:07:09, Epoch : 1, Step : 3380, Training Loss : 0.13306, Training Acc : 0.944, Run Time : 0.40
INFO:root:2019-05-11 01:07:09, Epoch : 1, Step : 3381, Training Loss : 0.14104, Training Acc : 0.956, Run Time : 0.39
INFO:root:2019-05-11 01:07:10, Epoch : 1, Step : 3382, Training Loss : 0.15872, Training Acc : 0.944, Run Time : 0.64
INFO:root:2019-05-11 01:07:15, Epoch : 1, Step : 3383, Training Loss : 0.14030, Training Acc : 0.950, Run Time : 5.16
INFO:root:2019-05-11 01:07:16, Epoch : 1, Step : 3384, Training Loss : 0.14716, Training Acc : 0.944, Run Time : 0.41
INFO:root:2019-05-11 01:07:16, Epoch : 1, Step : 3385, Training Loss : 0.12410, Training Acc : 0.944, Run Time : 0.42
INFO:root:2019-05-11 01:07:18, Epoch : 1, Step : 3386, Training Loss : 0.17397, Training Acc : 0.911, Run Time : 1.54
INFO:root:2019-05-11 01:07:24, Epoch : 1, Step : 3387, Training Loss : 0.18358, Training Acc : 0.922, Run Time : 6.13
INFO:root:2019-05-11 01:07:24, Epoch : 1, Step : 3388, Training Loss : 0.12876, Training Acc : 0.967, Run Time : 0.48
INFO:root:2019-05-11 01:07:25, Epoch : 1, Step : 3389, Training Loss : 0.17058, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-11 01:07:25, Epoch : 1, Step : 3390, Training Loss : 0.16657, Training Acc : 0.944, Run Time : 0.37
INFO:root:2019-05-11 01:07:26, Epoch : 1, Step : 3391, Training Loss : 0.18250, Training Acc : 0.906, Run Time : 1.52
INFO:root:2019-05-11 01:07:35, Epoch : 1, Step : 3392, Training Loss : 0.20572, Training Acc : 0.889, Run Time : 8.15
INFO:root:2019-05-11 01:07:35, Epoch : 1, Step : 3393, Training Loss : 0.16581, Training Acc : 0.933, Run Time : 0.69
INFO:root:2019-05-11 01:07:37, Epoch : 1, Step : 3394, Training Loss : 0.15195, Training Acc : 0.933, Run Time : 1.42
INFO:root:2019-05-11 01:07:45, Epoch : 1, Step : 3395, Training Loss : 0.22920, Training Acc : 0.883, Run Time : 8.05
INFO:root:2019-05-11 01:07:45, Epoch : 1, Step : 3396, Training Loss : 0.13909, Training Acc : 0.933, Run Time : 0.54
INFO:root:2019-05-11 01:07:46, Epoch : 1, Step : 3397, Training Loss : 0.13364, Training Acc : 0.956, Run Time : 0.38
INFO:root:2019-05-11 01:07:47, Epoch : 1, Step : 3398, Training Loss : 0.14246, Training Acc : 0.939, Run Time : 0.95
INFO:root:2019-05-11 01:07:56, Epoch : 1, Step : 3399, Training Loss : 0.11027, Training Acc : 0.956, Run Time : 9.36
INFO:root:2019-05-11 01:07:57, Epoch : 1, Step : 3400, Training Loss : 0.13675, Training Acc : 0.950, Run Time : 0.56
INFO:root:2019-05-11 01:08:06, Epoch : 1, Step : 3401, Training Loss : 0.53496, Training Acc : 0.822, Run Time : 9.10
INFO:root:2019-05-11 01:08:07, Epoch : 1, Step : 3402, Training Loss : 0.88538, Training Acc : 0.728, Run Time : 1.03
INFO:root:2019-05-11 01:08:07, Epoch : 1, Step : 3403, Training Loss : 0.60711, Training Acc : 0.811, Run Time : 0.41
INFO:root:2019-05-11 01:08:07, Epoch : 1, Step : 3404, Training Loss : 0.56121, Training Acc : 0.839, Run Time : 0.38
INFO:root:2019-05-11 01:08:08, Epoch : 1, Step : 3405, Training Loss : 0.42814, Training Acc : 0.822, Run Time : 0.47
INFO:root:2019-05-11 01:08:09, Epoch : 1, Step : 3406, Training Loss : 0.37885, Training Acc : 0.861, Run Time : 0.98
INFO:root:2019-05-11 01:08:15, Epoch : 1, Step : 3407, Training Loss : 0.30029, Training Acc : 0.872, Run Time : 6.05
INFO:root:2019-05-11 01:08:16, Epoch : 1, Step : 3408, Training Loss : 0.31325, Training Acc : 0.872, Run Time : 0.72
INFO:root:2019-05-11 01:08:16, Epoch : 1, Step : 3409, Training Loss : 0.40780, Training Acc : 0.844, Run Time : 0.65
INFO:root:2019-05-11 01:08:17, Epoch : 1, Step : 3410, Training Loss : 0.36700, Training Acc : 0.872, Run Time : 0.98
INFO:root:2019-05-11 01:08:20, Epoch : 1, Step : 3411, Training Loss : 0.86435, Training Acc : 0.756, Run Time : 2.28
INFO:root:2019-05-11 01:08:20, Epoch : 1, Step : 3412, Training Loss : 1.01938, Training Acc : 0.689, Run Time : 0.39
INFO:root:2019-05-11 01:08:21, Epoch : 1, Step : 3413, Training Loss : 0.38767, Training Acc : 0.817, Run Time : 0.74
INFO:root:2019-05-11 01:08:25, Epoch : 1, Step : 3414, Training Loss : 0.40737, Training Acc : 0.828, Run Time : 4.36
INFO:root:2019-05-11 01:08:26, Epoch : 1, Step : 3415, Training Loss : 0.59290, Training Acc : 0.789, Run Time : 0.49
INFO:root:2019-05-11 01:08:26, Epoch : 1, Step : 3416, Training Loss : 0.31209, Training Acc : 0.872, Run Time : 0.48
INFO:root:2019-05-11 01:08:26, Epoch : 1, Step : 3417, Training Loss : 0.18945, Training Acc : 0.911, Run Time : 0.40
INFO:root:2019-05-11 01:08:27, Epoch : 1, Step : 3418, Training Loss : 0.20146, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 01:08:27, Epoch : 1, Step : 3419, Training Loss : 0.13474, Training Acc : 0.939, Run Time : 0.67
INFO:root:2019-05-11 01:08:30, Epoch : 1, Step : 3420, Training Loss : 0.15495, Training Acc : 0.911, Run Time : 2.29
INFO:root:2019-05-11 01:08:30, Epoch : 1, Step : 3421, Training Loss : 0.14830, Training Acc : 0.939, Run Time : 0.49
INFO:root:2019-05-11 01:08:33, Epoch : 1, Step : 3422, Training Loss : 0.19873, Training Acc : 0.894, Run Time : 2.90
INFO:root:2019-05-11 01:08:34, Epoch : 1, Step : 3423, Training Loss : 0.18924, Training Acc : 0.950, Run Time : 0.67
INFO:root:2019-05-11 01:08:34, Epoch : 1, Step : 3424, Training Loss : 0.12026, Training Acc : 0.944, Run Time : 0.40
INFO:root:2019-05-11 01:08:35, Epoch : 1, Step : 3425, Training Loss : 0.13069, Training Acc : 0.956, Run Time : 1.16
INFO:root:2019-05-11 01:08:44, Epoch : 1, Step : 3426, Training Loss : 0.17381, Training Acc : 0.928, Run Time : 8.65
INFO:root:2019-05-11 01:08:45, Epoch : 1, Step : 3427, Training Loss : 0.16023, Training Acc : 0.961, Run Time : 0.53
INFO:root:2019-05-11 01:08:45, Epoch : 1, Step : 3428, Training Loss : 0.20325, Training Acc : 0.917, Run Time : 0.88
INFO:root:2019-05-11 01:08:54, Epoch : 1, Step : 3429, Training Loss : 0.14899, Training Acc : 0.967, Run Time : 8.62
INFO:root:2019-05-11 01:08:58, Epoch : 1, Step : 3430, Training Loss : 0.13811, Training Acc : 0.939, Run Time : 4.35
INFO:root:2019-05-11 01:08:59, Epoch : 1, Step : 3431, Training Loss : 0.26822, Training Acc : 0.939, Run Time : 0.41
INFO:root:2019-05-11 01:09:00, Epoch : 1, Step : 3432, Training Loss : 0.14004, Training Acc : 0.961, Run Time : 1.37
INFO:root:2019-05-11 01:09:08, Epoch : 1, Step : 3433, Training Loss : 0.12431, Training Acc : 0.983, Run Time : 8.12
INFO:root:2019-05-11 01:09:09, Epoch : 1, Step : 3434, Training Loss : 0.24488, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-11 01:09:09, Epoch : 1, Step : 3435, Training Loss : 0.16595, Training Acc : 0.956, Run Time : 0.40
INFO:root:2019-05-11 01:09:10, Epoch : 1, Step : 3436, Training Loss : 0.06372, Training Acc : 0.994, Run Time : 0.89
INFO:root:2019-05-11 01:09:17, Epoch : 1, Step : 3437, Training Loss : 0.13055, Training Acc : 0.944, Run Time : 7.10
INFO:root:2019-05-11 01:09:18, Epoch : 1, Step : 3438, Training Loss : 0.24198, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-11 01:09:18, Epoch : 1, Step : 3439, Training Loss : 0.18911, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 01:09:19, Epoch : 1, Step : 3440, Training Loss : 0.15376, Training Acc : 0.928, Run Time : 0.53
INFO:root:2019-05-11 01:09:21, Epoch : 1, Step : 3441, Training Loss : 0.15785, Training Acc : 0.944, Run Time : 2.67
INFO:root:2019-05-11 01:09:22, Epoch : 1, Step : 3442, Training Loss : 0.16992, Training Acc : 0.928, Run Time : 0.72
INFO:root:2019-05-11 01:09:23, Epoch : 1, Step : 3443, Training Loss : 0.27164, Training Acc : 0.889, Run Time : 0.62
INFO:root:2019-05-11 01:09:23, Epoch : 1, Step : 3444, Training Loss : 0.18461, Training Acc : 0.939, Run Time : 0.54
INFO:root:2019-05-11 01:09:29, Epoch : 1, Step : 3445, Training Loss : 0.18596, Training Acc : 0.939, Run Time : 5.53
INFO:root:2019-05-11 01:09:29, Epoch : 1, Step : 3446, Training Loss : 0.20500, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-11 01:09:30, Epoch : 1, Step : 3447, Training Loss : 0.14576, Training Acc : 0.933, Run Time : 0.59
INFO:root:2019-05-11 01:09:38, Epoch : 1, Step : 3448, Training Loss : 0.17056, Training Acc : 0.928, Run Time : 8.71
INFO:root:2019-05-11 01:09:39, Epoch : 1, Step : 3449, Training Loss : 0.26421, Training Acc : 0.906, Run Time : 0.68
INFO:root:2019-05-11 01:09:41, Epoch : 1, Step : 3450, Training Loss : 0.76349, Training Acc : 0.700, Run Time : 1.51
INFO:root:2019-05-11 01:09:49, Epoch : 1, Step : 3451, Training Loss : 0.70710, Training Acc : 0.778, Run Time : 8.74
INFO:root:2019-05-11 01:09:50, Epoch : 1, Step : 3452, Training Loss : 0.27730, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-11 01:09:50, Epoch : 1, Step : 3453, Training Loss : 0.18805, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-11 01:09:51, Epoch : 1, Step : 3454, Training Loss : 0.21499, Training Acc : 0.917, Run Time : 0.75
INFO:root:2019-05-11 01:09:58, Epoch : 1, Step : 3455, Training Loss : 0.23095, Training Acc : 0.894, Run Time : 7.45
INFO:root:2019-05-11 01:09:59, Epoch : 1, Step : 3456, Training Loss : 0.26189, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-11 01:09:59, Epoch : 1, Step : 3457, Training Loss : 0.24127, Training Acc : 0.894, Run Time : 0.37
INFO:root:2019-05-11 01:10:00, Epoch : 1, Step : 3458, Training Loss : 0.28845, Training Acc : 0.856, Run Time : 0.43
INFO:root:2019-05-11 01:10:00, Epoch : 1, Step : 3459, Training Loss : 0.17170, Training Acc : 0.956, Run Time : 0.39
INFO:root:2019-05-11 01:10:11, Epoch : 1, Step : 3460, Training Loss : 0.16450, Training Acc : 0.939, Run Time : 10.62
INFO:root:2019-05-11 01:10:11, Epoch : 1, Step : 3461, Training Loss : 0.13581, Training Acc : 0.933, Run Time : 0.43
INFO:root:2019-05-11 01:10:11, Epoch : 1, Step : 3462, Training Loss : 0.15330, Training Acc : 0.939, Run Time : 0.40
INFO:root:2019-05-11 01:10:13, Epoch : 1, Step : 3463, Training Loss : 0.17803, Training Acc : 0.933, Run Time : 1.46
INFO:root:2019-05-11 01:10:20, Epoch : 1, Step : 3464, Training Loss : 0.24241, Training Acc : 0.956, Run Time : 7.12
INFO:root:2019-05-11 01:10:20, Epoch : 1, Step : 3465, Training Loss : 0.09701, Training Acc : 0.961, Run Time : 0.41
INFO:root:2019-05-11 01:10:21, Epoch : 1, Step : 3466, Training Loss : 0.13539, Training Acc : 0.956, Run Time : 0.56
INFO:root:2019-05-11 01:10:26, Epoch : 1, Step : 3467, Training Loss : 0.17427, Training Acc : 0.933, Run Time : 5.04
INFO:root:2019-05-11 01:10:27, Epoch : 1, Step : 3468, Training Loss : 0.21450, Training Acc : 0.906, Run Time : 0.59
INFO:root:2019-05-11 01:10:27, Epoch : 1, Step : 3469, Training Loss : 0.10076, Training Acc : 0.961, Run Time : 0.90
INFO:root:2019-05-11 01:10:36, Epoch : 1, Step : 3470, Training Loss : 0.29282, Training Acc : 0.861, Run Time : 8.92
INFO:root:2019-05-11 01:10:38, Epoch : 1, Step : 3471, Training Loss : 0.20923, Training Acc : 0.933, Run Time : 1.96
INFO:root:2019-05-11 01:10:39, Epoch : 1, Step : 3472, Training Loss : 0.12236, Training Acc : 0.956, Run Time : 0.96
INFO:root:2019-05-11 01:10:40, Epoch : 1, Step : 3473, Training Loss : 0.09419, Training Acc : 0.983, Run Time : 0.37
INFO:root:2019-05-11 01:10:41, Epoch : 1, Step : 3474, Training Loss : 0.07115, Training Acc : 0.994, Run Time : 0.82
INFO:root:2019-05-11 01:10:48, Epoch : 1, Step : 3475, Training Loss : 0.09463, Training Acc : 0.956, Run Time : 7.17
INFO:root:2019-05-11 01:10:48, Epoch : 1, Step : 3476, Training Loss : 0.08212, Training Acc : 0.978, Run Time : 0.40
INFO:root:2019-05-11 01:10:49, Epoch : 1, Step : 3477, Training Loss : 0.13800, Training Acc : 0.950, Run Time : 0.61
INFO:root:2019-05-11 01:10:49, Epoch : 1, Step : 3478, Training Loss : 0.13831, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 01:10:50, Epoch : 1, Step : 3479, Training Loss : 0.24498, Training Acc : 0.900, Run Time : 0.76
INFO:root:2019-05-11 01:10:51, Epoch : 1, Step : 3480, Training Loss : 0.15345, Training Acc : 0.928, Run Time : 0.65
INFO:root:2019-05-11 01:10:58, Epoch : 1, Step : 3481, Training Loss : 0.13560, Training Acc : 0.928, Run Time : 7.18
INFO:root:2019-05-11 01:10:58, Epoch : 1, Step : 3482, Training Loss : 0.06952, Training Acc : 0.989, Run Time : 0.70
INFO:root:2019-05-11 01:10:59, Epoch : 1, Step : 3483, Training Loss : 0.33504, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-11 01:10:59, Epoch : 1, Step : 3484, Training Loss : 0.14744, Training Acc : 0.944, Run Time : 0.42
INFO:root:2019-05-11 01:11:04, Epoch : 1, Step : 3485, Training Loss : 0.25620, Training Acc : 0.900, Run Time : 5.24
INFO:root:2019-05-11 01:11:07, Epoch : 1, Step : 3486, Training Loss : 0.13953, Training Acc : 0.950, Run Time : 2.33
INFO:root:2019-05-11 01:11:07, Epoch : 1, Step : 3487, Training Loss : 0.11693, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-11 01:11:08, Epoch : 1, Step : 3488, Training Loss : 0.10994, Training Acc : 0.967, Run Time : 0.53
INFO:root:2019-05-11 01:11:12, Epoch : 1, Step : 3489, Training Loss : 0.12873, Training Acc : 0.961, Run Time : 3.92
INFO:root:2019-05-11 01:11:14, Epoch : 1, Step : 3490, Training Loss : 0.03744, Training Acc : 1.000, Run Time : 2.11
INFO:root:2019-05-11 01:11:14, Epoch : 1, Step : 3491, Training Loss : 0.07394, Training Acc : 0.989, Run Time : 0.37
INFO:root:2019-05-11 01:11:15, Epoch : 1, Step : 3492, Training Loss : 0.07339, Training Acc : 0.967, Run Time : 1.12
INFO:root:2019-05-11 01:11:20, Epoch : 1, Step : 3493, Training Loss : 0.09701, Training Acc : 0.967, Run Time : 4.81
INFO:root:2019-05-11 01:11:20, Epoch : 1, Step : 3494, Training Loss : 0.06473, Training Acc : 0.978, Run Time : 0.45
INFO:root:2019-05-11 01:11:21, Epoch : 1, Step : 3495, Training Loss : 0.09874, Training Acc : 0.967, Run Time : 0.60
INFO:root:2019-05-11 01:11:23, Epoch : 1, Step : 3496, Training Loss : 0.06610, Training Acc : 0.983, Run Time : 1.44
INFO:root:2019-05-11 01:11:23, Epoch : 1, Step : 3497, Training Loss : 0.05910, Training Acc : 0.983, Run Time : 0.40
INFO:root:2019-05-11 01:11:24, Epoch : 1, Step : 3498, Training Loss : 0.11324, Training Acc : 0.950, Run Time : 0.84
INFO:root:2019-05-11 01:11:30, Epoch : 1, Step : 3499, Training Loss : 0.12716, Training Acc : 0.950, Run Time : 5.87
INFO:root:2019-05-11 01:11:30, Epoch : 1, Step : 3500, Training Loss : 0.14648, Training Acc : 0.933, Run Time : 0.51
INFO:root:2019-05-11 01:11:31, Epoch : 1, Step : 3501, Training Loss : 0.12816, Training Acc : 0.944, Run Time : 0.87
INFO:root:2019-05-11 01:11:38, Epoch : 1, Step : 3502, Training Loss : 0.22895, Training Acc : 0.922, Run Time : 7.20
INFO:root:2019-05-11 01:11:39, Epoch : 1, Step : 3503, Training Loss : 0.14280, Training Acc : 0.939, Run Time : 0.43
INFO:root:2019-05-11 01:11:39, Epoch : 1, Step : 3504, Training Loss : 0.24764, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-11 01:11:39, Epoch : 1, Step : 3505, Training Loss : 0.28962, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 01:11:40, Epoch : 1, Step : 3506, Training Loss : 0.25174, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-11 01:11:44, Epoch : 1, Step : 3507, Training Loss : 0.30070, Training Acc : 0.889, Run Time : 3.90
INFO:root:2019-05-11 01:11:45, Epoch : 1, Step : 3508, Training Loss : 0.03676, Training Acc : 0.994, Run Time : 0.96
INFO:root:2019-05-11 01:11:48, Epoch : 1, Step : 3509, Training Loss : 0.29938, Training Acc : 0.883, Run Time : 3.00
INFO:root:2019-05-11 01:11:49, Epoch : 1, Step : 3510, Training Loss : 0.09774, Training Acc : 0.961, Run Time : 0.93
INFO:root:2019-05-11 01:11:55, Epoch : 1, Step : 3511, Training Loss : 0.05469, Training Acc : 0.978, Run Time : 6.03
INFO:root:2019-05-11 01:11:55, Epoch : 1, Step : 3512, Training Loss : 0.05314, Training Acc : 0.989, Run Time : 0.41
INFO:root:2019-05-11 01:11:56, Epoch : 1, Step : 3513, Training Loss : 0.07277, Training Acc : 0.972, Run Time : 0.37
INFO:root:2019-05-11 01:11:57, Epoch : 1, Step : 3514, Training Loss : 0.10620, Training Acc : 0.956, Run Time : 1.58
INFO:root:2019-05-11 01:12:03, Epoch : 1, Step : 3515, Training Loss : 0.16819, Training Acc : 0.939, Run Time : 6.00
INFO:root:2019-05-11 01:12:04, Epoch : 1, Step : 3516, Training Loss : 0.23733, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 01:12:05, Epoch : 1, Step : 3517, Training Loss : 0.14924, Training Acc : 0.950, Run Time : 1.19
INFO:root:2019-05-11 01:12:14, Epoch : 1, Step : 3518, Training Loss : 0.10493, Training Acc : 0.950, Run Time : 9.13
INFO:root:2019-05-11 01:12:14, Epoch : 1, Step : 3519, Training Loss : 0.25767, Training Acc : 0.894, Run Time : 0.42
INFO:root:2019-05-11 01:12:15, Epoch : 1, Step : 3520, Training Loss : 0.24052, Training Acc : 0.889, Run Time : 0.49
INFO:root:2019-05-11 01:12:15, Epoch : 1, Step : 3521, Training Loss : 0.10429, Training Acc : 0.956, Run Time : 0.39
INFO:root:2019-05-11 01:12:21, Epoch : 1, Step : 3522, Training Loss : 0.16708, Training Acc : 0.939, Run Time : 6.36
INFO:root:2019-05-11 01:12:23, Epoch : 1, Step : 3523, Training Loss : 0.14367, Training Acc : 0.944, Run Time : 1.09
INFO:root:2019-05-11 01:12:23, Epoch : 1, Step : 3524, Training Loss : 0.05771, Training Acc : 0.989, Run Time : 0.42
INFO:root:2019-05-11 01:12:31, Epoch : 1, Step : 3525, Training Loss : 0.17194, Training Acc : 0.928, Run Time : 7.62
INFO:root:2019-05-11 01:12:38, Epoch : 1, Step : 3526, Training Loss : 0.06579, Training Acc : 0.972, Run Time : 7.66
INFO:root:2019-05-11 01:12:39, Epoch : 1, Step : 3527, Training Loss : 0.09427, Training Acc : 0.978, Run Time : 0.44
INFO:root:2019-05-11 01:12:39, Epoch : 1, Step : 3528, Training Loss : 0.07318, Training Acc : 0.967, Run Time : 0.43
INFO:root:2019-05-11 01:12:40, Epoch : 1, Step : 3529, Training Loss : 0.07848, Training Acc : 0.972, Run Time : 0.81
INFO:root:2019-05-11 01:12:48, Epoch : 1, Step : 3530, Training Loss : 0.09816, Training Acc : 0.967, Run Time : 8.52
INFO:root:2019-05-11 01:12:49, Epoch : 1, Step : 3531, Training Loss : 0.09948, Training Acc : 0.961, Run Time : 0.41
INFO:root:2019-05-11 01:12:49, Epoch : 1, Step : 3532, Training Loss : 0.07496, Training Acc : 0.972, Run Time : 0.46
INFO:root:2019-05-11 01:12:50, Epoch : 1, Step : 3533, Training Loss : 0.05362, Training Acc : 0.994, Run Time : 0.61
INFO:root:2019-05-11 01:12:51, Epoch : 1, Step : 3534, Training Loss : 0.16179, Training Acc : 0.939, Run Time : 0.74
INFO:root:2019-05-11 01:12:58, Epoch : 1, Step : 3535, Training Loss : 0.09060, Training Acc : 0.956, Run Time : 6.92
INFO:root:2019-05-11 01:12:58, Epoch : 1, Step : 3536, Training Loss : 0.12834, Training Acc : 0.950, Run Time : 0.68
INFO:root:2019-05-11 01:12:59, Epoch : 1, Step : 3537, Training Loss : 0.03730, Training Acc : 0.983, Run Time : 0.86
INFO:root:2019-05-11 01:13:07, Epoch : 1, Step : 3538, Training Loss : 0.02964, Training Acc : 0.994, Run Time : 7.70
INFO:root:2019-05-11 01:13:07, Epoch : 1, Step : 3539, Training Loss : 0.07078, Training Acc : 0.978, Run Time : 0.41
INFO:root:2019-05-11 01:13:08, Epoch : 1, Step : 3540, Training Loss : 0.05329, Training Acc : 0.983, Run Time : 0.39
INFO:root:2019-05-11 01:13:09, Epoch : 1, Step : 3541, Training Loss : 0.08959, Training Acc : 0.961, Run Time : 1.19
INFO:root:2019-05-11 01:13:14, Epoch : 1, Step : 3542, Training Loss : 0.23869, Training Acc : 0.906, Run Time : 5.02
INFO:root:2019-05-11 01:13:14, Epoch : 1, Step : 3543, Training Loss : 0.16245, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 01:13:15, Epoch : 1, Step : 3544, Training Loss : 0.09223, Training Acc : 0.967, Run Time : 0.38
INFO:root:2019-05-11 01:13:16, Epoch : 1, Step : 3545, Training Loss : 0.07891, Training Acc : 0.967, Run Time : 1.09
INFO:root:2019-05-11 01:13:20, Epoch : 1, Step : 3546, Training Loss : 0.04884, Training Acc : 0.989, Run Time : 3.94
INFO:root:2019-05-11 01:13:20, Epoch : 1, Step : 3547, Training Loss : 0.13976, Training Acc : 0.950, Run Time : 0.40
INFO:root:2019-05-11 01:13:25, Epoch : 1, Step : 3548, Training Loss : 0.13334, Training Acc : 0.950, Run Time : 4.65
INFO:root:2019-05-11 01:13:27, Epoch : 1, Step : 3549, Training Loss : 0.04357, Training Acc : 0.983, Run Time : 1.99
INFO:root:2019-05-11 01:13:27, Epoch : 1, Step : 3550, Training Loss : 0.15376, Training Acc : 0.928, Run Time : 0.53
INFO:root:2019-05-11 01:13:28, Epoch : 1, Step : 3551, Training Loss : 0.14097, Training Acc : 0.950, Run Time : 0.54
INFO:root:2019-05-11 01:13:29, Epoch : 1, Step : 3552, Training Loss : 0.11004, Training Acc : 0.967, Run Time : 1.11
INFO:root:2019-05-11 01:13:30, Epoch : 1, Step : 3553, Training Loss : 0.21233, Training Acc : 0.917, Run Time : 1.21
INFO:root:2019-05-11 01:13:31, Epoch : 1, Step : 3554, Training Loss : 0.08483, Training Acc : 0.972, Run Time : 0.97
INFO:root:2019-05-11 01:13:36, Epoch : 1, Step : 3555, Training Loss : 0.12420, Training Acc : 0.950, Run Time : 4.79
INFO:root:2019-05-11 01:13:36, Epoch : 1, Step : 3556, Training Loss : 0.11027, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-11 01:13:37, Epoch : 1, Step : 3557, Training Loss : 0.05865, Training Acc : 0.989, Run Time : 0.41
INFO:root:2019-05-11 01:13:45, Epoch : 1, Step : 3558, Training Loss : 0.09917, Training Acc : 0.956, Run Time : 8.25
INFO:root:2019-05-11 01:13:46, Epoch : 1, Step : 3559, Training Loss : 0.06397, Training Acc : 0.972, Run Time : 0.76
INFO:root:2019-05-11 01:13:46, Epoch : 1, Step : 3560, Training Loss : 0.18743, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-11 01:13:54, Epoch : 1, Step : 3561, Training Loss : 0.12750, Training Acc : 0.944, Run Time : 7.64
INFO:root:2019-05-11 01:13:54, Epoch : 1, Step : 3562, Training Loss : 0.13578, Training Acc : 0.944, Run Time : 0.58
INFO:root:2019-05-11 01:13:55, Epoch : 1, Step : 3563, Training Loss : 0.32801, Training Acc : 0.889, Run Time : 0.98
INFO:root:2019-05-11 01:14:02, Epoch : 1, Step : 3564, Training Loss : 0.14997, Training Acc : 0.933, Run Time : 6.90
INFO:root:2019-05-11 01:14:03, Epoch : 1, Step : 3565, Training Loss : 0.29560, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-11 01:14:03, Epoch : 1, Step : 3566, Training Loss : 0.15176, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 01:14:03, Epoch : 1, Step : 3567, Training Loss : 0.09327, Training Acc : 0.967, Run Time : 0.37
INFO:root:2019-05-11 01:14:04, Epoch : 1, Step : 3568, Training Loss : 0.15267, Training Acc : 0.933, Run Time : 0.68
INFO:root:2019-05-11 01:14:05, Epoch : 1, Step : 3569, Training Loss : 0.17165, Training Acc : 0.922, Run Time : 1.06
INFO:root:2019-05-11 01:14:06, Epoch : 1, Step : 3570, Training Loss : 0.08914, Training Acc : 0.967, Run Time : 0.97
INFO:root:2019-05-11 01:14:13, Epoch : 1, Step : 3571, Training Loss : 0.13823, Training Acc : 0.917, Run Time : 6.47
INFO:root:2019-05-11 01:14:13, Epoch : 1, Step : 3572, Training Loss : 0.16028, Training Acc : 0.939, Run Time : 0.61
INFO:root:2019-05-11 01:14:14, Epoch : 1, Step : 3573, Training Loss : 0.13990, Training Acc : 0.961, Run Time : 0.51
INFO:root:2019-05-11 01:14:15, Epoch : 1, Step : 3574, Training Loss : 0.08431, Training Acc : 0.972, Run Time : 1.11
INFO:root:2019-05-11 01:14:23, Epoch : 1, Step : 3575, Training Loss : 0.08069, Training Acc : 0.978, Run Time : 7.99
INFO:root:2019-05-11 01:14:23, Epoch : 1, Step : 3576, Training Loss : 0.09043, Training Acc : 0.972, Run Time : 0.42
INFO:root:2019-05-11 01:14:24, Epoch : 1, Step : 3577, Training Loss : 0.10176, Training Acc : 0.967, Run Time : 0.37
INFO:root:2019-05-11 01:14:25, Epoch : 1, Step : 3578, Training Loss : 0.16955, Training Acc : 0.933, Run Time : 1.54
INFO:root:2019-05-11 01:14:31, Epoch : 1, Step : 3579, Training Loss : 0.15017, Training Acc : 0.928, Run Time : 6.12
INFO:root:2019-05-11 01:14:32, Epoch : 1, Step : 3580, Training Loss : 0.09850, Training Acc : 0.956, Run Time : 0.64
INFO:root:2019-05-11 01:14:32, Epoch : 1, Step : 3581, Training Loss : 0.14819, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 01:14:34, Epoch : 1, Step : 3582, Training Loss : 0.18534, Training Acc : 0.906, Run Time : 1.19
INFO:root:2019-05-11 01:14:37, Epoch : 1, Step : 3583, Training Loss : 0.09320, Training Acc : 0.972, Run Time : 3.10
INFO:root:2019-05-11 01:14:38, Epoch : 1, Step : 3584, Training Loss : 0.14856, Training Acc : 0.939, Run Time : 1.00
INFO:root:2019-05-11 01:14:44, Epoch : 1, Step : 3585, Training Loss : 0.27518, Training Acc : 0.883, Run Time : 6.28
INFO:root:2019-05-11 01:14:44, Epoch : 1, Step : 3586, Training Loss : 0.06369, Training Acc : 0.983, Run Time : 0.41
INFO:root:2019-05-11 01:14:45, Epoch : 1, Step : 3587, Training Loss : 0.15773, Training Acc : 0.928, Run Time : 0.37
INFO:root:2019-05-11 01:14:46, Epoch : 1, Step : 3588, Training Loss : 0.21484, Training Acc : 0.911, Run Time : 1.02
INFO:root:2019-05-11 01:14:53, Epoch : 1, Step : 3589, Training Loss : 0.08500, Training Acc : 0.956, Run Time : 7.10
INFO:root:2019-05-11 01:14:53, Epoch : 1, Step : 3590, Training Loss : 0.10028, Training Acc : 0.978, Run Time : 0.41
INFO:root:2019-05-11 01:14:54, Epoch : 1, Step : 3591, Training Loss : 0.09426, Training Acc : 0.967, Run Time : 0.39
INFO:root:2019-05-11 01:14:54, Epoch : 1, Step : 3592, Training Loss : 0.12087, Training Acc : 0.939, Run Time : 0.77
INFO:root:2019-05-11 01:15:03, Epoch : 1, Step : 3593, Training Loss : 0.17079, Training Acc : 0.939, Run Time : 8.45
INFO:root:2019-05-11 01:15:03, Epoch : 1, Step : 3594, Training Loss : 0.12053, Training Acc : 0.944, Run Time : 0.41
INFO:root:2019-05-11 01:15:11, Epoch : 1, Step : 3595, Training Loss : 0.13237, Training Acc : 0.950, Run Time : 7.37
INFO:root:2019-05-11 01:15:11, Epoch : 1, Step : 3596, Training Loss : 0.36577, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-11 01:15:11, Epoch : 1, Step : 3597, Training Loss : 0.23128, Training Acc : 0.894, Run Time : 0.37
INFO:root:2019-05-11 01:15:12, Epoch : 1, Step : 3598, Training Loss : 0.13988, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 01:15:12, Epoch : 1, Step : 3599, Training Loss : 0.30992, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-11 01:15:13, Epoch : 1, Step : 3600, Training Loss : 0.29327, Training Acc : 0.856, Run Time : 0.37
INFO:root:2019-05-11 01:15:23, Epoch : 1, Step : 3601, Training Loss : 0.79958, Training Acc : 0.733, Run Time : 9.99
INFO:root:2019-05-11 01:15:23, Epoch : 1, Step : 3602, Training Loss : 1.11817, Training Acc : 0.622, Run Time : 0.65
INFO:root:2019-05-11 01:15:24, Epoch : 1, Step : 3603, Training Loss : 0.69251, Training Acc : 0.750, Run Time : 0.54
INFO:root:2019-05-11 01:15:28, Epoch : 1, Step : 3604, Training Loss : 1.03412, Training Acc : 0.622, Run Time : 3.84
INFO:root:2019-05-11 01:15:34, Epoch : 1, Step : 3605, Training Loss : 0.86515, Training Acc : 0.694, Run Time : 6.13
INFO:root:2019-05-11 01:15:35, Epoch : 1, Step : 3606, Training Loss : 0.88473, Training Acc : 0.589, Run Time : 0.84
INFO:root:2019-05-11 01:15:35, Epoch : 1, Step : 3607, Training Loss : 0.58409, Training Acc : 0.678, Run Time : 0.46
INFO:root:2019-05-11 01:15:44, Epoch : 1, Step : 3608, Training Loss : 0.64146, Training Acc : 0.700, Run Time : 9.06
INFO:root:2019-05-11 01:15:45, Epoch : 1, Step : 3609, Training Loss : 0.48477, Training Acc : 0.778, Run Time : 1.02
INFO:root:2019-05-11 01:15:45, Epoch : 1, Step : 3610, Training Loss : 0.60438, Training Acc : 0.778, Run Time : 0.37
INFO:root:2019-05-11 01:15:47, Epoch : 1, Step : 3611, Training Loss : 0.59762, Training Acc : 0.711, Run Time : 1.25
INFO:root:2019-05-11 01:15:56, Epoch : 1, Step : 3612, Training Loss : 0.35214, Training Acc : 0.811, Run Time : 9.23
INFO:root:2019-05-11 01:15:57, Epoch : 1, Step : 3613, Training Loss : 0.30475, Training Acc : 0.867, Run Time : 0.87
INFO:root:2019-05-11 01:15:57, Epoch : 1, Step : 3614, Training Loss : 0.42512, Training Acc : 0.800, Run Time : 0.38
INFO:root:2019-05-11 01:15:58, Epoch : 1, Step : 3615, Training Loss : 0.50905, Training Acc : 0.744, Run Time : 0.50
INFO:root:2019-05-11 01:15:58, Epoch : 1, Step : 3616, Training Loss : 0.43560, Training Acc : 0.772, Run Time : 0.41
INFO:root:2019-05-11 01:15:58, Epoch : 1, Step : 3617, Training Loss : 0.43050, Training Acc : 0.822, Run Time : 0.38
INFO:root:2019-05-11 01:15:59, Epoch : 1, Step : 3618, Training Loss : 0.52886, Training Acc : 0.756, Run Time : 0.39
INFO:root:2019-05-11 01:16:00, Epoch : 1, Step : 3619, Training Loss : 0.43541, Training Acc : 0.794, Run Time : 0.80
INFO:root:2019-05-11 01:16:06, Epoch : 1, Step : 3620, Training Loss : 0.36715, Training Acc : 0.856, Run Time : 6.60
INFO:root:2019-05-11 01:16:07, Epoch : 1, Step : 3621, Training Loss : 0.48092, Training Acc : 0.717, Run Time : 0.56
INFO:root:2019-05-11 01:16:07, Epoch : 1, Step : 3622, Training Loss : 0.41570, Training Acc : 0.817, Run Time : 0.38
INFO:root:2019-05-11 01:16:08, Epoch : 1, Step : 3623, Training Loss : 0.47423, Training Acc : 0.767, Run Time : 0.66
INFO:root:2019-05-11 01:16:16, Epoch : 1, Step : 3624, Training Loss : 0.55577, Training Acc : 0.756, Run Time : 8.55
INFO:root:2019-05-11 01:16:17, Epoch : 1, Step : 3625, Training Loss : 0.60126, Training Acc : 0.667, Run Time : 0.48
INFO:root:2019-05-11 01:16:17, Epoch : 1, Step : 3626, Training Loss : 0.49108, Training Acc : 0.778, Run Time : 0.55
INFO:root:2019-05-11 01:16:18, Epoch : 1, Step : 3627, Training Loss : 0.39215, Training Acc : 0.861, Run Time : 0.84
INFO:root:2019-05-11 01:16:25, Epoch : 1, Step : 3628, Training Loss : 0.38341, Training Acc : 0.850, Run Time : 6.79
INFO:root:2019-05-11 01:16:25, Epoch : 1, Step : 3629, Training Loss : 0.45406, Training Acc : 0.794, Run Time : 0.41
INFO:root:2019-05-11 01:16:26, Epoch : 1, Step : 3630, Training Loss : 0.32790, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 01:16:26, Epoch : 1, Step : 3631, Training Loss : 0.33920, Training Acc : 0.806, Run Time : 0.51
INFO:root:2019-05-11 01:16:33, Epoch : 1, Step : 3632, Training Loss : 0.30357, Training Acc : 0.883, Run Time : 6.96
INFO:root:2019-05-11 01:16:34, Epoch : 1, Step : 3633, Training Loss : 0.31013, Training Acc : 0.872, Run Time : 1.06
INFO:root:2019-05-11 01:16:35, Epoch : 1, Step : 3634, Training Loss : 0.41088, Training Acc : 0.806, Run Time : 0.38
INFO:root:2019-05-11 01:16:35, Epoch : 1, Step : 3635, Training Loss : 0.26949, Training Acc : 0.917, Run Time : 0.37
INFO:root:2019-05-11 01:16:36, Epoch : 1, Step : 3636, Training Loss : 0.45331, Training Acc : 0.794, Run Time : 0.52
INFO:root:2019-05-11 01:16:37, Epoch : 1, Step : 3637, Training Loss : 0.36372, Training Acc : 0.861, Run Time : 1.24
INFO:root:2019-05-11 01:16:43, Epoch : 1, Step : 3638, Training Loss : 0.35518, Training Acc : 0.883, Run Time : 6.19
INFO:root:2019-05-11 01:16:44, Epoch : 1, Step : 3639, Training Loss : 0.34501, Training Acc : 0.850, Run Time : 0.51
INFO:root:2019-05-11 01:16:45, Epoch : 1, Step : 3640, Training Loss : 0.44938, Training Acc : 0.756, Run Time : 0.99
INFO:root:2019-05-11 01:16:54, Epoch : 1, Step : 3641, Training Loss : 0.24415, Training Acc : 0.900, Run Time : 9.06
INFO:root:2019-05-11 01:16:54, Epoch : 1, Step : 3642, Training Loss : 0.47796, Training Acc : 0.789, Run Time : 0.54
INFO:root:2019-05-11 01:16:55, Epoch : 1, Step : 3643, Training Loss : 0.27641, Training Acc : 0.894, Run Time : 0.37
INFO:root:2019-05-11 01:16:56, Epoch : 1, Step : 3644, Training Loss : 0.30143, Training Acc : 0.872, Run Time : 1.37
INFO:root:2019-05-11 01:17:03, Epoch : 1, Step : 3645, Training Loss : 0.26119, Training Acc : 0.900, Run Time : 7.25
INFO:root:2019-05-11 01:17:04, Epoch : 1, Step : 3646, Training Loss : 0.30939, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-11 01:17:04, Epoch : 1, Step : 3647, Training Loss : 0.37227, Training Acc : 0.833, Run Time : 0.37
INFO:root:2019-05-11 01:17:04, Epoch : 1, Step : 3648, Training Loss : 0.35421, Training Acc : 0.850, Run Time : 0.40
INFO:root:2019-05-11 01:17:10, Epoch : 1, Step : 3649, Training Loss : 0.31339, Training Acc : 0.856, Run Time : 5.74
INFO:root:2019-05-11 01:17:12, Epoch : 1, Step : 3650, Training Loss : 0.40446, Training Acc : 0.767, Run Time : 1.85
INFO:root:2019-05-11 01:17:16, Epoch : 1, Step : 3651, Training Loss : 0.42819, Training Acc : 0.756, Run Time : 4.41
INFO:root:2019-05-11 01:17:17, Epoch : 1, Step : 3652, Training Loss : 0.37527, Training Acc : 0.839, Run Time : 0.49
INFO:root:2019-05-11 01:17:18, Epoch : 1, Step : 3653, Training Loss : 0.32998, Training Acc : 0.828, Run Time : 1.21
INFO:root:2019-05-11 01:17:19, Epoch : 1, Step : 3654, Training Loss : 0.35013, Training Acc : 0.833, Run Time : 0.64
INFO:root:2019-05-11 01:17:28, Epoch : 1, Step : 3655, Training Loss : 0.22769, Training Acc : 0.917, Run Time : 9.23
INFO:root:2019-05-11 01:17:29, Epoch : 1, Step : 3656, Training Loss : 0.41316, Training Acc : 0.783, Run Time : 0.87
INFO:root:2019-05-11 01:17:29, Epoch : 1, Step : 3657, Training Loss : 0.43898, Training Acc : 0.739, Run Time : 0.43
INFO:root:2019-05-11 01:17:30, Epoch : 1, Step : 3658, Training Loss : 0.36829, Training Acc : 0.833, Run Time : 0.49
INFO:root:2019-05-11 01:17:36, Epoch : 1, Step : 3659, Training Loss : 0.33100, Training Acc : 0.839, Run Time : 5.88
INFO:root:2019-05-11 01:17:36, Epoch : 1, Step : 3660, Training Loss : 0.24046, Training Acc : 0.906, Run Time : 0.73
INFO:root:2019-05-11 01:17:37, Epoch : 1, Step : 3661, Training Loss : 0.27676, Training Acc : 0.911, Run Time : 1.04
INFO:root:2019-05-11 01:17:43, Epoch : 1, Step : 3662, Training Loss : 0.36718, Training Acc : 0.850, Run Time : 5.38
INFO:root:2019-05-11 01:17:43, Epoch : 1, Step : 3663, Training Loss : 0.31766, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-11 01:17:44, Epoch : 1, Step : 3664, Training Loss : 0.24583, Training Acc : 0.911, Run Time : 0.40
INFO:root:2019-05-11 01:17:44, Epoch : 1, Step : 3665, Training Loss : 0.34541, Training Acc : 0.850, Run Time : 0.87
INFO:root:2019-05-11 01:17:53, Epoch : 1, Step : 3666, Training Loss : 0.37299, Training Acc : 0.856, Run Time : 8.72
INFO:root:2019-05-11 01:17:54, Epoch : 1, Step : 3667, Training Loss : 0.30512, Training Acc : 0.906, Run Time : 0.73
INFO:root:2019-05-11 01:17:56, Epoch : 1, Step : 3668, Training Loss : 0.33682, Training Acc : 0.900, Run Time : 1.64
INFO:root:2019-05-11 01:18:04, Epoch : 1, Step : 3669, Training Loss : 0.51662, Training Acc : 0.756, Run Time : 8.69
INFO:root:2019-05-11 01:18:05, Epoch : 1, Step : 3670, Training Loss : 0.49120, Training Acc : 0.761, Run Time : 0.46
INFO:root:2019-05-11 01:18:05, Epoch : 1, Step : 3671, Training Loss : 0.28584, Training Acc : 0.889, Run Time : 0.47
INFO:root:2019-05-11 01:18:06, Epoch : 1, Step : 3672, Training Loss : 0.39548, Training Acc : 0.789, Run Time : 0.79
INFO:root:2019-05-11 01:18:12, Epoch : 1, Step : 3673, Training Loss : 0.32270, Training Acc : 0.828, Run Time : 6.40
INFO:root:2019-05-11 01:18:13, Epoch : 1, Step : 3674, Training Loss : 0.38371, Training Acc : 0.817, Run Time : 0.71
INFO:root:2019-05-11 01:18:13, Epoch : 1, Step : 3675, Training Loss : 0.35460, Training Acc : 0.850, Run Time : 0.37
INFO:root:2019-05-11 01:18:14, Epoch : 1, Step : 3676, Training Loss : 0.36940, Training Acc : 0.828, Run Time : 0.38
INFO:root:2019-05-11 01:18:17, Epoch : 1, Step : 3677, Training Loss : 0.42963, Training Acc : 0.767, Run Time : 3.31
INFO:root:2019-05-11 01:18:17, Epoch : 1, Step : 3678, Training Loss : 0.29140, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-11 01:18:18, Epoch : 1, Step : 3679, Training Loss : 0.41685, Training Acc : 0.772, Run Time : 0.38
INFO:root:2019-05-11 01:18:18, Epoch : 1, Step : 3680, Training Loss : 0.36850, Training Acc : 0.850, Run Time : 0.67
INFO:root:2019-05-11 01:18:19, Epoch : 1, Step : 3681, Training Loss : 0.34258, Training Acc : 0.856, Run Time : 0.81
INFO:root:2019-05-11 01:18:22, Epoch : 1, Step : 3682, Training Loss : 0.36907, Training Acc : 0.806, Run Time : 2.94
INFO:root:2019-05-11 01:18:23, Epoch : 1, Step : 3683, Training Loss : 0.33649, Training Acc : 0.878, Run Time : 1.16
INFO:root:2019-05-11 01:18:24, Epoch : 1, Step : 3684, Training Loss : 0.25333, Training Acc : 0.889, Run Time : 0.96
INFO:root:2019-05-11 01:18:33, Epoch : 1, Step : 3685, Training Loss : 0.37110, Training Acc : 0.772, Run Time : 8.35
INFO:root:2019-05-11 01:18:33, Epoch : 1, Step : 3686, Training Loss : 0.38770, Training Acc : 0.800, Run Time : 0.42
INFO:root:2019-05-11 01:18:34, Epoch : 1, Step : 3687, Training Loss : 0.25078, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-11 01:18:34, Epoch : 1, Step : 3688, Training Loss : 0.42668, Training Acc : 0.789, Run Time : 0.37
INFO:root:2019-05-11 01:18:35, Epoch : 1, Step : 3689, Training Loss : 0.24482, Training Acc : 0.900, Run Time : 1.21
INFO:root:2019-05-11 01:18:43, Epoch : 1, Step : 3690, Training Loss : 0.31162, Training Acc : 0.889, Run Time : 7.72
INFO:root:2019-05-11 01:18:43, Epoch : 1, Step : 3691, Training Loss : 0.45337, Training Acc : 0.800, Run Time : 0.53
INFO:root:2019-05-11 01:18:44, Epoch : 1, Step : 3692, Training Loss : 0.32800, Training Acc : 0.833, Run Time : 0.54
INFO:root:2019-05-11 01:18:45, Epoch : 1, Step : 3693, Training Loss : 0.38511, Training Acc : 0.844, Run Time : 1.34
INFO:root:2019-05-11 01:18:54, Epoch : 1, Step : 3694, Training Loss : 0.33043, Training Acc : 0.822, Run Time : 8.86
INFO:root:2019-05-11 01:18:55, Epoch : 1, Step : 3695, Training Loss : 0.30320, Training Acc : 0.867, Run Time : 0.63
INFO:root:2019-05-11 01:18:55, Epoch : 1, Step : 3696, Training Loss : 0.43866, Training Acc : 0.772, Run Time : 0.42
INFO:root:2019-05-11 01:18:56, Epoch : 1, Step : 3697, Training Loss : 0.28622, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-11 01:18:56, Epoch : 1, Step : 3698, Training Loss : 0.47632, Training Acc : 0.772, Run Time : 0.93
INFO:root:2019-05-11 01:19:04, Epoch : 1, Step : 3699, Training Loss : 0.28399, Training Acc : 0.883, Run Time : 7.15
INFO:root:2019-05-11 01:19:04, Epoch : 1, Step : 3700, Training Loss : 0.50202, Training Acc : 0.767, Run Time : 0.42
INFO:root:2019-05-11 01:19:06, Epoch : 1, Step : 3701, Training Loss : 0.45534, Training Acc : 0.783, Run Time : 1.92
INFO:root:2019-05-11 01:19:14, Epoch : 1, Step : 3702, Training Loss : 0.33920, Training Acc : 0.850, Run Time : 7.68
INFO:root:2019-05-11 01:19:14, Epoch : 1, Step : 3703, Training Loss : 0.43826, Training Acc : 0.822, Run Time : 0.55
INFO:root:2019-05-11 01:19:15, Epoch : 1, Step : 3704, Training Loss : 0.33499, Training Acc : 0.844, Run Time : 0.47
INFO:root:2019-05-11 01:19:15, Epoch : 1, Step : 3705, Training Loss : 0.36636, Training Acc : 0.833, Run Time : 0.38
INFO:root:2019-05-11 01:19:26, Epoch : 1, Step : 3706, Training Loss : 0.35552, Training Acc : 0.817, Run Time : 10.78
INFO:root:2019-05-11 01:19:26, Epoch : 1, Step : 3707, Training Loss : 0.43870, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-11 01:19:27, Epoch : 1, Step : 3708, Training Loss : 0.62238, Training Acc : 0.683, Run Time : 0.39
INFO:root:2019-05-11 01:19:27, Epoch : 1, Step : 3709, Training Loss : 0.48093, Training Acc : 0.733, Run Time : 0.40
INFO:root:2019-05-11 01:19:36, Epoch : 1, Step : 3710, Training Loss : 0.75549, Training Acc : 0.600, Run Time : 9.06
INFO:root:2019-05-11 01:19:37, Epoch : 1, Step : 3711, Training Loss : 0.42384, Training Acc : 0.772, Run Time : 0.49
INFO:root:2019-05-11 01:19:37, Epoch : 1, Step : 3712, Training Loss : 0.37847, Training Acc : 0.839, Run Time : 0.45
INFO:root:2019-05-11 01:19:37, Epoch : 1, Step : 3713, Training Loss : 0.20953, Training Acc : 0.906, Run Time : 0.43
INFO:root:2019-05-11 01:19:38, Epoch : 1, Step : 3714, Training Loss : 0.37069, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-11 01:19:47, Epoch : 1, Step : 3715, Training Loss : 0.20847, Training Acc : 0.944, Run Time : 8.83
INFO:root:2019-05-11 01:19:48, Epoch : 1, Step : 3716, Training Loss : 0.54277, Training Acc : 0.739, Run Time : 0.79
INFO:root:2019-05-11 01:19:48, Epoch : 1, Step : 3717, Training Loss : 0.36067, Training Acc : 0.817, Run Time : 0.40
INFO:root:2019-05-11 01:19:49, Epoch : 1, Step : 3718, Training Loss : 0.32220, Training Acc : 0.850, Run Time : 0.86
INFO:root:2019-05-11 01:19:57, Epoch : 1, Step : 3719, Training Loss : 0.23053, Training Acc : 0.894, Run Time : 7.73
INFO:root:2019-05-11 01:19:57, Epoch : 1, Step : 3720, Training Loss : 0.35547, Training Acc : 0.844, Run Time : 0.64
INFO:root:2019-05-11 01:19:58, Epoch : 1, Step : 3721, Training Loss : 0.25969, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-11 01:19:58, Epoch : 1, Step : 3722, Training Loss : 0.13587, Training Acc : 0.983, Run Time : 0.37
INFO:root:2019-05-11 01:19:59, Epoch : 1, Step : 3723, Training Loss : 0.25868, Training Acc : 0.889, Run Time : 0.93
INFO:root:2019-05-11 01:20:08, Epoch : 1, Step : 3724, Training Loss : 0.32757, Training Acc : 0.822, Run Time : 9.21
INFO:root:2019-05-11 01:20:09, Epoch : 1, Step : 3725, Training Loss : 0.22939, Training Acc : 0.900, Run Time : 0.62
INFO:root:2019-05-11 01:20:09, Epoch : 1, Step : 3726, Training Loss : 0.27869, Training Acc : 0.867, Run Time : 0.41
INFO:root:2019-05-11 01:20:11, Epoch : 1, Step : 3727, Training Loss : 0.25981, Training Acc : 0.917, Run Time : 1.57
INFO:root:2019-05-11 01:20:20, Epoch : 1, Step : 3728, Training Loss : 0.29457, Training Acc : 0.867, Run Time : 9.71
INFO:root:2019-05-11 01:20:21, Epoch : 1, Step : 3729, Training Loss : 0.18922, Training Acc : 0.922, Run Time : 0.77
INFO:root:2019-05-11 01:20:22, Epoch : 1, Step : 3730, Training Loss : 0.22575, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-11 01:20:23, Epoch : 1, Step : 3731, Training Loss : 0.12667, Training Acc : 0.972, Run Time : 1.25
INFO:root:2019-05-11 01:20:30, Epoch : 1, Step : 3732, Training Loss : 0.47355, Training Acc : 0.794, Run Time : 7.27
INFO:root:2019-05-11 01:20:31, Epoch : 1, Step : 3733, Training Loss : 0.29718, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-11 01:20:31, Epoch : 1, Step : 3734, Training Loss : 0.23863, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-11 01:20:31, Epoch : 1, Step : 3735, Training Loss : 0.26872, Training Acc : 0.872, Run Time : 0.42
INFO:root:2019-05-11 01:20:37, Epoch : 1, Step : 3736, Training Loss : 0.37409, Training Acc : 0.828, Run Time : 5.95
INFO:root:2019-05-11 01:20:42, Epoch : 1, Step : 3737, Training Loss : 0.58030, Training Acc : 0.694, Run Time : 4.18
INFO:root:2019-05-11 01:20:43, Epoch : 1, Step : 3738, Training Loss : 0.28046, Training Acc : 0.872, Run Time : 1.14
INFO:root:2019-05-11 01:20:43, Epoch : 1, Step : 3739, Training Loss : 0.36680, Training Acc : 0.822, Run Time : 0.38
INFO:root:2019-05-11 01:20:44, Epoch : 1, Step : 3740, Training Loss : 0.20884, Training Acc : 0.928, Run Time : 0.88
INFO:root:2019-05-11 01:20:48, Epoch : 1, Step : 3741, Training Loss : 0.18471, Training Acc : 0.944, Run Time : 3.58
INFO:root:2019-05-11 01:20:48, Epoch : 1, Step : 3742, Training Loss : 0.44839, Training Acc : 0.783, Run Time : 0.67
INFO:root:2019-05-11 01:20:49, Epoch : 1, Step : 3743, Training Loss : 0.28744, Training Acc : 0.861, Run Time : 0.37
INFO:root:2019-05-11 01:20:50, Epoch : 1, Step : 3744, Training Loss : 0.22050, Training Acc : 0.928, Run Time : 1.48
INFO:root:2019-05-11 01:20:59, Epoch : 1, Step : 3745, Training Loss : 0.32172, Training Acc : 0.872, Run Time : 9.20
INFO:root:2019-05-11 01:21:00, Epoch : 1, Step : 3746, Training Loss : 0.23275, Training Acc : 0.911, Run Time : 0.44
INFO:root:2019-05-11 01:21:00, Epoch : 1, Step : 3747, Training Loss : 0.28454, Training Acc : 0.883, Run Time : 0.37
INFO:root:2019-05-11 01:21:01, Epoch : 1, Step : 3748, Training Loss : 0.38116, Training Acc : 0.839, Run Time : 0.80
INFO:root:2019-05-11 01:21:08, Epoch : 1, Step : 3749, Training Loss : 0.44458, Training Acc : 0.772, Run Time : 6.69
INFO:root:2019-05-11 01:21:08, Epoch : 1, Step : 3750, Training Loss : 0.46262, Training Acc : 0.772, Run Time : 0.65
INFO:root:2019-05-11 01:21:09, Epoch : 1, Step : 3751, Training Loss : 0.47149, Training Acc : 0.789, Run Time : 0.41
INFO:root:2019-05-11 01:21:09, Epoch : 1, Step : 3752, Training Loss : 0.50646, Training Acc : 0.739, Run Time : 0.38
INFO:root:2019-05-11 01:21:22, Epoch : 1, Step : 3753, Training Loss : 0.23578, Training Acc : 0.922, Run Time : 12.97
INFO:root:2019-05-11 01:21:30, Epoch : 1, Step : 3754, Training Loss : 0.27371, Training Acc : 0.872, Run Time : 8.21
INFO:root:2019-05-11 01:21:32, Epoch : 1, Step : 3755, Training Loss : 0.31127, Training Acc : 0.878, Run Time : 2.31
INFO:root:2019-05-11 01:21:33, Epoch : 1, Step : 3756, Training Loss : 0.28013, Training Acc : 0.917, Run Time : 0.66
INFO:root:2019-05-11 01:21:34, Epoch : 1, Step : 3757, Training Loss : 0.35490, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-11 01:21:34, Epoch : 1, Step : 3758, Training Loss : 0.31411, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-11 01:21:43, Epoch : 1, Step : 3759, Training Loss : 0.30827, Training Acc : 0.856, Run Time : 8.78
INFO:root:2019-05-11 01:21:43, Epoch : 1, Step : 3760, Training Loss : 0.34506, Training Acc : 0.867, Run Time : 0.44
INFO:root:2019-05-11 01:21:44, Epoch : 1, Step : 3761, Training Loss : 0.44855, Training Acc : 0.800, Run Time : 0.39
INFO:root:2019-05-11 01:21:49, Epoch : 1, Step : 3762, Training Loss : 0.36495, Training Acc : 0.811, Run Time : 5.20
INFO:root:2019-05-11 01:21:49, Epoch : 1, Step : 3763, Training Loss : 0.46922, Training Acc : 0.739, Run Time : 0.64
INFO:root:2019-05-11 01:21:50, Epoch : 1, Step : 3764, Training Loss : 0.37649, Training Acc : 0.811, Run Time : 0.41
INFO:root:2019-05-11 01:21:56, Epoch : 1, Step : 3765, Training Loss : 0.34092, Training Acc : 0.817, Run Time : 6.05
INFO:root:2019-05-11 01:21:56, Epoch : 1, Step : 3766, Training Loss : 0.42296, Training Acc : 0.778, Run Time : 0.50
INFO:root:2019-05-11 01:21:57, Epoch : 1, Step : 3767, Training Loss : 0.33024, Training Acc : 0.856, Run Time : 0.54
INFO:root:2019-05-11 01:22:05, Epoch : 1, Step : 3768, Training Loss : 0.37349, Training Acc : 0.844, Run Time : 8.10
INFO:root:2019-05-11 01:22:06, Epoch : 1, Step : 3769, Training Loss : 0.32546, Training Acc : 0.839, Run Time : 0.49
INFO:root:2019-05-11 01:22:06, Epoch : 1, Step : 3770, Training Loss : 0.35958, Training Acc : 0.828, Run Time : 0.40
INFO:root:2019-05-11 01:22:07, Epoch : 1, Step : 3771, Training Loss : 0.42898, Training Acc : 0.811, Run Time : 1.37
INFO:root:2019-05-11 01:22:16, Epoch : 1, Step : 3772, Training Loss : 0.38031, Training Acc : 0.794, Run Time : 8.50
INFO:root:2019-05-11 01:22:16, Epoch : 1, Step : 3773, Training Loss : 0.46304, Training Acc : 0.822, Run Time : 0.47
INFO:root:2019-05-11 01:22:17, Epoch : 1, Step : 3774, Training Loss : 0.44875, Training Acc : 0.800, Run Time : 1.16
INFO:root:2019-05-11 01:22:25, Epoch : 1, Step : 3775, Training Loss : 0.30209, Training Acc : 0.889, Run Time : 7.67
INFO:root:2019-05-11 01:22:26, Epoch : 1, Step : 3776, Training Loss : 0.43153, Training Acc : 0.778, Run Time : 0.54
INFO:root:2019-05-11 01:22:26, Epoch : 1, Step : 3777, Training Loss : 0.31675, Training Acc : 0.844, Run Time : 0.42
INFO:root:2019-05-11 01:22:27, Epoch : 1, Step : 3778, Training Loss : 0.33551, Training Acc : 0.828, Run Time : 0.54
INFO:root:2019-05-11 01:22:27, Epoch : 1, Step : 3779, Training Loss : 0.31503, Training Acc : 0.839, Run Time : 0.43
INFO:root:2019-05-11 01:22:27, Epoch : 1, Step : 3780, Training Loss : 0.32626, Training Acc : 0.844, Run Time : 0.41
INFO:root:2019-05-11 01:22:28, Epoch : 1, Step : 3781, Training Loss : 0.36052, Training Acc : 0.811, Run Time : 0.48
INFO:root:2019-05-11 01:22:28, Epoch : 1, Step : 3782, Training Loss : 0.32845, Training Acc : 0.867, Run Time : 0.42
INFO:root:2019-05-11 01:22:38, Epoch : 1, Step : 3783, Training Loss : 0.32200, Training Acc : 0.828, Run Time : 9.23
INFO:root:2019-05-11 01:22:38, Epoch : 1, Step : 3784, Training Loss : 0.36063, Training Acc : 0.828, Run Time : 0.42
INFO:root:2019-05-11 01:22:39, Epoch : 1, Step : 3785, Training Loss : 0.44230, Training Acc : 0.750, Run Time : 1.30
INFO:root:2019-05-11 01:22:47, Epoch : 1, Step : 3786, Training Loss : 0.32710, Training Acc : 0.856, Run Time : 7.19
INFO:root:2019-05-11 01:22:47, Epoch : 1, Step : 3787, Training Loss : 0.36293, Training Acc : 0.861, Run Time : 0.43
INFO:root:2019-05-11 01:22:47, Epoch : 1, Step : 3788, Training Loss : 0.36628, Training Acc : 0.817, Run Time : 0.38
INFO:root:2019-05-11 01:22:48, Epoch : 1, Step : 3789, Training Loss : 0.32066, Training Acc : 0.839, Run Time : 0.39
INFO:root:2019-05-11 01:22:55, Epoch : 1, Step : 3790, Training Loss : 0.33627, Training Acc : 0.833, Run Time : 7.19
INFO:root:2019-05-11 01:22:55, Epoch : 1, Step : 3791, Training Loss : 0.33975, Training Acc : 0.839, Run Time : 0.54
INFO:root:2019-05-11 01:22:56, Epoch : 1, Step : 3792, Training Loss : 0.40051, Training Acc : 0.772, Run Time : 0.42
INFO:root:2019-05-11 01:22:56, Epoch : 1, Step : 3793, Training Loss : 0.38000, Training Acc : 0.800, Run Time : 0.38
INFO:root:2019-05-11 01:22:57, Epoch : 1, Step : 3794, Training Loss : 0.36954, Training Acc : 0.800, Run Time : 0.37
INFO:root:2019-05-11 01:22:57, Epoch : 1, Step : 3795, Training Loss : 0.36062, Training Acc : 0.822, Run Time : 0.70
INFO:root:2019-05-11 01:22:58, Epoch : 1, Step : 3796, Training Loss : 0.39068, Training Acc : 0.789, Run Time : 0.38
INFO:root:2019-05-11 01:22:58, Epoch : 1, Step : 3797, Training Loss : 0.37480, Training Acc : 0.789, Run Time : 0.38
INFO:root:2019-05-11 01:22:59, Epoch : 1, Step : 3798, Training Loss : 0.30002, Training Acc : 0.889, Run Time : 0.55
INFO:root:2019-05-11 01:23:02, Epoch : 1, Step : 3799, Training Loss : 0.34015, Training Acc : 0.817, Run Time : 3.47
INFO:root:2019-05-11 01:23:02, Epoch : 1, Step : 3800, Training Loss : 0.28776, Training Acc : 0.867, Run Time : 0.40
INFO:root:2019-05-11 01:23:04, Epoch : 1, Step : 3801, Training Loss : 0.96368, Training Acc : 0.678, Run Time : 1.96
INFO:root:2019-05-11 01:23:13, Epoch : 1, Step : 3802, Training Loss : 0.92487, Training Acc : 0.689, Run Time : 8.16
INFO:root:2019-05-11 01:23:13, Epoch : 1, Step : 3803, Training Loss : 0.88375, Training Acc : 0.700, Run Time : 0.41
INFO:root:2019-05-11 01:23:13, Epoch : 1, Step : 3804, Training Loss : 0.70688, Training Acc : 0.717, Run Time : 0.44
INFO:root:2019-05-11 01:23:15, Epoch : 1, Step : 3805, Training Loss : 0.75575, Training Acc : 0.661, Run Time : 1.53
INFO:root:2019-05-11 01:23:23, Epoch : 1, Step : 3806, Training Loss : 0.59671, Training Acc : 0.661, Run Time : 7.82
INFO:root:2019-05-11 01:23:23, Epoch : 1, Step : 3807, Training Loss : 0.42472, Training Acc : 0.789, Run Time : 0.40
INFO:root:2019-05-11 01:23:24, Epoch : 1, Step : 3808, Training Loss : 0.45106, Training Acc : 0.778, Run Time : 0.37
INFO:root:2019-05-11 01:23:24, Epoch : 1, Step : 3809, Training Loss : 0.32174, Training Acc : 0.856, Run Time : 0.51
INFO:root:2019-05-11 01:23:25, Epoch : 1, Step : 3810, Training Loss : 0.35651, Training Acc : 0.883, Run Time : 0.82
INFO:root:2019-05-11 01:23:32, Epoch : 1, Step : 3811, Training Loss : 0.38734, Training Acc : 0.850, Run Time : 7.33
INFO:root:2019-05-11 01:23:33, Epoch : 1, Step : 3812, Training Loss : 0.39667, Training Acc : 0.844, Run Time : 0.44
INFO:root:2019-05-11 01:23:33, Epoch : 1, Step : 3813, Training Loss : 0.31093, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 01:23:35, Epoch : 1, Step : 3814, Training Loss : 0.48979, Training Acc : 0.817, Run Time : 1.68
INFO:root:2019-05-11 01:23:42, Epoch : 1, Step : 3815, Training Loss : 0.29386, Training Acc : 0.883, Run Time : 7.28
INFO:root:2019-05-11 01:23:43, Epoch : 1, Step : 3816, Training Loss : 0.36235, Training Acc : 0.811, Run Time : 0.67
INFO:root:2019-05-11 01:23:43, Epoch : 1, Step : 3817, Training Loss : 0.27022, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-11 01:23:56, Epoch : 1, Step : 3818, Training Loss : 0.39511, Training Acc : 0.833, Run Time : 12.67
INFO:root:2019-05-11 01:23:57, Epoch : 1, Step : 3819, Training Loss : 0.35159, Training Acc : 0.839, Run Time : 1.07
INFO:root:2019-05-11 01:23:57, Epoch : 1, Step : 3820, Training Loss : 0.33345, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-11 01:23:58, Epoch : 1, Step : 3821, Training Loss : 0.53395, Training Acc : 0.733, Run Time : 0.43
INFO:root:2019-05-11 01:23:59, Epoch : 1, Step : 3822, Training Loss : 0.44260, Training Acc : 0.794, Run Time : 0.84
INFO:root:2019-05-11 01:23:59, Epoch : 1, Step : 3823, Training Loss : 0.50156, Training Acc : 0.772, Run Time : 0.38
INFO:root:2019-05-11 01:23:59, Epoch : 1, Step : 3824, Training Loss : 0.26034, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-11 01:24:11, Epoch : 1, Step : 3825, Training Loss : 0.41464, Training Acc : 0.800, Run Time : 11.23
INFO:root:2019-05-11 01:24:11, Epoch : 1, Step : 3826, Training Loss : 0.38345, Training Acc : 0.828, Run Time : 0.41
INFO:root:2019-05-11 01:24:11, Epoch : 1, Step : 3827, Training Loss : 0.37596, Training Acc : 0.856, Run Time : 0.38
INFO:root:2019-05-11 01:24:12, Epoch : 1, Step : 3828, Training Loss : 0.27287, Training Acc : 0.883, Run Time : 0.43
INFO:root:2019-05-11 01:24:13, Epoch : 1, Step : 3829, Training Loss : 0.26179, Training Acc : 0.878, Run Time : 0.95
INFO:root:2019-05-11 01:24:20, Epoch : 1, Step : 3830, Training Loss : 0.42283, Training Acc : 0.761, Run Time : 7.33
INFO:root:2019-05-11 01:24:21, Epoch : 1, Step : 3831, Training Loss : 0.43339, Training Acc : 0.822, Run Time : 1.12
INFO:root:2019-05-11 01:24:22, Epoch : 1, Step : 3832, Training Loss : 0.33419, Training Acc : 0.844, Run Time : 0.37
INFO:root:2019-05-11 01:24:23, Epoch : 1, Step : 3833, Training Loss : 0.31003, Training Acc : 0.867, Run Time : 1.16
INFO:root:2019-05-11 01:24:33, Epoch : 1, Step : 3834, Training Loss : 0.45552, Training Acc : 0.739, Run Time : 10.00
INFO:root:2019-05-11 01:24:33, Epoch : 1, Step : 3835, Training Loss : 0.24024, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 01:24:34, Epoch : 1, Step : 3836, Training Loss : 0.53047, Training Acc : 0.789, Run Time : 0.99
INFO:root:2019-05-11 01:24:45, Epoch : 1, Step : 3837, Training Loss : 0.43965, Training Acc : 0.794, Run Time : 10.91
INFO:root:2019-05-11 01:24:45, Epoch : 1, Step : 3838, Training Loss : 0.28194, Training Acc : 0.894, Run Time : 0.41
INFO:root:2019-05-11 01:24:46, Epoch : 1, Step : 3839, Training Loss : 0.43246, Training Acc : 0.744, Run Time : 0.38
INFO:root:2019-05-11 01:24:46, Epoch : 1, Step : 3840, Training Loss : 0.37060, Training Acc : 0.828, Run Time : 0.38
INFO:root:2019-05-11 01:24:47, Epoch : 1, Step : 3841, Training Loss : 0.38072, Training Acc : 0.800, Run Time : 1.14
INFO:root:2019-05-11 01:24:55, Epoch : 1, Step : 3842, Training Loss : 0.51396, Training Acc : 0.728, Run Time : 7.22
INFO:root:2019-05-11 01:24:55, Epoch : 1, Step : 3843, Training Loss : 0.64268, Training Acc : 0.772, Run Time : 0.90
INFO:root:2019-05-11 01:24:56, Epoch : 1, Step : 3844, Training Loss : 0.40734, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-11 01:24:57, Epoch : 1, Step : 3845, Training Loss : 0.38947, Training Acc : 0.856, Run Time : 0.72
INFO:root:2019-05-11 01:24:57, Epoch : 1, Step : 3846, Training Loss : 0.31647, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-11 01:25:00, Epoch : 1, Step : 3847, Training Loss : 0.28887, Training Acc : 0.889, Run Time : 2.56
INFO:root:2019-05-11 01:25:00, Epoch : 1, Step : 3848, Training Loss : 0.42995, Training Acc : 0.789, Run Time : 0.58
INFO:root:2019-05-11 01:25:07, Epoch : 1, Step : 3849, Training Loss : 0.42717, Training Acc : 0.772, Run Time : 6.45
INFO:root:2019-05-11 01:25:10, Epoch : 1, Step : 3850, Training Loss : 0.38382, Training Acc : 0.844, Run Time : 3.81
INFO:root:2019-05-11 01:25:11, Epoch : 1, Step : 3851, Training Loss : 0.35401, Training Acc : 0.850, Run Time : 0.65
INFO:root:2019-05-11 01:25:12, Epoch : 1, Step : 3852, Training Loss : 0.31374, Training Acc : 0.872, Run Time : 1.00
INFO:root:2019-05-11 01:25:22, Epoch : 1, Step : 3853, Training Loss : 0.35806, Training Acc : 0.883, Run Time : 9.62
INFO:root:2019-05-11 01:25:22, Epoch : 1, Step : 3854, Training Loss : 0.33566, Training Acc : 0.817, Run Time : 0.50
INFO:root:2019-05-11 01:25:23, Epoch : 1, Step : 3855, Training Loss : 0.22944, Training Acc : 0.922, Run Time : 0.49
INFO:root:2019-05-11 01:25:26, Epoch : 1, Step : 3856, Training Loss : 0.47823, Training Acc : 0.756, Run Time : 3.60
INFO:root:2019-05-11 01:25:27, Epoch : 1, Step : 3857, Training Loss : 0.50597, Training Acc : 0.739, Run Time : 0.64
INFO:root:2019-05-11 01:25:28, Epoch : 1, Step : 3858, Training Loss : 0.56672, Training Acc : 0.767, Run Time : 0.57
INFO:root:2019-05-11 01:25:29, Epoch : 1, Step : 3859, Training Loss : 0.56906, Training Acc : 0.683, Run Time : 1.19
INFO:root:2019-05-11 01:25:37, Epoch : 1, Step : 3860, Training Loss : 0.40485, Training Acc : 0.778, Run Time : 8.04
INFO:root:2019-05-11 01:25:37, Epoch : 1, Step : 3861, Training Loss : 0.51203, Training Acc : 0.761, Run Time : 0.64
INFO:root:2019-05-11 01:25:38, Epoch : 1, Step : 3862, Training Loss : 0.35570, Training Acc : 0.839, Run Time : 0.38
INFO:root:2019-05-11 01:25:39, Epoch : 1, Step : 3863, Training Loss : 0.36929, Training Acc : 0.822, Run Time : 1.62
INFO:root:2019-05-11 01:25:47, Epoch : 1, Step : 3864, Training Loss : 0.45083, Training Acc : 0.750, Run Time : 7.23
INFO:root:2019-05-11 01:25:47, Epoch : 1, Step : 3865, Training Loss : 0.46416, Training Acc : 0.761, Run Time : 0.63
INFO:root:2019-05-11 01:25:48, Epoch : 1, Step : 3866, Training Loss : 0.37586, Training Acc : 0.844, Run Time : 0.38
INFO:root:2019-05-11 01:25:49, Epoch : 1, Step : 3867, Training Loss : 0.35912, Training Acc : 0.794, Run Time : 1.12
INFO:root:2019-05-11 01:25:57, Epoch : 1, Step : 3868, Training Loss : 0.34356, Training Acc : 0.822, Run Time : 7.75
INFO:root:2019-05-11 01:25:57, Epoch : 1, Step : 3869, Training Loss : 0.27481, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-11 01:25:57, Epoch : 1, Step : 3870, Training Loss : 0.36674, Training Acc : 0.794, Run Time : 0.38
INFO:root:2019-05-11 01:25:58, Epoch : 1, Step : 3871, Training Loss : 0.15749, Training Acc : 0.950, Run Time : 0.66
INFO:root:2019-05-11 01:26:04, Epoch : 1, Step : 3872, Training Loss : 0.17120, Training Acc : 0.967, Run Time : 5.80
INFO:root:2019-05-11 01:26:04, Epoch : 1, Step : 3873, Training Loss : 0.19811, Training Acc : 0.933, Run Time : 0.49
INFO:root:2019-05-11 01:26:05, Epoch : 1, Step : 3874, Training Loss : 0.21739, Training Acc : 0.917, Run Time : 0.95
INFO:root:2019-05-11 01:26:15, Epoch : 1, Step : 3875, Training Loss : 0.14381, Training Acc : 0.978, Run Time : 9.50
INFO:root:2019-05-11 01:26:15, Epoch : 1, Step : 3876, Training Loss : 0.20598, Training Acc : 0.928, Run Time : 0.76
INFO:root:2019-05-11 01:26:16, Epoch : 1, Step : 3877, Training Loss : 0.16747, Training Acc : 0.956, Run Time : 0.53
INFO:root:2019-05-11 01:26:17, Epoch : 1, Step : 3878, Training Loss : 0.17943, Training Acc : 0.928, Run Time : 1.05
INFO:root:2019-05-11 01:26:22, Epoch : 1, Step : 3879, Training Loss : 0.26220, Training Acc : 0.872, Run Time : 4.54
INFO:root:2019-05-11 01:26:23, Epoch : 1, Step : 3880, Training Loss : 0.23188, Training Acc : 0.906, Run Time : 1.36
INFO:root:2019-05-11 01:26:23, Epoch : 1, Step : 3881, Training Loss : 0.38236, Training Acc : 0.811, Run Time : 0.38
INFO:root:2019-05-11 01:26:24, Epoch : 1, Step : 3882, Training Loss : 0.15158, Training Acc : 0.972, Run Time : 0.49
INFO:root:2019-05-11 01:26:24, Epoch : 1, Step : 3883, Training Loss : 0.26090, Training Acc : 0.872, Run Time : 0.37
INFO:root:2019-05-11 01:26:25, Epoch : 1, Step : 3884, Training Loss : 0.24858, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-11 01:26:29, Epoch : 1, Step : 3885, Training Loss : 0.23762, Training Acc : 0.900, Run Time : 4.20
INFO:root:2019-05-11 01:26:29, Epoch : 1, Step : 3886, Training Loss : 0.25326, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-11 01:26:30, Epoch : 1, Step : 3887, Training Loss : 0.26537, Training Acc : 0.900, Run Time : 0.46
INFO:root:2019-05-11 01:26:31, Epoch : 1, Step : 3888, Training Loss : 0.29754, Training Acc : 0.839, Run Time : 1.26
INFO:root:2019-05-11 01:26:36, Epoch : 1, Step : 3889, Training Loss : 0.41690, Training Acc : 0.772, Run Time : 4.95
INFO:root:2019-05-11 01:26:36, Epoch : 1, Step : 3890, Training Loss : 0.25726, Training Acc : 0.900, Run Time : 0.41
INFO:root:2019-05-11 01:26:37, Epoch : 1, Step : 3891, Training Loss : 0.34259, Training Acc : 0.811, Run Time : 0.37
INFO:root:2019-05-11 01:26:37, Epoch : 1, Step : 3892, Training Loss : 0.32966, Training Acc : 0.839, Run Time : 0.40
INFO:root:2019-05-11 01:26:38, Epoch : 1, Step : 3893, Training Loss : 0.28215, Training Acc : 0.856, Run Time : 0.39
INFO:root:2019-05-11 01:26:38, Epoch : 1, Step : 3894, Training Loss : 0.34498, Training Acc : 0.856, Run Time : 0.37
INFO:root:2019-05-11 01:26:39, Epoch : 1, Step : 3895, Training Loss : 0.28995, Training Acc : 0.861, Run Time : 0.61
INFO:root:2019-05-11 01:26:45, Epoch : 1, Step : 3896, Training Loss : 0.25255, Training Acc : 0.867, Run Time : 5.98
INFO:root:2019-05-11 01:26:45, Epoch : 1, Step : 3897, Training Loss : 0.21924, Training Acc : 0.917, Run Time : 0.40
INFO:root:2019-05-11 01:26:45, Epoch : 1, Step : 3898, Training Loss : 0.44192, Training Acc : 0.817, Run Time : 0.40
INFO:root:2019-05-11 01:26:47, Epoch : 1, Step : 3899, Training Loss : 0.22903, Training Acc : 0.900, Run Time : 1.41
INFO:root:2019-05-11 01:26:54, Epoch : 1, Step : 3900, Training Loss : 0.34519, Training Acc : 0.839, Run Time : 7.09
INFO:root:2019-05-11 01:26:55, Epoch : 1, Step : 3901, Training Loss : 0.41064, Training Acc : 0.783, Run Time : 0.83
INFO:root:2019-05-11 01:26:56, Epoch : 1, Step : 3902, Training Loss : 0.39113, Training Acc : 0.844, Run Time : 1.03
INFO:root:2019-05-11 01:27:04, Epoch : 1, Step : 3903, Training Loss : 0.33248, Training Acc : 0.867, Run Time : 8.69
INFO:root:2019-05-11 01:27:05, Epoch : 1, Step : 3904, Training Loss : 0.29540, Training Acc : 0.872, Run Time : 0.62
INFO:root:2019-05-11 01:27:06, Epoch : 1, Step : 3905, Training Loss : 0.20938, Training Acc : 0.917, Run Time : 0.59
INFO:root:2019-05-11 01:27:07, Epoch : 1, Step : 3906, Training Loss : 0.30542, Training Acc : 0.833, Run Time : 0.96
INFO:root:2019-05-11 01:27:16, Epoch : 1, Step : 3907, Training Loss : 0.27539, Training Acc : 0.878, Run Time : 9.66
INFO:root:2019-05-11 01:27:17, Epoch : 1, Step : 3908, Training Loss : 0.29009, Training Acc : 0.872, Run Time : 0.61
INFO:root:2019-05-11 01:27:18, Epoch : 1, Step : 3909, Training Loss : 0.36989, Training Acc : 0.806, Run Time : 0.71
INFO:root:2019-05-11 01:27:18, Epoch : 1, Step : 3910, Training Loss : 0.31787, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-11 01:27:18, Epoch : 1, Step : 3911, Training Loss : 0.19490, Training Acc : 0.933, Run Time : 0.55
INFO:root:2019-05-11 01:27:23, Epoch : 1, Step : 3912, Training Loss : 0.25680, Training Acc : 0.878, Run Time : 4.78
INFO:root:2019-05-11 01:27:24, Epoch : 1, Step : 3913, Training Loss : 0.21990, Training Acc : 0.928, Run Time : 0.71
INFO:root:2019-05-11 01:27:25, Epoch : 1, Step : 3914, Training Loss : 0.19237, Training Acc : 0.922, Run Time : 0.80
INFO:root:2019-05-11 01:27:32, Epoch : 1, Step : 3915, Training Loss : 0.18564, Training Acc : 0.928, Run Time : 6.93
INFO:root:2019-05-11 01:27:32, Epoch : 1, Step : 3916, Training Loss : 0.14079, Training Acc : 0.950, Run Time : 0.52
INFO:root:2019-05-11 01:27:33, Epoch : 1, Step : 3917, Training Loss : 0.20560, Training Acc : 0.917, Run Time : 1.16
INFO:root:2019-05-11 01:27:44, Epoch : 1, Step : 3918, Training Loss : 0.17692, Training Acc : 0.939, Run Time : 10.89
INFO:root:2019-05-11 01:27:45, Epoch : 1, Step : 3919, Training Loss : 0.13834, Training Acc : 0.978, Run Time : 0.42
INFO:root:2019-05-11 01:27:45, Epoch : 1, Step : 3920, Training Loss : 0.15892, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 01:27:45, Epoch : 1, Step : 3921, Training Loss : 0.25012, Training Acc : 0.917, Run Time : 0.37
INFO:root:2019-05-11 01:27:47, Epoch : 1, Step : 3922, Training Loss : 0.17322, Training Acc : 0.944, Run Time : 1.20
INFO:root:2019-05-11 01:27:54, Epoch : 1, Step : 3923, Training Loss : 0.13469, Training Acc : 0.944, Run Time : 7.82
INFO:root:2019-05-11 01:27:55, Epoch : 1, Step : 3924, Training Loss : 0.17514, Training Acc : 0.928, Run Time : 0.53
INFO:root:2019-05-11 01:27:55, Epoch : 1, Step : 3925, Training Loss : 0.15636, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-11 01:28:00, Epoch : 1, Step : 3926, Training Loss : 0.17012, Training Acc : 0.933, Run Time : 4.66
INFO:root:2019-05-11 01:28:01, Epoch : 1, Step : 3927, Training Loss : 0.26176, Training Acc : 0.917, Run Time : 0.61
INFO:root:2019-05-11 01:28:01, Epoch : 1, Step : 3928, Training Loss : 0.39725, Training Acc : 0.822, Run Time : 0.77
INFO:root:2019-05-11 01:28:11, Epoch : 1, Step : 3929, Training Loss : 0.34875, Training Acc : 0.794, Run Time : 9.13
INFO:root:2019-05-11 01:28:11, Epoch : 1, Step : 3930, Training Loss : 0.32570, Training Acc : 0.867, Run Time : 0.81
INFO:root:2019-05-11 01:28:12, Epoch : 1, Step : 3931, Training Loss : 0.35243, Training Acc : 0.844, Run Time : 1.11
INFO:root:2019-05-11 01:28:17, Epoch : 1, Step : 3932, Training Loss : 0.44675, Training Acc : 0.794, Run Time : 4.08
INFO:root:2019-05-11 01:28:17, Epoch : 1, Step : 3933, Training Loss : 0.55881, Training Acc : 0.750, Run Time : 0.41
INFO:root:2019-05-11 01:28:17, Epoch : 1, Step : 3934, Training Loss : 0.50017, Training Acc : 0.767, Run Time : 0.41
INFO:root:2019-05-11 01:28:18, Epoch : 1, Step : 3935, Training Loss : 0.31645, Training Acc : 0.872, Run Time : 0.59
INFO:root:2019-05-11 01:28:29, Epoch : 1, Step : 3936, Training Loss : 0.35127, Training Acc : 0.861, Run Time : 10.59
INFO:root:2019-05-11 01:28:29, Epoch : 1, Step : 3937, Training Loss : 0.38879, Training Acc : 0.850, Run Time : 0.65
INFO:root:2019-05-11 01:28:31, Epoch : 1, Step : 3938, Training Loss : 0.46168, Training Acc : 0.822, Run Time : 2.03
INFO:root:2019-05-11 01:28:41, Epoch : 1, Step : 3939, Training Loss : 0.29012, Training Acc : 0.911, Run Time : 10.00
INFO:root:2019-05-11 01:28:42, Epoch : 1, Step : 3940, Training Loss : 0.34705, Training Acc : 0.883, Run Time : 0.49
INFO:root:2019-05-11 01:28:42, Epoch : 1, Step : 3941, Training Loss : 0.66119, Training Acc : 0.678, Run Time : 0.37
INFO:root:2019-05-11 01:28:43, Epoch : 1, Step : 3942, Training Loss : 0.56267, Training Acc : 0.756, Run Time : 1.20
INFO:root:2019-05-11 01:28:57, Epoch : 1, Step : 3943, Training Loss : 0.40543, Training Acc : 0.850, Run Time : 14.11
INFO:root:2019-05-11 01:28:59, Epoch : 1, Step : 3944, Training Loss : 0.44483, Training Acc : 0.767, Run Time : 1.13
INFO:root:2019-05-11 01:28:59, Epoch : 1, Step : 3945, Training Loss : 0.27937, Training Acc : 0.889, Run Time : 0.50
INFO:root:2019-05-11 01:29:00, Epoch : 1, Step : 3946, Training Loss : 0.38589, Training Acc : 0.850, Run Time : 1.34
INFO:root:2019-05-11 01:29:08, Epoch : 1, Step : 3947, Training Loss : 0.32284, Training Acc : 0.861, Run Time : 7.30
INFO:root:2019-05-11 01:29:11, Epoch : 1, Step : 3948, Training Loss : 0.57386, Training Acc : 0.722, Run Time : 3.20
INFO:root:2019-05-11 01:29:23, Epoch : 1, Step : 3949, Training Loss : 0.35749, Training Acc : 0.822, Run Time : 12.24
INFO:root:2019-05-11 01:29:24, Epoch : 1, Step : 3950, Training Loss : 0.29546, Training Acc : 0.900, Run Time : 1.25
INFO:root:2019-05-11 01:29:29, Epoch : 1, Step : 3951, Training Loss : 0.54301, Training Acc : 0.778, Run Time : 4.57
INFO:root:2019-05-11 01:29:30, Epoch : 1, Step : 3952, Training Loss : 0.40880, Training Acc : 0.800, Run Time : 0.61
INFO:root:2019-05-11 01:29:30, Epoch : 1, Step : 3953, Training Loss : 0.43095, Training Acc : 0.822, Run Time : 0.55
INFO:root:2019-05-11 01:29:31, Epoch : 1, Step : 3954, Training Loss : 0.23431, Training Acc : 0.917, Run Time : 1.29
INFO:root:2019-05-11 01:29:42, Epoch : 1, Step : 3955, Training Loss : 0.28193, Training Acc : 0.883, Run Time : 10.77
INFO:root:2019-05-11 01:29:43, Epoch : 1, Step : 3956, Training Loss : 0.32246, Training Acc : 0.833, Run Time : 0.70
INFO:root:2019-05-11 01:29:43, Epoch : 1, Step : 3957, Training Loss : 0.21969, Training Acc : 0.906, Run Time : 0.37
INFO:root:2019-05-11 01:29:44, Epoch : 1, Step : 3958, Training Loss : 0.30291, Training Acc : 0.867, Run Time : 0.40
INFO:root:2019-05-11 01:29:45, Epoch : 1, Step : 3959, Training Loss : 0.41971, Training Acc : 0.789, Run Time : 1.05
INFO:root:2019-05-11 01:29:55, Epoch : 1, Step : 3960, Training Loss : 0.14656, Training Acc : 0.972, Run Time : 10.59
INFO:root:2019-05-11 01:29:56, Epoch : 1, Step : 3961, Training Loss : 0.59963, Training Acc : 0.767, Run Time : 1.01
INFO:root:2019-05-11 01:30:00, Epoch : 1, Step : 3962, Training Loss : 0.09858, Training Acc : 0.989, Run Time : 3.42
INFO:root:2019-05-11 01:30:00, Epoch : 1, Step : 3963, Training Loss : 0.18663, Training Acc : 0.933, Run Time : 0.56
INFO:root:2019-05-11 01:30:08, Epoch : 1, Step : 3964, Training Loss : 0.34131, Training Acc : 0.856, Run Time : 8.05
INFO:root:2019-05-11 01:30:09, Epoch : 1, Step : 3965, Training Loss : 0.22861, Training Acc : 0.928, Run Time : 0.44
INFO:root:2019-05-11 01:30:09, Epoch : 1, Step : 3966, Training Loss : 0.14823, Training Acc : 0.967, Run Time : 0.37
INFO:root:2019-05-11 01:30:11, Epoch : 1, Step : 3967, Training Loss : 0.14399, Training Acc : 0.972, Run Time : 1.65
INFO:root:2019-05-11 01:30:20, Epoch : 1, Step : 3968, Training Loss : 0.22796, Training Acc : 0.928, Run Time : 9.25
INFO:root:2019-05-11 01:30:21, Epoch : 1, Step : 3969, Training Loss : 0.24695, Training Acc : 0.911, Run Time : 0.62
INFO:root:2019-05-11 01:30:23, Epoch : 1, Step : 3970, Training Loss : 0.21812, Training Acc : 0.928, Run Time : 2.43
INFO:root:2019-05-11 01:30:33, Epoch : 1, Step : 3971, Training Loss : 0.16457, Training Acc : 0.928, Run Time : 10.18
INFO:root:2019-05-11 01:30:34, Epoch : 1, Step : 3972, Training Loss : 0.19412, Training Acc : 0.939, Run Time : 0.83
INFO:root:2019-05-11 01:30:34, Epoch : 1, Step : 3973, Training Loss : 0.38008, Training Acc : 0.850, Run Time : 0.37
INFO:root:2019-05-11 01:30:35, Epoch : 1, Step : 3974, Training Loss : 0.12471, Training Acc : 0.967, Run Time : 0.38
INFO:root:2019-05-11 01:30:35, Epoch : 1, Step : 3975, Training Loss : 0.16166, Training Acc : 0.956, Run Time : 0.50
INFO:root:2019-05-11 01:30:36, Epoch : 1, Step : 3976, Training Loss : 0.07494, Training Acc : 0.989, Run Time : 0.39
INFO:root:2019-05-11 01:30:36, Epoch : 1, Step : 3977, Training Loss : 0.20747, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 01:30:38, Epoch : 1, Step : 3978, Training Loss : 0.13184, Training Acc : 0.956, Run Time : 1.59
INFO:root:2019-05-11 01:30:46, Epoch : 1, Step : 3979, Training Loss : 0.24160, Training Acc : 0.906, Run Time : 8.63
INFO:root:2019-05-11 01:30:47, Epoch : 1, Step : 3980, Training Loss : 0.25520, Training Acc : 0.922, Run Time : 0.89
INFO:root:2019-05-11 01:30:48, Epoch : 1, Step : 3981, Training Loss : 0.36088, Training Acc : 0.872, Run Time : 0.38
INFO:root:2019-05-11 01:30:48, Epoch : 1, Step : 3982, Training Loss : 0.17018, Training Acc : 0.950, Run Time : 0.53
INFO:root:2019-05-11 01:31:01, Epoch : 1, Step : 3983, Training Loss : 0.18313, Training Acc : 0.933, Run Time : 12.86
INFO:root:2019-05-11 01:31:02, Epoch : 1, Step : 3984, Training Loss : 0.14572, Training Acc : 0.956, Run Time : 0.81
INFO:root:2019-05-11 01:31:02, Epoch : 1, Step : 3985, Training Loss : 0.17987, Training Acc : 0.939, Run Time : 0.37
INFO:root:2019-05-11 01:31:03, Epoch : 1, Step : 3986, Training Loss : 0.15670, Training Acc : 0.944, Run Time : 0.84
INFO:root:2019-05-11 01:31:10, Epoch : 1, Step : 3987, Training Loss : 0.13984, Training Acc : 0.961, Run Time : 7.42
INFO:root:2019-05-11 01:31:11, Epoch : 1, Step : 3988, Training Loss : 0.13387, Training Acc : 0.956, Run Time : 0.66
INFO:root:2019-05-11 01:31:12, Epoch : 1, Step : 3989, Training Loss : 0.15349, Training Acc : 0.950, Run Time : 0.64
INFO:root:2019-05-11 01:31:13, Epoch : 1, Step : 3990, Training Loss : 0.19346, Training Acc : 0.911, Run Time : 1.14
INFO:root:2019-05-11 01:31:22, Epoch : 1, Step : 3991, Training Loss : 0.17418, Training Acc : 0.933, Run Time : 9.38
INFO:root:2019-05-11 01:31:23, Epoch : 1, Step : 3992, Training Loss : 0.25809, Training Acc : 0.867, Run Time : 0.82
INFO:root:2019-05-11 01:31:25, Epoch : 1, Step : 3993, Training Loss : 0.15736, Training Acc : 0.928, Run Time : 1.69
INFO:root:2019-05-11 01:31:36, Epoch : 1, Step : 3994, Training Loss : 0.07698, Training Acc : 0.989, Run Time : 11.46
INFO:root:2019-05-11 01:31:37, Epoch : 1, Step : 3995, Training Loss : 0.12117, Training Acc : 0.961, Run Time : 0.68
INFO:root:2019-05-11 01:31:37, Epoch : 1, Step : 3996, Training Loss : 0.20819, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-11 01:31:51, Epoch : 1, Step : 3997, Training Loss : 0.12635, Training Acc : 0.939, Run Time : 14.08
INFO:root:2019-05-11 01:32:02, Epoch : 1, Step : 3998, Training Loss : 0.15138, Training Acc : 0.967, Run Time : 10.64
INFO:root:2019-05-11 01:32:03, Epoch : 1, Step : 3999, Training Loss : 0.23672, Training Acc : 0.889, Run Time : 0.88
INFO:root:2019-05-11 01:32:05, Epoch : 1, Step : 4000, Training Loss : 0.37581, Training Acc : 0.844, Run Time : 1.64
INFO:root:2019-05-11 01:32:19, Epoch : 1, Step : 4001, Training Loss : 0.62244, Training Acc : 0.667, Run Time : 13.96
INFO:root:2019-05-11 01:32:19, Epoch : 1, Step : 4002, Training Loss : 0.34634, Training Acc : 0.872, Run Time : 0.93
INFO:root:2019-05-11 01:32:30, Epoch : 1, Step : 4003, Training Loss : 0.35660, Training Acc : 0.833, Run Time : 11.00
INFO:root:2019-05-11 01:32:31, Epoch : 1, Step : 4004, Training Loss : 0.33907, Training Acc : 0.833, Run Time : 0.41
INFO:root:2019-05-11 01:32:31, Epoch : 1, Step : 4005, Training Loss : 0.24780, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-11 01:32:32, Epoch : 1, Step : 4006, Training Loss : 0.27337, Training Acc : 0.883, Run Time : 0.86
INFO:root:2019-05-11 01:32:42, Epoch : 1, Step : 4007, Training Loss : 0.22558, Training Acc : 0.900, Run Time : 10.14
INFO:root:2019-05-11 01:32:43, Epoch : 1, Step : 4008, Training Loss : 0.26688, Training Acc : 0.883, Run Time : 0.69
INFO:root:2019-05-11 01:32:43, Epoch : 1, Step : 4009, Training Loss : 0.28515, Training Acc : 0.894, Run Time : 0.37
INFO:root:2019-05-11 01:32:44, Epoch : 1, Step : 4010, Training Loss : 0.50379, Training Acc : 0.756, Run Time : 0.38
INFO:root:2019-05-11 01:32:56, Epoch : 1, Step : 4011, Training Loss : 0.22030, Training Acc : 0.906, Run Time : 12.26
INFO:root:2019-05-11 01:32:56, Epoch : 1, Step : 4012, Training Loss : 0.24636, Training Acc : 0.883, Run Time : 0.56
INFO:root:2019-05-11 01:32:57, Epoch : 1, Step : 4013, Training Loss : 0.37252, Training Acc : 0.833, Run Time : 0.43
INFO:root:2019-05-11 01:32:57, Epoch : 1, Step : 4014, Training Loss : 0.38997, Training Acc : 0.839, Run Time : 0.39
INFO:root:2019-05-11 01:32:59, Epoch : 1, Step : 4015, Training Loss : 0.26283, Training Acc : 0.883, Run Time : 1.54
INFO:root:2019-05-11 01:33:09, Epoch : 1, Step : 4016, Training Loss : 0.28863, Training Acc : 0.883, Run Time : 10.15
INFO:root:2019-05-11 01:33:11, Epoch : 1, Step : 4017, Training Loss : 0.29877, Training Acc : 0.878, Run Time : 1.65
INFO:root:2019-05-11 01:33:20, Epoch : 1, Step : 4018, Training Loss : 0.40238, Training Acc : 0.822, Run Time : 9.04
INFO:root:2019-05-11 01:33:21, Epoch : 1, Step : 4019, Training Loss : 0.29463, Training Acc : 0.861, Run Time : 1.34
INFO:root:2019-05-11 01:33:21, Epoch : 1, Step : 4020, Training Loss : 0.28815, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-11 01:33:22, Epoch : 1, Step : 4021, Training Loss : 0.21887, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 01:33:22, Epoch : 1, Step : 4022, Training Loss : 0.23509, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-11 01:33:23, Epoch : 1, Step : 4023, Training Loss : 0.33835, Training Acc : 0.822, Run Time : 0.42
INFO:root:2019-05-11 01:33:23, Epoch : 1, Step : 4024, Training Loss : 0.15239, Training Acc : 0.961, Run Time : 0.38
INFO:root:2019-05-11 01:33:29, Epoch : 1, Step : 4025, Training Loss : 0.16366, Training Acc : 0.928, Run Time : 5.81
INFO:root:2019-05-11 01:33:31, Epoch : 1, Step : 4026, Training Loss : 0.32613, Training Acc : 0.856, Run Time : 2.17
INFO:root:2019-05-11 01:33:42, Epoch : 1, Step : 4027, Training Loss : 0.24591, Training Acc : 0.911, Run Time : 10.67
INFO:root:2019-05-11 01:33:44, Epoch : 1, Step : 4028, Training Loss : 0.21268, Training Acc : 0.900, Run Time : 1.88
INFO:root:2019-05-11 01:33:52, Epoch : 1, Step : 4029, Training Loss : 0.16495, Training Acc : 0.939, Run Time : 8.64
INFO:root:2019-05-11 01:33:54, Epoch : 1, Step : 4030, Training Loss : 0.25085, Training Acc : 0.839, Run Time : 2.04
INFO:root:2019-05-11 01:33:55, Epoch : 1, Step : 4031, Training Loss : 0.23409, Training Acc : 0.906, Run Time : 0.92
INFO:root:2019-05-11 01:33:59, Epoch : 1, Step : 4032, Training Loss : 0.20525, Training Acc : 0.906, Run Time : 4.25
INFO:root:2019-05-11 01:34:00, Epoch : 1, Step : 4033, Training Loss : 0.16673, Training Acc : 0.939, Run Time : 0.62
INFO:root:2019-05-11 01:34:09, Epoch : 1, Step : 4034, Training Loss : 0.21437, Training Acc : 0.917, Run Time : 9.27
INFO:root:2019-05-11 01:34:10, Epoch : 1, Step : 4035, Training Loss : 0.33952, Training Acc : 0.844, Run Time : 0.56
INFO:root:2019-05-11 01:34:11, Epoch : 1, Step : 4036, Training Loss : 0.36002, Training Acc : 0.806, Run Time : 1.30
INFO:root:2019-05-11 01:34:22, Epoch : 1, Step : 4037, Training Loss : 0.21464, Training Acc : 0.900, Run Time : 10.56
INFO:root:2019-05-11 01:34:22, Epoch : 1, Step : 4038, Training Loss : 0.32302, Training Acc : 0.883, Run Time : 0.81
INFO:root:2019-05-11 01:34:23, Epoch : 1, Step : 4039, Training Loss : 0.29000, Training Acc : 0.878, Run Time : 0.59
INFO:root:2019-05-11 01:34:37, Epoch : 1, Step : 4040, Training Loss : 0.30453, Training Acc : 0.883, Run Time : 14.15
INFO:root:2019-05-11 01:34:38, Epoch : 1, Step : 4041, Training Loss : 0.31620, Training Acc : 0.867, Run Time : 1.25
INFO:root:2019-05-11 01:34:39, Epoch : 1, Step : 4042, Training Loss : 0.53589, Training Acc : 0.817, Run Time : 0.37
INFO:root:2019-05-11 01:34:49, Epoch : 1, Step : 4043, Training Loss : 0.65363, Training Acc : 0.806, Run Time : 10.17
INFO:root:2019-05-11 01:35:04, Epoch : 1, Step : 4044, Training Loss : 0.29246, Training Acc : 0.850, Run Time : 14.56
INFO:root:2019-05-11 01:35:11, Epoch : 1, Step : 4045, Training Loss : 0.32469, Training Acc : 0.867, Run Time : 7.36
INFO:root:2019-05-11 01:35:12, Epoch : 1, Step : 4046, Training Loss : 0.28948, Training Acc : 0.917, Run Time : 0.76
INFO:root:2019-05-11 01:35:14, Epoch : 1, Step : 4047, Training Loss : 0.21659, Training Acc : 0.917, Run Time : 1.89
INFO:root:2019-05-11 01:35:23, Epoch : 1, Step : 4048, Training Loss : 0.29167, Training Acc : 0.867, Run Time : 8.99
INFO:root:2019-05-11 01:35:24, Epoch : 1, Step : 4049, Training Loss : 0.34561, Training Acc : 0.839, Run Time : 1.04
INFO:root:2019-05-11 01:35:24, Epoch : 1, Step : 4050, Training Loss : 0.28511, Training Acc : 0.900, Run Time : 0.71
INFO:root:2019-05-11 01:35:25, Epoch : 1, Step : 4051, Training Loss : 0.33369, Training Acc : 0.861, Run Time : 1.09
INFO:root:2019-05-11 01:35:34, Epoch : 1, Step : 4052, Training Loss : 0.37236, Training Acc : 0.817, Run Time : 8.41
INFO:root:2019-05-11 01:35:35, Epoch : 1, Step : 4053, Training Loss : 0.38649, Training Acc : 0.828, Run Time : 1.49
INFO:root:2019-05-11 01:35:47, Epoch : 1, Step : 4054, Training Loss : 0.47090, Training Acc : 0.761, Run Time : 11.89
INFO:root:2019-05-11 01:35:48, Epoch : 1, Step : 4055, Training Loss : 0.65645, Training Acc : 0.722, Run Time : 0.77
INFO:root:2019-05-11 01:35:48, Epoch : 1, Step : 4056, Training Loss : 0.63240, Training Acc : 0.706, Run Time : 0.38
INFO:root:2019-05-11 01:35:50, Epoch : 1, Step : 4057, Training Loss : 0.54271, Training Acc : 0.789, Run Time : 1.75
INFO:root:2019-05-11 01:36:00, Epoch : 1, Step : 4058, Training Loss : 0.43848, Training Acc : 0.817, Run Time : 10.08
INFO:root:2019-05-11 01:36:01, Epoch : 1, Step : 4059, Training Loss : 0.42142, Training Acc : 0.800, Run Time : 1.06
INFO:root:2019-05-11 01:36:08, Epoch : 1, Step : 4060, Training Loss : 0.31856, Training Acc : 0.839, Run Time : 7.18
INFO:root:2019-05-11 01:36:09, Epoch : 1, Step : 4061, Training Loss : 0.34401, Training Acc : 0.856, Run Time : 0.79
INFO:root:2019-05-11 01:36:10, Epoch : 1, Step : 4062, Training Loss : 0.23528, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-11 01:36:18, Epoch : 1, Step : 4063, Training Loss : 0.33029, Training Acc : 0.833, Run Time : 8.50
INFO:root:2019-05-11 01:36:24, Epoch : 1, Step : 4064, Training Loss : 0.43889, Training Acc : 0.794, Run Time : 5.60
INFO:root:2019-05-11 01:36:24, Epoch : 1, Step : 4065, Training Loss : 0.39798, Training Acc : 0.794, Run Time : 0.68
INFO:root:2019-05-11 01:36:33, Epoch : 1, Step : 4066, Training Loss : 0.34119, Training Acc : 0.811, Run Time : 8.34
INFO:root:2019-05-11 01:36:34, Epoch : 1, Step : 4067, Training Loss : 0.36718, Training Acc : 0.822, Run Time : 1.08
INFO:root:2019-05-11 01:36:34, Epoch : 1, Step : 4068, Training Loss : 0.29739, Training Acc : 0.878, Run Time : 0.50
INFO:root:2019-05-11 01:36:36, Epoch : 1, Step : 4069, Training Loss : 0.23454, Training Acc : 0.917, Run Time : 1.21
INFO:root:2019-05-11 01:36:44, Epoch : 1, Step : 4070, Training Loss : 0.20611, Training Acc : 0.922, Run Time : 8.32
INFO:root:2019-05-11 01:36:45, Epoch : 1, Step : 4071, Training Loss : 0.36929, Training Acc : 0.828, Run Time : 0.85
INFO:root:2019-05-11 01:36:46, Epoch : 1, Step : 4072, Training Loss : 0.42364, Training Acc : 0.794, Run Time : 1.27
INFO:root:2019-05-11 01:36:55, Epoch : 1, Step : 4073, Training Loss : 0.38679, Training Acc : 0.806, Run Time : 9.39
INFO:root:2019-05-11 01:36:56, Epoch : 1, Step : 4074, Training Loss : 0.28667, Training Acc : 0.878, Run Time : 0.75
INFO:root:2019-05-11 01:36:57, Epoch : 1, Step : 4075, Training Loss : 0.28606, Training Acc : 0.894, Run Time : 1.20
INFO:root:2019-05-11 01:37:10, Epoch : 1, Step : 4076, Training Loss : 0.32680, Training Acc : 0.867, Run Time : 12.26
INFO:root:2019-05-11 01:37:11, Epoch : 1, Step : 4077, Training Loss : 0.26683, Training Acc : 0.889, Run Time : 1.28
INFO:root:2019-05-11 01:37:11, Epoch : 1, Step : 4078, Training Loss : 0.37587, Training Acc : 0.817, Run Time : 0.37
INFO:root:2019-05-11 01:37:13, Epoch : 1, Step : 4079, Training Loss : 0.28722, Training Acc : 0.883, Run Time : 1.51
INFO:root:2019-05-11 01:37:23, Epoch : 1, Step : 4080, Training Loss : 0.30701, Training Acc : 0.856, Run Time : 10.67
INFO:root:2019-05-11 01:37:24, Epoch : 1, Step : 4081, Training Loss : 0.29835, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-11 01:37:24, Epoch : 1, Step : 4082, Training Loss : 0.26409, Training Acc : 0.900, Run Time : 0.40
INFO:root:2019-05-11 01:37:25, Epoch : 1, Step : 4083, Training Loss : 0.32946, Training Acc : 0.850, Run Time : 0.87
INFO:root:2019-05-11 01:37:35, Epoch : 1, Step : 4084, Training Loss : 0.36359, Training Acc : 0.872, Run Time : 10.14
INFO:root:2019-05-11 01:37:36, Epoch : 1, Step : 4085, Training Loss : 0.32166, Training Acc : 0.844, Run Time : 0.99
INFO:root:2019-05-11 01:37:37, Epoch : 1, Step : 4086, Training Loss : 0.21217, Training Acc : 0.889, Run Time : 0.58
INFO:root:2019-05-11 01:37:37, Epoch : 1, Step : 4087, Training Loss : 0.35334, Training Acc : 0.856, Run Time : 0.38
INFO:root:2019-05-11 01:37:39, Epoch : 1, Step : 4088, Training Loss : 0.23911, Training Acc : 0.911, Run Time : 1.98
INFO:root:2019-05-11 01:37:50, Epoch : 1, Step : 4089, Training Loss : 0.25629, Training Acc : 0.878, Run Time : 10.47
INFO:root:2019-05-11 01:37:50, Epoch : 1, Step : 4090, Training Loss : 0.31263, Training Acc : 0.878, Run Time : 0.42
INFO:root:2019-05-11 01:37:51, Epoch : 1, Step : 4091, Training Loss : 0.36986, Training Acc : 0.844, Run Time : 0.42
INFO:root:2019-05-11 01:37:51, Epoch : 1, Step : 4092, Training Loss : 0.33549, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-11 01:38:05, Epoch : 1, Step : 4093, Training Loss : 0.20678, Training Acc : 0.928, Run Time : 14.15
INFO:root:2019-05-11 01:38:10, Epoch : 1, Step : 4094, Training Loss : 0.20587, Training Acc : 0.939, Run Time : 5.10
INFO:root:2019-05-11 01:38:11, Epoch : 1, Step : 4095, Training Loss : 0.23359, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-11 01:38:21, Epoch : 1, Step : 4096, Training Loss : 0.31701, Training Acc : 0.878, Run Time : 10.16
INFO:root:2019-05-11 01:38:21, Epoch : 1, Step : 4097, Training Loss : 0.22748, Training Acc : 0.928, Run Time : 0.63
INFO:root:2019-05-11 01:38:22, Epoch : 1, Step : 4098, Training Loss : 0.31120, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 01:38:22, Epoch : 1, Step : 4099, Training Loss : 0.25130, Training Acc : 0.922, Run Time : 0.40
INFO:root:2019-05-11 01:38:23, Epoch : 1, Step : 4100, Training Loss : 0.21313, Training Acc : 0.944, Run Time : 1.07
INFO:root:2019-05-11 01:38:33, Epoch : 1, Step : 4101, Training Loss : 0.29896, Training Acc : 0.867, Run Time : 10.04
INFO:root:2019-05-11 01:38:34, Epoch : 1, Step : 4102, Training Loss : 0.21610, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 01:38:34, Epoch : 1, Step : 4103, Training Loss : 0.24379, Training Acc : 0.894, Run Time : 0.47
INFO:root:2019-05-11 01:38:35, Epoch : 1, Step : 4104, Training Loss : 0.19820, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-11 01:38:36, Epoch : 1, Step : 4105, Training Loss : 0.26630, Training Acc : 0.889, Run Time : 1.75
INFO:root:2019-05-11 01:38:47, Epoch : 1, Step : 4106, Training Loss : 0.34035, Training Acc : 0.856, Run Time : 10.13
INFO:root:2019-05-11 01:38:47, Epoch : 1, Step : 4107, Training Loss : 0.31196, Training Acc : 0.878, Run Time : 0.42
INFO:root:2019-05-11 01:38:48, Epoch : 1, Step : 4108, Training Loss : 0.21941, Training Acc : 0.922, Run Time : 0.60
INFO:root:2019-05-11 01:38:48, Epoch : 1, Step : 4109, Training Loss : 0.39023, Training Acc : 0.856, Run Time : 0.60
INFO:root:2019-05-11 01:38:49, Epoch : 1, Step : 4110, Training Loss : 0.28064, Training Acc : 0.889, Run Time : 1.23
INFO:root:2019-05-11 01:38:59, Epoch : 1, Step : 4111, Training Loss : 0.41938, Training Acc : 0.828, Run Time : 9.34
INFO:root:2019-05-11 01:38:59, Epoch : 1, Step : 4112, Training Loss : 0.23705, Training Acc : 0.906, Run Time : 0.74
INFO:root:2019-05-11 01:39:01, Epoch : 1, Step : 4113, Training Loss : 0.43208, Training Acc : 0.794, Run Time : 1.60
INFO:root:2019-05-11 01:39:17, Epoch : 1, Step : 4114, Training Loss : 0.27014, Training Acc : 0.878, Run Time : 15.55
INFO:root:2019-05-11 01:39:19, Epoch : 1, Step : 4115, Training Loss : 0.15752, Training Acc : 0.950, Run Time : 2.72
INFO:root:2019-05-11 01:39:20, Epoch : 1, Step : 4116, Training Loss : 0.22435, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-11 01:39:20, Epoch : 1, Step : 4117, Training Loss : 0.30117, Training Acc : 0.878, Run Time : 0.39
INFO:root:2019-05-11 01:39:21, Epoch : 1, Step : 4118, Training Loss : 0.26632, Training Acc : 0.889, Run Time : 0.90
INFO:root:2019-05-11 01:39:30, Epoch : 1, Step : 4119, Training Loss : 0.19304, Training Acc : 0.933, Run Time : 9.38
INFO:root:2019-05-11 01:39:31, Epoch : 1, Step : 4120, Training Loss : 0.25236, Training Acc : 0.933, Run Time : 0.41
INFO:root:2019-05-11 01:39:31, Epoch : 1, Step : 4121, Training Loss : 0.28184, Training Acc : 0.878, Run Time : 0.50
INFO:root:2019-05-11 01:39:32, Epoch : 1, Step : 4122, Training Loss : 0.26810, Training Acc : 0.878, Run Time : 0.58
INFO:root:2019-05-11 01:39:44, Epoch : 1, Step : 4123, Training Loss : 0.29939, Training Acc : 0.867, Run Time : 12.00
INFO:root:2019-05-11 01:39:44, Epoch : 1, Step : 4124, Training Loss : 0.25451, Training Acc : 0.889, Run Time : 0.42
INFO:root:2019-05-11 01:39:45, Epoch : 1, Step : 4125, Training Loss : 0.27172, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-11 01:39:47, Epoch : 1, Step : 4126, Training Loss : 0.24091, Training Acc : 0.922, Run Time : 1.77
INFO:root:2019-05-11 01:39:58, Epoch : 1, Step : 4127, Training Loss : 0.20136, Training Acc : 0.928, Run Time : 11.27
INFO:root:2019-05-11 01:39:58, Epoch : 1, Step : 4128, Training Loss : 0.12962, Training Acc : 0.967, Run Time : 0.40
INFO:root:2019-05-11 01:39:59, Epoch : 1, Step : 4129, Training Loss : 0.18962, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 01:39:59, Epoch : 1, Step : 4130, Training Loss : 0.23088, Training Acc : 0.917, Run Time : 0.73
INFO:root:2019-05-11 01:40:09, Epoch : 1, Step : 4131, Training Loss : 0.29437, Training Acc : 0.889, Run Time : 9.53
INFO:root:2019-05-11 01:40:09, Epoch : 1, Step : 4132, Training Loss : 0.21956, Training Acc : 0.922, Run Time : 0.44
INFO:root:2019-05-11 01:40:10, Epoch : 1, Step : 4133, Training Loss : 0.39124, Training Acc : 0.822, Run Time : 0.58
INFO:root:2019-05-11 01:40:11, Epoch : 1, Step : 4134, Training Loss : 0.40642, Training Acc : 0.844, Run Time : 1.25
INFO:root:2019-05-11 01:40:21, Epoch : 1, Step : 4135, Training Loss : 0.31156, Training Acc : 0.839, Run Time : 9.76
INFO:root:2019-05-11 01:40:22, Epoch : 1, Step : 4136, Training Loss : 0.36529, Training Acc : 0.839, Run Time : 0.79
INFO:root:2019-05-11 01:40:22, Epoch : 1, Step : 4137, Training Loss : 0.21462, Training Acc : 0.922, Run Time : 0.74
INFO:root:2019-05-11 01:40:26, Epoch : 1, Step : 4138, Training Loss : 0.26238, Training Acc : 0.878, Run Time : 3.11
INFO:root:2019-05-11 01:40:26, Epoch : 1, Step : 4139, Training Loss : 0.30766, Training Acc : 0.872, Run Time : 0.38
INFO:root:2019-05-11 01:40:26, Epoch : 1, Step : 4140, Training Loss : 0.31703, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-11 01:40:28, Epoch : 1, Step : 4141, Training Loss : 0.26262, Training Acc : 0.878, Run Time : 1.58
INFO:root:2019-05-11 01:40:37, Epoch : 1, Step : 4142, Training Loss : 0.30537, Training Acc : 0.867, Run Time : 9.06
INFO:root:2019-05-11 01:40:37, Epoch : 1, Step : 4143, Training Loss : 0.19153, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 01:40:38, Epoch : 1, Step : 4144, Training Loss : 0.19900, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 01:40:39, Epoch : 1, Step : 4145, Training Loss : 0.18093, Training Acc : 0.917, Run Time : 1.63
INFO:root:2019-05-11 01:40:49, Epoch : 1, Step : 4146, Training Loss : 0.18511, Training Acc : 0.944, Run Time : 9.85
INFO:root:2019-05-11 01:40:50, Epoch : 1, Step : 4147, Training Loss : 0.22604, Training Acc : 0.939, Run Time : 0.47
INFO:root:2019-05-11 01:40:50, Epoch : 1, Step : 4148, Training Loss : 0.27326, Training Acc : 0.872, Run Time : 0.43
INFO:root:2019-05-11 01:40:52, Epoch : 1, Step : 4149, Training Loss : 0.37081, Training Acc : 0.833, Run Time : 1.51
INFO:root:2019-05-11 01:41:02, Epoch : 1, Step : 4150, Training Loss : 0.36700, Training Acc : 0.839, Run Time : 9.92
INFO:root:2019-05-11 01:41:02, Epoch : 1, Step : 4151, Training Loss : 0.39063, Training Acc : 0.856, Run Time : 0.62
INFO:root:2019-05-11 01:41:03, Epoch : 1, Step : 4152, Training Loss : 0.36649, Training Acc : 0.894, Run Time : 0.62
INFO:root:2019-05-11 01:41:14, Epoch : 1, Step : 4153, Training Loss : 0.35868, Training Acc : 0.850, Run Time : 11.65
INFO:root:2019-05-11 01:41:15, Epoch : 1, Step : 4154, Training Loss : 0.19475, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-11 01:41:15, Epoch : 1, Step : 4155, Training Loss : 0.30284, Training Acc : 0.894, Run Time : 0.37
INFO:root:2019-05-11 01:41:16, Epoch : 1, Step : 4156, Training Loss : 0.17741, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 01:41:17, Epoch : 1, Step : 4157, Training Loss : 0.23057, Training Acc : 0.939, Run Time : 1.26
INFO:root:2019-05-11 01:41:25, Epoch : 1, Step : 4158, Training Loss : 0.19290, Training Acc : 0.917, Run Time : 7.84
INFO:root:2019-05-11 01:41:25, Epoch : 1, Step : 4159, Training Loss : 0.32953, Training Acc : 0.850, Run Time : 0.56
INFO:root:2019-05-11 01:41:26, Epoch : 1, Step : 4160, Training Loss : 0.29159, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 01:41:26, Epoch : 1, Step : 4161, Training Loss : 0.30987, Training Acc : 0.872, Run Time : 0.38
INFO:root:2019-05-11 01:41:27, Epoch : 1, Step : 4162, Training Loss : 0.23523, Training Acc : 0.911, Run Time : 1.17
INFO:root:2019-05-11 01:41:40, Epoch : 1, Step : 4163, Training Loss : 0.28778, Training Acc : 0.883, Run Time : 13.18
INFO:root:2019-05-11 01:41:41, Epoch : 1, Step : 4164, Training Loss : 0.24728, Training Acc : 0.894, Run Time : 0.54
INFO:root:2019-05-11 01:41:41, Epoch : 1, Step : 4165, Training Loss : 0.26157, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-11 01:41:42, Epoch : 1, Step : 4166, Training Loss : 0.20462, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-11 01:41:43, Epoch : 1, Step : 4167, Training Loss : 0.28009, Training Acc : 0.872, Run Time : 1.04
INFO:root:2019-05-11 01:41:56, Epoch : 1, Step : 4168, Training Loss : 0.29658, Training Acc : 0.872, Run Time : 13.08
INFO:root:2019-05-11 01:41:56, Epoch : 1, Step : 4169, Training Loss : 0.38482, Training Acc : 0.850, Run Time : 0.44
INFO:root:2019-05-11 01:41:57, Epoch : 1, Step : 4170, Training Loss : 0.31100, Training Acc : 0.872, Run Time : 0.41
INFO:root:2019-05-11 01:41:59, Epoch : 1, Step : 4171, Training Loss : 0.25892, Training Acc : 0.906, Run Time : 2.16
INFO:root:2019-05-11 01:41:59, Epoch : 1, Step : 4172, Training Loss : 0.17780, Training Acc : 0.933, Run Time : 0.37
INFO:root:2019-05-11 01:42:00, Epoch : 1, Step : 4173, Training Loss : 0.32157, Training Acc : 0.867, Run Time : 0.51
INFO:root:2019-05-11 01:42:00, Epoch : 1, Step : 4174, Training Loss : 0.26838, Training Acc : 0.867, Run Time : 0.39
INFO:root:2019-05-11 01:42:14, Epoch : 1, Step : 4175, Training Loss : 0.22989, Training Acc : 0.900, Run Time : 14.05
INFO:root:2019-05-11 01:42:15, Epoch : 1, Step : 4176, Training Loss : 0.33424, Training Acc : 0.883, Run Time : 0.60
INFO:root:2019-05-11 01:42:16, Epoch : 1, Step : 4177, Training Loss : 0.45097, Training Acc : 0.844, Run Time : 0.73
INFO:root:2019-05-11 01:42:17, Epoch : 1, Step : 4178, Training Loss : 0.27827, Training Acc : 0.878, Run Time : 0.90
INFO:root:2019-05-11 01:42:26, Epoch : 1, Step : 4179, Training Loss : 0.14881, Training Acc : 0.939, Run Time : 9.04
INFO:root:2019-05-11 01:42:26, Epoch : 1, Step : 4180, Training Loss : 0.14375, Training Acc : 0.933, Run Time : 0.73
INFO:root:2019-05-11 01:42:27, Epoch : 1, Step : 4181, Training Loss : 0.23525, Training Acc : 0.900, Run Time : 1.07
INFO:root:2019-05-11 01:42:38, Epoch : 1, Step : 4182, Training Loss : 0.19323, Training Acc : 0.922, Run Time : 10.19
INFO:root:2019-05-11 01:42:39, Epoch : 1, Step : 4183, Training Loss : 0.14361, Training Acc : 0.950, Run Time : 1.03
INFO:root:2019-05-11 01:42:39, Epoch : 1, Step : 4184, Training Loss : 0.13563, Training Acc : 0.956, Run Time : 0.75
INFO:root:2019-05-11 01:42:49, Epoch : 1, Step : 4185, Training Loss : 0.15486, Training Acc : 0.950, Run Time : 9.24
INFO:root:2019-05-11 01:42:50, Epoch : 1, Step : 4186, Training Loss : 0.11729, Training Acc : 0.967, Run Time : 1.02
INFO:root:2019-05-11 01:42:50, Epoch : 1, Step : 4187, Training Loss : 0.13054, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 01:43:04, Epoch : 1, Step : 4188, Training Loss : 0.10730, Training Acc : 0.978, Run Time : 13.88
INFO:root:2019-05-11 01:43:05, Epoch : 1, Step : 4189, Training Loss : 0.16148, Training Acc : 0.922, Run Time : 0.75
INFO:root:2019-05-11 01:43:05, Epoch : 1, Step : 4190, Training Loss : 0.16856, Training Acc : 0.933, Run Time : 0.37
INFO:root:2019-05-11 01:43:07, Epoch : 1, Step : 4191, Training Loss : 0.11514, Training Acc : 0.956, Run Time : 1.62
INFO:root:2019-05-11 01:43:16, Epoch : 1, Step : 4192, Training Loss : 0.13741, Training Acc : 0.950, Run Time : 9.69
INFO:root:2019-05-11 01:43:17, Epoch : 1, Step : 4193, Training Loss : 0.32225, Training Acc : 0.900, Run Time : 0.44
INFO:root:2019-05-11 01:43:17, Epoch : 1, Step : 4194, Training Loss : 0.16587, Training Acc : 0.917, Run Time : 0.37
INFO:root:2019-05-11 01:43:19, Epoch : 1, Step : 4195, Training Loss : 0.15910, Training Acc : 0.933, Run Time : 1.58
INFO:root:2019-05-11 01:43:28, Epoch : 1, Step : 4196, Training Loss : 0.17615, Training Acc : 0.933, Run Time : 9.37
INFO:root:2019-05-11 01:43:29, Epoch : 1, Step : 4197, Training Loss : 0.25666, Training Acc : 0.922, Run Time : 0.62
INFO:root:2019-05-11 01:43:29, Epoch : 1, Step : 4198, Training Loss : 0.49743, Training Acc : 0.844, Run Time : 0.57
INFO:root:2019-05-11 01:43:30, Epoch : 1, Step : 4199, Training Loss : 0.47877, Training Acc : 0.806, Run Time : 1.04
INFO:root:2019-05-11 01:43:40, Epoch : 1, Step : 4200, Training Loss : 0.53606, Training Acc : 0.789, Run Time : 9.61
INFO:root:2019-05-11 01:43:41, Epoch : 1, Step : 4201, Training Loss : 0.77934, Training Acc : 0.661, Run Time : 1.13
INFO:root:2019-05-11 01:43:42, Epoch : 1, Step : 4202, Training Loss : 0.67066, Training Acc : 0.772, Run Time : 1.02
INFO:root:2019-05-11 01:43:52, Epoch : 1, Step : 4203, Training Loss : 0.29423, Training Acc : 0.889, Run Time : 9.66
INFO:root:2019-05-11 01:43:52, Epoch : 1, Step : 4204, Training Loss : 0.29869, Training Acc : 0.872, Run Time : 0.41
INFO:root:2019-05-11 01:43:52, Epoch : 1, Step : 4205, Training Loss : 0.45618, Training Acc : 0.833, Run Time : 0.39
INFO:root:2019-05-11 01:43:53, Epoch : 1, Step : 4206, Training Loss : 0.52038, Training Acc : 0.767, Run Time : 0.38
INFO:root:2019-05-11 01:43:53, Epoch : 1, Step : 4207, Training Loss : 0.45603, Training Acc : 0.811, Run Time : 0.38
INFO:root:2019-05-11 01:43:54, Epoch : 1, Step : 4208, Training Loss : 0.58577, Training Acc : 0.783, Run Time : 0.82
INFO:root:2019-05-11 01:44:05, Epoch : 1, Step : 4209, Training Loss : 0.64489, Training Acc : 0.689, Run Time : 10.61
INFO:root:2019-05-11 01:44:07, Epoch : 1, Step : 4210, Training Loss : 0.32358, Training Acc : 0.856, Run Time : 2.59
INFO:root:2019-05-11 01:44:08, Epoch : 1, Step : 4211, Training Loss : 0.25987, Training Acc : 0.917, Run Time : 0.37
INFO:root:2019-05-11 01:44:08, Epoch : 1, Step : 4212, Training Loss : 0.26669, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-11 01:44:09, Epoch : 1, Step : 4213, Training Loss : 0.31939, Training Acc : 0.850, Run Time : 1.19
INFO:root:2019-05-11 01:44:18, Epoch : 1, Step : 4214, Training Loss : 0.30617, Training Acc : 0.872, Run Time : 9.02
INFO:root:2019-05-11 01:44:19, Epoch : 1, Step : 4215, Training Loss : 0.24187, Training Acc : 0.872, Run Time : 0.90
INFO:root:2019-05-11 01:44:20, Epoch : 1, Step : 4216, Training Loss : 0.21759, Training Acc : 0.917, Run Time : 1.02
INFO:root:2019-05-11 01:44:32, Epoch : 1, Step : 4217, Training Loss : 0.45696, Training Acc : 0.806, Run Time : 11.37
INFO:root:2019-05-11 01:44:32, Epoch : 1, Step : 4218, Training Loss : 0.38277, Training Acc : 0.806, Run Time : 0.43
INFO:root:2019-05-11 01:44:33, Epoch : 1, Step : 4219, Training Loss : 0.35077, Training Acc : 0.833, Run Time : 0.55
INFO:root:2019-05-11 01:44:33, Epoch : 1, Step : 4220, Training Loss : 0.45668, Training Acc : 0.817, Run Time : 0.88
INFO:root:2019-05-11 01:44:35, Epoch : 1, Step : 4221, Training Loss : 0.44971, Training Acc : 0.800, Run Time : 1.73
INFO:root:2019-05-11 01:44:48, Epoch : 1, Step : 4222, Training Loss : 0.56837, Training Acc : 0.794, Run Time : 13.38
INFO:root:2019-05-11 01:44:50, Epoch : 1, Step : 4223, Training Loss : 0.36182, Training Acc : 0.839, Run Time : 1.06
INFO:root:2019-05-11 01:44:52, Epoch : 1, Step : 4224, Training Loss : 0.46681, Training Acc : 0.806, Run Time : 1.96
INFO:root:2019-05-11 01:45:04, Epoch : 1, Step : 4225, Training Loss : 0.25703, Training Acc : 0.883, Run Time : 12.70
INFO:root:2019-05-11 01:45:06, Epoch : 1, Step : 4226, Training Loss : 0.33027, Training Acc : 0.833, Run Time : 2.00
INFO:root:2019-05-11 01:45:07, Epoch : 1, Step : 4227, Training Loss : 0.33437, Training Acc : 0.850, Run Time : 0.86
INFO:root:2019-05-11 01:45:17, Epoch : 1, Step : 4228, Training Loss : 0.43391, Training Acc : 0.833, Run Time : 9.99
INFO:root:2019-05-11 01:45:18, Epoch : 1, Step : 4229, Training Loss : 0.31355, Training Acc : 0.861, Run Time : 1.02
INFO:root:2019-05-11 01:45:25, Epoch : 1, Step : 4230, Training Loss : 0.37568, Training Acc : 0.822, Run Time : 7.08
INFO:root:2019-05-11 01:45:26, Epoch : 1, Step : 4231, Training Loss : 0.33985, Training Acc : 0.850, Run Time : 0.58
INFO:root:2019-05-11 01:45:27, Epoch : 1, Step : 4232, Training Loss : 0.31595, Training Acc : 0.872, Run Time : 1.39
INFO:root:2019-05-11 01:45:35, Epoch : 1, Step : 4233, Training Loss : 0.33729, Training Acc : 0.872, Run Time : 8.37
INFO:root:2019-05-11 01:45:37, Epoch : 1, Step : 4234, Training Loss : 0.39710, Training Acc : 0.833, Run Time : 1.11
INFO:root:2019-05-11 01:45:37, Epoch : 1, Step : 4235, Training Loss : 0.28497, Training Acc : 0.861, Run Time : 0.63
INFO:root:2019-05-11 01:45:38, Epoch : 1, Step : 4236, Training Loss : 0.37617, Training Acc : 0.806, Run Time : 1.15
INFO:root:2019-05-11 01:45:48, Epoch : 1, Step : 4237, Training Loss : 0.24870, Training Acc : 0.883, Run Time : 9.21
INFO:root:2019-05-11 01:45:49, Epoch : 1, Step : 4238, Training Loss : 0.35623, Training Acc : 0.833, Run Time : 0.97
INFO:root:2019-05-11 01:45:50, Epoch : 1, Step : 4239, Training Loss : 0.31920, Training Acc : 0.839, Run Time : 1.26
INFO:root:2019-05-11 01:45:59, Epoch : 1, Step : 4240, Training Loss : 0.39069, Training Acc : 0.822, Run Time : 8.81
INFO:root:2019-05-11 01:45:59, Epoch : 1, Step : 4241, Training Loss : 0.29146, Training Acc : 0.856, Run Time : 0.43
INFO:root:2019-05-11 01:45:59, Epoch : 1, Step : 4242, Training Loss : 0.53200, Training Acc : 0.806, Run Time : 0.38
INFO:root:2019-05-11 01:46:00, Epoch : 1, Step : 4243, Training Loss : 0.40677, Training Acc : 0.811, Run Time : 0.55
INFO:root:2019-05-11 01:46:11, Epoch : 1, Step : 4244, Training Loss : 0.32389, Training Acc : 0.867, Run Time : 11.34
INFO:root:2019-05-11 01:46:12, Epoch : 1, Step : 4245, Training Loss : 0.47336, Training Acc : 0.817, Run Time : 0.38
INFO:root:2019-05-11 01:46:12, Epoch : 1, Step : 4246, Training Loss : 0.35145, Training Acc : 0.822, Run Time : 0.38
INFO:root:2019-05-11 01:46:14, Epoch : 1, Step : 4247, Training Loss : 0.27504, Training Acc : 0.883, Run Time : 1.61
INFO:root:2019-05-11 01:46:26, Epoch : 1, Step : 4248, Training Loss : 0.27165, Training Acc : 0.861, Run Time : 12.30
INFO:root:2019-05-11 01:46:26, Epoch : 1, Step : 4249, Training Loss : 0.42106, Training Acc : 0.806, Run Time : 0.42
INFO:root:2019-05-11 01:46:27, Epoch : 1, Step : 4250, Training Loss : 0.41573, Training Acc : 0.800, Run Time : 0.45
INFO:root:2019-05-11 01:46:28, Epoch : 1, Step : 4251, Training Loss : 0.32872, Training Acc : 0.839, Run Time : 1.54
INFO:root:2019-05-11 01:46:40, Epoch : 1, Step : 4252, Training Loss : 0.39501, Training Acc : 0.817, Run Time : 11.62
INFO:root:2019-05-11 01:46:40, Epoch : 1, Step : 4253, Training Loss : 0.24767, Training Acc : 0.911, Run Time : 0.42
INFO:root:2019-05-11 01:46:41, Epoch : 1, Step : 4254, Training Loss : 0.27391, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-11 01:46:43, Epoch : 1, Step : 4255, Training Loss : 0.35473, Training Acc : 0.822, Run Time : 2.14
INFO:root:2019-05-11 01:46:53, Epoch : 1, Step : 4256, Training Loss : 0.17044, Training Acc : 0.961, Run Time : 10.11
INFO:root:2019-05-11 01:46:54, Epoch : 1, Step : 4257, Training Loss : 0.23083, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-11 01:46:54, Epoch : 1, Step : 4258, Training Loss : 0.27574, Training Acc : 0.883, Run Time : 0.43
INFO:root:2019-05-11 01:46:56, Epoch : 1, Step : 4259, Training Loss : 0.48661, Training Acc : 0.789, Run Time : 2.01
INFO:root:2019-05-11 01:47:07, Epoch : 1, Step : 4260, Training Loss : 0.25347, Training Acc : 0.906, Run Time : 11.17
INFO:root:2019-05-11 01:47:08, Epoch : 1, Step : 4261, Training Loss : 0.33962, Training Acc : 0.839, Run Time : 0.41
INFO:root:2019-05-11 01:47:08, Epoch : 1, Step : 4262, Training Loss : 0.46160, Training Acc : 0.761, Run Time : 0.39
INFO:root:2019-05-11 01:47:08, Epoch : 1, Step : 4263, Training Loss : 0.54341, Training Acc : 0.700, Run Time : 0.53
INFO:root:2019-05-11 01:47:09, Epoch : 1, Step : 4264, Training Loss : 0.22859, Training Acc : 0.917, Run Time : 0.59
INFO:root:2019-05-11 01:47:21, Epoch : 1, Step : 4265, Training Loss : 0.49004, Training Acc : 0.806, Run Time : 11.66
INFO:root:2019-05-11 01:47:22, Epoch : 1, Step : 4266, Training Loss : 0.40071, Training Acc : 0.822, Run Time : 1.18
INFO:root:2019-05-11 01:47:22, Epoch : 1, Step : 4267, Training Loss : 0.42549, Training Acc : 0.794, Run Time : 0.39
INFO:root:2019-05-11 01:47:23, Epoch : 1, Step : 4268, Training Loss : 0.37073, Training Acc : 0.822, Run Time : 0.38
INFO:root:2019-05-11 01:47:24, Epoch : 1, Step : 4269, Training Loss : 0.41926, Training Acc : 0.817, Run Time : 0.90
INFO:root:2019-05-11 01:47:31, Epoch : 1, Step : 4270, Training Loss : 0.29244, Training Acc : 0.889, Run Time : 7.87
INFO:root:2019-05-11 01:47:32, Epoch : 1, Step : 4271, Training Loss : 0.33578, Training Acc : 0.844, Run Time : 0.83
INFO:root:2019-05-11 01:47:33, Epoch : 1, Step : 4272, Training Loss : 0.33853, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-11 01:47:40, Epoch : 1, Step : 4273, Training Loss : 0.33464, Training Acc : 0.861, Run Time : 6.97
INFO:root:2019-05-11 01:47:40, Epoch : 1, Step : 4274, Training Loss : 0.46714, Training Acc : 0.761, Run Time : 0.45
INFO:root:2019-05-11 01:47:42, Epoch : 1, Step : 4275, Training Loss : 0.53676, Training Acc : 0.717, Run Time : 1.87
INFO:root:2019-05-11 01:47:51, Epoch : 1, Step : 4276, Training Loss : 0.75350, Training Acc : 0.722, Run Time : 9.57
INFO:root:2019-05-11 01:47:52, Epoch : 1, Step : 4277, Training Loss : 0.57549, Training Acc : 0.728, Run Time : 0.41
INFO:root:2019-05-11 01:47:52, Epoch : 1, Step : 4278, Training Loss : 0.36370, Training Acc : 0.833, Run Time : 0.44
INFO:root:2019-05-11 01:47:53, Epoch : 1, Step : 4279, Training Loss : 0.31919, Training Acc : 0.856, Run Time : 1.09
INFO:root:2019-05-11 01:47:56, Epoch : 1, Step : 4280, Training Loss : 0.33068, Training Acc : 0.828, Run Time : 2.73
INFO:root:2019-05-11 01:48:00, Epoch : 1, Step : 4281, Training Loss : 0.55234, Training Acc : 0.833, Run Time : 3.95
INFO:root:2019-05-11 01:48:01, Epoch : 1, Step : 4282, Training Loss : 0.50167, Training Acc : 0.778, Run Time : 1.18
INFO:root:2019-05-11 01:48:02, Epoch : 1, Step : 4283, Training Loss : 0.35535, Training Acc : 0.856, Run Time : 0.41
INFO:root:2019-05-11 01:48:03, Epoch : 1, Step : 4284, Training Loss : 0.44223, Training Acc : 0.856, Run Time : 1.17
INFO:root:2019-05-11 01:48:14, Epoch : 1, Step : 4285, Training Loss : 0.37286, Training Acc : 0.839, Run Time : 11.50
INFO:root:2019-05-11 01:48:15, Epoch : 1, Step : 4286, Training Loss : 0.42679, Training Acc : 0.794, Run Time : 0.82
INFO:root:2019-05-11 01:48:17, Epoch : 1, Step : 4287, Training Loss : 0.41493, Training Acc : 0.817, Run Time : 1.82
INFO:root:2019-05-11 01:48:26, Epoch : 1, Step : 4288, Training Loss : 0.44270, Training Acc : 0.772, Run Time : 9.13
INFO:root:2019-05-11 01:48:27, Epoch : 1, Step : 4289, Training Loss : 0.39505, Training Acc : 0.800, Run Time : 0.42
INFO:root:2019-05-11 01:48:27, Epoch : 1, Step : 4290, Training Loss : 0.39912, Training Acc : 0.778, Run Time : 0.38
INFO:root:2019-05-11 01:48:27, Epoch : 1, Step : 4291, Training Loss : 0.40054, Training Acc : 0.850, Run Time : 0.39
INFO:root:2019-05-11 01:48:29, Epoch : 1, Step : 4292, Training Loss : 0.31589, Training Acc : 0.861, Run Time : 1.45
INFO:root:2019-05-11 01:48:38, Epoch : 1, Step : 4293, Training Loss : 0.37546, Training Acc : 0.839, Run Time : 8.84
INFO:root:2019-05-11 01:48:39, Epoch : 1, Step : 4294, Training Loss : 0.26727, Training Acc : 0.917, Run Time : 1.23
INFO:root:2019-05-11 01:48:40, Epoch : 1, Step : 4295, Training Loss : 0.30139, Training Acc : 0.872, Run Time : 0.83
INFO:root:2019-05-11 01:48:50, Epoch : 1, Step : 4296, Training Loss : 0.33764, Training Acc : 0.833, Run Time : 10.77
INFO:root:2019-05-11 01:48:52, Epoch : 1, Step : 4297, Training Loss : 0.24470, Training Acc : 0.922, Run Time : 1.16
INFO:root:2019-05-11 01:48:53, Epoch : 1, Step : 4298, Training Loss : 0.32095, Training Acc : 0.839, Run Time : 1.22
INFO:root:2019-05-11 01:49:05, Epoch : 1, Step : 4299, Training Loss : 0.31138, Training Acc : 0.844, Run Time : 12.66
INFO:root:2019-05-11 01:49:06, Epoch : 1, Step : 4300, Training Loss : 0.52219, Training Acc : 0.767, Run Time : 0.59
INFO:root:2019-05-11 01:49:22, Epoch : 1, Step : 4301, Training Loss : 0.66108, Training Acc : 0.661, Run Time : 15.79
INFO:root:2019-05-11 01:49:23, Epoch : 1, Step : 4302, Training Loss : 0.53468, Training Acc : 0.744, Run Time : 0.91
INFO:root:2019-05-11 01:49:24, Epoch : 1, Step : 4303, Training Loss : 0.71841, Training Acc : 0.633, Run Time : 0.89
INFO:root:2019-05-11 01:49:35, Epoch : 1, Step : 4304, Training Loss : 0.65802, Training Acc : 0.622, Run Time : 10.95
INFO:root:2019-05-11 01:49:35, Epoch : 1, Step : 4305, Training Loss : 0.88451, Training Acc : 0.561, Run Time : 0.86
INFO:root:2019-05-11 01:49:36, Epoch : 1, Step : 4306, Training Loss : 0.54733, Training Acc : 0.717, Run Time : 0.38
INFO:root:2019-05-11 01:49:37, Epoch : 1, Step : 4307, Training Loss : 0.43914, Training Acc : 0.789, Run Time : 1.52
INFO:root:2019-05-11 01:49:48, Epoch : 1, Step : 4308, Training Loss : 0.35061, Training Acc : 0.861, Run Time : 11.09
INFO:root:2019-05-11 01:49:49, Epoch : 1, Step : 4309, Training Loss : 0.64657, Training Acc : 0.756, Run Time : 0.41
INFO:root:2019-05-11 01:49:50, Epoch : 1, Step : 4310, Training Loss : 0.42930, Training Acc : 0.839, Run Time : 0.76
INFO:root:2019-05-11 01:50:01, Epoch : 1, Step : 4311, Training Loss : 0.43128, Training Acc : 0.794, Run Time : 11.48
INFO:root:2019-05-11 01:50:02, Epoch : 1, Step : 4312, Training Loss : 0.39282, Training Acc : 0.867, Run Time : 0.75
INFO:root:2019-05-11 01:50:02, Epoch : 1, Step : 4313, Training Loss : 0.40457, Training Acc : 0.833, Run Time : 0.56
INFO:root:2019-05-11 01:50:03, Epoch : 1, Step : 4314, Training Loss : 0.37076, Training Acc : 0.844, Run Time : 0.78
INFO:root:2019-05-11 01:50:13, Epoch : 1, Step : 4315, Training Loss : 0.38952, Training Acc : 0.844, Run Time : 9.74
INFO:root:2019-05-11 01:50:13, Epoch : 1, Step : 4316, Training Loss : 0.43329, Training Acc : 0.806, Run Time : 0.43
INFO:root:2019-05-11 01:50:14, Epoch : 1, Step : 4317, Training Loss : 0.46423, Training Acc : 0.756, Run Time : 0.45
INFO:root:2019-05-11 01:50:14, Epoch : 1, Step : 4318, Training Loss : 0.40877, Training Acc : 0.833, Run Time : 0.46
INFO:root:2019-05-11 01:50:16, Epoch : 1, Step : 4319, Training Loss : 0.44206, Training Acc : 0.778, Run Time : 1.81
INFO:root:2019-05-11 01:50:25, Epoch : 1, Step : 4320, Training Loss : 0.41552, Training Acc : 0.783, Run Time : 9.22
INFO:root:2019-05-11 01:50:26, Epoch : 1, Step : 4321, Training Loss : 0.52235, Training Acc : 0.733, Run Time : 0.93
INFO:root:2019-05-11 01:50:40, Epoch : 1, Step : 4322, Training Loss : 0.60625, Training Acc : 0.672, Run Time : 13.99
INFO:root:2019-05-11 01:50:41, Epoch : 1, Step : 4323, Training Loss : 0.65180, Training Acc : 0.667, Run Time : 1.01
INFO:root:2019-05-11 01:50:43, Epoch : 1, Step : 4324, Training Loss : 0.56173, Training Acc : 0.672, Run Time : 1.43
INFO:root:2019-05-11 01:50:58, Epoch : 1, Step : 4325, Training Loss : 0.47904, Training Acc : 0.728, Run Time : 15.69
INFO:root:2019-05-11 01:51:00, Epoch : 1, Step : 4326, Training Loss : 0.58557, Training Acc : 0.678, Run Time : 1.40
INFO:root:2019-05-11 01:51:00, Epoch : 1, Step : 4327, Training Loss : 0.53839, Training Acc : 0.694, Run Time : 0.39
INFO:root:2019-05-11 01:51:02, Epoch : 1, Step : 4328, Training Loss : 0.50926, Training Acc : 0.739, Run Time : 1.43
INFO:root:2019-05-11 01:51:14, Epoch : 1, Step : 4329, Training Loss : 0.50033, Training Acc : 0.750, Run Time : 11.94
INFO:root:2019-05-11 01:51:14, Epoch : 1, Step : 4330, Training Loss : 0.48749, Training Acc : 0.733, Run Time : 0.98
INFO:root:2019-05-11 01:51:16, Epoch : 1, Step : 4331, Training Loss : 0.45968, Training Acc : 0.811, Run Time : 1.42
INFO:root:2019-05-11 01:51:26, Epoch : 1, Step : 4332, Training Loss : 0.37243, Training Acc : 0.878, Run Time : 9.88
INFO:root:2019-05-11 01:51:26, Epoch : 1, Step : 4333, Training Loss : 0.42966, Training Acc : 0.811, Run Time : 0.63
INFO:root:2019-05-11 01:51:27, Epoch : 1, Step : 4334, Training Loss : 0.48780, Training Acc : 0.756, Run Time : 0.41
INFO:root:2019-05-11 01:51:28, Epoch : 1, Step : 4335, Training Loss : 0.43662, Training Acc : 0.767, Run Time : 1.41
INFO:root:2019-05-11 01:51:39, Epoch : 1, Step : 4336, Training Loss : 0.43395, Training Acc : 0.778, Run Time : 10.52
INFO:root:2019-05-11 01:51:40, Epoch : 1, Step : 4337, Training Loss : 0.43431, Training Acc : 0.828, Run Time : 1.13
INFO:root:2019-05-11 01:51:40, Epoch : 1, Step : 4338, Training Loss : 0.52871, Training Acc : 0.711, Run Time : 0.38
INFO:root:2019-05-11 01:51:51, Epoch : 1, Step : 4339, Training Loss : 0.52161, Training Acc : 0.767, Run Time : 10.96
INFO:root:2019-05-11 01:51:52, Epoch : 1, Step : 4340, Training Loss : 0.41146, Training Acc : 0.806, Run Time : 0.79
INFO:root:2019-05-11 01:51:54, Epoch : 1, Step : 4341, Training Loss : 0.38200, Training Acc : 0.861, Run Time : 1.79
INFO:root:2019-05-11 01:52:06, Epoch : 1, Step : 4342, Training Loss : 0.43734, Training Acc : 0.783, Run Time : 11.76
INFO:root:2019-05-11 01:52:06, Epoch : 1, Step : 4343, Training Loss : 0.39329, Training Acc : 0.856, Run Time : 0.42
INFO:root:2019-05-11 01:52:06, Epoch : 1, Step : 4344, Training Loss : 0.39853, Training Acc : 0.850, Run Time : 0.42
INFO:root:2019-05-11 01:52:07, Epoch : 1, Step : 4345, Training Loss : 0.39182, Training Acc : 0.828, Run Time : 0.98
INFO:root:2019-05-11 01:52:18, Epoch : 1, Step : 4346, Training Loss : 0.53125, Training Acc : 0.739, Run Time : 10.24
INFO:root:2019-05-11 01:52:19, Epoch : 1, Step : 4347, Training Loss : 0.55494, Training Acc : 0.728, Run Time : 1.58
INFO:root:2019-05-11 01:52:30, Epoch : 1, Step : 4348, Training Loss : 0.52769, Training Acc : 0.750, Run Time : 10.48
INFO:root:2019-05-11 01:52:33, Epoch : 1, Step : 4349, Training Loss : 0.63473, Training Acc : 0.644, Run Time : 3.35
INFO:root:2019-05-11 01:52:33, Epoch : 1, Step : 4350, Training Loss : 0.48931, Training Acc : 0.717, Run Time : 0.38
INFO:root:2019-05-11 01:52:34, Epoch : 1, Step : 4351, Training Loss : 0.45018, Training Acc : 0.756, Run Time : 0.38
INFO:root:2019-05-11 01:52:42, Epoch : 1, Step : 4352, Training Loss : 0.43521, Training Acc : 0.828, Run Time : 7.71
INFO:root:2019-05-11 01:52:43, Epoch : 1, Step : 4353, Training Loss : 0.38253, Training Acc : 0.828, Run Time : 1.50
INFO:root:2019-05-11 01:52:43, Epoch : 1, Step : 4354, Training Loss : 0.35991, Training Acc : 0.850, Run Time : 0.39
INFO:root:2019-05-11 01:52:44, Epoch : 1, Step : 4355, Training Loss : 0.38500, Training Acc : 0.833, Run Time : 0.52
INFO:root:2019-05-11 01:52:44, Epoch : 1, Step : 4356, Training Loss : 0.33395, Training Acc : 0.872, Run Time : 0.39
INFO:root:2019-05-11 01:52:45, Epoch : 1, Step : 4357, Training Loss : 0.44945, Training Acc : 0.822, Run Time : 0.70
INFO:root:2019-05-11 01:52:57, Epoch : 1, Step : 4358, Training Loss : 0.49670, Training Acc : 0.800, Run Time : 12.34
INFO:root:2019-05-11 01:53:11, Epoch : 1, Step : 4359, Training Loss : 0.46043, Training Acc : 0.794, Run Time : 13.27
INFO:root:2019-05-11 01:53:13, Epoch : 1, Step : 4360, Training Loss : 0.45981, Training Acc : 0.800, Run Time : 2.79
INFO:root:2019-05-11 01:53:14, Epoch : 1, Step : 4361, Training Loss : 0.48366, Training Acc : 0.772, Run Time : 0.68
INFO:root:2019-05-11 01:53:23, Epoch : 1, Step : 4362, Training Loss : 0.36355, Training Acc : 0.856, Run Time : 8.69
INFO:root:2019-05-11 01:53:24, Epoch : 1, Step : 4363, Training Loss : 0.31284, Training Acc : 0.894, Run Time : 1.13
INFO:root:2019-05-11 01:53:24, Epoch : 1, Step : 4364, Training Loss : 0.42297, Training Acc : 0.778, Run Time : 0.58
INFO:root:2019-05-11 01:53:26, Epoch : 1, Step : 4365, Training Loss : 0.42350, Training Acc : 0.811, Run Time : 1.12
INFO:root:2019-05-11 01:53:26, Epoch : 1, Step : 4366, Training Loss : 0.31302, Training Acc : 0.856, Run Time : 0.38
INFO:root:2019-05-11 01:53:27, Epoch : 1, Step : 4367, Training Loss : 0.30384, Training Acc : 0.856, Run Time : 0.83
INFO:root:2019-05-11 01:53:36, Epoch : 1, Step : 4368, Training Loss : 0.26259, Training Acc : 0.917, Run Time : 9.66
INFO:root:2019-05-11 01:53:39, Epoch : 1, Step : 4369, Training Loss : 0.26636, Training Acc : 0.878, Run Time : 2.11
INFO:root:2019-05-11 01:53:43, Epoch : 1, Step : 4370, Training Loss : 0.23947, Training Acc : 0.917, Run Time : 4.57
INFO:root:2019-05-11 01:53:44, Epoch : 1, Step : 4371, Training Loss : 0.26788, Training Acc : 0.900, Run Time : 0.45
INFO:root:2019-05-11 01:53:44, Epoch : 1, Step : 4372, Training Loss : 0.21199, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 01:53:45, Epoch : 1, Step : 4373, Training Loss : 0.24341, Training Acc : 0.911, Run Time : 0.97
INFO:root:2019-05-11 01:53:55, Epoch : 1, Step : 4374, Training Loss : 0.23696, Training Acc : 0.894, Run Time : 10.47
INFO:root:2019-05-11 01:53:57, Epoch : 1, Step : 4375, Training Loss : 0.28971, Training Acc : 0.861, Run Time : 1.45
INFO:root:2019-05-11 01:53:57, Epoch : 1, Step : 4376, Training Loss : 0.30969, Training Acc : 0.844, Run Time : 0.41
INFO:root:2019-05-11 01:53:58, Epoch : 1, Step : 4377, Training Loss : 0.28405, Training Acc : 0.844, Run Time : 0.38
INFO:root:2019-05-11 01:53:58, Epoch : 1, Step : 4378, Training Loss : 0.28518, Training Acc : 0.850, Run Time : 0.82
INFO:root:2019-05-11 01:54:09, Epoch : 1, Step : 4379, Training Loss : 0.26613, Training Acc : 0.894, Run Time : 10.29
INFO:root:2019-05-11 01:54:09, Epoch : 1, Step : 4380, Training Loss : 0.28698, Training Acc : 0.861, Run Time : 0.73
INFO:root:2019-05-11 01:54:10, Epoch : 1, Step : 4381, Training Loss : 0.26755, Training Acc : 0.856, Run Time : 0.52
INFO:root:2019-05-11 01:54:11, Epoch : 1, Step : 4382, Training Loss : 0.26031, Training Acc : 0.900, Run Time : 1.41
INFO:root:2019-05-11 01:54:22, Epoch : 1, Step : 4383, Training Loss : 0.25389, Training Acc : 0.889, Run Time : 11.05
INFO:root:2019-05-11 01:54:23, Epoch : 1, Step : 4384, Training Loss : 0.35239, Training Acc : 0.828, Run Time : 0.41
INFO:root:2019-05-11 01:54:23, Epoch : 1, Step : 4385, Training Loss : 0.37594, Training Acc : 0.817, Run Time : 0.43
INFO:root:2019-05-11 01:54:24, Epoch : 1, Step : 4386, Training Loss : 0.36991, Training Acc : 0.811, Run Time : 0.44
INFO:root:2019-05-11 01:54:24, Epoch : 1, Step : 4387, Training Loss : 0.34842, Training Acc : 0.817, Run Time : 0.37
INFO:root:2019-05-11 01:54:25, Epoch : 1, Step : 4388, Training Loss : 0.41454, Training Acc : 0.733, Run Time : 0.57
INFO:root:2019-05-11 01:54:33, Epoch : 1, Step : 4389, Training Loss : 0.29833, Training Acc : 0.839, Run Time : 8.09
INFO:root:2019-05-11 01:54:37, Epoch : 1, Step : 4390, Training Loss : 0.36469, Training Acc : 0.800, Run Time : 4.04
INFO:root:2019-05-11 01:54:37, Epoch : 1, Step : 4391, Training Loss : 0.42740, Training Acc : 0.761, Run Time : 0.57
INFO:root:2019-05-11 01:54:38, Epoch : 1, Step : 4392, Training Loss : 0.45526, Training Acc : 0.789, Run Time : 0.38
INFO:root:2019-05-11 01:54:38, Epoch : 1, Step : 4393, Training Loss : 0.42440, Training Acc : 0.761, Run Time : 0.38
INFO:root:2019-05-11 01:54:49, Epoch : 1, Step : 4394, Training Loss : 0.35166, Training Acc : 0.800, Run Time : 10.50
INFO:root:2019-05-11 01:54:49, Epoch : 1, Step : 4395, Training Loss : 0.33760, Training Acc : 0.822, Run Time : 0.54
INFO:root:2019-05-11 01:54:50, Epoch : 1, Step : 4396, Training Loss : 0.27502, Training Acc : 0.867, Run Time : 0.70
INFO:root:2019-05-11 01:55:00, Epoch : 1, Step : 4397, Training Loss : 0.25524, Training Acc : 0.878, Run Time : 10.62
INFO:root:2019-05-11 01:55:01, Epoch : 1, Step : 4398, Training Loss : 0.19482, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 01:55:01, Epoch : 1, Step : 4399, Training Loss : 0.27703, Training Acc : 0.844, Run Time : 0.38
INFO:root:2019-05-11 01:55:02, Epoch : 1, Step : 4400, Training Loss : 0.20409, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-11 01:55:14, Epoch : 1, Step : 4401, Training Loss : 0.33355, Training Acc : 0.794, Run Time : 12.33
INFO:root:2019-05-11 01:55:14, Epoch : 1, Step : 4402, Training Loss : 0.31525, Training Acc : 0.839, Run Time : 0.40
INFO:root:2019-05-11 01:55:15, Epoch : 1, Step : 4403, Training Loss : 0.29095, Training Acc : 0.833, Run Time : 0.89
INFO:root:2019-05-11 01:55:27, Epoch : 1, Step : 4404, Training Loss : 0.33490, Training Acc : 0.839, Run Time : 11.94
INFO:root:2019-05-11 01:55:28, Epoch : 1, Step : 4405, Training Loss : 0.29371, Training Acc : 0.817, Run Time : 0.84
INFO:root:2019-05-11 01:55:29, Epoch : 1, Step : 4406, Training Loss : 0.34719, Training Acc : 0.833, Run Time : 0.91
INFO:root:2019-05-11 01:55:29, Epoch : 1, Step : 4407, Training Loss : 0.25789, Training Acc : 0.894, Run Time : 0.42
INFO:root:2019-05-11 01:55:30, Epoch : 1, Step : 4408, Training Loss : 0.22813, Training Acc : 0.894, Run Time : 0.39
INFO:root:2019-05-11 01:55:30, Epoch : 1, Step : 4409, Training Loss : 0.21513, Training Acc : 0.911, Run Time : 0.39
INFO:root:2019-05-11 01:55:38, Epoch : 1, Step : 4410, Training Loss : 0.28731, Training Acc : 0.839, Run Time : 7.86
INFO:root:2019-05-11 01:55:38, Epoch : 1, Step : 4411, Training Loss : 0.31422, Training Acc : 0.822, Run Time : 0.41
INFO:root:2019-05-11 01:55:39, Epoch : 1, Step : 4412, Training Loss : 0.31618, Training Acc : 0.806, Run Time : 0.38
INFO:root:2019-05-11 01:55:39, Epoch : 1, Step : 4413, Training Loss : 0.32830, Training Acc : 0.800, Run Time : 0.38
INFO:root:2019-05-11 01:55:40, Epoch : 1, Step : 4414, Training Loss : 0.32618, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-11 01:55:49, Epoch : 1, Step : 4415, Training Loss : 0.30392, Training Acc : 0.817, Run Time : 9.52
INFO:root:2019-05-11 01:55:50, Epoch : 1, Step : 4416, Training Loss : 0.30754, Training Acc : 0.850, Run Time : 0.63
INFO:root:2019-05-11 01:55:50, Epoch : 1, Step : 4417, Training Loss : 0.32902, Training Acc : 0.833, Run Time : 0.44
INFO:root:2019-05-11 01:55:59, Epoch : 1, Step : 4418, Training Loss : 0.26465, Training Acc : 0.894, Run Time : 9.13
INFO:root:2019-05-11 01:56:02, Epoch : 1, Step : 4419, Training Loss : 0.25297, Training Acc : 0.900, Run Time : 3.02
INFO:root:2019-05-11 01:56:03, Epoch : 1, Step : 4420, Training Loss : 0.24851, Training Acc : 0.883, Run Time : 0.60
INFO:root:2019-05-11 01:56:03, Epoch : 1, Step : 4421, Training Loss : 0.25407, Training Acc : 0.889, Run Time : 0.37
INFO:root:2019-05-11 01:56:14, Epoch : 1, Step : 4422, Training Loss : 0.23914, Training Acc : 0.867, Run Time : 10.78
INFO:root:2019-05-11 01:56:15, Epoch : 1, Step : 4423, Training Loss : 0.24895, Training Acc : 0.878, Run Time : 0.45
INFO:root:2019-05-11 01:56:15, Epoch : 1, Step : 4424, Training Loss : 0.28207, Training Acc : 0.867, Run Time : 0.64
INFO:root:2019-05-11 01:56:16, Epoch : 1, Step : 4425, Training Loss : 0.28002, Training Acc : 0.872, Run Time : 0.49
INFO:root:2019-05-11 01:56:16, Epoch : 1, Step : 4426, Training Loss : 0.15449, Training Acc : 0.950, Run Time : 0.39
INFO:root:2019-05-11 01:56:17, Epoch : 1, Step : 4427, Training Loss : 0.17689, Training Acc : 0.944, Run Time : 0.40
INFO:root:2019-05-11 01:56:17, Epoch : 1, Step : 4428, Training Loss : 0.20421, Training Acc : 0.872, Run Time : 0.69
INFO:root:2019-05-11 01:56:18, Epoch : 1, Step : 4429, Training Loss : 0.16816, Training Acc : 0.933, Run Time : 1.21
INFO:root:2019-05-11 01:56:25, Epoch : 1, Step : 4430, Training Loss : 0.16715, Training Acc : 0.944, Run Time : 6.89
INFO:root:2019-05-11 01:56:26, Epoch : 1, Step : 4431, Training Loss : 0.12353, Training Acc : 0.972, Run Time : 0.41
INFO:root:2019-05-11 01:56:37, Epoch : 1, Step : 4432, Training Loss : 0.13746, Training Acc : 0.967, Run Time : 11.68
INFO:root:2019-05-11 01:56:38, Epoch : 1, Step : 4433, Training Loss : 0.15258, Training Acc : 0.950, Run Time : 0.75
INFO:root:2019-05-11 01:56:39, Epoch : 1, Step : 4434, Training Loss : 0.17204, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 01:56:40, Epoch : 1, Step : 4435, Training Loss : 0.13896, Training Acc : 0.933, Run Time : 1.27
INFO:root:2019-05-11 01:56:51, Epoch : 1, Step : 4436, Training Loss : 0.18280, Training Acc : 0.900, Run Time : 11.32
INFO:root:2019-05-11 01:56:52, Epoch : 1, Step : 4437, Training Loss : 0.16259, Training Acc : 0.939, Run Time : 0.54
INFO:root:2019-05-11 01:56:52, Epoch : 1, Step : 4438, Training Loss : 0.19875, Training Acc : 0.900, Run Time : 0.40
INFO:root:2019-05-11 01:57:03, Epoch : 1, Step : 4439, Training Loss : 0.19815, Training Acc : 0.917, Run Time : 10.91
INFO:root:2019-05-11 01:57:04, Epoch : 1, Step : 4440, Training Loss : 0.22790, Training Acc : 0.917, Run Time : 0.73
INFO:root:2019-05-11 01:57:04, Epoch : 1, Step : 4441, Training Loss : 0.23243, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-11 01:57:05, Epoch : 1, Step : 4442, Training Loss : 0.24362, Training Acc : 0.856, Run Time : 0.73
INFO:root:2019-05-11 01:57:05, Epoch : 1, Step : 4443, Training Loss : 0.24448, Training Acc : 0.856, Run Time : 0.52
INFO:root:2019-05-11 01:57:06, Epoch : 1, Step : 4444, Training Loss : 0.23245, Training Acc : 0.889, Run Time : 1.09
INFO:root:2019-05-11 01:57:07, Epoch : 1, Step : 4445, Training Loss : 0.15291, Training Acc : 0.928, Run Time : 0.76
INFO:root:2019-05-11 01:57:19, Epoch : 1, Step : 4446, Training Loss : 0.17759, Training Acc : 0.939, Run Time : 11.81
INFO:root:2019-05-11 01:57:20, Epoch : 1, Step : 4447, Training Loss : 0.14437, Training Acc : 0.933, Run Time : 0.76
INFO:root:2019-05-11 01:57:20, Epoch : 1, Step : 4448, Training Loss : 0.23864, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 01:57:29, Epoch : 1, Step : 4449, Training Loss : 0.29228, Training Acc : 0.872, Run Time : 9.07
INFO:root:2019-05-11 01:57:30, Epoch : 1, Step : 4450, Training Loss : 0.23696, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-11 01:57:30, Epoch : 1, Step : 4451, Training Loss : 0.26692, Training Acc : 0.861, Run Time : 0.39
INFO:root:2019-05-11 01:57:32, Epoch : 1, Step : 4452, Training Loss : 0.25277, Training Acc : 0.861, Run Time : 1.90
INFO:root:2019-05-11 01:57:44, Epoch : 1, Step : 4453, Training Loss : 0.26690, Training Acc : 0.856, Run Time : 12.12
INFO:root:2019-05-11 01:57:44, Epoch : 1, Step : 4454, Training Loss : 0.31963, Training Acc : 0.850, Run Time : 0.42
INFO:root:2019-05-11 01:57:45, Epoch : 1, Step : 4455, Training Loss : 0.29508, Training Acc : 0.878, Run Time : 0.43
INFO:root:2019-05-11 01:57:46, Epoch : 1, Step : 4456, Training Loss : 0.19226, Training Acc : 0.906, Run Time : 1.38
INFO:root:2019-05-11 01:57:56, Epoch : 1, Step : 4457, Training Loss : 0.20032, Training Acc : 0.928, Run Time : 9.83
INFO:root:2019-05-11 01:57:58, Epoch : 1, Step : 4458, Training Loss : 0.20270, Training Acc : 0.917, Run Time : 1.72
INFO:root:2019-05-11 01:58:09, Epoch : 1, Step : 4459, Training Loss : 0.21773, Training Acc : 0.906, Run Time : 10.80
INFO:root:2019-05-11 01:58:09, Epoch : 1, Step : 4460, Training Loss : 0.22427, Training Acc : 0.906, Run Time : 0.64
INFO:root:2019-05-11 01:58:10, Epoch : 1, Step : 4461, Training Loss : 0.25185, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-11 01:58:10, Epoch : 1, Step : 4462, Training Loss : 0.23279, Training Acc : 0.906, Run Time : 0.37
INFO:root:2019-05-11 01:58:12, Epoch : 1, Step : 4463, Training Loss : 0.20156, Training Acc : 0.911, Run Time : 1.99
INFO:root:2019-05-11 01:58:25, Epoch : 1, Step : 4464, Training Loss : 0.41357, Training Acc : 0.806, Run Time : 12.58
INFO:root:2019-05-11 01:58:25, Epoch : 1, Step : 4465, Training Loss : 0.31027, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-11 01:58:25, Epoch : 1, Step : 4466, Training Loss : 0.23538, Training Acc : 0.906, Run Time : 0.39
INFO:root:2019-05-11 01:58:26, Epoch : 1, Step : 4467, Training Loss : 0.22091, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-11 01:58:26, Epoch : 1, Step : 4468, Training Loss : 0.43664, Training Acc : 0.800, Run Time : 0.39
INFO:root:2019-05-11 01:58:27, Epoch : 1, Step : 4469, Training Loss : 0.14705, Training Acc : 0.961, Run Time : 0.78
INFO:root:2019-05-11 01:58:37, Epoch : 1, Step : 4470, Training Loss : 0.21887, Training Acc : 0.900, Run Time : 10.43
INFO:root:2019-05-11 01:58:38, Epoch : 1, Step : 4471, Training Loss : 0.18325, Training Acc : 0.894, Run Time : 0.86
INFO:root:2019-05-11 01:58:39, Epoch : 1, Step : 4472, Training Loss : 0.22489, Training Acc : 0.911, Run Time : 0.58
INFO:root:2019-05-11 01:58:39, Epoch : 1, Step : 4473, Training Loss : 0.42150, Training Acc : 0.817, Run Time : 0.38
INFO:root:2019-05-11 01:58:40, Epoch : 1, Step : 4474, Training Loss : 0.22211, Training Acc : 0.906, Run Time : 0.76
INFO:root:2019-05-11 01:58:50, Epoch : 1, Step : 4475, Training Loss : 0.24813, Training Acc : 0.917, Run Time : 9.87
INFO:root:2019-05-11 01:58:52, Epoch : 1, Step : 4476, Training Loss : 0.35648, Training Acc : 0.861, Run Time : 2.33
INFO:root:2019-05-11 01:58:53, Epoch : 1, Step : 4477, Training Loss : 0.27529, Training Acc : 0.889, Run Time : 0.42
INFO:root:2019-05-11 01:58:53, Epoch : 1, Step : 4478, Training Loss : 0.13114, Training Acc : 0.972, Run Time : 0.39
INFO:root:2019-05-11 01:58:54, Epoch : 1, Step : 4479, Training Loss : 0.12697, Training Acc : 0.961, Run Time : 1.02
INFO:root:2019-05-11 01:59:06, Epoch : 1, Step : 4480, Training Loss : 0.23802, Training Acc : 0.889, Run Time : 11.67
INFO:root:2019-05-11 01:59:06, Epoch : 1, Step : 4481, Training Loss : 0.13354, Training Acc : 0.967, Run Time : 0.47
INFO:root:2019-05-11 01:59:06, Epoch : 1, Step : 4482, Training Loss : 0.16942, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-11 01:59:07, Epoch : 1, Step : 4483, Training Loss : 0.18859, Training Acc : 0.928, Run Time : 0.53
INFO:root:2019-05-11 01:59:08, Epoch : 1, Step : 4484, Training Loss : 0.16231, Training Acc : 0.944, Run Time : 0.97
INFO:root:2019-05-11 01:59:17, Epoch : 1, Step : 4485, Training Loss : 0.31403, Training Acc : 0.867, Run Time : 9.20
INFO:root:2019-05-11 01:59:18, Epoch : 1, Step : 4486, Training Loss : 0.26031, Training Acc : 0.894, Run Time : 0.64
INFO:root:2019-05-11 01:59:18, Epoch : 1, Step : 4487, Training Loss : 0.18219, Training Acc : 0.933, Run Time : 0.54
INFO:root:2019-05-11 01:59:21, Epoch : 1, Step : 4488, Training Loss : 0.25382, Training Acc : 0.883, Run Time : 2.56
INFO:root:2019-05-11 01:59:30, Epoch : 1, Step : 4489, Training Loss : 0.17509, Training Acc : 0.928, Run Time : 8.95
INFO:root:2019-05-11 01:59:31, Epoch : 1, Step : 4490, Training Loss : 0.35515, Training Acc : 0.850, Run Time : 0.86
INFO:root:2019-05-11 01:59:31, Epoch : 1, Step : 4491, Training Loss : 0.34466, Training Acc : 0.828, Run Time : 0.41
INFO:root:2019-05-11 01:59:33, Epoch : 1, Step : 4492, Training Loss : 0.27508, Training Acc : 0.856, Run Time : 1.55
INFO:root:2019-05-11 01:59:42, Epoch : 1, Step : 4493, Training Loss : 0.33496, Training Acc : 0.828, Run Time : 9.27
INFO:root:2019-05-11 01:59:42, Epoch : 1, Step : 4494, Training Loss : 0.20139, Training Acc : 0.900, Run Time : 0.41
INFO:root:2019-05-11 01:59:43, Epoch : 1, Step : 4495, Training Loss : 0.24282, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-11 01:59:44, Epoch : 1, Step : 4496, Training Loss : 0.20940, Training Acc : 0.889, Run Time : 1.13
INFO:root:2019-05-11 01:59:55, Epoch : 1, Step : 4497, Training Loss : 0.27212, Training Acc : 0.894, Run Time : 11.05
INFO:root:2019-05-11 01:59:55, Epoch : 1, Step : 4498, Training Loss : 0.25632, Training Acc : 0.894, Run Time : 0.49
INFO:root:2019-05-11 01:59:56, Epoch : 1, Step : 4499, Training Loss : 0.22643, Training Acc : 0.906, Run Time : 0.40
INFO:root:2019-05-11 01:59:58, Epoch : 1, Step : 4500, Training Loss : 0.23620, Training Acc : 0.911, Run Time : 1.77
INFO:root:2019-05-11 02:00:08, Epoch : 1, Step : 4501, Training Loss : 0.16017, Training Acc : 0.950, Run Time : 10.09
INFO:root:2019-05-11 02:00:08, Epoch : 1, Step : 4502, Training Loss : 0.23451, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-11 02:00:09, Epoch : 1, Step : 4503, Training Loss : 0.19251, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 02:00:10, Epoch : 1, Step : 4504, Training Loss : 0.25091, Training Acc : 0.894, Run Time : 1.40
INFO:root:2019-05-11 02:00:21, Epoch : 1, Step : 4505, Training Loss : 0.23047, Training Acc : 0.917, Run Time : 11.33
INFO:root:2019-05-11 02:00:23, Epoch : 1, Step : 4506, Training Loss : 0.22982, Training Acc : 0.894, Run Time : 1.71
INFO:root:2019-05-11 02:00:34, Epoch : 1, Step : 4507, Training Loss : 0.30846, Training Acc : 0.839, Run Time : 10.80
INFO:root:2019-05-11 02:00:34, Epoch : 1, Step : 4508, Training Loss : 0.35209, Training Acc : 0.844, Run Time : 0.60
INFO:root:2019-05-11 02:00:35, Epoch : 1, Step : 4509, Training Loss : 0.27215, Training Acc : 0.894, Run Time : 0.37
INFO:root:2019-05-11 02:00:36, Epoch : 1, Step : 4510, Training Loss : 0.21181, Training Acc : 0.906, Run Time : 1.02
INFO:root:2019-05-11 02:00:46, Epoch : 1, Step : 4511, Training Loss : 0.20521, Training Acc : 0.917, Run Time : 9.92
INFO:root:2019-05-11 02:00:47, Epoch : 1, Step : 4512, Training Loss : 0.21537, Training Acc : 0.917, Run Time : 1.37
INFO:root:2019-05-11 02:00:51, Epoch : 1, Step : 4513, Training Loss : 0.24379, Training Acc : 0.878, Run Time : 3.83
INFO:root:2019-05-11 02:01:04, Epoch : 1, Step : 4514, Training Loss : 0.18475, Training Acc : 0.944, Run Time : 13.26
INFO:root:2019-05-11 02:01:05, Epoch : 1, Step : 4515, Training Loss : 0.14740, Training Acc : 0.956, Run Time : 1.02
INFO:root:2019-05-11 02:01:06, Epoch : 1, Step : 4516, Training Loss : 0.16976, Training Acc : 0.956, Run Time : 0.37
INFO:root:2019-05-11 02:01:07, Epoch : 1, Step : 4517, Training Loss : 0.16745, Training Acc : 0.956, Run Time : 0.98
INFO:root:2019-05-11 02:01:08, Epoch : 1, Step : 4518, Training Loss : 0.18824, Training Acc : 0.933, Run Time : 1.51
INFO:root:2019-05-11 02:01:08, Epoch : 1, Step : 4519, Training Loss : 0.17052, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 02:01:09, Epoch : 1, Step : 4520, Training Loss : 0.20944, Training Acc : 0.928, Run Time : 0.56
INFO:root:2019-05-11 02:01:16, Epoch : 1, Step : 4521, Training Loss : 0.18347, Training Acc : 0.922, Run Time : 7.01
INFO:root:2019-05-11 02:01:20, Epoch : 1, Step : 4522, Training Loss : 0.17719, Training Acc : 0.933, Run Time : 4.11
INFO:root:2019-05-11 02:01:22, Epoch : 1, Step : 4523, Training Loss : 0.20632, Training Acc : 0.922, Run Time : 1.60
INFO:root:2019-05-11 02:01:22, Epoch : 1, Step : 4524, Training Loss : 0.25454, Training Acc : 0.889, Run Time : 0.60
INFO:root:2019-05-11 02:01:23, Epoch : 1, Step : 4525, Training Loss : 0.20574, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 02:01:32, Epoch : 1, Step : 4526, Training Loss : 0.15873, Training Acc : 0.956, Run Time : 9.12
INFO:root:2019-05-11 02:01:32, Epoch : 1, Step : 4527, Training Loss : 0.16259, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-11 02:01:33, Epoch : 1, Step : 4528, Training Loss : 0.27910, Training Acc : 0.894, Run Time : 0.72
INFO:root:2019-05-11 02:01:36, Epoch : 1, Step : 4529, Training Loss : 0.30968, Training Acc : 0.867, Run Time : 3.16
INFO:root:2019-05-11 02:01:36, Epoch : 1, Step : 4530, Training Loss : 0.20822, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-11 02:01:37, Epoch : 1, Step : 4531, Training Loss : 0.32208, Training Acc : 0.850, Run Time : 0.37
INFO:root:2019-05-11 02:01:37, Epoch : 1, Step : 4532, Training Loss : 0.18617, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 02:01:38, Epoch : 1, Step : 4533, Training Loss : 0.16319, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 02:01:38, Epoch : 1, Step : 4534, Training Loss : 0.19980, Training Acc : 0.939, Run Time : 0.87
INFO:root:2019-05-11 02:01:39, Epoch : 1, Step : 4535, Training Loss : 0.19341, Training Acc : 0.906, Run Time : 0.53
INFO:root:2019-05-11 02:01:39, Epoch : 1, Step : 4536, Training Loss : 0.27414, Training Acc : 0.872, Run Time : 0.38
INFO:root:2019-05-11 02:01:40, Epoch : 1, Step : 4537, Training Loss : 0.29390, Training Acc : 0.861, Run Time : 0.82
INFO:root:2019-05-11 02:01:50, Epoch : 1, Step : 4538, Training Loss : 0.24902, Training Acc : 0.872, Run Time : 9.87
INFO:root:2019-05-11 02:01:51, Epoch : 1, Step : 4539, Training Loss : 0.35672, Training Acc : 0.844, Run Time : 0.54
INFO:root:2019-05-11 02:01:52, Epoch : 1, Step : 4540, Training Loss : 0.32434, Training Acc : 0.856, Run Time : 1.60
INFO:root:2019-05-11 02:02:03, Epoch : 1, Step : 4541, Training Loss : 0.47093, Training Acc : 0.794, Run Time : 10.79
INFO:root:2019-05-11 02:02:03, Epoch : 1, Step : 4542, Training Loss : 0.22496, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-11 02:02:04, Epoch : 1, Step : 4543, Training Loss : 0.28173, Training Acc : 0.889, Run Time : 0.55
INFO:root:2019-05-11 02:02:06, Epoch : 1, Step : 4544, Training Loss : 0.35376, Training Acc : 0.833, Run Time : 1.96
INFO:root:2019-05-11 02:02:15, Epoch : 1, Step : 4545, Training Loss : 0.39752, Training Acc : 0.806, Run Time : 9.13
INFO:root:2019-05-11 02:02:15, Epoch : 1, Step : 4546, Training Loss : 0.43243, Training Acc : 0.806, Run Time : 0.41
INFO:root:2019-05-11 02:02:16, Epoch : 1, Step : 4547, Training Loss : 0.25456, Training Acc : 0.883, Run Time : 0.52
INFO:root:2019-05-11 02:02:17, Epoch : 1, Step : 4548, Training Loss : 0.26511, Training Acc : 0.878, Run Time : 1.03
INFO:root:2019-05-11 02:02:28, Epoch : 1, Step : 4549, Training Loss : 0.28363, Training Acc : 0.906, Run Time : 11.46
INFO:root:2019-05-11 02:02:29, Epoch : 1, Step : 4550, Training Loss : 0.26640, Training Acc : 0.911, Run Time : 0.67
INFO:root:2019-05-11 02:02:30, Epoch : 1, Step : 4551, Training Loss : 0.28681, Training Acc : 0.878, Run Time : 0.91
INFO:root:2019-05-11 02:02:31, Epoch : 1, Step : 4552, Training Loss : 0.20820, Training Acc : 0.906, Run Time : 1.30
INFO:root:2019-05-11 02:02:41, Epoch : 1, Step : 4553, Training Loss : 0.31728, Training Acc : 0.828, Run Time : 9.98
INFO:root:2019-05-11 02:02:42, Epoch : 1, Step : 4554, Training Loss : 0.40108, Training Acc : 0.789, Run Time : 0.40
INFO:root:2019-05-11 02:02:42, Epoch : 1, Step : 4555, Training Loss : 0.36295, Training Acc : 0.856, Run Time : 0.44
INFO:root:2019-05-11 02:02:44, Epoch : 1, Step : 4556, Training Loss : 0.35676, Training Acc : 0.856, Run Time : 1.65
INFO:root:2019-05-11 02:02:53, Epoch : 1, Step : 4557, Training Loss : 0.27967, Training Acc : 0.894, Run Time : 8.77
INFO:root:2019-05-11 02:02:54, Epoch : 1, Step : 4558, Training Loss : 0.36577, Training Acc : 0.850, Run Time : 1.00
INFO:root:2019-05-11 02:03:03, Epoch : 1, Step : 4559, Training Loss : 0.18443, Training Acc : 0.922, Run Time : 9.68
INFO:root:2019-05-11 02:03:04, Epoch : 1, Step : 4560, Training Loss : 0.29467, Training Acc : 0.856, Run Time : 0.87
INFO:root:2019-05-11 02:03:06, Epoch : 1, Step : 4561, Training Loss : 0.26832, Training Acc : 0.883, Run Time : 2.15
INFO:root:2019-05-11 02:03:17, Epoch : 1, Step : 4562, Training Loss : 0.32702, Training Acc : 0.861, Run Time : 10.95
INFO:root:2019-05-11 02:03:18, Epoch : 1, Step : 4563, Training Loss : 0.29589, Training Acc : 0.883, Run Time : 0.87
INFO:root:2019-05-11 02:03:19, Epoch : 1, Step : 4564, Training Loss : 0.31219, Training Acc : 0.861, Run Time : 0.76
INFO:root:2019-05-11 02:03:32, Epoch : 1, Step : 4565, Training Loss : 0.18571, Training Acc : 0.944, Run Time : 13.58
INFO:root:2019-05-11 02:03:33, Epoch : 1, Step : 4566, Training Loss : 0.20033, Training Acc : 0.933, Run Time : 0.64
INFO:root:2019-05-11 02:03:33, Epoch : 1, Step : 4567, Training Loss : 0.14812, Training Acc : 0.939, Run Time : 0.40
INFO:root:2019-05-11 02:03:36, Epoch : 1, Step : 4568, Training Loss : 0.22470, Training Acc : 0.906, Run Time : 2.20
INFO:root:2019-05-11 02:03:46, Epoch : 1, Step : 4569, Training Loss : 0.18574, Training Acc : 0.944, Run Time : 10.33
INFO:root:2019-05-11 02:03:46, Epoch : 1, Step : 4570, Training Loss : 0.11064, Training Acc : 0.983, Run Time : 0.41
INFO:root:2019-05-11 02:03:47, Epoch : 1, Step : 4571, Training Loss : 0.16082, Training Acc : 0.928, Run Time : 0.80
INFO:root:2019-05-11 02:03:58, Epoch : 1, Step : 4572, Training Loss : 0.12208, Training Acc : 0.939, Run Time : 10.97
INFO:root:2019-05-11 02:03:59, Epoch : 1, Step : 4573, Training Loss : 0.12228, Training Acc : 0.972, Run Time : 0.41
INFO:root:2019-05-11 02:03:59, Epoch : 1, Step : 4574, Training Loss : 0.12884, Training Acc : 0.950, Run Time : 0.43
INFO:root:2019-05-11 02:04:01, Epoch : 1, Step : 4575, Training Loss : 0.11029, Training Acc : 0.967, Run Time : 1.67
INFO:root:2019-05-11 02:04:11, Epoch : 1, Step : 4576, Training Loss : 0.22852, Training Acc : 0.900, Run Time : 10.73
INFO:root:2019-05-11 02:04:12, Epoch : 1, Step : 4577, Training Loss : 0.16901, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-11 02:04:12, Epoch : 1, Step : 4578, Training Loss : 0.15211, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 02:04:13, Epoch : 1, Step : 4579, Training Loss : 0.10700, Training Acc : 0.961, Run Time : 1.23
INFO:root:2019-05-11 02:04:26, Epoch : 1, Step : 4580, Training Loss : 0.18994, Training Acc : 0.922, Run Time : 12.27
INFO:root:2019-05-11 02:04:26, Epoch : 1, Step : 4581, Training Loss : 0.17280, Training Acc : 0.928, Run Time : 0.66
INFO:root:2019-05-11 02:04:27, Epoch : 1, Step : 4582, Training Loss : 0.18675, Training Acc : 0.928, Run Time : 0.64
INFO:root:2019-05-11 02:04:39, Epoch : 1, Step : 4583, Training Loss : 0.14742, Training Acc : 0.956, Run Time : 12.28
INFO:root:2019-05-11 02:04:40, Epoch : 1, Step : 4584, Training Loss : 0.13843, Training Acc : 0.961, Run Time : 0.42
INFO:root:2019-05-11 02:04:40, Epoch : 1, Step : 4585, Training Loss : 0.07237, Training Acc : 0.994, Run Time : 0.38
INFO:root:2019-05-11 02:04:52, Epoch : 1, Step : 4586, Training Loss : 0.17796, Training Acc : 0.906, Run Time : 11.64
INFO:root:2019-05-11 02:04:52, Epoch : 1, Step : 4587, Training Loss : 0.13210, Training Acc : 0.939, Run Time : 0.46
INFO:root:2019-05-11 02:04:53, Epoch : 1, Step : 4588, Training Loss : 0.08187, Training Acc : 0.983, Run Time : 0.37
INFO:root:2019-05-11 02:04:55, Epoch : 1, Step : 4589, Training Loss : 0.11377, Training Acc : 0.956, Run Time : 2.13
INFO:root:2019-05-11 02:05:04, Epoch : 1, Step : 4590, Training Loss : 0.18073, Training Acc : 0.933, Run Time : 9.60
INFO:root:2019-05-11 02:05:05, Epoch : 1, Step : 4591, Training Loss : 0.38320, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-11 02:05:05, Epoch : 1, Step : 4592, Training Loss : 0.19721, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-11 02:05:06, Epoch : 1, Step : 4593, Training Loss : 0.19829, Training Acc : 0.922, Run Time : 0.61
INFO:root:2019-05-11 02:05:09, Epoch : 1, Step : 4594, Training Loss : 0.41720, Training Acc : 0.850, Run Time : 2.85
INFO:root:2019-05-11 02:05:09, Epoch : 1, Step : 4595, Training Loss : 0.30853, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-11 02:05:10, Epoch : 1, Step : 4596, Training Loss : 0.34807, Training Acc : 0.850, Run Time : 0.59
INFO:root:2019-05-11 02:05:10, Epoch : 1, Step : 4597, Training Loss : 0.34730, Training Acc : 0.872, Run Time : 0.41
INFO:root:2019-05-11 02:05:11, Epoch : 1, Step : 4598, Training Loss : 0.32132, Training Acc : 0.878, Run Time : 1.27
INFO:root:2019-05-11 02:05:21, Epoch : 1, Step : 4599, Training Loss : 0.38119, Training Acc : 0.850, Run Time : 9.66
INFO:root:2019-05-11 02:05:21, Epoch : 1, Step : 4600, Training Loss : 0.26971, Training Acc : 0.900, Run Time : 0.40
INFO:root:2019-05-11 02:05:26, Epoch : 1, Step : 4601, Training Loss : 0.25952, Training Acc : 0.900, Run Time : 5.18
INFO:root:2019-05-11 02:05:27, Epoch : 1, Step : 4602, Training Loss : 0.23755, Training Acc : 0.911, Run Time : 0.56
INFO:root:2019-05-11 02:05:27, Epoch : 1, Step : 4603, Training Loss : 0.25790, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-11 02:05:30, Epoch : 1, Step : 4604, Training Loss : 0.56208, Training Acc : 0.800, Run Time : 2.79
INFO:root:2019-05-11 02:05:35, Epoch : 1, Step : 4605, Training Loss : 0.35259, Training Acc : 0.872, Run Time : 4.55
INFO:root:2019-05-11 02:05:40, Epoch : 1, Step : 4606, Training Loss : 0.35673, Training Acc : 0.856, Run Time : 5.28
INFO:root:2019-05-11 02:05:41, Epoch : 1, Step : 4607, Training Loss : 0.34772, Training Acc : 0.861, Run Time : 0.69
INFO:root:2019-05-11 02:05:50, Epoch : 1, Step : 4608, Training Loss : 0.46536, Training Acc : 0.806, Run Time : 9.02
INFO:root:2019-05-11 02:05:51, Epoch : 1, Step : 4609, Training Loss : 0.32220, Training Acc : 0.856, Run Time : 1.64
INFO:root:2019-05-11 02:05:52, Epoch : 1, Step : 4610, Training Loss : 0.27359, Training Acc : 0.867, Run Time : 1.06
INFO:root:2019-05-11 02:06:05, Epoch : 1, Step : 4611, Training Loss : 0.24294, Training Acc : 0.883, Run Time : 12.28
INFO:root:2019-05-11 02:06:06, Epoch : 1, Step : 4612, Training Loss : 0.28790, Training Acc : 0.856, Run Time : 1.04
INFO:root:2019-05-11 02:06:06, Epoch : 1, Step : 4613, Training Loss : 0.18063, Training Acc : 0.922, Run Time : 0.46
INFO:root:2019-05-11 02:06:07, Epoch : 1, Step : 4614, Training Loss : 0.26170, Training Acc : 0.872, Run Time : 0.57
INFO:root:2019-05-11 02:06:22, Epoch : 1, Step : 4615, Training Loss : 0.24854, Training Acc : 0.906, Run Time : 15.43
INFO:root:2019-05-11 02:06:23, Epoch : 1, Step : 4616, Training Loss : 0.29971, Training Acc : 0.861, Run Time : 0.60
INFO:root:2019-05-11 02:06:24, Epoch : 1, Step : 4617, Training Loss : 0.24502, Training Acc : 0.900, Run Time : 1.03
INFO:root:2019-05-11 02:06:35, Epoch : 1, Step : 4618, Training Loss : 0.22942, Training Acc : 0.883, Run Time : 10.87
INFO:root:2019-05-11 02:06:35, Epoch : 1, Step : 4619, Training Loss : 0.22836, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-11 02:06:36, Epoch : 1, Step : 4620, Training Loss : 0.22524, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-11 02:06:37, Epoch : 1, Step : 4621, Training Loss : 0.18449, Training Acc : 0.917, Run Time : 1.32
INFO:root:2019-05-11 02:06:50, Epoch : 1, Step : 4622, Training Loss : 0.19577, Training Acc : 0.911, Run Time : 12.97
INFO:root:2019-05-11 02:06:51, Epoch : 1, Step : 4623, Training Loss : 0.24105, Training Acc : 0.889, Run Time : 1.21
INFO:root:2019-05-11 02:06:52, Epoch : 1, Step : 4624, Training Loss : 0.20203, Training Acc : 0.917, Run Time : 0.60
INFO:root:2019-05-11 02:07:03, Epoch : 1, Step : 4625, Training Loss : 0.21193, Training Acc : 0.906, Run Time : 11.26
INFO:root:2019-05-11 02:07:03, Epoch : 1, Step : 4626, Training Loss : 0.21427, Training Acc : 0.928, Run Time : 0.42
INFO:root:2019-05-11 02:07:04, Epoch : 1, Step : 4627, Training Loss : 0.17489, Training Acc : 0.944, Run Time : 0.54
INFO:root:2019-05-11 02:07:04, Epoch : 1, Step : 4628, Training Loss : 0.23316, Training Acc : 0.889, Run Time : 0.63
INFO:root:2019-05-11 02:07:07, Epoch : 1, Step : 4629, Training Loss : 0.22148, Training Acc : 0.911, Run Time : 2.39
INFO:root:2019-05-11 02:07:07, Epoch : 1, Step : 4630, Training Loss : 0.20632, Training Acc : 0.900, Run Time : 0.37
INFO:root:2019-05-11 02:07:08, Epoch : 1, Step : 4631, Training Loss : 0.21973, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-11 02:07:18, Epoch : 1, Step : 4632, Training Loss : 0.19645, Training Acc : 0.911, Run Time : 10.59
INFO:root:2019-05-11 02:07:19, Epoch : 1, Step : 4633, Training Loss : 0.18398, Training Acc : 0.928, Run Time : 1.09
INFO:root:2019-05-11 02:07:23, Epoch : 1, Step : 4634, Training Loss : 0.19831, Training Acc : 0.906, Run Time : 4.09
INFO:root:2019-05-11 02:07:24, Epoch : 1, Step : 4635, Training Loss : 0.20159, Training Acc : 0.906, Run Time : 0.73
INFO:root:2019-05-11 02:07:24, Epoch : 1, Step : 4636, Training Loss : 0.22059, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-11 02:07:25, Epoch : 1, Step : 4637, Training Loss : 0.31083, Training Acc : 0.878, Run Time : 0.48
INFO:root:2019-05-11 02:07:26, Epoch : 1, Step : 4638, Training Loss : 0.21622, Training Acc : 0.928, Run Time : 0.89
INFO:root:2019-05-11 02:07:37, Epoch : 1, Step : 4639, Training Loss : 0.19794, Training Acc : 0.922, Run Time : 11.11
INFO:root:2019-05-11 02:07:38, Epoch : 1, Step : 4640, Training Loss : 0.17471, Training Acc : 0.933, Run Time : 0.60
INFO:root:2019-05-11 02:07:38, Epoch : 1, Step : 4641, Training Loss : 0.17694, Training Acc : 0.944, Run Time : 0.49
INFO:root:2019-05-11 02:07:38, Epoch : 1, Step : 4642, Training Loss : 0.27713, Training Acc : 0.883, Run Time : 0.39
INFO:root:2019-05-11 02:07:48, Epoch : 1, Step : 4643, Training Loss : 0.16706, Training Acc : 0.950, Run Time : 9.71
INFO:root:2019-05-11 02:07:49, Epoch : 1, Step : 4644, Training Loss : 0.11745, Training Acc : 0.967, Run Time : 0.41
INFO:root:2019-05-11 02:07:49, Epoch : 1, Step : 4645, Training Loss : 0.13208, Training Acc : 0.956, Run Time : 0.64
INFO:root:2019-05-11 02:08:00, Epoch : 1, Step : 4646, Training Loss : 0.18801, Training Acc : 0.933, Run Time : 10.53
INFO:root:2019-05-11 02:08:00, Epoch : 1, Step : 4647, Training Loss : 0.18729, Training Acc : 0.922, Run Time : 0.52
INFO:root:2019-05-11 02:08:01, Epoch : 1, Step : 4648, Training Loss : 0.16655, Training Acc : 0.939, Run Time : 0.99
INFO:root:2019-05-11 02:08:12, Epoch : 1, Step : 4649, Training Loss : 0.17752, Training Acc : 0.928, Run Time : 10.82
INFO:root:2019-05-11 02:08:13, Epoch : 1, Step : 4650, Training Loss : 0.21590, Training Acc : 0.928, Run Time : 0.53
INFO:root:2019-05-11 02:08:13, Epoch : 1, Step : 4651, Training Loss : 0.13352, Training Acc : 0.956, Run Time : 0.37
INFO:root:2019-05-11 02:08:14, Epoch : 1, Step : 4652, Training Loss : 0.14275, Training Acc : 0.950, Run Time : 1.51
INFO:root:2019-05-11 02:08:24, Epoch : 1, Step : 4653, Training Loss : 0.15114, Training Acc : 0.939, Run Time : 9.88
INFO:root:2019-05-11 02:08:25, Epoch : 1, Step : 4654, Training Loss : 0.15868, Training Acc : 0.928, Run Time : 0.47
INFO:root:2019-05-11 02:08:25, Epoch : 1, Step : 4655, Training Loss : 0.20596, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-11 02:08:26, Epoch : 1, Step : 4656, Training Loss : 0.14349, Training Acc : 0.944, Run Time : 0.39
INFO:root:2019-05-11 02:08:27, Epoch : 1, Step : 4657, Training Loss : 0.14916, Training Acc : 0.967, Run Time : 1.40
INFO:root:2019-05-11 02:08:36, Epoch : 1, Step : 4658, Training Loss : 0.22910, Training Acc : 0.911, Run Time : 9.42
INFO:root:2019-05-11 02:08:37, Epoch : 1, Step : 4659, Training Loss : 0.17249, Training Acc : 0.917, Run Time : 0.60
INFO:root:2019-05-11 02:08:37, Epoch : 1, Step : 4660, Training Loss : 0.27621, Training Acc : 0.878, Run Time : 0.39
INFO:root:2019-05-11 02:08:39, Epoch : 1, Step : 4661, Training Loss : 0.37404, Training Acc : 0.850, Run Time : 1.24
INFO:root:2019-05-11 02:08:52, Epoch : 1, Step : 4662, Training Loss : 0.45441, Training Acc : 0.783, Run Time : 13.28
INFO:root:2019-05-11 02:08:52, Epoch : 1, Step : 4663, Training Loss : 0.29033, Training Acc : 0.844, Run Time : 0.45
INFO:root:2019-05-11 02:08:53, Epoch : 1, Step : 4664, Training Loss : 0.32360, Training Acc : 0.844, Run Time : 0.49
INFO:root:2019-05-11 02:09:07, Epoch : 1, Step : 4665, Training Loss : 0.44228, Training Acc : 0.789, Run Time : 13.84
INFO:root:2019-05-11 02:09:08, Epoch : 1, Step : 4666, Training Loss : 0.29026, Training Acc : 0.867, Run Time : 1.08
INFO:root:2019-05-11 02:09:09, Epoch : 1, Step : 4667, Training Loss : 0.29636, Training Acc : 0.889, Run Time : 0.96
INFO:root:2019-05-11 02:09:12, Epoch : 1, Step : 4668, Training Loss : 0.32327, Training Acc : 0.894, Run Time : 2.80
INFO:root:2019-05-11 02:09:16, Epoch : 1, Step : 4669, Training Loss : 0.21282, Training Acc : 0.922, Run Time : 4.69
INFO:root:2019-05-11 02:09:17, Epoch : 1, Step : 4670, Training Loss : 0.25211, Training Acc : 0.911, Run Time : 0.62
INFO:root:2019-05-11 02:09:18, Epoch : 1, Step : 4671, Training Loss : 0.20500, Training Acc : 0.917, Run Time : 0.91
INFO:root:2019-05-11 02:09:28, Epoch : 1, Step : 4672, Training Loss : 0.18715, Training Acc : 0.928, Run Time : 10.33
INFO:root:2019-05-11 02:09:35, Epoch : 1, Step : 4673, Training Loss : 0.30798, Training Acc : 0.856, Run Time : 6.67
INFO:root:2019-05-11 02:09:35, Epoch : 1, Step : 4674, Training Loss : 0.21254, Training Acc : 0.917, Run Time : 0.46
INFO:root:2019-05-11 02:09:36, Epoch : 1, Step : 4675, Training Loss : 0.22092, Training Acc : 0.922, Run Time : 0.53
INFO:root:2019-05-11 02:09:37, Epoch : 1, Step : 4676, Training Loss : 0.23065, Training Acc : 0.911, Run Time : 1.67
INFO:root:2019-05-11 02:09:39, Epoch : 1, Step : 4677, Training Loss : 0.22772, Training Acc : 0.900, Run Time : 1.09
INFO:root:2019-05-11 02:09:46, Epoch : 1, Step : 4678, Training Loss : 0.17697, Training Acc : 0.922, Run Time : 7.61
INFO:root:2019-05-11 02:09:47, Epoch : 1, Step : 4679, Training Loss : 0.15976, Training Acc : 0.933, Run Time : 0.43
INFO:root:2019-05-11 02:09:47, Epoch : 1, Step : 4680, Training Loss : 0.28145, Training Acc : 0.883, Run Time : 0.37
INFO:root:2019-05-11 02:09:49, Epoch : 1, Step : 4681, Training Loss : 0.21927, Training Acc : 0.911, Run Time : 1.57
INFO:root:2019-05-11 02:09:59, Epoch : 1, Step : 4682, Training Loss : 0.27454, Training Acc : 0.894, Run Time : 10.47
INFO:root:2019-05-11 02:10:00, Epoch : 1, Step : 4683, Training Loss : 0.32765, Training Acc : 0.850, Run Time : 0.58
INFO:root:2019-05-11 02:10:00, Epoch : 1, Step : 4684, Training Loss : 0.20099, Training Acc : 0.917, Run Time : 0.49
INFO:root:2019-05-11 02:10:12, Epoch : 1, Step : 4685, Training Loss : 0.28721, Training Acc : 0.906, Run Time : 11.78
INFO:root:2019-05-11 02:10:12, Epoch : 1, Step : 4686, Training Loss : 0.17213, Training Acc : 0.922, Run Time : 0.65
INFO:root:2019-05-11 02:10:13, Epoch : 1, Step : 4687, Training Loss : 0.23786, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-11 02:10:13, Epoch : 1, Step : 4688, Training Loss : 0.19073, Training Acc : 0.922, Run Time : 0.37
INFO:root:2019-05-11 02:10:14, Epoch : 1, Step : 4689, Training Loss : 0.21774, Training Acc : 0.906, Run Time : 0.90
INFO:root:2019-05-11 02:10:23, Epoch : 1, Step : 4690, Training Loss : 0.15104, Training Acc : 0.950, Run Time : 8.51
INFO:root:2019-05-11 02:10:23, Epoch : 1, Step : 4691, Training Loss : 0.11449, Training Acc : 0.961, Run Time : 0.41
INFO:root:2019-05-11 02:10:24, Epoch : 1, Step : 4692, Training Loss : 0.15361, Training Acc : 0.950, Run Time : 0.58
INFO:root:2019-05-11 02:10:25, Epoch : 1, Step : 4693, Training Loss : 0.11845, Training Acc : 0.967, Run Time : 1.56
INFO:root:2019-05-11 02:10:35, Epoch : 1, Step : 4694, Training Loss : 0.10866, Training Acc : 0.956, Run Time : 9.46
INFO:root:2019-05-11 02:10:35, Epoch : 1, Step : 4695, Training Loss : 0.12379, Training Acc : 0.956, Run Time : 0.82
INFO:root:2019-05-11 02:10:36, Epoch : 1, Step : 4696, Training Loss : 0.14554, Training Acc : 0.944, Run Time : 0.41
INFO:root:2019-05-11 02:10:37, Epoch : 1, Step : 4697, Training Loss : 0.14997, Training Acc : 0.928, Run Time : 1.42
INFO:root:2019-05-11 02:10:46, Epoch : 1, Step : 4698, Training Loss : 0.11523, Training Acc : 0.944, Run Time : 9.13
INFO:root:2019-05-11 02:10:47, Epoch : 1, Step : 4699, Training Loss : 0.13630, Training Acc : 0.939, Run Time : 0.40
INFO:root:2019-05-11 02:10:47, Epoch : 1, Step : 4700, Training Loss : 0.18519, Training Acc : 0.922, Run Time : 0.60
INFO:root:2019-05-11 02:10:52, Epoch : 1, Step : 4701, Training Loss : 0.17060, Training Acc : 0.933, Run Time : 4.95
INFO:root:2019-05-11 02:10:54, Epoch : 1, Step : 4702, Training Loss : 0.16522, Training Acc : 0.917, Run Time : 1.36
INFO:root:2019-05-11 02:10:55, Epoch : 1, Step : 4703, Training Loss : 0.14887, Training Acc : 0.928, Run Time : 1.01
INFO:root:2019-05-11 02:11:05, Epoch : 1, Step : 4704, Training Loss : 0.14941, Training Acc : 0.922, Run Time : 10.70
INFO:root:2019-05-11 02:11:17, Epoch : 1, Step : 4705, Training Loss : 0.14892, Training Acc : 0.944, Run Time : 12.01
INFO:root:2019-05-11 02:11:22, Epoch : 1, Step : 4706, Training Loss : 0.11317, Training Acc : 0.956, Run Time : 4.69
INFO:root:2019-05-11 02:11:23, Epoch : 1, Step : 4707, Training Loss : 0.13283, Training Acc : 0.944, Run Time : 0.69
INFO:root:2019-05-11 02:11:32, Epoch : 1, Step : 4708, Training Loss : 0.07126, Training Acc : 0.978, Run Time : 9.03
INFO:root:2019-05-11 02:11:33, Epoch : 1, Step : 4709, Training Loss : 0.15158, Training Acc : 0.928, Run Time : 1.29
INFO:root:2019-05-11 02:11:34, Epoch : 1, Step : 4710, Training Loss : 0.13184, Training Acc : 0.944, Run Time : 0.65
INFO:root:2019-05-11 02:11:42, Epoch : 1, Step : 4711, Training Loss : 0.16256, Training Acc : 0.922, Run Time : 8.61
INFO:root:2019-05-11 02:11:43, Epoch : 1, Step : 4712, Training Loss : 0.18561, Training Acc : 0.900, Run Time : 0.68
INFO:root:2019-05-11 02:11:43, Epoch : 1, Step : 4713, Training Loss : 0.18421, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 02:11:55, Epoch : 1, Step : 4714, Training Loss : 0.11120, Training Acc : 0.961, Run Time : 11.29
INFO:root:2019-05-11 02:11:56, Epoch : 1, Step : 4715, Training Loss : 0.16007, Training Acc : 0.933, Run Time : 0.76
INFO:root:2019-05-11 02:11:56, Epoch : 1, Step : 4716, Training Loss : 0.15539, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 02:12:03, Epoch : 1, Step : 4717, Training Loss : 0.19947, Training Acc : 0.906, Run Time : 7.06
INFO:root:2019-05-11 02:12:07, Epoch : 1, Step : 4718, Training Loss : 0.16998, Training Acc : 0.917, Run Time : 4.23
INFO:root:2019-05-11 02:12:08, Epoch : 1, Step : 4719, Training Loss : 0.24518, Training Acc : 0.872, Run Time : 0.37
INFO:root:2019-05-11 02:12:08, Epoch : 1, Step : 4720, Training Loss : 0.16863, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-11 02:12:18, Epoch : 1, Step : 4721, Training Loss : 0.21353, Training Acc : 0.939, Run Time : 10.11
INFO:root:2019-05-11 02:12:19, Epoch : 1, Step : 4722, Training Loss : 0.22048, Training Acc : 0.906, Run Time : 0.93
INFO:root:2019-05-11 02:12:20, Epoch : 1, Step : 4723, Training Loss : 0.17697, Training Acc : 0.939, Run Time : 0.41
INFO:root:2019-05-11 02:12:21, Epoch : 1, Step : 4724, Training Loss : 0.11787, Training Acc : 0.950, Run Time : 1.02
INFO:root:2019-05-11 02:12:33, Epoch : 1, Step : 4725, Training Loss : 0.16096, Training Acc : 0.922, Run Time : 12.11
INFO:root:2019-05-11 02:12:33, Epoch : 1, Step : 4726, Training Loss : 0.13171, Training Acc : 0.944, Run Time : 0.50
INFO:root:2019-05-11 02:12:34, Epoch : 1, Step : 4727, Training Loss : 0.10614, Training Acc : 0.956, Run Time : 0.78
INFO:root:2019-05-11 02:12:44, Epoch : 1, Step : 4728, Training Loss : 0.16214, Training Acc : 0.939, Run Time : 10.45
INFO:root:2019-05-11 02:12:45, Epoch : 1, Step : 4729, Training Loss : 0.12242, Training Acc : 0.961, Run Time : 0.53
INFO:root:2019-05-11 02:12:45, Epoch : 1, Step : 4730, Training Loss : 0.15053, Training Acc : 0.950, Run Time : 0.41
INFO:root:2019-05-11 02:12:47, Epoch : 1, Step : 4731, Training Loss : 0.21822, Training Acc : 0.928, Run Time : 1.39
INFO:root:2019-05-11 02:12:59, Epoch : 1, Step : 4732, Training Loss : 0.13133, Training Acc : 0.961, Run Time : 11.94
INFO:root:2019-05-11 02:13:00, Epoch : 1, Step : 4733, Training Loss : 0.29511, Training Acc : 0.883, Run Time : 0.95
INFO:root:2019-05-11 02:13:10, Epoch : 1, Step : 4734, Training Loss : 0.13543, Training Acc : 0.961, Run Time : 10.37
INFO:root:2019-05-11 02:13:10, Epoch : 1, Step : 4735, Training Loss : 0.16058, Training Acc : 0.956, Run Time : 0.49
INFO:root:2019-05-11 02:13:11, Epoch : 1, Step : 4736, Training Loss : 0.13533, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-11 02:13:12, Epoch : 1, Step : 4737, Training Loss : 0.14875, Training Acc : 0.939, Run Time : 1.02
INFO:root:2019-05-11 02:13:13, Epoch : 1, Step : 4738, Training Loss : 0.16786, Training Acc : 0.950, Run Time : 1.45
INFO:root:2019-05-11 02:13:14, Epoch : 1, Step : 4739, Training Loss : 0.14033, Training Acc : 0.944, Run Time : 0.42
INFO:root:2019-05-11 02:13:14, Epoch : 1, Step : 4740, Training Loss : 0.24205, Training Acc : 0.900, Run Time : 0.38
INFO:root:2019-05-11 02:13:15, Epoch : 1, Step : 4741, Training Loss : 0.22155, Training Acc : 0.900, Run Time : 1.09
INFO:root:2019-05-11 02:13:25, Epoch : 1, Step : 4742, Training Loss : 0.13994, Training Acc : 0.939, Run Time : 9.37
INFO:root:2019-05-11 02:13:25, Epoch : 1, Step : 4743, Training Loss : 0.16462, Training Acc : 0.939, Run Time : 0.42
INFO:root:2019-05-11 02:13:25, Epoch : 1, Step : 4744, Training Loss : 0.14892, Training Acc : 0.956, Run Time : 0.38
INFO:root:2019-05-11 02:13:26, Epoch : 1, Step : 4745, Training Loss : 0.14223, Training Acc : 0.961, Run Time : 0.41
INFO:root:2019-05-11 02:13:27, Epoch : 1, Step : 4746, Training Loss : 0.23957, Training Acc : 0.894, Run Time : 0.96
INFO:root:2019-05-11 02:13:35, Epoch : 1, Step : 4747, Training Loss : 0.16613, Training Acc : 0.922, Run Time : 8.36
INFO:root:2019-05-11 02:13:36, Epoch : 1, Step : 4748, Training Loss : 0.21776, Training Acc : 0.911, Run Time : 0.94
INFO:root:2019-05-11 02:13:37, Epoch : 1, Step : 4749, Training Loss : 0.29087, Training Acc : 0.872, Run Time : 0.41
INFO:root:2019-05-11 02:13:38, Epoch : 1, Step : 4750, Training Loss : 0.43933, Training Acc : 0.828, Run Time : 1.92
INFO:root:2019-05-11 02:13:48, Epoch : 1, Step : 4751, Training Loss : 0.34982, Training Acc : 0.861, Run Time : 9.19
INFO:root:2019-05-11 02:13:48, Epoch : 1, Step : 4752, Training Loss : 0.14342, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 02:13:48, Epoch : 1, Step : 4753, Training Loss : 0.21689, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 02:13:49, Epoch : 1, Step : 4754, Training Loss : 0.24550, Training Acc : 0.900, Run Time : 0.75
INFO:root:2019-05-11 02:13:59, Epoch : 1, Step : 4755, Training Loss : 0.23480, Training Acc : 0.900, Run Time : 9.75
INFO:root:2019-05-11 02:13:59, Epoch : 1, Step : 4756, Training Loss : 0.28885, Training Acc : 0.889, Run Time : 0.40
INFO:root:2019-05-11 02:14:00, Epoch : 1, Step : 4757, Training Loss : 0.72434, Training Acc : 0.733, Run Time : 0.38
INFO:root:2019-05-11 02:14:00, Epoch : 1, Step : 4758, Training Loss : 0.33630, Training Acc : 0.911, Run Time : 0.48
INFO:root:2019-05-11 02:14:03, Epoch : 1, Step : 4759, Training Loss : 0.35887, Training Acc : 0.817, Run Time : 2.46
INFO:root:2019-05-11 02:14:13, Epoch : 1, Step : 4760, Training Loss : 0.20886, Training Acc : 0.917, Run Time : 10.84
INFO:root:2019-05-11 02:14:14, Epoch : 1, Step : 4761, Training Loss : 0.29146, Training Acc : 0.867, Run Time : 0.42
INFO:root:2019-05-11 02:14:15, Epoch : 1, Step : 4762, Training Loss : 0.18528, Training Acc : 0.928, Run Time : 0.61
INFO:root:2019-05-11 02:14:29, Epoch : 1, Step : 4763, Training Loss : 0.12791, Training Acc : 0.961, Run Time : 14.44
INFO:root:2019-05-11 02:14:34, Epoch : 1, Step : 4764, Training Loss : 0.19935, Training Acc : 0.889, Run Time : 5.21
INFO:root:2019-05-11 02:14:41, Epoch : 1, Step : 4765, Training Loss : 0.16531, Training Acc : 0.939, Run Time : 6.99
INFO:root:2019-05-11 02:14:42, Epoch : 1, Step : 4766, Training Loss : 0.27898, Training Acc : 0.872, Run Time : 0.61
INFO:root:2019-05-11 02:14:43, Epoch : 1, Step : 4767, Training Loss : 0.24214, Training Acc : 0.883, Run Time : 1.29
INFO:root:2019-05-11 02:14:45, Epoch : 1, Step : 4768, Training Loss : 0.17907, Training Acc : 0.922, Run Time : 2.11
INFO:root:2019-05-11 02:14:46, Epoch : 1, Step : 4769, Training Loss : 0.20242, Training Acc : 0.894, Run Time : 0.43
INFO:root:2019-05-11 02:14:47, Epoch : 1, Step : 4770, Training Loss : 0.15524, Training Acc : 0.939, Run Time : 1.03
INFO:root:2019-05-11 02:14:58, Epoch : 1, Step : 4771, Training Loss : 0.18583, Training Acc : 0.939, Run Time : 11.84
INFO:root:2019-05-11 02:14:59, Epoch : 1, Step : 4772, Training Loss : 0.30007, Training Acc : 0.850, Run Time : 0.87
INFO:root:2019-05-11 02:15:00, Epoch : 1, Step : 4773, Training Loss : 0.28989, Training Acc : 0.828, Run Time : 0.94
INFO:root:2019-05-11 02:15:10, Epoch : 1, Step : 4774, Training Loss : 0.14439, Training Acc : 0.961, Run Time : 10.00
INFO:root:2019-05-11 02:15:11, Epoch : 1, Step : 4775, Training Loss : 0.20431, Training Acc : 0.906, Run Time : 0.46
INFO:root:2019-05-11 02:15:11, Epoch : 1, Step : 4776, Training Loss : 0.21444, Training Acc : 0.906, Run Time : 0.37
INFO:root:2019-05-11 02:15:12, Epoch : 1, Step : 4777, Training Loss : 0.26443, Training Acc : 0.894, Run Time : 0.91
INFO:root:2019-05-11 02:15:15, Epoch : 1, Step : 4778, Training Loss : 0.13447, Training Acc : 0.933, Run Time : 2.66
INFO:root:2019-05-11 02:15:24, Epoch : 1, Step : 4779, Training Loss : 0.22896, Training Acc : 0.894, Run Time : 9.25
INFO:root:2019-05-11 02:15:25, Epoch : 1, Step : 4780, Training Loss : 0.21085, Training Acc : 0.900, Run Time : 0.79
INFO:root:2019-05-11 02:15:25, Epoch : 1, Step : 4781, Training Loss : 0.29876, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-11 02:15:25, Epoch : 1, Step : 4782, Training Loss : 0.20476, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-11 02:15:26, Epoch : 1, Step : 4783, Training Loss : 0.36440, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-11 02:15:27, Epoch : 1, Step : 4784, Training Loss : 0.25219, Training Acc : 0.917, Run Time : 0.71
INFO:root:2019-05-11 02:15:39, Epoch : 1, Step : 4785, Training Loss : 0.18687, Training Acc : 0.944, Run Time : 12.88
INFO:root:2019-05-11 02:15:40, Epoch : 1, Step : 4786, Training Loss : 0.10721, Training Acc : 0.961, Run Time : 0.62
INFO:root:2019-05-11 02:15:41, Epoch : 1, Step : 4787, Training Loss : 0.07958, Training Acc : 0.983, Run Time : 0.48
INFO:root:2019-05-11 02:15:41, Epoch : 1, Step : 4788, Training Loss : 0.09045, Training Acc : 0.972, Run Time : 0.37
INFO:root:2019-05-11 02:15:41, Epoch : 1, Step : 4789, Training Loss : 0.10534, Training Acc : 0.967, Run Time : 0.38
INFO:root:2019-05-11 02:15:49, Epoch : 1, Step : 4790, Training Loss : 0.16196, Training Acc : 0.944, Run Time : 8.13
INFO:root:2019-05-11 02:15:50, Epoch : 1, Step : 4791, Training Loss : 0.13271, Training Acc : 0.978, Run Time : 0.62
INFO:root:2019-05-11 02:15:51, Epoch : 1, Step : 4792, Training Loss : 0.18094, Training Acc : 0.944, Run Time : 0.49
INFO:root:2019-05-11 02:16:00, Epoch : 1, Step : 4793, Training Loss : 0.19771, Training Acc : 0.939, Run Time : 9.25
INFO:root:2019-05-11 02:16:04, Epoch : 1, Step : 4794, Training Loss : 0.16156, Training Acc : 0.950, Run Time : 4.44
INFO:root:2019-05-11 02:16:05, Epoch : 1, Step : 4795, Training Loss : 0.17137, Training Acc : 0.928, Run Time : 0.37
INFO:root:2019-05-11 02:16:06, Epoch : 1, Step : 4796, Training Loss : 0.11676, Training Acc : 0.961, Run Time : 1.66
INFO:root:2019-05-11 02:16:15, Epoch : 1, Step : 4797, Training Loss : 0.15021, Training Acc : 0.950, Run Time : 9.03
INFO:root:2019-05-11 02:16:16, Epoch : 1, Step : 4798, Training Loss : 0.19107, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-11 02:16:16, Epoch : 1, Step : 4799, Training Loss : 0.22921, Training Acc : 0.906, Run Time : 0.37
INFO:root:2019-05-11 02:16:18, Epoch : 1, Step : 4800, Training Loss : 0.29482, Training Acc : 0.889, Run Time : 1.55
INFO:root:2019-05-11 02:16:28, Epoch : 1, Step : 4801, Training Loss : 1.09263, Training Acc : 0.583, Run Time : 10.13
INFO:root:2019-05-11 02:16:28, Epoch : 1, Step : 4802, Training Loss : 0.88492, Training Acc : 0.633, Run Time : 0.44
INFO:root:2019-05-11 02:16:29, Epoch : 1, Step : 4803, Training Loss : 0.80069, Training Acc : 0.711, Run Time : 0.41
INFO:root:2019-05-11 02:16:32, Epoch : 1, Step : 4804, Training Loss : 0.41470, Training Acc : 0.767, Run Time : 3.36
INFO:root:2019-05-11 02:16:33, Epoch : 1, Step : 4805, Training Loss : 0.42820, Training Acc : 0.844, Run Time : 0.69
INFO:root:2019-05-11 02:16:33, Epoch : 1, Step : 4806, Training Loss : 0.29452, Training Acc : 0.867, Run Time : 0.37
INFO:root:2019-05-11 02:16:40, Epoch : 1, Step : 4807, Training Loss : 0.57832, Training Acc : 0.772, Run Time : 7.13
INFO:root:2019-05-11 02:16:42, Epoch : 1, Step : 4808, Training Loss : 0.30521, Training Acc : 0.856, Run Time : 1.76
INFO:root:2019-05-11 02:16:42, Epoch : 1, Step : 4809, Training Loss : 0.42605, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-11 02:16:43, Epoch : 1, Step : 4810, Training Loss : 0.20395, Training Acc : 0.883, Run Time : 0.43
INFO:root:2019-05-11 02:16:54, Epoch : 1, Step : 4811, Training Loss : 0.21140, Training Acc : 0.894, Run Time : 11.46
INFO:root:2019-05-11 02:16:55, Epoch : 1, Step : 4812, Training Loss : 0.18558, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 02:16:55, Epoch : 1, Step : 4813, Training Loss : 0.17404, Training Acc : 0.917, Run Time : 0.37
INFO:root:2019-05-11 02:16:57, Epoch : 1, Step : 4814, Training Loss : 0.31828, Training Acc : 0.867, Run Time : 1.53
INFO:root:2019-05-11 02:17:07, Epoch : 1, Step : 4815, Training Loss : 0.36364, Training Acc : 0.878, Run Time : 10.46
INFO:root:2019-05-11 02:17:08, Epoch : 1, Step : 4816, Training Loss : 0.11143, Training Acc : 0.972, Run Time : 0.66
INFO:root:2019-05-11 02:17:09, Epoch : 1, Step : 4817, Training Loss : 0.22094, Training Acc : 0.922, Run Time : 1.75
INFO:root:2019-05-11 02:17:19, Epoch : 1, Step : 4818, Training Loss : 0.34819, Training Acc : 0.856, Run Time : 9.49
INFO:root:2019-05-11 02:17:19, Epoch : 1, Step : 4819, Training Loss : 0.11388, Training Acc : 0.956, Run Time : 0.57
INFO:root:2019-05-11 02:17:20, Epoch : 1, Step : 4820, Training Loss : 0.20721, Training Acc : 0.950, Run Time : 0.41
INFO:root:2019-05-11 02:17:21, Epoch : 1, Step : 4821, Training Loss : 0.12893, Training Acc : 0.956, Run Time : 1.47
INFO:root:2019-05-11 02:17:30, Epoch : 1, Step : 4822, Training Loss : 0.15195, Training Acc : 0.939, Run Time : 8.94
INFO:root:2019-05-11 02:17:31, Epoch : 1, Step : 4823, Training Loss : 0.30250, Training Acc : 0.922, Run Time : 0.63
INFO:root:2019-05-11 02:17:31, Epoch : 1, Step : 4824, Training Loss : 0.35388, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 02:17:42, Epoch : 1, Step : 4825, Training Loss : 0.16883, Training Acc : 0.956, Run Time : 10.61
INFO:root:2019-05-11 02:17:42, Epoch : 1, Step : 4826, Training Loss : 0.21521, Training Acc : 0.939, Run Time : 0.41
INFO:root:2019-05-11 02:17:43, Epoch : 1, Step : 4827, Training Loss : 0.08657, Training Acc : 0.944, Run Time : 0.39
INFO:root:2019-05-11 02:17:43, Epoch : 1, Step : 4828, Training Loss : 0.09506, Training Acc : 0.978, Run Time : 0.45
INFO:root:2019-05-11 02:17:44, Epoch : 1, Step : 4829, Training Loss : 0.25037, Training Acc : 0.928, Run Time : 0.41
INFO:root:2019-05-11 02:17:55, Epoch : 1, Step : 4830, Training Loss : 0.08802, Training Acc : 0.967, Run Time : 11.39
INFO:root:2019-05-11 02:17:56, Epoch : 1, Step : 4831, Training Loss : 0.07258, Training Acc : 0.983, Run Time : 1.13
INFO:root:2019-05-11 02:17:57, Epoch : 1, Step : 4832, Training Loss : 0.12535, Training Acc : 0.961, Run Time : 0.56
INFO:root:2019-05-11 02:17:58, Epoch : 1, Step : 4833, Training Loss : 0.05415, Training Acc : 0.989, Run Time : 1.42
INFO:root:2019-05-11 02:18:06, Epoch : 1, Step : 4834, Training Loss : 0.02538, Training Acc : 1.000, Run Time : 7.86
INFO:root:2019-05-11 02:18:07, Epoch : 1, Step : 4835, Training Loss : 0.08994, Training Acc : 0.972, Run Time : 0.72
INFO:root:2019-05-11 02:18:07, Epoch : 1, Step : 4836, Training Loss : 0.10380, Training Acc : 0.961, Run Time : 0.87
INFO:root:2019-05-11 02:18:20, Epoch : 1, Step : 4837, Training Loss : 0.16789, Training Acc : 0.950, Run Time : 12.34
INFO:root:2019-05-11 02:18:21, Epoch : 1, Step : 4838, Training Loss : 0.10773, Training Acc : 0.967, Run Time : 0.81
INFO:root:2019-05-11 02:18:25, Epoch : 1, Step : 4839, Training Loss : 0.19275, Training Acc : 0.928, Run Time : 4.17
INFO:root:2019-05-11 02:18:25, Epoch : 1, Step : 4840, Training Loss : 0.23378, Training Acc : 0.889, Run Time : 0.40
INFO:root:2019-05-11 02:18:26, Epoch : 1, Step : 4841, Training Loss : 0.22618, Training Acc : 0.917, Run Time : 0.53
INFO:root:2019-05-11 02:18:35, Epoch : 1, Step : 4842, Training Loss : 0.15923, Training Acc : 0.939, Run Time : 8.96
INFO:root:2019-05-11 02:18:35, Epoch : 1, Step : 4843, Training Loss : 0.32403, Training Acc : 0.889, Run Time : 0.66
INFO:root:2019-05-11 02:18:36, Epoch : 1, Step : 4844, Training Loss : 0.40400, Training Acc : 0.861, Run Time : 0.43
INFO:root:2019-05-11 02:18:37, Epoch : 1, Step : 4845, Training Loss : 0.06321, Training Acc : 0.989, Run Time : 1.39
INFO:root:2019-05-11 02:18:44, Epoch : 1, Step : 4846, Training Loss : 0.23592, Training Acc : 0.944, Run Time : 6.98
INFO:root:2019-05-11 02:18:45, Epoch : 1, Step : 4847, Training Loss : 0.07685, Training Acc : 0.967, Run Time : 0.40
INFO:root:2019-05-11 02:18:46, Epoch : 1, Step : 4848, Training Loss : 0.10511, Training Acc : 0.978, Run Time : 1.80
INFO:root:2019-05-11 02:18:58, Epoch : 1, Step : 4849, Training Loss : 0.12883, Training Acc : 0.956, Run Time : 11.66
INFO:root:2019-05-11 02:18:58, Epoch : 1, Step : 4850, Training Loss : 0.08510, Training Acc : 0.972, Run Time : 0.40
INFO:root:2019-05-11 02:18:59, Epoch : 1, Step : 4851, Training Loss : 0.05387, Training Acc : 0.983, Run Time : 0.73
INFO:root:2019-05-11 02:19:11, Epoch : 1, Step : 4852, Training Loss : 0.10561, Training Acc : 0.956, Run Time : 12.12
INFO:root:2019-05-11 02:19:12, Epoch : 1, Step : 4853, Training Loss : 0.20873, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-11 02:19:12, Epoch : 1, Step : 4854, Training Loss : 0.16049, Training Acc : 0.950, Run Time : 0.37
INFO:root:2019-05-11 02:19:12, Epoch : 1, Step : 4855, Training Loss : 0.09612, Training Acc : 0.978, Run Time : 0.38
INFO:root:2019-05-11 02:19:25, Epoch : 1, Step : 4856, Training Loss : 0.06745, Training Acc : 0.994, Run Time : 12.46
INFO:root:2019-05-11 02:19:26, Epoch : 1, Step : 4857, Training Loss : 0.38413, Training Acc : 0.872, Run Time : 0.67
INFO:root:2019-05-11 02:19:27, Epoch : 1, Step : 4858, Training Loss : 0.30450, Training Acc : 0.878, Run Time : 1.03
INFO:root:2019-05-11 02:19:37, Epoch : 1, Step : 4859, Training Loss : 0.24112, Training Acc : 0.922, Run Time : 10.73
INFO:root:2019-05-11 02:19:38, Epoch : 1, Step : 4860, Training Loss : 0.13175, Training Acc : 0.944, Run Time : 0.66
INFO:root:2019-05-11 02:19:38, Epoch : 1, Step : 4861, Training Loss : 0.13482, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-11 02:19:40, Epoch : 1, Step : 4862, Training Loss : 0.22075, Training Acc : 0.922, Run Time : 1.36
INFO:root:2019-05-11 02:19:50, Epoch : 1, Step : 4863, Training Loss : 0.14789, Training Acc : 0.939, Run Time : 9.84
INFO:root:2019-05-11 02:19:50, Epoch : 1, Step : 4864, Training Loss : 0.38157, Training Acc : 0.850, Run Time : 0.44
INFO:root:2019-05-11 02:19:51, Epoch : 1, Step : 4865, Training Loss : 0.28883, Training Acc : 0.878, Run Time : 1.14
INFO:root:2019-05-11 02:19:59, Epoch : 1, Step : 4866, Training Loss : 0.27997, Training Acc : 0.922, Run Time : 7.27
INFO:root:2019-05-11 02:19:59, Epoch : 1, Step : 4867, Training Loss : 0.32374, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-11 02:20:10, Epoch : 1, Step : 4868, Training Loss : 0.48587, Training Acc : 0.806, Run Time : 10.93
INFO:root:2019-05-11 02:20:11, Epoch : 1, Step : 4869, Training Loss : 0.47064, Training Acc : 0.817, Run Time : 1.12
INFO:root:2019-05-11 02:20:12, Epoch : 1, Step : 4870, Training Loss : 0.29726, Training Acc : 0.883, Run Time : 1.20
INFO:root:2019-05-11 02:20:23, Epoch : 1, Step : 4871, Training Loss : 0.44224, Training Acc : 0.856, Run Time : 10.64
INFO:root:2019-05-11 02:20:24, Epoch : 1, Step : 4872, Training Loss : 0.40358, Training Acc : 0.872, Run Time : 1.01
INFO:root:2019-05-11 02:20:24, Epoch : 1, Step : 4873, Training Loss : 0.50450, Training Acc : 0.844, Run Time : 0.38
INFO:root:2019-05-11 02:20:25, Epoch : 1, Step : 4874, Training Loss : 0.38830, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-11 02:20:26, Epoch : 1, Step : 4875, Training Loss : 0.65871, Training Acc : 0.783, Run Time : 1.18
INFO:root:2019-05-11 02:20:42, Epoch : 1, Step : 4876, Training Loss : 0.30139, Training Acc : 0.894, Run Time : 15.74
INFO:root:2019-05-11 02:20:42, Epoch : 1, Step : 4877, Training Loss : 0.38687, Training Acc : 0.867, Run Time : 0.81
INFO:root:2019-05-11 02:20:43, Epoch : 1, Step : 4878, Training Loss : 0.52615, Training Acc : 0.811, Run Time : 0.40
INFO:root:2019-05-11 02:20:58, Epoch : 1, Step : 4879, Training Loss : 0.65707, Training Acc : 0.778, Run Time : 15.62
INFO:root:2019-05-11 02:20:59, Epoch : 1, Step : 4880, Training Loss : 0.46925, Training Acc : 0.806, Run Time : 0.90
INFO:root:2019-05-11 02:21:07, Epoch : 1, Step : 4881, Training Loss : 0.47260, Training Acc : 0.822, Run Time : 7.71
INFO:root:2019-05-11 02:21:10, Epoch : 1, Step : 4882, Training Loss : 0.20544, Training Acc : 0.928, Run Time : 2.78
INFO:root:2019-05-11 02:21:10, Epoch : 1, Step : 4883, Training Loss : 0.40106, Training Acc : 0.822, Run Time : 0.52
INFO:root:2019-05-11 02:21:21, Epoch : 1, Step : 4884, Training Loss : 0.31179, Training Acc : 0.906, Run Time : 10.83
INFO:root:2019-05-11 02:21:22, Epoch : 1, Step : 4885, Training Loss : 0.62719, Training Acc : 0.728, Run Time : 0.98
INFO:root:2019-05-11 02:21:22, Epoch : 1, Step : 4886, Training Loss : 0.93675, Training Acc : 0.678, Run Time : 0.37
INFO:root:2019-05-11 02:21:23, Epoch : 1, Step : 4887, Training Loss : 1.07148, Training Acc : 0.572, Run Time : 0.38
INFO:root:2019-05-11 02:21:33, Epoch : 1, Step : 4888, Training Loss : 0.66150, Training Acc : 0.761, Run Time : 9.99
INFO:root:2019-05-11 02:21:36, Epoch : 1, Step : 4889, Training Loss : 0.45606, Training Acc : 0.772, Run Time : 3.43
INFO:root:2019-05-11 02:21:37, Epoch : 1, Step : 4890, Training Loss : 0.23988, Training Acc : 0.928, Run Time : 0.50
INFO:root:2019-05-11 02:21:37, Epoch : 1, Step : 4891, Training Loss : 0.28778, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-11 02:21:39, Epoch : 1, Step : 4892, Training Loss : 0.25814, Training Acc : 0.883, Run Time : 2.34
INFO:root:2019-05-11 02:21:40, Epoch : 1, Step : 4893, Training Loss : 0.42819, Training Acc : 0.833, Run Time : 0.59
INFO:root:2019-05-11 02:21:41, Epoch : 1, Step : 4894, Training Loss : 0.38918, Training Acc : 0.783, Run Time : 0.86
INFO:root:2019-05-11 02:21:50, Epoch : 1, Step : 4895, Training Loss : 0.53073, Training Acc : 0.772, Run Time : 8.68
INFO:root:2019-05-11 02:21:50, Epoch : 1, Step : 4896, Training Loss : 0.23427, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 02:21:51, Epoch : 1, Step : 4897, Training Loss : 0.29143, Training Acc : 0.939, Run Time : 0.56
INFO:root:2019-05-11 02:22:04, Epoch : 1, Step : 4898, Training Loss : 0.30720, Training Acc : 0.861, Run Time : 12.94
INFO:root:2019-05-11 02:22:04, Epoch : 1, Step : 4899, Training Loss : 0.24849, Training Acc : 0.900, Run Time : 0.83
INFO:root:2019-05-11 02:22:05, Epoch : 1, Step : 4900, Training Loss : 0.27146, Training Acc : 0.867, Run Time : 0.72
INFO:root:2019-05-11 02:22:06, Epoch : 1, Step : 4901, Training Loss : 0.29005, Training Acc : 0.889, Run Time : 0.76
INFO:root:2019-05-11 02:22:11, Epoch : 1, Step : 4902, Training Loss : 0.40958, Training Acc : 0.817, Run Time : 5.47
INFO:root:2019-05-11 02:22:12, Epoch : 1, Step : 4903, Training Loss : 0.38128, Training Acc : 0.839, Run Time : 0.40
INFO:root:2019-05-11 02:22:12, Epoch : 1, Step : 4904, Training Loss : 0.25893, Training Acc : 0.928, Run Time : 0.39
INFO:root:2019-05-11 02:22:13, Epoch : 1, Step : 4905, Training Loss : 0.37913, Training Acc : 0.839, Run Time : 0.54
INFO:root:2019-05-11 02:22:22, Epoch : 1, Step : 4906, Training Loss : 0.36232, Training Acc : 0.856, Run Time : 9.66
INFO:root:2019-05-11 02:22:23, Epoch : 1, Step : 4907, Training Loss : 0.29132, Training Acc : 0.922, Run Time : 0.73
INFO:root:2019-05-11 02:22:23, Epoch : 1, Step : 4908, Training Loss : 0.29191, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-11 02:22:25, Epoch : 1, Step : 4909, Training Loss : 0.29222, Training Acc : 0.922, Run Time : 1.18
INFO:root:2019-05-11 02:22:35, Epoch : 1, Step : 4910, Training Loss : 0.32943, Training Acc : 0.878, Run Time : 10.02
INFO:root:2019-05-11 02:22:35, Epoch : 1, Step : 4911, Training Loss : 0.28725, Training Acc : 0.889, Run Time : 0.43
INFO:root:2019-05-11 02:22:36, Epoch : 1, Step : 4912, Training Loss : 0.42840, Training Acc : 0.817, Run Time : 0.50
INFO:root:2019-05-11 02:22:36, Epoch : 1, Step : 4913, Training Loss : 0.37948, Training Acc : 0.811, Run Time : 0.41
INFO:root:2019-05-11 02:22:47, Epoch : 1, Step : 4914, Training Loss : 0.43924, Training Acc : 0.794, Run Time : 11.05
INFO:root:2019-05-11 02:22:49, Epoch : 1, Step : 4915, Training Loss : 0.47370, Training Acc : 0.789, Run Time : 1.84
INFO:root:2019-05-11 02:22:50, Epoch : 1, Step : 4916, Training Loss : 0.61416, Training Acc : 0.706, Run Time : 1.19
INFO:root:2019-05-11 02:23:01, Epoch : 1, Step : 4917, Training Loss : 0.25760, Training Acc : 0.917, Run Time : 11.17
INFO:root:2019-05-11 02:23:02, Epoch : 1, Step : 4918, Training Loss : 0.41517, Training Acc : 0.828, Run Time : 0.44
INFO:root:2019-05-11 02:23:02, Epoch : 1, Step : 4919, Training Loss : 0.51603, Training Acc : 0.739, Run Time : 0.37
INFO:root:2019-05-11 02:23:03, Epoch : 1, Step : 4920, Training Loss : 0.58225, Training Acc : 0.728, Run Time : 1.33
INFO:root:2019-05-11 02:23:14, Epoch : 1, Step : 4921, Training Loss : 0.40938, Training Acc : 0.839, Run Time : 10.93
INFO:root:2019-05-11 02:23:15, Epoch : 1, Step : 4922, Training Loss : 0.45027, Training Acc : 0.800, Run Time : 0.40
INFO:root:2019-05-11 02:23:15, Epoch : 1, Step : 4923, Training Loss : 0.64555, Training Acc : 0.628, Run Time : 0.37
INFO:root:2019-05-11 02:23:18, Epoch : 1, Step : 4924, Training Loss : 0.44892, Training Acc : 0.750, Run Time : 3.45
INFO:root:2019-05-11 02:23:34, Epoch : 1, Step : 4925, Training Loss : 0.31887, Training Acc : 0.844, Run Time : 15.13
INFO:root:2019-05-11 02:23:35, Epoch : 1, Step : 4926, Training Loss : 0.31108, Training Acc : 0.839, Run Time : 1.06
INFO:root:2019-05-11 02:23:35, Epoch : 1, Step : 4927, Training Loss : 0.27540, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-11 02:23:36, Epoch : 1, Step : 4928, Training Loss : 0.21441, Training Acc : 0.972, Run Time : 1.31
INFO:root:2019-05-11 02:23:47, Epoch : 1, Step : 4929, Training Loss : 0.30303, Training Acc : 0.867, Run Time : 10.46
INFO:root:2019-05-11 02:23:47, Epoch : 1, Step : 4930, Training Loss : 0.40539, Training Acc : 0.833, Run Time : 0.60
INFO:root:2019-05-11 02:23:57, Epoch : 1, Step : 4931, Training Loss : 0.24139, Training Acc : 0.933, Run Time : 10.02
INFO:root:2019-05-11 02:24:09, Epoch : 1, Step : 4932, Training Loss : 0.40655, Training Acc : 0.822, Run Time : 11.02
INFO:root:2019-05-11 02:24:09, Epoch : 1, Step : 4933, Training Loss : 0.52605, Training Acc : 0.817, Run Time : 0.75
INFO:root:2019-05-11 02:24:10, Epoch : 1, Step : 4934, Training Loss : 0.37194, Training Acc : 0.811, Run Time : 0.51
INFO:root:2019-05-11 02:24:10, Epoch : 1, Step : 4935, Training Loss : 0.88063, Training Acc : 0.606, Run Time : 0.39
INFO:root:2019-05-11 02:24:22, Epoch : 1, Step : 4936, Training Loss : 0.64802, Training Acc : 0.617, Run Time : 12.25
INFO:root:2019-05-11 02:24:23, Epoch : 1, Step : 4937, Training Loss : 0.71551, Training Acc : 0.589, Run Time : 0.60
INFO:root:2019-05-11 02:24:23, Epoch : 1, Step : 4938, Training Loss : 0.67175, Training Acc : 0.583, Run Time : 0.39
INFO:root:2019-05-11 02:24:33, Epoch : 1, Step : 4939, Training Loss : 0.67124, Training Acc : 0.644, Run Time : 9.32
INFO:root:2019-05-11 02:24:34, Epoch : 1, Step : 4940, Training Loss : 0.61631, Training Acc : 0.689, Run Time : 1.02
INFO:root:2019-05-11 02:24:34, Epoch : 1, Step : 4941, Training Loss : 0.54143, Training Acc : 0.744, Run Time : 0.37
INFO:root:2019-05-11 02:24:36, Epoch : 1, Step : 4942, Training Loss : 0.51186, Training Acc : 0.772, Run Time : 1.67
INFO:root:2019-05-11 02:24:44, Epoch : 1, Step : 4943, Training Loss : 0.37694, Training Acc : 0.878, Run Time : 8.51
INFO:root:2019-05-11 02:24:45, Epoch : 1, Step : 4944, Training Loss : 0.46415, Training Acc : 0.822, Run Time : 0.40
INFO:root:2019-05-11 02:24:46, Epoch : 1, Step : 4945, Training Loss : 0.44796, Training Acc : 0.811, Run Time : 1.62
INFO:root:2019-05-11 02:24:56, Epoch : 1, Step : 4946, Training Loss : 0.38755, Training Acc : 0.806, Run Time : 9.44
INFO:root:2019-05-11 02:24:56, Epoch : 1, Step : 4947, Training Loss : 0.42230, Training Acc : 0.856, Run Time : 0.42
INFO:root:2019-05-11 02:24:57, Epoch : 1, Step : 4948, Training Loss : 0.59185, Training Acc : 0.694, Run Time : 0.37
INFO:root:2019-05-11 02:24:57, Epoch : 1, Step : 4949, Training Loss : 0.32474, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-11 02:25:08, Epoch : 1, Step : 4950, Training Loss : 0.55565, Training Acc : 0.761, Run Time : 10.72
INFO:root:2019-05-11 02:25:09, Epoch : 1, Step : 4951, Training Loss : 0.53334, Training Acc : 0.739, Run Time : 0.98
INFO:root:2019-05-11 02:25:10, Epoch : 1, Step : 4952, Training Loss : 0.35864, Training Acc : 0.828, Run Time : 0.90
INFO:root:2019-05-11 02:25:19, Epoch : 1, Step : 4953, Training Loss : 0.33052, Training Acc : 0.872, Run Time : 9.48
INFO:root:2019-05-11 02:25:19, Epoch : 1, Step : 4954, Training Loss : 0.37236, Training Acc : 0.828, Run Time : 0.41
INFO:root:2019-05-11 02:25:20, Epoch : 1, Step : 4955, Training Loss : 0.46188, Training Acc : 0.772, Run Time : 0.48
INFO:root:2019-05-11 02:25:21, Epoch : 1, Step : 4956, Training Loss : 0.36794, Training Acc : 0.861, Run Time : 1.37
INFO:root:2019-05-11 02:25:31, Epoch : 1, Step : 4957, Training Loss : 0.29506, Training Acc : 0.833, Run Time : 9.60
INFO:root:2019-05-11 02:25:31, Epoch : 1, Step : 4958, Training Loss : 0.31608, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-11 02:25:32, Epoch : 1, Step : 4959, Training Loss : 0.42655, Training Acc : 0.756, Run Time : 0.51
INFO:root:2019-05-11 02:25:33, Epoch : 1, Step : 4960, Training Loss : 0.48825, Training Acc : 0.767, Run Time : 1.57
INFO:root:2019-05-11 02:25:44, Epoch : 1, Step : 4961, Training Loss : 0.66796, Training Acc : 0.617, Run Time : 10.54
INFO:root:2019-05-11 02:25:45, Epoch : 1, Step : 4962, Training Loss : 0.37761, Training Acc : 0.822, Run Time : 0.60
INFO:root:2019-05-11 02:25:45, Epoch : 1, Step : 4963, Training Loss : 0.38689, Training Acc : 0.800, Run Time : 0.37
INFO:root:2019-05-11 02:25:45, Epoch : 1, Step : 4964, Training Loss : 0.34186, Training Acc : 0.822, Run Time : 0.42
INFO:root:2019-05-11 02:25:49, Epoch : 1, Step : 4965, Training Loss : 0.40690, Training Acc : 0.822, Run Time : 3.27
INFO:root:2019-05-11 02:25:57, Epoch : 1, Step : 4966, Training Loss : 0.75113, Training Acc : 0.644, Run Time : 8.36
INFO:root:2019-05-11 02:25:58, Epoch : 1, Step : 4967, Training Loss : 0.47764, Training Acc : 0.778, Run Time : 0.72
INFO:root:2019-05-11 02:26:10, Epoch : 1, Step : 4968, Training Loss : 0.60950, Training Acc : 0.689, Run Time : 11.81
INFO:root:2019-05-11 02:26:10, Epoch : 1, Step : 4969, Training Loss : 0.89632, Training Acc : 0.656, Run Time : 0.40
INFO:root:2019-05-11 02:26:10, Epoch : 1, Step : 4970, Training Loss : 0.36353, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-11 02:26:12, Epoch : 1, Step : 4971, Training Loss : 0.49467, Training Acc : 0.739, Run Time : 1.62
INFO:root:2019-05-11 02:26:22, Epoch : 1, Step : 4972, Training Loss : 0.70306, Training Acc : 0.678, Run Time : 9.97
INFO:root:2019-05-11 02:26:22, Epoch : 1, Step : 4973, Training Loss : 0.55341, Training Acc : 0.778, Run Time : 0.41
INFO:root:2019-05-11 02:26:23, Epoch : 1, Step : 4974, Training Loss : 0.34443, Training Acc : 0.839, Run Time : 0.45
INFO:root:2019-05-11 02:26:29, Epoch : 1, Step : 4975, Training Loss : 0.51437, Training Acc : 0.794, Run Time : 5.93
INFO:root:2019-05-11 02:26:32, Epoch : 1, Step : 4976, Training Loss : 0.40012, Training Acc : 0.850, Run Time : 3.55
INFO:root:2019-05-11 02:26:33, Epoch : 1, Step : 4977, Training Loss : 0.28096, Training Acc : 0.900, Run Time : 0.63
INFO:root:2019-05-11 02:26:33, Epoch : 1, Step : 4978, Training Loss : 0.51383, Training Acc : 0.817, Run Time : 0.37
INFO:root:2019-05-11 02:26:34, Epoch : 1, Step : 4979, Training Loss : 0.48623, Training Acc : 0.772, Run Time : 0.40
INFO:root:2019-05-11 02:26:34, Epoch : 1, Step : 4980, Training Loss : 0.52764, Training Acc : 0.689, Run Time : 0.38
INFO:root:2019-05-11 02:26:35, Epoch : 1, Step : 4981, Training Loss : 0.63286, Training Acc : 0.633, Run Time : 0.54
INFO:root:2019-05-11 02:26:42, Epoch : 1, Step : 4982, Training Loss : 0.46591, Training Acc : 0.756, Run Time : 6.92
INFO:root:2019-05-11 02:26:42, Epoch : 1, Step : 4983, Training Loss : 0.45115, Training Acc : 0.756, Run Time : 0.65
INFO:root:2019-05-11 02:26:43, Epoch : 1, Step : 4984, Training Loss : 0.53189, Training Acc : 0.706, Run Time : 0.38
INFO:root:2019-05-11 02:26:43, Epoch : 1, Step : 4985, Training Loss : 0.48481, Training Acc : 0.733, Run Time : 0.81
INFO:root:2019-05-11 02:26:53, Epoch : 1, Step : 4986, Training Loss : 0.60267, Training Acc : 0.761, Run Time : 10.01
INFO:root:2019-05-11 02:26:54, Epoch : 1, Step : 4987, Training Loss : 0.39365, Training Acc : 0.800, Run Time : 0.43
INFO:root:2019-05-11 02:26:54, Epoch : 1, Step : 4988, Training Loss : 0.51705, Training Acc : 0.761, Run Time : 0.37
INFO:root:2019-05-11 02:26:56, Epoch : 1, Step : 4989, Training Loss : 0.48616, Training Acc : 0.783, Run Time : 1.36
INFO:root:2019-05-11 02:27:05, Epoch : 1, Step : 4990, Training Loss : 0.61330, Training Acc : 0.683, Run Time : 9.10
INFO:root:2019-05-11 02:27:05, Epoch : 1, Step : 4991, Training Loss : 0.73937, Training Acc : 0.606, Run Time : 0.56
INFO:root:2019-05-11 02:27:06, Epoch : 1, Step : 4992, Training Loss : 0.46288, Training Acc : 0.756, Run Time : 0.38
INFO:root:2019-05-11 02:27:06, Epoch : 1, Step : 4993, Training Loss : 0.47611, Training Acc : 0.811, Run Time : 0.38
INFO:root:2019-05-11 02:27:15, Epoch : 1, Step : 4994, Training Loss : 0.80884, Training Acc : 0.533, Run Time : 8.87
INFO:root:2019-05-11 02:27:16, Epoch : 1, Step : 4995, Training Loss : 0.70236, Training Acc : 0.572, Run Time : 1.41
INFO:root:2019-05-11 02:27:17, Epoch : 1, Step : 4996, Training Loss : 0.63216, Training Acc : 0.678, Run Time : 0.38
INFO:root:2019-05-11 02:27:17, Epoch : 1, Step : 4997, Training Loss : 0.70090, Training Acc : 0.600, Run Time : 0.82
INFO:root:2019-05-11 02:27:26, Epoch : 1, Step : 4998, Training Loss : 0.56885, Training Acc : 0.683, Run Time : 8.31
INFO:root:2019-05-11 02:27:26, Epoch : 1, Step : 4999, Training Loss : 0.63292, Training Acc : 0.672, Run Time : 0.47
INFO:root:2019-05-11 02:27:27, Epoch : 1, Step : 5000, Training Loss : 0.53486, Training Acc : 0.733, Run Time : 0.42
INFO:root:2019-05-11 02:27:37, Epoch : 1, Step : 5001, Training Loss : 0.69074, Training Acc : 0.622, Run Time : 9.88
INFO:root:2019-05-11 02:27:37, Epoch : 1, Step : 5002, Training Loss : 0.78493, Training Acc : 0.544, Run Time : 0.41
INFO:root:2019-05-11 02:27:38, Epoch : 1, Step : 5003, Training Loss : 0.67819, Training Acc : 0.672, Run Time : 1.02
INFO:root:2019-05-11 02:27:49, Epoch : 1, Step : 5004, Training Loss : 1.07074, Training Acc : 0.394, Run Time : 11.27
INFO:root:2019-05-11 02:27:50, Epoch : 1, Step : 5005, Training Loss : 0.75948, Training Acc : 0.528, Run Time : 0.86
INFO:root:2019-05-11 02:27:51, Epoch : 1, Step : 5006, Training Loss : 0.90385, Training Acc : 0.428, Run Time : 0.94
INFO:root:2019-05-11 02:27:57, Epoch : 1, Step : 5007, Training Loss : 0.88367, Training Acc : 0.500, Run Time : 6.33
INFO:root:2019-05-11 02:27:59, Epoch : 1, Step : 5008, Training Loss : 0.70229, Training Acc : 0.650, Run Time : 1.38
INFO:root:2019-05-11 02:28:00, Epoch : 1, Step : 5009, Training Loss : 0.76263, Training Acc : 0.506, Run Time : 0.94
INFO:root:2019-05-11 02:28:05, Epoch : 1, Step : 5010, Training Loss : 0.67409, Training Acc : 0.606, Run Time : 5.68
INFO:root:2019-05-11 02:28:06, Epoch : 1, Step : 5011, Training Loss : 0.61695, Training Acc : 0.694, Run Time : 0.43
INFO:root:2019-05-11 02:28:06, Epoch : 1, Step : 5012, Training Loss : 0.67224, Training Acc : 0.606, Run Time : 0.37
INFO:root:2019-05-11 02:28:07, Epoch : 1, Step : 5013, Training Loss : 0.63917, Training Acc : 0.633, Run Time : 0.39
INFO:root:2019-05-11 02:28:07, Epoch : 1, Step : 5014, Training Loss : 0.63824, Training Acc : 0.711, Run Time : 0.38
INFO:root:2019-05-11 02:28:07, Epoch : 1, Step : 5015, Training Loss : 0.79392, Training Acc : 0.489, Run Time : 0.49
INFO:root:2019-05-11 02:28:21, Epoch : 1, Step : 5016, Training Loss : 0.65611, Training Acc : 0.622, Run Time : 13.36
INFO:root:2019-05-11 02:28:22, Epoch : 1, Step : 5017, Training Loss : 0.70381, Training Acc : 0.556, Run Time : 1.14
INFO:root:2019-05-11 02:28:22, Epoch : 1, Step : 5018, Training Loss : 0.59861, Training Acc : 0.633, Run Time : 0.57
INFO:root:2019-05-11 02:28:33, Epoch : 1, Step : 5019, Training Loss : 0.63198, Training Acc : 0.656, Run Time : 10.22
INFO:root:2019-05-11 02:28:35, Epoch : 1, Step : 5020, Training Loss : 0.46978, Training Acc : 0.817, Run Time : 1.91
INFO:root:2019-05-11 02:28:35, Epoch : 1, Step : 5021, Training Loss : 0.63651, Training Acc : 0.622, Run Time : 0.43
INFO:root:2019-05-11 02:28:36, Epoch : 1, Step : 5022, Training Loss : 0.54250, Training Acc : 0.761, Run Time : 1.08
INFO:root:2019-05-11 02:28:46, Epoch : 1, Step : 5023, Training Loss : 0.55436, Training Acc : 0.694, Run Time : 9.42
INFO:root:2019-05-11 02:28:46, Epoch : 1, Step : 5024, Training Loss : 0.57796, Training Acc : 0.678, Run Time : 0.82
INFO:root:2019-05-11 02:28:47, Epoch : 1, Step : 5025, Training Loss : 0.57762, Training Acc : 0.661, Run Time : 0.37
INFO:root:2019-05-11 02:28:47, Epoch : 1, Step : 5026, Training Loss : 0.49022, Training Acc : 0.767, Run Time : 0.44
INFO:root:2019-05-11 02:28:58, Epoch : 1, Step : 5027, Training Loss : 0.42754, Training Acc : 0.839, Run Time : 10.76
INFO:root:2019-05-11 02:29:01, Epoch : 1, Step : 5028, Training Loss : 0.47367, Training Acc : 0.811, Run Time : 2.87
INFO:root:2019-05-11 02:29:01, Epoch : 1, Step : 5029, Training Loss : 0.52952, Training Acc : 0.678, Run Time : 0.61
INFO:root:2019-05-11 02:29:02, Epoch : 1, Step : 5030, Training Loss : 0.69698, Training Acc : 0.650, Run Time : 0.38
INFO:root:2019-05-11 02:29:02, Epoch : 1, Step : 5031, Training Loss : 0.45231, Training Acc : 0.811, Run Time : 0.38
INFO:root:2019-05-11 02:29:03, Epoch : 1, Step : 5032, Training Loss : 0.50929, Training Acc : 0.817, Run Time : 0.67
INFO:root:2019-05-11 02:29:09, Epoch : 1, Step : 5033, Training Loss : 0.51903, Training Acc : 0.717, Run Time : 6.13
INFO:root:2019-05-11 02:29:09, Epoch : 1, Step : 5034, Training Loss : 0.49977, Training Acc : 0.733, Run Time : 0.44
INFO:root:2019-05-11 02:29:10, Epoch : 1, Step : 5035, Training Loss : 0.51945, Training Acc : 0.806, Run Time : 0.38
INFO:root:2019-05-11 02:29:11, Epoch : 1, Step : 5036, Training Loss : 0.52318, Training Acc : 0.800, Run Time : 1.24
INFO:root:2019-05-11 02:29:22, Epoch : 1, Step : 5037, Training Loss : 0.42955, Training Acc : 0.828, Run Time : 10.94
INFO:root:2019-05-11 02:29:22, Epoch : 1, Step : 5038, Training Loss : 0.37334, Training Acc : 0.883, Run Time : 0.42
INFO:root:2019-05-11 02:29:23, Epoch : 1, Step : 5039, Training Loss : 0.41194, Training Acc : 0.833, Run Time : 0.37
INFO:root:2019-05-11 02:29:24, Epoch : 1, Step : 5040, Training Loss : 0.39101, Training Acc : 0.828, Run Time : 1.05
INFO:root:2019-05-11 02:29:34, Epoch : 1, Step : 5041, Training Loss : 0.44552, Training Acc : 0.789, Run Time : 9.77
INFO:root:2019-05-11 02:29:34, Epoch : 1, Step : 5042, Training Loss : 0.46099, Training Acc : 0.767, Run Time : 0.42
INFO:root:2019-05-11 02:29:35, Epoch : 1, Step : 5043, Training Loss : 0.30494, Training Acc : 0.867, Run Time : 0.67
INFO:root:2019-05-11 02:29:36, Epoch : 1, Step : 5044, Training Loss : 0.36445, Training Acc : 0.867, Run Time : 1.48
INFO:root:2019-05-11 02:29:39, Epoch : 1, Step : 5045, Training Loss : 0.55128, Training Acc : 0.744, Run Time : 2.58
INFO:root:2019-05-11 02:29:39, Epoch : 1, Step : 5046, Training Loss : 0.26002, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 02:29:40, Epoch : 1, Step : 5047, Training Loss : 0.32099, Training Acc : 0.906, Run Time : 0.37
INFO:root:2019-05-11 02:29:41, Epoch : 1, Step : 5048, Training Loss : 0.52639, Training Acc : 0.717, Run Time : 1.33
INFO:root:2019-05-11 02:29:49, Epoch : 1, Step : 5049, Training Loss : 0.51263, Training Acc : 0.728, Run Time : 8.23
INFO:root:2019-05-11 02:29:49, Epoch : 1, Step : 5050, Training Loss : 0.31654, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-11 02:29:50, Epoch : 1, Step : 5051, Training Loss : 0.43259, Training Acc : 0.761, Run Time : 0.38
INFO:root:2019-05-11 02:29:52, Epoch : 1, Step : 5052, Training Loss : 0.28824, Training Acc : 0.911, Run Time : 1.85
INFO:root:2019-05-11 02:30:01, Epoch : 1, Step : 5053, Training Loss : 0.44148, Training Acc : 0.772, Run Time : 9.01
INFO:root:2019-05-11 02:30:01, Epoch : 1, Step : 5054, Training Loss : 0.36046, Training Acc : 0.833, Run Time : 0.42
INFO:root:2019-05-11 02:30:02, Epoch : 1, Step : 5055, Training Loss : 0.31703, Training Acc : 0.872, Run Time : 0.39
INFO:root:2019-05-11 02:30:02, Epoch : 1, Step : 5056, Training Loss : 0.31510, Training Acc : 0.889, Run Time : 0.57
INFO:root:2019-05-11 02:30:14, Epoch : 1, Step : 5057, Training Loss : 0.48612, Training Acc : 0.761, Run Time : 11.63
INFO:root:2019-05-11 02:30:14, Epoch : 1, Step : 5058, Training Loss : 0.31594, Training Acc : 0.900, Run Time : 0.48
INFO:root:2019-05-11 02:30:15, Epoch : 1, Step : 5059, Training Loss : 0.34123, Training Acc : 0.867, Run Time : 0.41
INFO:root:2019-05-11 02:30:16, Epoch : 1, Step : 5060, Training Loss : 0.33334, Training Acc : 0.856, Run Time : 1.45
INFO:root:2019-05-11 02:30:24, Epoch : 1, Step : 5061, Training Loss : 0.30001, Training Acc : 0.872, Run Time : 8.20
INFO:root:2019-05-11 02:30:25, Epoch : 1, Step : 5062, Training Loss : 0.29256, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-11 02:30:25, Epoch : 1, Step : 5063, Training Loss : 0.35056, Training Acc : 0.894, Run Time : 0.59
INFO:root:2019-05-11 02:30:26, Epoch : 1, Step : 5064, Training Loss : 0.71166, Training Acc : 0.628, Run Time : 0.53
INFO:root:2019-05-11 02:30:36, Epoch : 1, Step : 5065, Training Loss : 0.36863, Training Acc : 0.839, Run Time : 10.02
INFO:root:2019-05-11 02:30:37, Epoch : 1, Step : 5066, Training Loss : 0.25837, Training Acc : 0.906, Run Time : 0.73
INFO:root:2019-05-11 02:30:38, Epoch : 1, Step : 5067, Training Loss : 0.28500, Training Acc : 0.894, Run Time : 1.67
INFO:root:2019-05-11 02:30:49, Epoch : 1, Step : 5068, Training Loss : 0.21966, Training Acc : 0.933, Run Time : 10.47
INFO:root:2019-05-11 02:30:49, Epoch : 1, Step : 5069, Training Loss : 0.30177, Training Acc : 0.867, Run Time : 0.42
INFO:root:2019-05-11 02:30:50, Epoch : 1, Step : 5070, Training Loss : 0.27512, Training Acc : 0.894, Run Time : 0.42
INFO:root:2019-05-11 02:30:50, Epoch : 1, Step : 5071, Training Loss : 0.21603, Training Acc : 0.939, Run Time : 0.40
INFO:root:2019-05-11 02:30:51, Epoch : 1, Step : 5072, Training Loss : 0.31094, Training Acc : 0.861, Run Time : 1.34
INFO:root:2019-05-11 02:31:03, Epoch : 1, Step : 5073, Training Loss : 0.36419, Training Acc : 0.856, Run Time : 12.09
INFO:root:2019-05-11 02:31:04, Epoch : 1, Step : 5074, Training Loss : 0.33352, Training Acc : 0.889, Run Time : 0.74
INFO:root:2019-05-11 02:31:05, Epoch : 1, Step : 5075, Training Loss : 0.31941, Training Acc : 0.861, Run Time : 0.74
INFO:root:2019-05-11 02:31:19, Epoch : 1, Step : 5076, Training Loss : 0.28261, Training Acc : 0.906, Run Time : 13.86
INFO:root:2019-05-11 02:31:20, Epoch : 1, Step : 5077, Training Loss : 0.52532, Training Acc : 0.789, Run Time : 1.47
INFO:root:2019-05-11 02:31:21, Epoch : 1, Step : 5078, Training Loss : 0.31030, Training Acc : 0.850, Run Time : 1.09
INFO:root:2019-05-11 02:31:27, Epoch : 1, Step : 5079, Training Loss : 0.50841, Training Acc : 0.800, Run Time : 5.41
INFO:root:2019-05-11 02:31:37, Epoch : 1, Step : 5080, Training Loss : 0.22980, Training Acc : 0.922, Run Time : 10.03
INFO:root:2019-05-11 02:31:41, Epoch : 1, Step : 5081, Training Loss : 0.32778, Training Acc : 0.850, Run Time : 3.91
INFO:root:2019-05-11 02:32:03, Epoch : 1, Step : 5082, Training Loss : 0.23039, Training Acc : 0.917, Run Time : 21.91
INFO:root:2019-05-11 02:32:04, Epoch : 1, Step : 5083, Training Loss : 0.29307, Training Acc : 0.889, Run Time : 1.81
INFO:root:2019-05-11 02:32:05, Epoch : 1, Step : 5084, Training Loss : 0.55539, Training Acc : 0.706, Run Time : 0.41
INFO:root:2019-05-11 02:32:05, Epoch : 1, Step : 5085, Training Loss : 0.50859, Training Acc : 0.756, Run Time : 0.50
INFO:root:2019-05-11 02:32:06, Epoch : 1, Step : 5086, Training Loss : 0.35210, Training Acc : 0.844, Run Time : 0.54
INFO:root:2019-05-11 02:32:07, Epoch : 1, Step : 5087, Training Loss : 0.47241, Training Acc : 0.783, Run Time : 0.79
INFO:root:2019-05-11 02:32:15, Epoch : 1, Step : 5088, Training Loss : 0.43359, Training Acc : 0.778, Run Time : 8.59
INFO:root:2019-05-11 02:32:16, Epoch : 1, Step : 5089, Training Loss : 0.31212, Training Acc : 0.856, Run Time : 1.01
INFO:root:2019-05-11 02:32:17, Epoch : 1, Step : 5090, Training Loss : 0.27242, Training Acc : 0.906, Run Time : 0.86
INFO:root:2019-05-11 02:32:28, Epoch : 1, Step : 5091, Training Loss : 0.43586, Training Acc : 0.822, Run Time : 11.03
INFO:root:2019-05-11 02:32:29, Epoch : 1, Step : 5092, Training Loss : 0.20613, Training Acc : 0.944, Run Time : 0.47
INFO:root:2019-05-11 02:32:29, Epoch : 1, Step : 5093, Training Loss : 0.47463, Training Acc : 0.794, Run Time : 0.37
INFO:root:2019-05-11 02:32:31, Epoch : 1, Step : 5094, Training Loss : 0.46016, Training Acc : 0.811, Run Time : 1.67
INFO:root:2019-05-11 02:32:41, Epoch : 1, Step : 5095, Training Loss : 0.33521, Training Acc : 0.878, Run Time : 10.56
INFO:root:2019-05-11 02:32:42, Epoch : 1, Step : 5096, Training Loss : 0.23984, Training Acc : 0.894, Run Time : 0.40
INFO:root:2019-05-11 02:32:42, Epoch : 1, Step : 5097, Training Loss : 0.30688, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-11 02:32:42, Epoch : 1, Step : 5098, Training Loss : 0.28619, Training Acc : 0.861, Run Time : 0.57
INFO:root:2019-05-11 02:32:56, Epoch : 1, Step : 5099, Training Loss : 0.34569, Training Acc : 0.822, Run Time : 13.37
INFO:root:2019-05-11 02:32:56, Epoch : 1, Step : 5100, Training Loss : 0.33159, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-11 02:33:10, Epoch : 1, Step : 5101, Training Loss : 0.49670, Training Acc : 0.739, Run Time : 13.70
INFO:root:2019-05-11 02:33:11, Epoch : 1, Step : 5102, Training Loss : 0.37520, Training Acc : 0.806, Run Time : 0.69
INFO:root:2019-05-11 02:33:12, Epoch : 1, Step : 5103, Training Loss : 0.33382, Training Acc : 0.833, Run Time : 1.46
INFO:root:2019-05-11 02:33:22, Epoch : 1, Step : 5104, Training Loss : 0.29300, Training Acc : 0.894, Run Time : 10.27
INFO:root:2019-05-11 02:33:23, Epoch : 1, Step : 5105, Training Loss : 0.47985, Training Acc : 0.733, Run Time : 0.93
INFO:root:2019-05-11 02:33:24, Epoch : 1, Step : 5106, Training Loss : 0.39405, Training Acc : 0.822, Run Time : 0.38
INFO:root:2019-05-11 02:33:25, Epoch : 1, Step : 5107, Training Loss : 0.36112, Training Acc : 0.833, Run Time : 1.75
INFO:root:2019-05-11 02:33:46, Epoch : 1, Step : 5108, Training Loss : 0.52100, Training Acc : 0.694, Run Time : 20.05
INFO:root:2019-05-11 02:33:51, Epoch : 1, Step : 5109, Training Loss : 0.54968, Training Acc : 0.717, Run Time : 5.65
INFO:root:2019-05-11 02:33:52, Epoch : 1, Step : 5110, Training Loss : 0.38749, Training Acc : 0.772, Run Time : 0.55
INFO:root:2019-05-11 02:34:11, Epoch : 1, Step : 5111, Training Loss : 0.49771, Training Acc : 0.739, Run Time : 18.95
INFO:root:2019-05-11 02:34:13, Epoch : 1, Step : 5112, Training Loss : 0.43522, Training Acc : 0.772, Run Time : 2.47
INFO:root:2019-05-11 02:34:14, Epoch : 1, Step : 5113, Training Loss : 0.33645, Training Acc : 0.856, Run Time : 1.10
INFO:root:2019-05-11 02:34:23, Epoch : 1, Step : 5114, Training Loss : 0.46309, Training Acc : 0.806, Run Time : 9.06
INFO:root:2019-05-11 02:34:25, Epoch : 1, Step : 5115, Training Loss : 0.48213, Training Acc : 0.711, Run Time : 1.42
INFO:root:2019-05-11 02:34:42, Epoch : 1, Step : 5116, Training Loss : 0.45043, Training Acc : 0.800, Run Time : 17.22
INFO:root:2019-05-11 02:34:44, Epoch : 1, Step : 5117, Training Loss : 0.53168, Training Acc : 0.744, Run Time : 1.97
INFO:root:2019-05-11 02:34:44, Epoch : 1, Step : 5118, Training Loss : 0.53422, Training Acc : 0.694, Run Time : 0.38
INFO:root:2019-05-11 02:34:51, Epoch : 1, Step : 5119, Training Loss : 0.36255, Training Acc : 0.839, Run Time : 7.10
INFO:root:2019-05-11 02:34:58, Epoch : 1, Step : 5120, Training Loss : 0.53764, Training Acc : 0.750, Run Time : 7.09
INFO:root:2019-05-11 02:34:59, Epoch : 1, Step : 5121, Training Loss : 0.57357, Training Acc : 0.717, Run Time : 0.41
INFO:root:2019-05-11 02:35:14, Epoch : 1, Step : 5122, Training Loss : 0.28099, Training Acc : 0.894, Run Time : 15.43
INFO:root:2019-05-11 02:35:15, Epoch : 1, Step : 5123, Training Loss : 0.61678, Training Acc : 0.661, Run Time : 0.89
INFO:root:2019-05-11 02:35:16, Epoch : 1, Step : 5124, Training Loss : 0.62072, Training Acc : 0.722, Run Time : 0.51
INFO:root:2019-05-11 02:35:29, Epoch : 1, Step : 5125, Training Loss : 0.30387, Training Acc : 0.878, Run Time : 13.34
INFO:root:2019-05-11 02:35:30, Epoch : 1, Step : 5126, Training Loss : 0.56001, Training Acc : 0.689, Run Time : 1.08
INFO:root:2019-05-11 02:35:32, Epoch : 1, Step : 5127, Training Loss : 0.42944, Training Acc : 0.811, Run Time : 1.57
INFO:root:2019-05-11 02:35:44, Epoch : 1, Step : 5128, Training Loss : 0.90076, Training Acc : 0.550, Run Time : 11.82
INFO:root:2019-05-11 02:35:45, Epoch : 1, Step : 5129, Training Loss : 0.66045, Training Acc : 0.683, Run Time : 1.46
INFO:root:2019-05-11 02:36:00, Epoch : 1, Step : 5130, Training Loss : 0.71570, Training Acc : 0.694, Run Time : 15.34
INFO:root:2019-05-11 02:36:02, Epoch : 1, Step : 5131, Training Loss : 1.10825, Training Acc : 0.478, Run Time : 1.63
INFO:root:2019-05-11 02:36:02, Epoch : 1, Step : 5132, Training Loss : 0.64172, Training Acc : 0.622, Run Time : 0.40
INFO:root:2019-05-11 02:36:03, Epoch : 1, Step : 5133, Training Loss : 0.50895, Training Acc : 0.739, Run Time : 0.89
INFO:root:2019-05-11 02:36:15, Epoch : 1, Step : 5134, Training Loss : 0.51119, Training Acc : 0.733, Run Time : 11.60
INFO:root:2019-05-11 02:36:39, Epoch : 1, Step : 5135, Training Loss : 0.69579, Training Acc : 0.672, Run Time : 24.18
INFO:root:2019-05-11 02:36:44, Epoch : 1, Step : 5136, Training Loss : 0.44790, Training Acc : 0.800, Run Time : 5.31
INFO:root:2019-05-11 02:36:45, Epoch : 1, Step : 5137, Training Loss : 0.40114, Training Acc : 0.828, Run Time : 0.69
INFO:root:2019-05-11 02:37:11, Epoch : 1, Step : 5138, Training Loss : 0.29475, Training Acc : 0.906, Run Time : 25.78
INFO:root:2019-05-11 02:37:12, Epoch : 1, Step : 5139, Training Loss : 0.24909, Training Acc : 0.894, Run Time : 1.62
INFO:root:2019-05-11 02:37:13, Epoch : 1, Step : 5140, Training Loss : 0.42459, Training Acc : 0.806, Run Time : 0.39
INFO:root:2019-05-11 02:37:15, Epoch : 1, Step : 5141, Training Loss : 0.30996, Training Acc : 0.878, Run Time : 1.73
INFO:root:2019-05-11 02:37:25, Epoch : 1, Step : 5142, Training Loss : 0.40836, Training Acc : 0.850, Run Time : 10.30
INFO:root:2019-05-11 02:37:25, Epoch : 1, Step : 5143, Training Loss : 0.30176, Training Acc : 0.883, Run Time : 0.40
INFO:root:2019-05-11 02:37:26, Epoch : 1, Step : 5144, Training Loss : 0.41331, Training Acc : 0.828, Run Time : 0.58
INFO:root:2019-05-11 02:37:42, Epoch : 1, Step : 5145, Training Loss : 0.22698, Training Acc : 0.939, Run Time : 16.11
INFO:root:2019-05-11 02:37:44, Epoch : 1, Step : 5146, Training Loss : 0.28838, Training Acc : 0.917, Run Time : 1.72
INFO:root:2019-05-11 02:37:44, Epoch : 1, Step : 5147, Training Loss : 0.37018, Training Acc : 0.811, Run Time : 0.37
INFO:root:2019-05-11 02:37:45, Epoch : 1, Step : 5148, Training Loss : 0.32185, Training Acc : 0.872, Run Time : 1.34
INFO:root:2019-05-11 02:38:01, Epoch : 1, Step : 5149, Training Loss : 0.36735, Training Acc : 0.822, Run Time : 15.92
INFO:root:2019-05-11 02:38:12, Epoch : 1, Step : 5150, Training Loss : 0.45155, Training Acc : 0.767, Run Time : 10.81
INFO:root:2019-05-11 02:38:14, Epoch : 1, Step : 5151, Training Loss : 0.37100, Training Acc : 0.844, Run Time : 1.44
INFO:root:2019-05-11 02:38:29, Epoch : 1, Step : 5152, Training Loss : 0.43017, Training Acc : 0.789, Run Time : 15.01
INFO:root:2019-05-11 02:38:30, Epoch : 1, Step : 5153, Training Loss : 0.30765, Training Acc : 0.878, Run Time : 1.06
INFO:root:2019-05-11 02:38:31, Epoch : 1, Step : 5154, Training Loss : 0.40526, Training Acc : 0.806, Run Time : 1.44
INFO:root:2019-05-11 02:38:45, Epoch : 1, Step : 5155, Training Loss : 0.29320, Training Acc : 0.889, Run Time : 13.79
INFO:root:2019-05-11 02:38:47, Epoch : 1, Step : 5156, Training Loss : 0.44299, Training Acc : 0.794, Run Time : 2.05
INFO:root:2019-05-11 02:38:47, Epoch : 1, Step : 5157, Training Loss : 0.38257, Training Acc : 0.822, Run Time : 0.45
INFO:root:2019-05-11 02:38:48, Epoch : 1, Step : 5158, Training Loss : 0.45768, Training Acc : 0.772, Run Time : 1.06
INFO:root:2019-05-11 02:38:59, Epoch : 1, Step : 5159, Training Loss : 0.62076, Training Acc : 0.694, Run Time : 10.76
INFO:root:2019-05-11 02:39:00, Epoch : 1, Step : 5160, Training Loss : 0.63796, Training Acc : 0.722, Run Time : 0.44
INFO:root:2019-05-11 02:39:00, Epoch : 1, Step : 5161, Training Loss : 0.41045, Training Acc : 0.806, Run Time : 0.39
INFO:root:2019-05-11 02:39:12, Epoch : 1, Step : 5162, Training Loss : 0.54952, Training Acc : 0.756, Run Time : 11.79
INFO:root:2019-05-11 02:39:16, Epoch : 1, Step : 5163, Training Loss : 0.47979, Training Acc : 0.772, Run Time : 4.03
INFO:root:2019-05-11 02:39:17, Epoch : 1, Step : 5164, Training Loss : 0.43136, Training Acc : 0.744, Run Time : 1.08
INFO:root:2019-05-11 02:39:30, Epoch : 1, Step : 5165, Training Loss : 0.36370, Training Acc : 0.822, Run Time : 12.95
INFO:root:2019-05-11 02:39:31, Epoch : 1, Step : 5166, Training Loss : 0.29197, Training Acc : 0.883, Run Time : 0.74
INFO:root:2019-05-11 02:39:31, Epoch : 1, Step : 5167, Training Loss : 0.25795, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-11 02:39:43, Epoch : 1, Step : 5168, Training Loss : 0.32195, Training Acc : 0.878, Run Time : 11.88
INFO:root:2019-05-11 02:39:44, Epoch : 1, Step : 5169, Training Loss : 0.35708, Training Acc : 0.844, Run Time : 0.84
INFO:root:2019-05-11 02:39:44, Epoch : 1, Step : 5170, Training Loss : 0.40850, Training Acc : 0.800, Run Time : 0.41
INFO:root:2019-05-11 02:39:46, Epoch : 1, Step : 5171, Training Loss : 0.35881, Training Acc : 0.872, Run Time : 1.80
INFO:root:2019-05-11 02:40:00, Epoch : 1, Step : 5172, Training Loss : 0.23165, Training Acc : 0.917, Run Time : 13.62
INFO:root:2019-05-11 02:40:03, Epoch : 1, Step : 5173, Training Loss : 0.27542, Training Acc : 0.922, Run Time : 3.94
INFO:root:2019-05-11 02:40:08, Epoch : 1, Step : 5174, Training Loss : 0.37023, Training Acc : 0.839, Run Time : 5.02
INFO:root:2019-05-11 02:40:18, Epoch : 1, Step : 5175, Training Loss : 0.28768, Training Acc : 0.900, Run Time : 9.56
INFO:root:2019-05-11 02:40:19, Epoch : 1, Step : 5176, Training Loss : 0.47137, Training Acc : 0.844, Run Time : 1.23
INFO:root:2019-05-11 02:40:32, Epoch : 1, Step : 5177, Training Loss : 0.39344, Training Acc : 0.794, Run Time : 12.92
INFO:root:2019-05-11 02:40:33, Epoch : 1, Step : 5178, Training Loss : 0.64535, Training Acc : 0.700, Run Time : 0.43
INFO:root:2019-05-11 02:40:47, Epoch : 1, Step : 5179, Training Loss : 0.29857, Training Acc : 0.889, Run Time : 14.52
INFO:root:2019-05-11 02:41:12, Epoch : 1, Step : 5180, Training Loss : 0.25781, Training Acc : 0.917, Run Time : 24.58
INFO:root:2019-05-11 02:41:20, Epoch : 1, Step : 5181, Training Loss : 0.51129, Training Acc : 0.689, Run Time : 7.89
INFO:root:2019-05-11 02:41:21, Epoch : 1, Step : 5182, Training Loss : 0.27830, Training Acc : 0.894, Run Time : 1.44
INFO:root:2019-05-11 02:41:35, Epoch : 1, Step : 5183, Training Loss : 0.40765, Training Acc : 0.806, Run Time : 13.81
INFO:root:2019-05-11 02:41:36, Epoch : 1, Step : 5184, Training Loss : 0.25628, Training Acc : 0.922, Run Time : 0.79
INFO:root:2019-05-11 02:41:36, Epoch : 1, Step : 5185, Training Loss : 0.35075, Training Acc : 0.850, Run Time : 0.59
INFO:root:2019-05-11 02:41:47, Epoch : 1, Step : 5186, Training Loss : 0.29069, Training Acc : 0.878, Run Time : 10.97
INFO:root:2019-05-11 02:41:48, Epoch : 1, Step : 5187, Training Loss : 0.31155, Training Acc : 0.878, Run Time : 0.90
INFO:root:2019-05-11 02:41:49, Epoch : 1, Step : 5188, Training Loss : 0.32053, Training Acc : 0.828, Run Time : 0.43
INFO:root:2019-05-11 02:41:50, Epoch : 1, Step : 5189, Training Loss : 0.29063, Training Acc : 0.883, Run Time : 1.47
INFO:root:2019-05-11 02:42:00, Epoch : 1, Step : 5190, Training Loss : 0.35303, Training Acc : 0.839, Run Time : 9.55
INFO:root:2019-05-11 02:42:00, Epoch : 1, Step : 5191, Training Loss : 0.41555, Training Acc : 0.794, Run Time : 0.69
INFO:root:2019-05-11 02:42:02, Epoch : 1, Step : 5192, Training Loss : 0.41404, Training Acc : 0.833, Run Time : 1.79
INFO:root:2019-05-11 02:42:14, Epoch : 1, Step : 5193, Training Loss : 0.40009, Training Acc : 0.817, Run Time : 11.52
INFO:root:2019-05-11 02:42:14, Epoch : 1, Step : 5194, Training Loss : 0.27742, Training Acc : 0.883, Run Time : 0.55
INFO:root:2019-05-11 02:42:16, Epoch : 1, Step : 5195, Training Loss : 0.33059, Training Acc : 0.867, Run Time : 1.64
INFO:root:2019-05-11 02:42:30, Epoch : 1, Step : 5196, Training Loss : 0.32743, Training Acc : 0.872, Run Time : 14.42
INFO:root:2019-05-11 02:42:44, Epoch : 1, Step : 5197, Training Loss : 0.29335, Training Acc : 0.878, Run Time : 13.89
INFO:root:2019-05-11 02:42:46, Epoch : 1, Step : 5198, Training Loss : 0.33148, Training Acc : 0.850, Run Time : 1.64
INFO:root:2019-05-11 02:43:03, Epoch : 1, Step : 5199, Training Loss : 0.48836, Training Acc : 0.794, Run Time : 17.05
INFO:root:2019-05-11 02:43:04, Epoch : 1, Step : 5200, Training Loss : 0.64639, Training Acc : 0.656, Run Time : 0.75
INFO:root:2019-05-11 02:43:17, Epoch : 1, Step : 5201, Training Loss : 1.06476, Training Acc : 0.544, Run Time : 13.42
INFO:root:2019-05-11 02:43:18, Epoch : 1, Step : 5202, Training Loss : 0.85057, Training Acc : 0.611, Run Time : 0.81
INFO:root:2019-05-11 02:43:18, Epoch : 1, Step : 5203, Training Loss : 0.90127, Training Acc : 0.561, Run Time : 0.60
INFO:root:2019-05-11 02:43:34, Epoch : 1, Step : 5204, Training Loss : 0.88171, Training Acc : 0.633, Run Time : 15.70
INFO:root:2019-05-11 02:43:35, Epoch : 1, Step : 5205, Training Loss : 0.74350, Training Acc : 0.650, Run Time : 0.78
INFO:root:2019-05-11 02:43:35, Epoch : 1, Step : 5206, Training Loss : 0.42734, Training Acc : 0.833, Run Time : 0.41
INFO:root:2019-05-11 02:43:37, Epoch : 1, Step : 5207, Training Loss : 0.55231, Training Acc : 0.700, Run Time : 1.62
INFO:root:2019-05-11 02:43:50, Epoch : 1, Step : 5208, Training Loss : 0.44509, Training Acc : 0.756, Run Time : 13.33
INFO:root:2019-05-11 02:43:51, Epoch : 1, Step : 5209, Training Loss : 0.34748, Training Acc : 0.839, Run Time : 0.86
INFO:root:2019-05-11 02:43:52, Epoch : 1, Step : 5210, Training Loss : 0.75834, Training Acc : 0.633, Run Time : 0.95
INFO:root:2019-05-11 02:44:05, Epoch : 1, Step : 5211, Training Loss : 0.80596, Training Acc : 0.617, Run Time : 13.32
INFO:root:2019-05-11 02:44:07, Epoch : 1, Step : 5212, Training Loss : 0.58352, Training Acc : 0.706, Run Time : 1.29
INFO:root:2019-05-11 02:44:07, Epoch : 1, Step : 5213, Training Loss : 0.54105, Training Acc : 0.706, Run Time : 0.37
INFO:root:2019-05-11 02:44:08, Epoch : 1, Step : 5214, Training Loss : 0.61004, Training Acc : 0.733, Run Time : 1.30
INFO:root:2019-05-11 02:44:19, Epoch : 1, Step : 5215, Training Loss : 0.75638, Training Acc : 0.639, Run Time : 10.96
INFO:root:2019-05-11 02:44:21, Epoch : 1, Step : 5216, Training Loss : 0.45990, Training Acc : 0.761, Run Time : 1.48
INFO:root:2019-05-11 02:44:34, Epoch : 1, Step : 5217, Training Loss : 0.54260, Training Acc : 0.722, Run Time : 12.85
INFO:root:2019-05-11 02:44:35, Epoch : 1, Step : 5218, Training Loss : 0.37458, Training Acc : 0.817, Run Time : 1.02
INFO:root:2019-05-11 02:44:36, Epoch : 1, Step : 5219, Training Loss : 0.42147, Training Acc : 0.817, Run Time : 1.52
INFO:root:2019-05-11 02:44:48, Epoch : 1, Step : 5220, Training Loss : 0.39807, Training Acc : 0.867, Run Time : 11.44
INFO:root:2019-05-11 02:44:49, Epoch : 1, Step : 5221, Training Loss : 0.43936, Training Acc : 0.794, Run Time : 1.42
INFO:root:2019-05-11 02:45:07, Epoch : 1, Step : 5222, Training Loss : 0.41682, Training Acc : 0.811, Run Time : 17.64
INFO:root:2019-05-11 02:45:16, Epoch : 1, Step : 5223, Training Loss : 0.38817, Training Acc : 0.817, Run Time : 9.83
INFO:root:2019-05-11 02:45:27, Epoch : 1, Step : 5224, Training Loss : 0.47756, Training Acc : 0.717, Run Time : 10.39
INFO:root:2019-05-11 02:45:28, Epoch : 1, Step : 5225, Training Loss : 0.51086, Training Acc : 0.733, Run Time : 1.00
INFO:root:2019-05-11 02:45:28, Epoch : 1, Step : 5226, Training Loss : 0.65026, Training Acc : 0.650, Run Time : 0.38
INFO:root:2019-05-11 02:45:29, Epoch : 1, Step : 5227, Training Loss : 0.63359, Training Acc : 0.683, Run Time : 0.39
INFO:root:2019-05-11 02:45:29, Epoch : 1, Step : 5228, Training Loss : 0.63601, Training Acc : 0.694, Run Time : 0.39
INFO:root:2019-05-11 02:45:42, Epoch : 1, Step : 5229, Training Loss : 0.54122, Training Acc : 0.783, Run Time : 12.56
INFO:root:2019-05-11 02:45:42, Epoch : 1, Step : 5230, Training Loss : 0.71409, Training Acc : 0.617, Run Time : 0.44
INFO:root:2019-05-11 02:45:42, Epoch : 1, Step : 5231, Training Loss : 0.70642, Training Acc : 0.656, Run Time : 0.42
INFO:root:2019-05-11 02:45:44, Epoch : 1, Step : 5232, Training Loss : 0.57084, Training Acc : 0.694, Run Time : 1.64
INFO:root:2019-05-11 02:45:52, Epoch : 1, Step : 5233, Training Loss : 0.47242, Training Acc : 0.811, Run Time : 7.47
INFO:root:2019-05-11 02:45:52, Epoch : 1, Step : 5234, Training Loss : 0.37935, Training Acc : 0.872, Run Time : 0.84
INFO:root:2019-05-11 02:45:54, Epoch : 1, Step : 5235, Training Loss : 0.44066, Training Acc : 0.806, Run Time : 1.59
INFO:root:2019-05-11 02:46:04, Epoch : 1, Step : 5236, Training Loss : 0.49057, Training Acc : 0.750, Run Time : 10.40
INFO:root:2019-05-11 02:46:13, Epoch : 1, Step : 5237, Training Loss : 0.48740, Training Acc : 0.756, Run Time : 8.84
INFO:root:2019-05-11 02:46:17, Epoch : 1, Step : 5238, Training Loss : 0.46513, Training Acc : 0.811, Run Time : 4.07
INFO:root:2019-05-11 02:46:18, Epoch : 1, Step : 5239, Training Loss : 0.37948, Training Acc : 0.800, Run Time : 0.38
INFO:root:2019-05-11 02:46:20, Epoch : 1, Step : 5240, Training Loss : 0.36952, Training Acc : 0.844, Run Time : 2.20
INFO:root:2019-05-11 02:46:43, Epoch : 1, Step : 5241, Training Loss : 0.41568, Training Acc : 0.817, Run Time : 23.51
INFO:root:2019-05-11 02:46:45, Epoch : 1, Step : 5242, Training Loss : 0.29747, Training Acc : 0.911, Run Time : 1.99
INFO:root:2019-05-11 02:46:46, Epoch : 1, Step : 5243, Training Loss : 0.35753, Training Acc : 0.806, Run Time : 0.55
INFO:root:2019-05-11 02:46:47, Epoch : 1, Step : 5244, Training Loss : 0.32341, Training Acc : 0.850, Run Time : 0.85
INFO:root:2019-05-11 02:47:01, Epoch : 1, Step : 5245, Training Loss : 0.22652, Training Acc : 0.928, Run Time : 13.84
INFO:root:2019-05-11 02:47:03, Epoch : 1, Step : 5246, Training Loss : 0.31963, Training Acc : 0.872, Run Time : 1.98
INFO:root:2019-05-11 02:47:03, Epoch : 1, Step : 5247, Training Loss : 0.26119, Training Acc : 0.906, Run Time : 0.63
INFO:root:2019-05-11 02:47:14, Epoch : 1, Step : 5248, Training Loss : 0.20920, Training Acc : 0.950, Run Time : 10.80
INFO:root:2019-05-11 02:47:14, Epoch : 1, Step : 5249, Training Loss : 0.66498, Training Acc : 0.650, Run Time : 0.49
INFO:root:2019-05-11 02:47:15, Epoch : 1, Step : 5250, Training Loss : 0.54847, Training Acc : 0.789, Run Time : 0.38
INFO:root:2019-05-11 02:47:28, Epoch : 1, Step : 5251, Training Loss : 0.58216, Training Acc : 0.700, Run Time : 12.65
INFO:root:2019-05-11 02:47:28, Epoch : 1, Step : 5252, Training Loss : 0.66995, Training Acc : 0.678, Run Time : 0.59
INFO:root:2019-05-11 02:47:28, Epoch : 1, Step : 5253, Training Loss : 0.80382, Training Acc : 0.617, Run Time : 0.39
INFO:root:2019-05-11 02:47:30, Epoch : 1, Step : 5254, Training Loss : 0.30258, Training Acc : 0.844, Run Time : 1.42
INFO:root:2019-05-11 02:47:42, Epoch : 1, Step : 5255, Training Loss : 0.34294, Training Acc : 0.839, Run Time : 11.94
INFO:root:2019-05-11 02:47:42, Epoch : 1, Step : 5256, Training Loss : 0.27429, Training Acc : 0.894, Run Time : 0.43
INFO:root:2019-05-11 02:47:43, Epoch : 1, Step : 5257, Training Loss : 0.27203, Training Acc : 0.872, Run Time : 0.37
INFO:root:2019-05-11 02:47:44, Epoch : 1, Step : 5258, Training Loss : 0.34127, Training Acc : 0.822, Run Time : 1.70
INFO:root:2019-05-11 02:48:03, Epoch : 1, Step : 5259, Training Loss : 0.37370, Training Acc : 0.833, Run Time : 18.70
INFO:root:2019-05-11 02:48:05, Epoch : 1, Step : 5260, Training Loss : 0.34552, Training Acc : 0.833, Run Time : 1.60
INFO:root:2019-05-11 02:48:05, Epoch : 1, Step : 5261, Training Loss : 0.40225, Training Acc : 0.856, Run Time : 0.81
INFO:root:2019-05-11 02:48:27, Epoch : 1, Step : 5262, Training Loss : 0.26584, Training Acc : 0.867, Run Time : 21.62
INFO:root:2019-05-11 02:48:29, Epoch : 1, Step : 5263, Training Loss : 0.27446, Training Acc : 0.911, Run Time : 1.97
INFO:root:2019-05-11 02:48:31, Epoch : 1, Step : 5264, Training Loss : 0.30988, Training Acc : 0.850, Run Time : 1.85
INFO:root:2019-05-11 02:48:42, Epoch : 1, Step : 5265, Training Loss : 0.22368, Training Acc : 0.900, Run Time : 11.22
INFO:root:2019-05-11 02:48:43, Epoch : 1, Step : 5266, Training Loss : 0.35540, Training Acc : 0.833, Run Time : 0.82
INFO:root:2019-05-11 02:48:55, Epoch : 1, Step : 5267, Training Loss : 0.35315, Training Acc : 0.833, Run Time : 11.89
INFO:root:2019-05-11 02:48:56, Epoch : 1, Step : 5268, Training Loss : 0.18884, Training Acc : 0.922, Run Time : 0.83
INFO:root:2019-05-11 02:48:57, Epoch : 1, Step : 5269, Training Loss : 0.31058, Training Acc : 0.867, Run Time : 1.25
INFO:root:2019-05-11 02:49:09, Epoch : 1, Step : 5270, Training Loss : 0.36387, Training Acc : 0.861, Run Time : 11.89
INFO:root:2019-05-11 02:49:25, Epoch : 1, Step : 5271, Training Loss : 0.31616, Training Acc : 0.883, Run Time : 15.97
INFO:root:2019-05-11 02:49:27, Epoch : 1, Step : 5272, Training Loss : 0.29119, Training Acc : 0.878, Run Time : 1.86
INFO:root:2019-05-11 02:49:27, Epoch : 1, Step : 5273, Training Loss : 0.31427, Training Acc : 0.844, Run Time : 0.37
INFO:root:2019-05-11 02:49:28, Epoch : 1, Step : 5274, Training Loss : 0.42750, Training Acc : 0.794, Run Time : 1.04
INFO:root:2019-05-11 02:49:42, Epoch : 1, Step : 5275, Training Loss : 0.22576, Training Acc : 0.906, Run Time : 13.93
INFO:root:2019-05-11 02:49:55, Epoch : 1, Step : 5276, Training Loss : 0.28045, Training Acc : 0.900, Run Time : 12.56
INFO:root:2019-05-11 02:50:01, Epoch : 1, Step : 5277, Training Loss : 0.31041, Training Acc : 0.844, Run Time : 6.87
INFO:root:2019-05-11 02:50:13, Epoch : 1, Step : 5278, Training Loss : 0.20188, Training Acc : 0.922, Run Time : 11.46
INFO:root:2019-05-11 02:50:14, Epoch : 1, Step : 5279, Training Loss : 0.27889, Training Acc : 0.894, Run Time : 0.66
INFO:root:2019-05-11 02:50:14, Epoch : 1, Step : 5280, Training Loss : 0.16008, Training Acc : 0.956, Run Time : 0.38
INFO:root:2019-05-11 02:50:15, Epoch : 1, Step : 5281, Training Loss : 0.28304, Training Acc : 0.878, Run Time : 1.44
INFO:root:2019-05-11 02:50:28, Epoch : 1, Step : 5282, Training Loss : 0.22071, Training Acc : 0.911, Run Time : 12.56
INFO:root:2019-05-11 02:50:28, Epoch : 1, Step : 5283, Training Loss : 0.34743, Training Acc : 0.817, Run Time : 0.49
INFO:root:2019-05-11 02:50:29, Epoch : 1, Step : 5284, Training Loss : 0.21719, Training Acc : 0.911, Run Time : 0.42
INFO:root:2019-05-11 02:50:31, Epoch : 1, Step : 5285, Training Loss : 0.15912, Training Acc : 0.956, Run Time : 1.93
INFO:root:2019-05-11 02:50:41, Epoch : 1, Step : 5286, Training Loss : 0.26174, Training Acc : 0.906, Run Time : 9.82
INFO:root:2019-05-11 02:50:41, Epoch : 1, Step : 5287, Training Loss : 0.18241, Training Acc : 0.939, Run Time : 0.40
INFO:root:2019-05-11 02:50:42, Epoch : 1, Step : 5288, Training Loss : 0.19061, Training Acc : 0.922, Run Time : 0.74
INFO:root:2019-05-11 02:50:51, Epoch : 1, Step : 5289, Training Loss : 0.19602, Training Acc : 0.939, Run Time : 9.47
INFO:root:2019-05-11 02:50:52, Epoch : 1, Step : 5290, Training Loss : 0.18499, Training Acc : 0.939, Run Time : 0.71
INFO:root:2019-05-11 02:50:53, Epoch : 1, Step : 5291, Training Loss : 0.19539, Training Acc : 0.933, Run Time : 0.67
INFO:root:2019-05-11 02:51:03, Epoch : 1, Step : 5292, Training Loss : 0.18807, Training Acc : 0.944, Run Time : 9.99
INFO:root:2019-05-11 02:51:03, Epoch : 1, Step : 5293, Training Loss : 0.23286, Training Acc : 0.933, Run Time : 0.73
INFO:root:2019-05-11 02:51:05, Epoch : 1, Step : 5294, Training Loss : 0.18891, Training Acc : 0.944, Run Time : 1.43
INFO:root:2019-05-11 02:51:15, Epoch : 1, Step : 5295, Training Loss : 0.27132, Training Acc : 0.883, Run Time : 10.70
INFO:root:2019-05-11 02:51:17, Epoch : 1, Step : 5296, Training Loss : 0.21932, Training Acc : 0.911, Run Time : 1.95
INFO:root:2019-05-11 02:51:29, Epoch : 1, Step : 5297, Training Loss : 0.27880, Training Acc : 0.878, Run Time : 11.90
INFO:root:2019-05-11 02:51:32, Epoch : 1, Step : 5298, Training Loss : 0.28499, Training Acc : 0.878, Run Time : 2.58
INFO:root:2019-05-11 02:51:43, Epoch : 1, Step : 5299, Training Loss : 0.20513, Training Acc : 0.911, Run Time : 11.08
INFO:root:2019-05-11 02:51:45, Epoch : 1, Step : 5300, Training Loss : 0.22181, Training Acc : 0.928, Run Time : 2.20
INFO:root:2019-05-11 02:51:59, Epoch : 1, Step : 5301, Training Loss : 0.20068, Training Acc : 0.922, Run Time : 13.98
INFO:root:2019-05-11 02:52:00, Epoch : 1, Step : 5302, Training Loss : 0.25506, Training Acc : 0.922, Run Time : 0.75
INFO:root:2019-05-11 02:52:02, Epoch : 1, Step : 5303, Training Loss : 0.24131, Training Acc : 0.900, Run Time : 1.72
INFO:root:2019-05-11 02:52:14, Epoch : 1, Step : 5304, Training Loss : 0.27065, Training Acc : 0.878, Run Time : 12.04
INFO:root:2019-05-11 02:52:14, Epoch : 1, Step : 5305, Training Loss : 0.26595, Training Acc : 0.872, Run Time : 0.41
INFO:root:2019-05-11 02:52:14, Epoch : 1, Step : 5306, Training Loss : 0.23571, Training Acc : 0.911, Run Time : 0.45
INFO:root:2019-05-11 02:52:15, Epoch : 1, Step : 5307, Training Loss : 0.29540, Training Acc : 0.856, Run Time : 0.38
INFO:root:2019-05-11 02:52:16, Epoch : 1, Step : 5308, Training Loss : 0.26427, Training Acc : 0.850, Run Time : 1.41
INFO:root:2019-05-11 02:52:26, Epoch : 1, Step : 5309, Training Loss : 0.31163, Training Acc : 0.861, Run Time : 10.17
INFO:root:2019-05-11 02:52:27, Epoch : 1, Step : 5310, Training Loss : 0.21634, Training Acc : 0.906, Run Time : 0.67
INFO:root:2019-05-11 02:52:29, Epoch : 1, Step : 5311, Training Loss : 0.30843, Training Acc : 0.889, Run Time : 1.71
INFO:root:2019-05-11 02:52:39, Epoch : 1, Step : 5312, Training Loss : 0.27173, Training Acc : 0.861, Run Time : 10.13
INFO:root:2019-05-11 02:52:41, Epoch : 1, Step : 5313, Training Loss : 0.21970, Training Acc : 0.906, Run Time : 2.04
INFO:root:2019-05-11 02:52:52, Epoch : 1, Step : 5314, Training Loss : 0.18714, Training Acc : 0.933, Run Time : 10.67
INFO:root:2019-05-11 02:52:53, Epoch : 1, Step : 5315, Training Loss : 0.19791, Training Acc : 0.917, Run Time : 0.94
INFO:root:2019-05-11 02:52:53, Epoch : 1, Step : 5316, Training Loss : 0.19838, Training Acc : 0.906, Run Time : 0.43
INFO:root:2019-05-11 02:52:54, Epoch : 1, Step : 5317, Training Loss : 0.27822, Training Acc : 0.861, Run Time : 1.32
INFO:root:2019-05-11 02:53:04, Epoch : 1, Step : 5318, Training Loss : 0.22692, Training Acc : 0.883, Run Time : 10.10
INFO:root:2019-05-11 02:53:05, Epoch : 1, Step : 5319, Training Loss : 0.25967, Training Acc : 0.867, Run Time : 0.47
INFO:root:2019-05-11 02:53:05, Epoch : 1, Step : 5320, Training Loss : 0.27829, Training Acc : 0.861, Run Time : 0.42
INFO:root:2019-05-11 02:53:06, Epoch : 1, Step : 5321, Training Loss : 0.26760, Training Acc : 0.883, Run Time : 0.91
INFO:root:2019-05-11 02:53:19, Epoch : 1, Step : 5322, Training Loss : 0.24395, Training Acc : 0.878, Run Time : 13.14
INFO:root:2019-05-11 02:53:21, Epoch : 1, Step : 5323, Training Loss : 0.28539, Training Acc : 0.889, Run Time : 2.06
INFO:root:2019-05-11 02:53:36, Epoch : 1, Step : 5324, Training Loss : 0.27527, Training Acc : 0.883, Run Time : 14.29
INFO:root:2019-05-11 02:53:38, Epoch : 1, Step : 5325, Training Loss : 0.40204, Training Acc : 0.828, Run Time : 2.15
INFO:root:2019-05-11 02:54:05, Epoch : 1, Step : 5326, Training Loss : 0.25194, Training Acc : 0.867, Run Time : 27.56
INFO:root:2019-05-11 02:54:12, Epoch : 1, Step : 5327, Training Loss : 0.30362, Training Acc : 0.844, Run Time : 6.77
INFO:root:2019-05-11 02:54:25, Epoch : 1, Step : 5328, Training Loss : 0.29762, Training Acc : 0.839, Run Time : 13.09
INFO:root:2019-05-11 02:54:39, Epoch : 1, Step : 5329, Training Loss : 0.29640, Training Acc : 0.867, Run Time : 13.46
INFO:root:2019-05-11 02:54:51, Epoch : 1, Step : 5330, Training Loss : 0.41997, Training Acc : 0.794, Run Time : 12.28
INFO:root:2019-05-11 02:55:21, Epoch : 1, Step : 5331, Training Loss : 0.29770, Training Acc : 0.867, Run Time : 29.98
INFO:root:2019-05-11 02:55:23, Epoch : 1, Step : 5332, Training Loss : 0.21612, Training Acc : 0.911, Run Time : 1.74
INFO:root:2019-05-11 02:55:23, Epoch : 1, Step : 5333, Training Loss : 0.23080, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 02:55:25, Epoch : 1, Step : 5334, Training Loss : 0.24445, Training Acc : 0.894, Run Time : 1.60
INFO:root:2019-05-11 02:55:52, Epoch : 1, Step : 5335, Training Loss : 0.29562, Training Acc : 0.850, Run Time : 27.68
INFO:root:2019-05-11 02:56:16, Epoch : 1, Step : 5336, Training Loss : 0.28785, Training Acc : 0.844, Run Time : 23.43
INFO:root:2019-05-11 02:56:20, Epoch : 1, Step : 5337, Training Loss : 0.23234, Training Acc : 0.894, Run Time : 4.57
INFO:root:2019-05-11 02:56:21, Epoch : 1, Step : 5338, Training Loss : 0.27546, Training Acc : 0.861, Run Time : 0.47
INFO:root:2019-05-11 02:56:21, Epoch : 1, Step : 5339, Training Loss : 0.27242, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-11 02:56:22, Epoch : 1, Step : 5340, Training Loss : 0.31715, Training Acc : 0.844, Run Time : 0.80
INFO:root:2019-05-11 02:56:42, Epoch : 1, Step : 5341, Training Loss : 0.29562, Training Acc : 0.850, Run Time : 19.75
INFO:root:2019-05-11 02:56:44, Epoch : 1, Step : 5342, Training Loss : 0.26782, Training Acc : 0.883, Run Time : 1.71
INFO:root:2019-05-11 02:56:44, Epoch : 1, Step : 5343, Training Loss : 0.27335, Training Acc : 0.833, Run Time : 0.38
INFO:root:2019-05-11 02:57:02, Epoch : 1, Step : 5344, Training Loss : 0.25010, Training Acc : 0.856, Run Time : 18.53
INFO:root:2019-05-11 02:57:09, Epoch : 1, Step : 5345, Training Loss : 0.26658, Training Acc : 0.867, Run Time : 6.97
INFO:root:2019-05-11 02:57:10, Epoch : 1, Step : 5346, Training Loss : 0.33831, Training Acc : 0.806, Run Time : 0.50
INFO:root:2019-05-11 02:57:24, Epoch : 1, Step : 5347, Training Loss : 0.29780, Training Acc : 0.861, Run Time : 14.19
INFO:root:2019-05-11 02:57:26, Epoch : 1, Step : 5348, Training Loss : 0.26107, Training Acc : 0.856, Run Time : 1.55
INFO:root:2019-05-11 02:57:27, Epoch : 1, Step : 5349, Training Loss : 0.46232, Training Acc : 0.811, Run Time : 1.07
INFO:root:2019-05-11 02:57:41, Epoch : 1, Step : 5350, Training Loss : 0.42763, Training Acc : 0.789, Run Time : 14.14
INFO:root:2019-05-11 02:57:42, Epoch : 1, Step : 5351, Training Loss : 0.42055, Training Acc : 0.822, Run Time : 1.23
INFO:root:2019-05-11 02:57:56, Epoch : 1, Step : 5352, Training Loss : 0.57250, Training Acc : 0.722, Run Time : 13.60
INFO:root:2019-05-11 02:57:57, Epoch : 1, Step : 5353, Training Loss : 0.30635, Training Acc : 0.850, Run Time : 1.66
INFO:root:2019-05-11 02:57:59, Epoch : 1, Step : 5354, Training Loss : 0.49237, Training Acc : 0.806, Run Time : 1.55
INFO:root:2019-05-11 02:58:41, Epoch : 1, Step : 5355, Training Loss : 0.47687, Training Acc : 0.806, Run Time : 42.26
INFO:root:2019-05-11 02:58:52, Epoch : 1, Step : 5356, Training Loss : 0.47760, Training Acc : 0.783, Run Time : 10.41
INFO:root:2019-05-11 02:58:52, Epoch : 1, Step : 5357, Training Loss : 0.47560, Training Acc : 0.789, Run Time : 0.41
INFO:root:2019-05-11 02:58:52, Epoch : 1, Step : 5358, Training Loss : 0.60474, Training Acc : 0.722, Run Time : 0.39
INFO:root:2019-05-11 02:58:53, Epoch : 1, Step : 5359, Training Loss : 0.47263, Training Acc : 0.772, Run Time : 0.38
INFO:root:2019-05-11 02:58:54, Epoch : 1, Step : 5360, Training Loss : 0.52119, Training Acc : 0.767, Run Time : 0.99
INFO:root:2019-05-11 02:59:06, Epoch : 1, Step : 5361, Training Loss : 0.56218, Training Acc : 0.700, Run Time : 12.03
INFO:root:2019-05-11 02:59:06, Epoch : 1, Step : 5362, Training Loss : 0.42301, Training Acc : 0.783, Run Time : 0.70
INFO:root:2019-05-11 02:59:07, Epoch : 1, Step : 5363, Training Loss : 0.35524, Training Acc : 0.817, Run Time : 0.39
INFO:root:2019-05-11 02:59:22, Epoch : 1, Step : 5364, Training Loss : 0.42883, Training Acc : 0.794, Run Time : 15.53
INFO:root:2019-05-11 02:59:24, Epoch : 1, Step : 5365, Training Loss : 0.42797, Training Acc : 0.789, Run Time : 1.24
INFO:root:2019-05-11 02:59:24, Epoch : 1, Step : 5366, Training Loss : 0.41778, Training Acc : 0.833, Run Time : 0.42
INFO:root:2019-05-11 02:59:25, Epoch : 1, Step : 5367, Training Loss : 0.38544, Training Acc : 0.833, Run Time : 1.22
INFO:root:2019-05-11 02:59:36, Epoch : 1, Step : 5368, Training Loss : 0.44819, Training Acc : 0.778, Run Time : 10.40
INFO:root:2019-05-11 02:59:36, Epoch : 1, Step : 5369, Training Loss : 0.59129, Training Acc : 0.711, Run Time : 0.66
INFO:root:2019-05-11 02:59:37, Epoch : 1, Step : 5370, Training Loss : 0.64054, Training Acc : 0.739, Run Time : 0.42
INFO:root:2019-05-11 02:59:37, Epoch : 1, Step : 5371, Training Loss : 0.61110, Training Acc : 0.683, Run Time : 0.38
INFO:root:2019-05-11 02:59:47, Epoch : 1, Step : 5372, Training Loss : 0.58596, Training Acc : 0.728, Run Time : 9.97
INFO:root:2019-05-11 02:59:48, Epoch : 1, Step : 5373, Training Loss : 0.48148, Training Acc : 0.789, Run Time : 0.47
INFO:root:2019-05-11 02:59:48, Epoch : 1, Step : 5374, Training Loss : 0.44123, Training Acc : 0.778, Run Time : 0.38
INFO:root:2019-05-11 02:59:50, Epoch : 1, Step : 5375, Training Loss : 0.40185, Training Acc : 0.822, Run Time : 2.43
INFO:root:2019-05-11 03:00:05, Epoch : 1, Step : 5376, Training Loss : 0.52549, Training Acc : 0.772, Run Time : 14.74
INFO:root:2019-05-11 03:00:06, Epoch : 1, Step : 5377, Training Loss : 0.37421, Training Acc : 0.822, Run Time : 0.65
INFO:root:2019-05-11 03:00:08, Epoch : 1, Step : 5378, Training Loss : 0.39521, Training Acc : 0.794, Run Time : 1.72
INFO:root:2019-05-11 03:00:20, Epoch : 1, Step : 5379, Training Loss : 0.65552, Training Acc : 0.733, Run Time : 12.73
INFO:root:2019-05-11 03:00:21, Epoch : 1, Step : 5380, Training Loss : 0.34090, Training Acc : 0.850, Run Time : 0.80
INFO:root:2019-05-11 03:00:37, Epoch : 1, Step : 5381, Training Loss : 0.32907, Training Acc : 0.850, Run Time : 16.47
INFO:root:2019-05-11 03:01:10, Epoch : 1, Step : 5382, Training Loss : 0.57102, Training Acc : 0.794, Run Time : 32.43
INFO:root:2019-05-11 03:01:24, Epoch : 1, Step : 5383, Training Loss : 0.39292, Training Acc : 0.856, Run Time : 13.85
INFO:root:2019-05-11 03:01:26, Epoch : 1, Step : 5384, Training Loss : 0.54162, Training Acc : 0.761, Run Time : 1.87
INFO:root:2019-05-11 03:01:42, Epoch : 1, Step : 5385, Training Loss : 0.38206, Training Acc : 0.800, Run Time : 16.48
INFO:root:2019-05-11 03:01:43, Epoch : 1, Step : 5386, Training Loss : 0.32345, Training Acc : 0.822, Run Time : 1.35
INFO:root:2019-05-11 03:01:54, Epoch : 1, Step : 5387, Training Loss : 0.45492, Training Acc : 0.817, Run Time : 10.95
INFO:root:2019-05-11 03:02:07, Epoch : 1, Step : 5388, Training Loss : 0.35375, Training Acc : 0.817, Run Time : 12.75
INFO:root:2019-05-11 03:02:09, Epoch : 1, Step : 5389, Training Loss : 0.23316, Training Acc : 0.917, Run Time : 1.56
INFO:root:2019-05-11 03:02:09, Epoch : 1, Step : 5390, Training Loss : 0.28988, Training Acc : 0.872, Run Time : 0.41
INFO:root:2019-05-11 03:02:10, Epoch : 1, Step : 5391, Training Loss : 0.32757, Training Acc : 0.856, Run Time : 1.28
INFO:root:2019-05-11 03:02:22, Epoch : 1, Step : 5392, Training Loss : 0.46131, Training Acc : 0.811, Run Time : 11.80
INFO:root:2019-05-11 03:02:24, Epoch : 1, Step : 5393, Training Loss : 0.31844, Training Acc : 0.856, Run Time : 2.22
INFO:root:2019-05-11 03:02:37, Epoch : 1, Step : 5394, Training Loss : 0.30671, Training Acc : 0.900, Run Time : 12.97
INFO:root:2019-05-11 03:02:40, Epoch : 1, Step : 5395, Training Loss : 0.45039, Training Acc : 0.817, Run Time : 2.74
INFO:root:2019-05-11 03:02:52, Epoch : 1, Step : 5396, Training Loss : 0.30177, Training Acc : 0.883, Run Time : 11.67
INFO:root:2019-05-11 03:02:52, Epoch : 1, Step : 5397, Training Loss : 0.50603, Training Acc : 0.800, Run Time : 0.54
INFO:root:2019-05-11 03:02:53, Epoch : 1, Step : 5398, Training Loss : 0.47553, Training Acc : 0.806, Run Time : 0.60
INFO:root:2019-05-11 03:02:53, Epoch : 1, Step : 5399, Training Loss : 0.36789, Training Acc : 0.806, Run Time : 0.38
INFO:root:2019-05-11 03:02:55, Epoch : 1, Step : 5400, Training Loss : 0.29267, Training Acc : 0.872, Run Time : 1.54
INFO:root:2019-05-11 03:03:07, Epoch : 1, Step : 5401, Training Loss : 0.50197, Training Acc : 0.806, Run Time : 12.05
INFO:root:2019-05-11 03:03:07, Epoch : 1, Step : 5402, Training Loss : 0.48484, Training Acc : 0.778, Run Time : 0.42
INFO:root:2019-05-11 03:03:09, Epoch : 1, Step : 5403, Training Loss : 0.39069, Training Acc : 0.822, Run Time : 1.72
INFO:root:2019-05-11 03:03:22, Epoch : 1, Step : 5404, Training Loss : 0.37357, Training Acc : 0.833, Run Time : 12.43
INFO:root:2019-05-11 03:03:22, Epoch : 1, Step : 5405, Training Loss : 0.32632, Training Acc : 0.878, Run Time : 0.60
INFO:root:2019-05-11 03:03:23, Epoch : 1, Step : 5406, Training Loss : 0.42464, Training Acc : 0.839, Run Time : 0.69
INFO:root:2019-05-11 03:03:42, Epoch : 1, Step : 5407, Training Loss : 0.36202, Training Acc : 0.839, Run Time : 19.57
INFO:root:2019-05-11 03:03:44, Epoch : 1, Step : 5408, Training Loss : 0.27186, Training Acc : 0.861, Run Time : 1.51
INFO:root:2019-05-11 03:03:44, Epoch : 1, Step : 5409, Training Loss : 0.38048, Training Acc : 0.833, Run Time : 0.45
INFO:root:2019-05-11 03:03:46, Epoch : 1, Step : 5410, Training Loss : 0.32916, Training Acc : 0.872, Run Time : 1.64
INFO:root:2019-05-11 03:03:57, Epoch : 1, Step : 5411, Training Loss : 0.24031, Training Acc : 0.894, Run Time : 11.15
INFO:root:2019-05-11 03:03:58, Epoch : 1, Step : 5412, Training Loss : 0.21404, Training Acc : 0.906, Run Time : 0.83
INFO:root:2019-05-11 03:03:59, Epoch : 1, Step : 5413, Training Loss : 0.26085, Training Acc : 0.872, Run Time : 1.53
INFO:root:2019-05-11 03:04:10, Epoch : 1, Step : 5414, Training Loss : 0.22375, Training Acc : 0.900, Run Time : 10.69
INFO:root:2019-05-11 03:04:11, Epoch : 1, Step : 5415, Training Loss : 0.18360, Training Acc : 0.928, Run Time : 0.52
INFO:root:2019-05-11 03:04:13, Epoch : 1, Step : 5416, Training Loss : 0.18332, Training Acc : 0.906, Run Time : 1.87
INFO:root:2019-05-11 03:04:24, Epoch : 1, Step : 5417, Training Loss : 0.22004, Training Acc : 0.889, Run Time : 11.49
INFO:root:2019-05-11 03:04:24, Epoch : 1, Step : 5418, Training Loss : 0.18925, Training Acc : 0.889, Run Time : 0.42
INFO:root:2019-05-11 03:04:25, Epoch : 1, Step : 5419, Training Loss : 0.18351, Training Acc : 0.906, Run Time : 0.39
INFO:root:2019-05-11 03:04:27, Epoch : 1, Step : 5420, Training Loss : 0.16003, Training Acc : 0.944, Run Time : 1.79
INFO:root:2019-05-11 03:04:40, Epoch : 1, Step : 5421, Training Loss : 0.14498, Training Acc : 0.944, Run Time : 13.47
INFO:root:2019-05-11 03:04:41, Epoch : 1, Step : 5422, Training Loss : 0.19538, Training Acc : 0.944, Run Time : 1.18
INFO:root:2019-05-11 03:04:53, Epoch : 1, Step : 5423, Training Loss : 0.17828, Training Acc : 0.922, Run Time : 11.22
INFO:root:2019-05-11 03:05:05, Epoch : 1, Step : 5424, Training Loss : 0.25944, Training Acc : 0.933, Run Time : 12.25
INFO:root:2019-05-11 03:05:07, Epoch : 1, Step : 5425, Training Loss : 0.20735, Training Acc : 0.894, Run Time : 1.85
INFO:root:2019-05-11 03:05:09, Epoch : 1, Step : 5426, Training Loss : 0.26450, Training Acc : 0.867, Run Time : 2.13
INFO:root:2019-05-11 03:05:19, Epoch : 1, Step : 5427, Training Loss : 0.29153, Training Acc : 0.844, Run Time : 10.35
INFO:root:2019-05-11 03:05:22, Epoch : 1, Step : 5428, Training Loss : 0.25036, Training Acc : 0.872, Run Time : 2.99
INFO:root:2019-05-11 03:05:34, Epoch : 1, Step : 5429, Training Loss : 0.21892, Training Acc : 0.922, Run Time : 12.26
INFO:root:2019-05-11 03:05:35, Epoch : 1, Step : 5430, Training Loss : 0.19909, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 03:05:35, Epoch : 1, Step : 5431, Training Loss : 0.20925, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-11 03:05:48, Epoch : 1, Step : 5432, Training Loss : 0.16435, Training Acc : 0.944, Run Time : 13.23
INFO:root:2019-05-11 03:05:49, Epoch : 1, Step : 5433, Training Loss : 0.15257, Training Acc : 0.939, Run Time : 0.74
INFO:root:2019-05-11 03:05:51, Epoch : 1, Step : 5434, Training Loss : 0.16371, Training Acc : 0.933, Run Time : 2.19
INFO:root:2019-05-11 03:06:08, Epoch : 1, Step : 5435, Training Loss : 0.18567, Training Acc : 0.928, Run Time : 16.97
INFO:root:2019-05-11 03:06:10, Epoch : 1, Step : 5436, Training Loss : 0.19355, Training Acc : 0.900, Run Time : 1.96
INFO:root:2019-05-11 03:06:11, Epoch : 1, Step : 5437, Training Loss : 0.16750, Training Acc : 0.922, Run Time : 0.95
INFO:root:2019-05-11 03:06:24, Epoch : 1, Step : 5438, Training Loss : 0.17189, Training Acc : 0.928, Run Time : 13.04
INFO:root:2019-05-11 03:06:26, Epoch : 1, Step : 5439, Training Loss : 0.20802, Training Acc : 0.906, Run Time : 1.52
INFO:root:2019-05-11 03:06:26, Epoch : 1, Step : 5440, Training Loss : 0.25349, Training Acc : 0.894, Run Time : 0.41
INFO:root:2019-05-11 03:06:27, Epoch : 1, Step : 5441, Training Loss : 0.25279, Training Acc : 0.822, Run Time : 0.59
INFO:root:2019-05-11 03:06:28, Epoch : 1, Step : 5442, Training Loss : 0.30645, Training Acc : 0.856, Run Time : 1.12
INFO:root:2019-05-11 03:06:29, Epoch : 1, Step : 5443, Training Loss : 0.32189, Training Acc : 0.867, Run Time : 1.33
INFO:root:2019-05-11 03:06:44, Epoch : 1, Step : 5444, Training Loss : 0.39245, Training Acc : 0.822, Run Time : 14.74
INFO:root:2019-05-11 03:06:53, Epoch : 1, Step : 5445, Training Loss : 0.27558, Training Acc : 0.872, Run Time : 8.91
INFO:root:2019-05-11 03:07:19, Epoch : 1, Step : 5446, Training Loss : 0.21531, Training Acc : 0.906, Run Time : 26.60
INFO:root:2019-05-11 03:07:25, Epoch : 1, Step : 5447, Training Loss : 0.22856, Training Acc : 0.894, Run Time : 5.51
INFO:root:2019-05-11 03:07:25, Epoch : 1, Step : 5448, Training Loss : 0.25888, Training Acc : 0.867, Run Time : 0.38
INFO:root:2019-05-11 03:07:26, Epoch : 1, Step : 5449, Training Loss : 0.19858, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-11 03:07:41, Epoch : 1, Step : 5450, Training Loss : 0.29811, Training Acc : 0.867, Run Time : 15.07
INFO:root:2019-05-11 03:07:41, Epoch : 1, Step : 5451, Training Loss : 0.28699, Training Acc : 0.883, Run Time : 0.55
INFO:root:2019-05-11 03:07:43, Epoch : 1, Step : 5452, Training Loss : 0.27851, Training Acc : 0.906, Run Time : 1.35
INFO:root:2019-05-11 03:07:56, Epoch : 1, Step : 5453, Training Loss : 0.16465, Training Acc : 0.928, Run Time : 13.70
INFO:root:2019-05-11 03:08:14, Epoch : 1, Step : 5454, Training Loss : 0.20778, Training Acc : 0.906, Run Time : 18.12
INFO:root:2019-05-11 03:08:15, Epoch : 1, Step : 5455, Training Loss : 0.30638, Training Acc : 0.867, Run Time : 0.44
INFO:root:2019-05-11 03:08:15, Epoch : 1, Step : 5456, Training Loss : 0.22312, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-11 03:08:17, Epoch : 1, Step : 5457, Training Loss : 0.23408, Training Acc : 0.900, Run Time : 1.49
INFO:root:2019-05-11 03:08:28, Epoch : 1, Step : 5458, Training Loss : 0.25888, Training Acc : 0.906, Run Time : 11.49
INFO:root:2019-05-11 03:08:31, Epoch : 1, Step : 5459, Training Loss : 0.23471, Training Acc : 0.906, Run Time : 2.32
INFO:root:2019-05-11 03:08:42, Epoch : 1, Step : 5460, Training Loss : 0.25512, Training Acc : 0.856, Run Time : 11.52
INFO:root:2019-05-11 03:08:43, Epoch : 1, Step : 5461, Training Loss : 0.34761, Training Acc : 0.844, Run Time : 0.80
INFO:root:2019-05-11 03:08:44, Epoch : 1, Step : 5462, Training Loss : 0.32444, Training Acc : 0.850, Run Time : 1.03
INFO:root:2019-05-11 03:09:05, Epoch : 1, Step : 5463, Training Loss : 0.28195, Training Acc : 0.844, Run Time : 20.98
INFO:root:2019-05-11 03:09:15, Epoch : 1, Step : 5464, Training Loss : 0.36620, Training Acc : 0.800, Run Time : 10.48
INFO:root:2019-05-11 03:09:27, Epoch : 1, Step : 5465, Training Loss : 0.26023, Training Acc : 0.861, Run Time : 11.63
INFO:root:2019-05-11 03:09:40, Epoch : 1, Step : 5466, Training Loss : 0.16424, Training Acc : 0.950, Run Time : 13.04
INFO:root:2019-05-11 03:09:41, Epoch : 1, Step : 5467, Training Loss : 0.15202, Training Acc : 0.950, Run Time : 0.65
INFO:root:2019-05-11 03:09:41, Epoch : 1, Step : 5468, Training Loss : 0.17705, Training Acc : 0.906, Run Time : 0.57
INFO:root:2019-05-11 03:09:53, Epoch : 1, Step : 5469, Training Loss : 0.13917, Training Acc : 0.939, Run Time : 11.32
INFO:root:2019-05-11 03:09:53, Epoch : 1, Step : 5470, Training Loss : 0.11795, Training Acc : 0.972, Run Time : 0.51
INFO:root:2019-05-11 03:09:54, Epoch : 1, Step : 5471, Training Loss : 0.08153, Training Acc : 0.983, Run Time : 0.64
INFO:root:2019-05-11 03:09:55, Epoch : 1, Step : 5472, Training Loss : 0.10786, Training Acc : 0.950, Run Time : 1.37
INFO:root:2019-05-11 03:10:05, Epoch : 1, Step : 5473, Training Loss : 0.14887, Training Acc : 0.900, Run Time : 9.86
INFO:root:2019-05-11 03:10:06, Epoch : 1, Step : 5474, Training Loss : 0.16922, Training Acc : 0.906, Run Time : 0.95
INFO:root:2019-05-11 03:10:21, Epoch : 1, Step : 5475, Training Loss : 0.24395, Training Acc : 0.867, Run Time : 15.50
INFO:root:2019-05-11 03:10:22, Epoch : 1, Step : 5476, Training Loss : 0.23584, Training Acc : 0.878, Run Time : 0.81
INFO:root:2019-05-11 03:10:23, Epoch : 1, Step : 5477, Training Loss : 0.12275, Training Acc : 0.939, Run Time : 0.94
INFO:root:2019-05-11 03:10:36, Epoch : 1, Step : 5478, Training Loss : 0.12658, Training Acc : 0.944, Run Time : 13.18
INFO:root:2019-05-11 03:10:37, Epoch : 1, Step : 5479, Training Loss : 0.09885, Training Acc : 0.961, Run Time : 0.67
INFO:root:2019-05-11 03:10:37, Epoch : 1, Step : 5480, Training Loss : 0.10905, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-11 03:10:48, Epoch : 1, Step : 5481, Training Loss : 0.10099, Training Acc : 0.978, Run Time : 10.72
INFO:root:2019-05-11 03:10:50, Epoch : 1, Step : 5482, Training Loss : 0.12797, Training Acc : 0.933, Run Time : 1.98
INFO:root:2019-05-11 03:10:52, Epoch : 1, Step : 5483, Training Loss : 0.35957, Training Acc : 0.878, Run Time : 1.70
INFO:root:2019-05-11 03:11:03, Epoch : 1, Step : 5484, Training Loss : 0.41545, Training Acc : 0.878, Run Time : 10.79
INFO:root:2019-05-11 03:11:03, Epoch : 1, Step : 5485, Training Loss : 0.32382, Training Acc : 0.889, Run Time : 0.43
INFO:root:2019-05-11 03:11:03, Epoch : 1, Step : 5486, Training Loss : 0.25680, Training Acc : 0.867, Run Time : 0.40
INFO:root:2019-05-11 03:11:16, Epoch : 1, Step : 5487, Training Loss : 0.40026, Training Acc : 0.839, Run Time : 12.30
INFO:root:2019-05-11 03:11:17, Epoch : 1, Step : 5488, Training Loss : 0.26282, Training Acc : 0.878, Run Time : 1.17
INFO:root:2019-05-11 03:11:29, Epoch : 1, Step : 5489, Training Loss : 0.33425, Training Acc : 0.850, Run Time : 12.30
INFO:root:2019-05-11 03:11:30, Epoch : 1, Step : 5490, Training Loss : 0.21088, Training Acc : 0.883, Run Time : 0.54
INFO:root:2019-05-11 03:11:30, Epoch : 1, Step : 5491, Training Loss : 0.39742, Training Acc : 0.833, Run Time : 0.45
INFO:root:2019-05-11 03:11:40, Epoch : 1, Step : 5492, Training Loss : 0.35409, Training Acc : 0.861, Run Time : 9.84
INFO:root:2019-05-11 03:11:41, Epoch : 1, Step : 5493, Training Loss : 0.61474, Training Acc : 0.761, Run Time : 0.78
INFO:root:2019-05-11 03:11:42, Epoch : 1, Step : 5494, Training Loss : 0.20346, Training Acc : 0.911, Run Time : 0.73
INFO:root:2019-05-11 03:12:01, Epoch : 1, Step : 5495, Training Loss : 0.54509, Training Acc : 0.783, Run Time : 19.91
INFO:root:2019-05-11 03:12:11, Epoch : 1, Step : 5496, Training Loss : 0.22535, Training Acc : 0.889, Run Time : 9.07
INFO:root:2019-05-11 03:12:28, Epoch : 1, Step : 5497, Training Loss : 0.49517, Training Acc : 0.844, Run Time : 17.58
INFO:root:2019-05-11 03:12:30, Epoch : 1, Step : 5498, Training Loss : 0.28011, Training Acc : 0.906, Run Time : 2.13
INFO:root:2019-05-11 03:12:31, Epoch : 1, Step : 5499, Training Loss : 0.23972, Training Acc : 0.906, Run Time : 1.23
INFO:root:2019-05-11 03:12:44, Epoch : 1, Step : 5500, Training Loss : 0.26588, Training Acc : 0.872, Run Time : 12.06
INFO:root:2019-05-11 03:12:46, Epoch : 1, Step : 5501, Training Loss : 0.33932, Training Acc : 0.856, Run Time : 2.94
INFO:root:2019-05-11 03:13:04, Epoch : 1, Step : 5502, Training Loss : 0.24857, Training Acc : 0.894, Run Time : 17.99
INFO:root:2019-05-11 03:13:07, Epoch : 1, Step : 5503, Training Loss : 0.34355, Training Acc : 0.856, Run Time : 3.02
INFO:root:2019-05-11 03:13:08, Epoch : 1, Step : 5504, Training Loss : 0.34820, Training Acc : 0.883, Run Time : 0.40
INFO:root:2019-05-11 03:13:08, Epoch : 1, Step : 5505, Training Loss : 0.27323, Training Acc : 0.867, Run Time : 0.61
INFO:root:2019-05-11 03:13:17, Epoch : 1, Step : 5506, Training Loss : 0.35930, Training Acc : 0.861, Run Time : 8.42
INFO:root:2019-05-11 03:13:18, Epoch : 1, Step : 5507, Training Loss : 0.22578, Training Acc : 0.906, Run Time : 1.44
INFO:root:2019-05-11 03:13:20, Epoch : 1, Step : 5508, Training Loss : 0.28337, Training Acc : 0.883, Run Time : 2.06
INFO:root:2019-05-11 03:13:37, Epoch : 1, Step : 5509, Training Loss : 0.27160, Training Acc : 0.872, Run Time : 16.67
INFO:root:2019-05-11 03:13:47, Epoch : 1, Step : 5510, Training Loss : 0.22524, Training Acc : 0.928, Run Time : 9.61
INFO:root:2019-05-11 03:13:56, Epoch : 1, Step : 5511, Training Loss : 0.27387, Training Acc : 0.883, Run Time : 9.41
INFO:root:2019-05-11 03:13:57, Epoch : 1, Step : 5512, Training Loss : 0.26242, Training Acc : 0.906, Run Time : 1.06
INFO:root:2019-05-11 03:13:58, Epoch : 1, Step : 5513, Training Loss : 0.19507, Training Acc : 0.894, Run Time : 0.41
INFO:root:2019-05-11 03:13:58, Epoch : 1, Step : 5514, Training Loss : 0.16607, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 03:14:15, Epoch : 1, Step : 5515, Training Loss : 0.14762, Training Acc : 0.961, Run Time : 16.60
INFO:root:2019-05-11 03:14:16, Epoch : 1, Step : 5516, Training Loss : 0.25662, Training Acc : 0.894, Run Time : 1.64
INFO:root:2019-05-11 03:14:18, Epoch : 1, Step : 5517, Training Loss : 0.41716, Training Acc : 0.844, Run Time : 1.80
INFO:root:2019-05-11 03:14:30, Epoch : 1, Step : 5518, Training Loss : 0.29480, Training Acc : 0.883, Run Time : 11.60
INFO:root:2019-05-11 03:14:32, Epoch : 1, Step : 5519, Training Loss : 0.46878, Training Acc : 0.850, Run Time : 2.77
INFO:root:2019-05-11 03:14:53, Epoch : 1, Step : 5520, Training Loss : 0.21148, Training Acc : 0.917, Run Time : 20.91
INFO:root:2019-05-11 03:14:56, Epoch : 1, Step : 5521, Training Loss : 0.45706, Training Acc : 0.839, Run Time : 3.14
INFO:root:2019-05-11 03:14:57, Epoch : 1, Step : 5522, Training Loss : 0.31251, Training Acc : 0.867, Run Time : 0.38
INFO:root:2019-05-11 03:14:58, Epoch : 1, Step : 5523, Training Loss : 0.54941, Training Acc : 0.800, Run Time : 0.73
INFO:root:2019-05-11 03:15:07, Epoch : 1, Step : 5524, Training Loss : 0.32640, Training Acc : 0.856, Run Time : 9.15
INFO:root:2019-05-11 03:15:08, Epoch : 1, Step : 5525, Training Loss : 0.55250, Training Acc : 0.789, Run Time : 1.46
INFO:root:2019-05-11 03:15:17, Epoch : 1, Step : 5526, Training Loss : 0.28887, Training Acc : 0.856, Run Time : 9.09
INFO:root:2019-05-11 03:15:18, Epoch : 1, Step : 5527, Training Loss : 0.38551, Training Acc : 0.839, Run Time : 0.77
INFO:root:2019-05-11 03:15:20, Epoch : 1, Step : 5528, Training Loss : 0.59154, Training Acc : 0.806, Run Time : 1.54
INFO:root:2019-05-11 03:15:50, Epoch : 1, Step : 5529, Training Loss : 0.23477, Training Acc : 0.917, Run Time : 30.75
INFO:root:2019-05-11 03:16:09, Epoch : 1, Step : 5530, Training Loss : 0.37501, Training Acc : 0.861, Run Time : 18.77
INFO:root:2019-05-11 03:16:15, Epoch : 1, Step : 5531, Training Loss : 0.36282, Training Acc : 0.856, Run Time : 5.75
INFO:root:2019-05-11 03:16:15, Epoch : 1, Step : 5532, Training Loss : 0.29976, Training Acc : 0.861, Run Time : 0.58
INFO:root:2019-05-11 03:16:30, Epoch : 1, Step : 5533, Training Loss : 0.43168, Training Acc : 0.817, Run Time : 14.82
INFO:root:2019-05-11 03:16:44, Epoch : 1, Step : 5534, Training Loss : 0.46243, Training Acc : 0.822, Run Time : 13.74
INFO:root:2019-05-11 03:16:48, Epoch : 1, Step : 5535, Training Loss : 0.51399, Training Acc : 0.744, Run Time : 3.71
INFO:root:2019-05-11 03:16:48, Epoch : 1, Step : 5536, Training Loss : 0.30542, Training Acc : 0.872, Run Time : 0.41
INFO:root:2019-05-11 03:17:01, Epoch : 1, Step : 5537, Training Loss : 0.55986, Training Acc : 0.744, Run Time : 13.29
INFO:root:2019-05-11 03:17:03, Epoch : 1, Step : 5538, Training Loss : 0.36313, Training Acc : 0.822, Run Time : 1.37
INFO:root:2019-05-11 03:17:19, Epoch : 1, Step : 5539, Training Loss : 0.47602, Training Acc : 0.778, Run Time : 16.18
INFO:root:2019-05-11 03:17:21, Epoch : 1, Step : 5540, Training Loss : 0.48417, Training Acc : 0.778, Run Time : 2.60
INFO:root:2019-05-11 03:17:37, Epoch : 1, Step : 5541, Training Loss : 0.40473, Training Acc : 0.817, Run Time : 15.65
INFO:root:2019-05-11 03:17:49, Epoch : 1, Step : 5542, Training Loss : 0.32328, Training Acc : 0.861, Run Time : 12.00
INFO:root:2019-05-11 03:18:21, Epoch : 1, Step : 5543, Training Loss : 0.33350, Training Acc : 0.850, Run Time : 31.59
INFO:root:2019-05-11 03:18:24, Epoch : 1, Step : 5544, Training Loss : 0.45098, Training Acc : 0.783, Run Time : 3.70
INFO:root:2019-05-11 03:18:25, Epoch : 1, Step : 5545, Training Loss : 0.40969, Training Acc : 0.800, Run Time : 0.40
INFO:root:2019-05-11 03:18:25, Epoch : 1, Step : 5546, Training Loss : 0.41468, Training Acc : 0.778, Run Time : 0.38
INFO:root:2019-05-11 03:18:39, Epoch : 1, Step : 5547, Training Loss : 0.59795, Training Acc : 0.711, Run Time : 13.45
INFO:root:2019-05-11 03:18:40, Epoch : 1, Step : 5548, Training Loss : 0.25768, Training Acc : 0.872, Run Time : 1.02
INFO:root:2019-05-11 03:18:41, Epoch : 1, Step : 5549, Training Loss : 0.37801, Training Acc : 0.839, Run Time : 1.65
INFO:root:2019-05-11 03:18:51, Epoch : 1, Step : 5550, Training Loss : 0.43204, Training Acc : 0.744, Run Time : 9.49
INFO:root:2019-05-11 03:18:51, Epoch : 1, Step : 5551, Training Loss : 0.31958, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-11 03:18:53, Epoch : 1, Step : 5552, Training Loss : 0.32223, Training Acc : 0.878, Run Time : 2.25
INFO:root:2019-05-11 03:19:08, Epoch : 1, Step : 5553, Training Loss : 0.26406, Training Acc : 0.889, Run Time : 14.07
INFO:root:2019-05-11 03:19:20, Epoch : 1, Step : 5554, Training Loss : 0.28385, Training Acc : 0.883, Run Time : 12.57
INFO:root:2019-05-11 03:19:21, Epoch : 1, Step : 5555, Training Loss : 0.22439, Training Acc : 0.906, Run Time : 0.71
INFO:root:2019-05-11 03:19:32, Epoch : 1, Step : 5556, Training Loss : 0.22374, Training Acc : 0.894, Run Time : 11.36
INFO:root:2019-05-11 03:19:33, Epoch : 1, Step : 5557, Training Loss : 0.21730, Training Acc : 0.922, Run Time : 1.19
INFO:root:2019-05-11 03:19:34, Epoch : 1, Step : 5558, Training Loss : 0.24972, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-11 03:19:35, Epoch : 1, Step : 5559, Training Loss : 0.31961, Training Acc : 0.833, Run Time : 1.47
INFO:root:2019-05-11 03:19:47, Epoch : 1, Step : 5560, Training Loss : 0.24320, Training Acc : 0.917, Run Time : 11.98
INFO:root:2019-05-11 03:19:48, Epoch : 1, Step : 5561, Training Loss : 0.26527, Training Acc : 0.894, Run Time : 0.42
INFO:root:2019-05-11 03:19:48, Epoch : 1, Step : 5562, Training Loss : 0.27750, Training Acc : 0.883, Run Time : 0.40
INFO:root:2019-05-11 03:19:48, Epoch : 1, Step : 5563, Training Loss : 0.24227, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-11 03:20:50, Epoch : 1, Step : 5564, Training Loss : 0.25364, Training Acc : 0.900, Run Time : 61.55
INFO:root:2019-05-11 03:20:55, Epoch : 1, Step : 5565, Training Loss : 0.25477, Training Acc : 0.872, Run Time : 5.19
INFO:root:2019-05-11 03:20:56, Epoch : 1, Step : 5566, Training Loss : 0.19339, Training Acc : 0.917, Run Time : 0.87
INFO:root:2019-05-11 03:21:13, Epoch : 1, Step : 5567, Training Loss : 0.20015, Training Acc : 0.922, Run Time : 17.33
INFO:root:2019-05-11 03:21:16, Epoch : 1, Step : 5568, Training Loss : 0.20299, Training Acc : 0.917, Run Time : 2.20
INFO:root:2019-05-11 03:21:16, Epoch : 1, Step : 5569, Training Loss : 0.28697, Training Acc : 0.889, Run Time : 0.39
INFO:root:2019-05-11 03:21:17, Epoch : 1, Step : 5570, Training Loss : 0.50077, Training Acc : 0.783, Run Time : 0.71
INFO:root:2019-05-11 03:21:26, Epoch : 1, Step : 5571, Training Loss : 0.33096, Training Acc : 0.822, Run Time : 9.66
INFO:root:2019-05-11 03:21:27, Epoch : 1, Step : 5572, Training Loss : 0.37788, Training Acc : 0.856, Run Time : 1.12
INFO:root:2019-05-11 03:21:28, Epoch : 1, Step : 5573, Training Loss : 0.52367, Training Acc : 0.750, Run Time : 0.38
INFO:root:2019-05-11 03:21:28, Epoch : 1, Step : 5574, Training Loss : 0.28088, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-11 03:21:39, Epoch : 1, Step : 5575, Training Loss : 0.28385, Training Acc : 0.872, Run Time : 10.93
INFO:root:2019-05-11 03:21:40, Epoch : 1, Step : 5576, Training Loss : 0.37957, Training Acc : 0.861, Run Time : 0.64
INFO:root:2019-05-11 03:21:41, Epoch : 1, Step : 5577, Training Loss : 0.28548, Training Acc : 0.878, Run Time : 1.25
INFO:root:2019-05-11 03:21:53, Epoch : 1, Step : 5578, Training Loss : 0.29197, Training Acc : 0.861, Run Time : 12.28
INFO:root:2019-05-11 03:21:54, Epoch : 1, Step : 5579, Training Loss : 0.38259, Training Acc : 0.822, Run Time : 0.84
INFO:root:2019-05-11 03:21:56, Epoch : 1, Step : 5580, Training Loss : 0.32268, Training Acc : 0.856, Run Time : 1.60
INFO:root:2019-05-11 03:22:07, Epoch : 1, Step : 5581, Training Loss : 0.28420, Training Acc : 0.867, Run Time : 11.26
INFO:root:2019-05-11 03:22:25, Epoch : 1, Step : 5582, Training Loss : 0.26890, Training Acc : 0.872, Run Time : 17.73
INFO:root:2019-05-11 03:22:25, Epoch : 1, Step : 5583, Training Loss : 0.16548, Training Acc : 0.939, Run Time : 0.42
INFO:root:2019-05-11 03:22:26, Epoch : 1, Step : 5584, Training Loss : 0.28044, Training Acc : 0.878, Run Time : 0.50
INFO:root:2019-05-11 03:22:27, Epoch : 1, Step : 5585, Training Loss : 0.28061, Training Acc : 0.900, Run Time : 1.43
INFO:root:2019-05-11 03:22:44, Epoch : 1, Step : 5586, Training Loss : 0.36351, Training Acc : 0.833, Run Time : 16.94
INFO:root:2019-05-11 03:22:47, Epoch : 1, Step : 5587, Training Loss : 0.30569, Training Acc : 0.867, Run Time : 2.68
INFO:root:2019-05-11 03:22:47, Epoch : 1, Step : 5588, Training Loss : 0.22849, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-11 03:22:48, Epoch : 1, Step : 5589, Training Loss : 0.33635, Training Acc : 0.867, Run Time : 0.41
INFO:root:2019-05-11 03:22:48, Epoch : 1, Step : 5590, Training Loss : 0.42600, Training Acc : 0.833, Run Time : 0.67
INFO:root:2019-05-11 03:22:52, Epoch : 1, Step : 5591, Training Loss : 0.29410, Training Acc : 0.867, Run Time : 3.98
INFO:root:2019-05-11 03:22:53, Epoch : 1, Step : 5592, Training Loss : 0.26339, Training Acc : 0.872, Run Time : 0.83
INFO:root:2019-05-11 03:22:54, Epoch : 1, Step : 5593, Training Loss : 0.31089, Training Acc : 0.867, Run Time : 1.50
INFO:root:2019-05-11 03:22:55, Epoch : 1, Step : 5594, Training Loss : 0.33841, Training Acc : 0.839, Run Time : 0.38
INFO:root:2019-05-11 03:22:55, Epoch : 1, Step : 5595, Training Loss : 0.39183, Training Acc : 0.839, Run Time : 0.44
INFO:root:2019-05-11 03:22:56, Epoch : 1, Step : 5596, Training Loss : 0.31471, Training Acc : 0.872, Run Time : 0.58
INFO:root:2019-05-11 03:22:56, Epoch : 1, Step : 5597, Training Loss : 0.31075, Training Acc : 0.850, Run Time : 0.42
INFO:root:2019-05-11 03:23:09, Epoch : 1, Step : 5598, Training Loss : 0.21549, Training Acc : 0.906, Run Time : 13.14
INFO:root:2019-05-11 03:23:12, Epoch : 1, Step : 5599, Training Loss : 0.32850, Training Acc : 0.861, Run Time : 2.59
INFO:root:2019-05-11 03:23:25, Epoch : 1, Step : 5600, Training Loss : 0.30374, Training Acc : 0.850, Run Time : 12.60
INFO:root:2019-05-11 03:24:16, Epoch : 1, Step : 5601, Training Loss : 0.45610, Training Acc : 0.822, Run Time : 50.95
INFO:root:2019-05-11 03:24:32, Epoch : 1, Step : 5602, Training Loss : 0.40036, Training Acc : 0.839, Run Time : 16.76
INFO:root:2019-05-11 03:24:34, Epoch : 1, Step : 5603, Training Loss : 0.32600, Training Acc : 0.844, Run Time : 1.64
INFO:root:2019-05-11 03:24:45, Epoch : 1, Step : 5604, Training Loss : 0.35731, Training Acc : 0.778, Run Time : 11.32
INFO:root:2019-05-11 03:24:47, Epoch : 1, Step : 5605, Training Loss : 0.33148, Training Acc : 0.850, Run Time : 1.69
INFO:root:2019-05-11 03:25:01, Epoch : 1, Step : 5606, Training Loss : 0.20694, Training Acc : 0.928, Run Time : 13.51
INFO:root:2019-05-11 03:25:02, Epoch : 1, Step : 5607, Training Loss : 0.58990, Training Acc : 0.839, Run Time : 1.50
INFO:root:2019-05-11 03:25:16, Epoch : 1, Step : 5608, Training Loss : 0.75702, Training Acc : 0.667, Run Time : 13.62
INFO:root:2019-05-11 03:25:24, Epoch : 1, Step : 5609, Training Loss : 0.96708, Training Acc : 0.611, Run Time : 8.22
INFO:root:2019-05-11 03:25:31, Epoch : 1, Step : 5610, Training Loss : 0.78245, Training Acc : 0.628, Run Time : 6.71
INFO:root:2019-05-11 03:25:40, Epoch : 1, Step : 5611, Training Loss : 1.02969, Training Acc : 0.472, Run Time : 8.99
INFO:root:2019-05-11 03:25:59, Epoch : 1, Step : 5612, Training Loss : 0.60069, Training Acc : 0.722, Run Time : 19.71
INFO:root:2019-05-11 03:26:05, Epoch : 1, Step : 5613, Training Loss : 0.51745, Training Acc : 0.756, Run Time : 6.01
INFO:root:2019-05-11 03:26:06, Epoch : 1, Step : 5614, Training Loss : 0.71818, Training Acc : 0.661, Run Time : 0.56
INFO:root:2019-05-11 03:26:06, Epoch : 1, Step : 5615, Training Loss : 0.53498, Training Acc : 0.778, Run Time : 0.63
INFO:root:2019-05-11 03:26:08, Epoch : 1, Step : 5616, Training Loss : 0.55428, Training Acc : 0.789, Run Time : 1.07
INFO:root:2019-05-11 03:26:19, Epoch : 1, Step : 5617, Training Loss : 0.71997, Training Acc : 0.656, Run Time : 11.91
INFO:root:2019-05-11 03:26:28, Epoch : 1, Step : 5618, Training Loss : 0.77799, Training Acc : 0.617, Run Time : 8.17
INFO:root:2019-05-11 03:26:46, Epoch : 1, Step : 5619, Training Loss : 0.73265, Training Acc : 0.650, Run Time : 18.34
INFO:root:2019-05-11 03:27:00, Epoch : 1, Step : 5620, Training Loss : 0.60644, Training Acc : 0.728, Run Time : 13.72
INFO:root:2019-05-11 03:27:02, Epoch : 1, Step : 5621, Training Loss : 0.55465, Training Acc : 0.783, Run Time : 2.44
INFO:root:2019-05-11 03:27:18, Epoch : 1, Step : 5622, Training Loss : 0.60743, Training Acc : 0.711, Run Time : 15.87
INFO:root:2019-05-11 03:27:19, Epoch : 1, Step : 5623, Training Loss : 0.54840, Training Acc : 0.767, Run Time : 1.46
INFO:root:2019-05-11 03:27:30, Epoch : 1, Step : 5624, Training Loss : 0.48893, Training Acc : 0.794, Run Time : 10.38
INFO:root:2019-05-11 03:27:31, Epoch : 1, Step : 5625, Training Loss : 0.48426, Training Acc : 0.744, Run Time : 1.19
INFO:root:2019-05-11 03:27:31, Epoch : 1, Step : 5626, Training Loss : 0.54425, Training Acc : 0.728, Run Time : 0.38
INFO:root:2019-05-11 03:27:33, Epoch : 1, Step : 5627, Training Loss : 0.46666, Training Acc : 0.728, Run Time : 1.27
INFO:root:2019-05-11 03:27:45, Epoch : 1, Step : 5628, Training Loss : 0.62385, Training Acc : 0.711, Run Time : 12.15
INFO:root:2019-05-11 03:27:46, Epoch : 1, Step : 5629, Training Loss : 0.61856, Training Acc : 0.694, Run Time : 0.83
INFO:root:2019-05-11 03:27:46, Epoch : 1, Step : 5630, Training Loss : 0.66852, Training Acc : 0.694, Run Time : 0.53
INFO:root:2019-05-11 03:27:47, Epoch : 1, Step : 5631, Training Loss : 0.67916, Training Acc : 0.644, Run Time : 0.93
INFO:root:2019-05-11 03:27:59, Epoch : 1, Step : 5632, Training Loss : 0.53816, Training Acc : 0.706, Run Time : 11.72
INFO:root:2019-05-11 03:27:59, Epoch : 1, Step : 5633, Training Loss : 0.40617, Training Acc : 0.828, Run Time : 0.52
INFO:root:2019-05-11 03:28:00, Epoch : 1, Step : 5634, Training Loss : 0.53167, Training Acc : 0.767, Run Time : 0.42
INFO:root:2019-05-11 03:28:36, Epoch : 1, Step : 5635, Training Loss : 0.48285, Training Acc : 0.806, Run Time : 36.27
INFO:root:2019-05-11 03:28:42, Epoch : 1, Step : 5636, Training Loss : 0.62530, Training Acc : 0.700, Run Time : 5.89
INFO:root:2019-05-11 03:28:43, Epoch : 1, Step : 5637, Training Loss : 0.39260, Training Acc : 0.806, Run Time : 0.59
INFO:root:2019-05-11 03:28:58, Epoch : 1, Step : 5638, Training Loss : 0.39208, Training Acc : 0.833, Run Time : 15.81
INFO:root:2019-05-11 03:28:59, Epoch : 1, Step : 5639, Training Loss : 0.31988, Training Acc : 0.889, Run Time : 0.45
INFO:root:2019-05-11 03:28:59, Epoch : 1, Step : 5640, Training Loss : 0.41829, Training Acc : 0.844, Run Time : 0.38
INFO:root:2019-05-11 03:29:00, Epoch : 1, Step : 5641, Training Loss : 0.43890, Training Acc : 0.811, Run Time : 0.84
INFO:root:2019-05-11 03:29:12, Epoch : 1, Step : 5642, Training Loss : 0.41318, Training Acc : 0.844, Run Time : 12.26
INFO:root:2019-05-11 03:29:13, Epoch : 1, Step : 5643, Training Loss : 0.41400, Training Acc : 0.822, Run Time : 0.87
INFO:root:2019-05-11 03:29:22, Epoch : 1, Step : 5644, Training Loss : 0.48210, Training Acc : 0.800, Run Time : 8.66
INFO:root:2019-05-11 03:29:47, Epoch : 1, Step : 5645, Training Loss : 0.46692, Training Acc : 0.800, Run Time : 25.13
INFO:root:2019-05-11 03:29:55, Epoch : 1, Step : 5646, Training Loss : 0.40470, Training Acc : 0.806, Run Time : 8.42
INFO:root:2019-05-11 03:29:56, Epoch : 1, Step : 5647, Training Loss : 0.31736, Training Acc : 0.872, Run Time : 0.81
INFO:root:2019-05-11 03:30:07, Epoch : 1, Step : 5648, Training Loss : 0.43793, Training Acc : 0.806, Run Time : 11.14
INFO:root:2019-05-11 03:30:16, Epoch : 1, Step : 5649, Training Loss : 0.23644, Training Acc : 0.928, Run Time : 8.40
INFO:root:2019-05-11 03:30:22, Epoch : 1, Step : 5650, Training Loss : 0.34172, Training Acc : 0.878, Run Time : 5.81
INFO:root:2019-05-11 03:30:22, Epoch : 1, Step : 5651, Training Loss : 0.50299, Training Acc : 0.761, Run Time : 0.65
INFO:root:2019-05-11 03:30:49, Epoch : 1, Step : 5652, Training Loss : 0.42015, Training Acc : 0.778, Run Time : 26.85
INFO:root:2019-05-11 03:30:51, Epoch : 1, Step : 5653, Training Loss : 0.32271, Training Acc : 0.911, Run Time : 2.16
INFO:root:2019-05-11 03:30:52, Epoch : 1, Step : 5654, Training Loss : 0.35472, Training Acc : 0.856, Run Time : 0.38
INFO:root:2019-05-11 03:30:52, Epoch : 1, Step : 5655, Training Loss : 0.35447, Training Acc : 0.833, Run Time : 0.64
INFO:root:2019-05-11 03:31:04, Epoch : 1, Step : 5656, Training Loss : 0.37960, Training Acc : 0.822, Run Time : 11.35
INFO:root:2019-05-11 03:31:05, Epoch : 1, Step : 5657, Training Loss : 0.40108, Training Acc : 0.811, Run Time : 1.92
INFO:root:2019-05-11 03:31:14, Epoch : 1, Step : 5658, Training Loss : 0.36093, Training Acc : 0.872, Run Time : 8.93
INFO:root:2019-05-11 03:31:15, Epoch : 1, Step : 5659, Training Loss : 0.42827, Training Acc : 0.828, Run Time : 0.58
INFO:root:2019-05-11 03:31:15, Epoch : 1, Step : 5660, Training Loss : 0.42836, Training Acc : 0.856, Run Time : 0.41
INFO:root:2019-05-11 03:31:17, Epoch : 1, Step : 5661, Training Loss : 0.33867, Training Acc : 0.850, Run Time : 1.88
INFO:root:2019-05-11 03:31:31, Epoch : 1, Step : 5662, Training Loss : 0.22783, Training Acc : 0.922, Run Time : 13.52
INFO:root:2019-05-11 03:31:31, Epoch : 1, Step : 5663, Training Loss : 0.24757, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-11 03:31:32, Epoch : 1, Step : 5664, Training Loss : 0.31449, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 03:31:32, Epoch : 1, Step : 5665, Training Loss : 0.26805, Training Acc : 0.867, Run Time : 0.40
INFO:root:2019-05-11 03:31:34, Epoch : 1, Step : 5666, Training Loss : 0.28378, Training Acc : 0.889, Run Time : 1.96
INFO:root:2019-05-11 03:31:45, Epoch : 1, Step : 5667, Training Loss : 0.30605, Training Acc : 0.872, Run Time : 11.15
INFO:root:2019-05-11 03:31:46, Epoch : 1, Step : 5668, Training Loss : 0.20917, Training Acc : 0.911, Run Time : 1.06
INFO:root:2019-05-11 03:31:48, Epoch : 1, Step : 5669, Training Loss : 0.30899, Training Acc : 0.861, Run Time : 1.73
INFO:root:2019-05-11 03:32:13, Epoch : 1, Step : 5670, Training Loss : 0.26065, Training Acc : 0.872, Run Time : 25.41
INFO:root:2019-05-11 03:32:19, Epoch : 1, Step : 5671, Training Loss : 0.33726, Training Acc : 0.861, Run Time : 6.02
INFO:root:2019-05-11 03:32:20, Epoch : 1, Step : 5672, Training Loss : 0.35469, Training Acc : 0.844, Run Time : 0.63
INFO:root:2019-05-11 03:32:22, Epoch : 1, Step : 5673, Training Loss : 0.29700, Training Acc : 0.861, Run Time : 2.19
INFO:root:2019-05-11 03:32:32, Epoch : 1, Step : 5674, Training Loss : 0.27615, Training Acc : 0.894, Run Time : 10.34
INFO:root:2019-05-11 03:32:33, Epoch : 1, Step : 5675, Training Loss : 0.27457, Training Acc : 0.894, Run Time : 0.96
INFO:root:2019-05-11 03:32:47, Epoch : 1, Step : 5676, Training Loss : 0.26317, Training Acc : 0.911, Run Time : 13.95
INFO:root:2019-05-11 03:32:48, Epoch : 1, Step : 5677, Training Loss : 0.20434, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-11 03:32:48, Epoch : 1, Step : 5678, Training Loss : 0.37962, Training Acc : 0.828, Run Time : 0.39
INFO:root:2019-05-11 03:32:50, Epoch : 1, Step : 5679, Training Loss : 0.27208, Training Acc : 0.911, Run Time : 1.37
INFO:root:2019-05-11 03:33:04, Epoch : 1, Step : 5680, Training Loss : 0.17022, Training Acc : 0.972, Run Time : 13.94
INFO:root:2019-05-11 03:33:04, Epoch : 1, Step : 5681, Training Loss : 0.29401, Training Acc : 0.922, Run Time : 0.89
INFO:root:2019-05-11 03:33:05, Epoch : 1, Step : 5682, Training Loss : 0.17809, Training Acc : 0.961, Run Time : 0.41
INFO:root:2019-05-11 03:33:05, Epoch : 1, Step : 5683, Training Loss : 0.27766, Training Acc : 0.911, Run Time : 0.58
INFO:root:2019-05-11 03:33:07, Epoch : 1, Step : 5684, Training Loss : 0.22304, Training Acc : 0.933, Run Time : 1.55
INFO:root:2019-05-11 03:33:20, Epoch : 1, Step : 5685, Training Loss : 0.34993, Training Acc : 0.878, Run Time : 12.96
INFO:root:2019-05-11 03:33:22, Epoch : 1, Step : 5686, Training Loss : 0.41435, Training Acc : 0.861, Run Time : 1.84
INFO:root:2019-05-11 03:33:46, Epoch : 1, Step : 5687, Training Loss : 0.24009, Training Acc : 0.928, Run Time : 24.31
INFO:root:2019-05-11 03:33:49, Epoch : 1, Step : 5688, Training Loss : 0.37145, Training Acc : 0.839, Run Time : 2.44
INFO:root:2019-05-11 03:33:49, Epoch : 1, Step : 5689, Training Loss : 0.34239, Training Acc : 0.889, Run Time : 0.71
INFO:root:2019-05-11 03:34:05, Epoch : 1, Step : 5690, Training Loss : 0.34175, Training Acc : 0.889, Run Time : 15.99
INFO:root:2019-05-11 03:34:07, Epoch : 1, Step : 5691, Training Loss : 0.32713, Training Acc : 0.878, Run Time : 1.72
INFO:root:2019-05-11 03:34:07, Epoch : 1, Step : 5692, Training Loss : 0.26977, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-11 03:34:08, Epoch : 1, Step : 5693, Training Loss : 0.26454, Training Acc : 0.911, Run Time : 1.04
INFO:root:2019-05-11 03:34:22, Epoch : 1, Step : 5694, Training Loss : 0.28303, Training Acc : 0.906, Run Time : 13.54
INFO:root:2019-05-11 03:34:24, Epoch : 1, Step : 5695, Training Loss : 0.31103, Training Acc : 0.872, Run Time : 2.00
INFO:root:2019-05-11 03:34:40, Epoch : 1, Step : 5696, Training Loss : 0.40398, Training Acc : 0.839, Run Time : 15.83
INFO:root:2019-05-11 03:34:41, Epoch : 1, Step : 5697, Training Loss : 0.37103, Training Acc : 0.828, Run Time : 1.17
INFO:root:2019-05-11 03:34:41, Epoch : 1, Step : 5698, Training Loss : 0.26525, Training Acc : 0.889, Run Time : 0.61
INFO:root:2019-05-11 03:34:54, Epoch : 1, Step : 5699, Training Loss : 0.19765, Training Acc : 0.922, Run Time : 12.29
INFO:root:2019-05-11 03:34:55, Epoch : 1, Step : 5700, Training Loss : 0.21204, Training Acc : 0.922, Run Time : 0.75
INFO:root:2019-05-11 03:35:25, Epoch : 1, Step : 5701, Training Loss : 0.33016, Training Acc : 0.822, Run Time : 29.99
INFO:root:2019-05-11 03:35:32, Epoch : 1, Step : 5702, Training Loss : 0.33124, Training Acc : 0.856, Run Time : 7.32
INFO:root:2019-05-11 03:35:32, Epoch : 1, Step : 5703, Training Loss : 0.33478, Training Acc : 0.872, Run Time : 0.39
INFO:root:2019-05-11 03:35:34, Epoch : 1, Step : 5704, Training Loss : 0.21466, Training Acc : 0.928, Run Time : 1.45
INFO:root:2019-05-11 03:35:46, Epoch : 1, Step : 5705, Training Loss : 0.26828, Training Acc : 0.911, Run Time : 12.75
INFO:root:2019-05-11 03:35:47, Epoch : 1, Step : 5706, Training Loss : 0.23545, Training Acc : 0.939, Run Time : 0.95
INFO:root:2019-05-11 03:35:48, Epoch : 1, Step : 5707, Training Loss : 0.24282, Training Acc : 0.894, Run Time : 0.41
INFO:root:2019-05-11 03:35:58, Epoch : 1, Step : 5708, Training Loss : 0.16063, Training Acc : 0.961, Run Time : 9.88
INFO:root:2019-05-11 03:36:03, Epoch : 1, Step : 5709, Training Loss : 0.18432, Training Acc : 0.928, Run Time : 5.52
INFO:root:2019-05-11 03:36:04, Epoch : 1, Step : 5710, Training Loss : 0.15469, Training Acc : 0.933, Run Time : 0.75
INFO:root:2019-05-11 03:36:15, Epoch : 1, Step : 5711, Training Loss : 0.16872, Training Acc : 0.939, Run Time : 11.43
INFO:root:2019-05-11 03:36:16, Epoch : 1, Step : 5712, Training Loss : 0.14951, Training Acc : 0.961, Run Time : 0.41
INFO:root:2019-05-11 03:36:16, Epoch : 1, Step : 5713, Training Loss : 0.23796, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-11 03:36:18, Epoch : 1, Step : 5714, Training Loss : 0.21913, Training Acc : 0.933, Run Time : 1.65
INFO:root:2019-05-11 03:36:29, Epoch : 1, Step : 5715, Training Loss : 0.22101, Training Acc : 0.928, Run Time : 10.80
INFO:root:2019-05-11 03:36:30, Epoch : 1, Step : 5716, Training Loss : 0.28068, Training Acc : 0.867, Run Time : 1.42
INFO:root:2019-05-11 03:36:42, Epoch : 1, Step : 5717, Training Loss : 0.26849, Training Acc : 0.900, Run Time : 11.54
INFO:root:2019-05-11 03:36:42, Epoch : 1, Step : 5718, Training Loss : 0.23624, Training Acc : 0.933, Run Time : 0.49
INFO:root:2019-05-11 03:36:42, Epoch : 1, Step : 5719, Training Loss : 0.23725, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-11 03:36:51, Epoch : 1, Step : 5720, Training Loss : 0.26440, Training Acc : 0.933, Run Time : 8.21
INFO:root:2019-05-11 03:36:52, Epoch : 1, Step : 5721, Training Loss : 0.21110, Training Acc : 0.939, Run Time : 1.05
INFO:root:2019-05-11 03:36:52, Epoch : 1, Step : 5722, Training Loss : 0.19099, Training Acc : 0.939, Run Time : 0.49
INFO:root:2019-05-11 03:36:54, Epoch : 1, Step : 5723, Training Loss : 0.25443, Training Acc : 0.906, Run Time : 1.48
INFO:root:2019-05-11 03:37:03, Epoch : 1, Step : 5724, Training Loss : 0.13949, Training Acc : 0.961, Run Time : 9.66
INFO:root:2019-05-11 03:37:04, Epoch : 1, Step : 5725, Training Loss : 0.19164, Training Acc : 0.944, Run Time : 0.56
INFO:root:2019-05-11 03:37:04, Epoch : 1, Step : 5726, Training Loss : 0.15866, Training Acc : 0.961, Run Time : 0.48
INFO:root:2019-05-11 03:37:06, Epoch : 1, Step : 5727, Training Loss : 0.20235, Training Acc : 0.894, Run Time : 1.43
INFO:root:2019-05-11 03:37:16, Epoch : 1, Step : 5728, Training Loss : 0.19564, Training Acc : 0.950, Run Time : 10.43
INFO:root:2019-05-11 03:37:18, Epoch : 1, Step : 5729, Training Loss : 0.17520, Training Acc : 0.950, Run Time : 2.18
INFO:root:2019-05-11 03:37:30, Epoch : 1, Step : 5730, Training Loss : 0.21542, Training Acc : 0.956, Run Time : 11.36
INFO:root:2019-05-11 03:37:30, Epoch : 1, Step : 5731, Training Loss : 0.25470, Training Acc : 0.922, Run Time : 0.45
INFO:root:2019-05-11 03:37:31, Epoch : 1, Step : 5732, Training Loss : 0.25798, Training Acc : 0.906, Run Time : 0.39
INFO:root:2019-05-11 03:37:32, Epoch : 1, Step : 5733, Training Loss : 0.29151, Training Acc : 0.878, Run Time : 1.76
INFO:root:2019-05-11 03:37:44, Epoch : 1, Step : 5734, Training Loss : 0.16290, Training Acc : 0.956, Run Time : 11.34
INFO:root:2019-05-11 03:37:44, Epoch : 1, Step : 5735, Training Loss : 0.37352, Training Acc : 0.833, Run Time : 0.47
INFO:root:2019-05-11 03:37:45, Epoch : 1, Step : 5736, Training Loss : 0.18201, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 03:38:00, Epoch : 1, Step : 5737, Training Loss : 0.28680, Training Acc : 0.906, Run Time : 15.72
INFO:root:2019-05-11 03:38:01, Epoch : 1, Step : 5738, Training Loss : 0.30208, Training Acc : 0.883, Run Time : 0.68
INFO:root:2019-05-11 03:38:01, Epoch : 1, Step : 5739, Training Loss : 0.24775, Training Acc : 0.917, Run Time : 0.37
INFO:root:2019-05-11 03:38:16, Epoch : 1, Step : 5740, Training Loss : 0.33122, Training Acc : 0.872, Run Time : 14.37
INFO:root:2019-05-11 03:38:17, Epoch : 1, Step : 5741, Training Loss : 0.29089, Training Acc : 0.906, Run Time : 0.93
INFO:root:2019-05-11 03:38:18, Epoch : 1, Step : 5742, Training Loss : 0.34333, Training Acc : 0.844, Run Time : 1.58
INFO:root:2019-05-11 03:38:28, Epoch : 1, Step : 5743, Training Loss : 0.31821, Training Acc : 0.883, Run Time : 9.90
INFO:root:2019-05-11 03:38:30, Epoch : 1, Step : 5744, Training Loss : 0.40111, Training Acc : 0.817, Run Time : 1.45
INFO:root:2019-05-11 03:38:30, Epoch : 1, Step : 5745, Training Loss : 0.26334, Training Acc : 0.883, Run Time : 0.43
INFO:root:2019-05-11 03:38:31, Epoch : 1, Step : 5746, Training Loss : 0.52217, Training Acc : 0.844, Run Time : 0.83
INFO:root:2019-05-11 03:38:46, Epoch : 1, Step : 5747, Training Loss : 0.46719, Training Acc : 0.778, Run Time : 15.00
INFO:root:2019-05-11 03:38:54, Epoch : 1, Step : 5748, Training Loss : 0.33207, Training Acc : 0.839, Run Time : 7.62
INFO:root:2019-05-11 03:39:13, Epoch : 1, Step : 5749, Training Loss : 0.31422, Training Acc : 0.878, Run Time : 19.70
INFO:root:2019-05-11 03:39:15, Epoch : 1, Step : 5750, Training Loss : 0.32447, Training Acc : 0.867, Run Time : 1.86
INFO:root:2019-05-11 03:39:15, Epoch : 1, Step : 5751, Training Loss : 0.30249, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 03:39:16, Epoch : 1, Step : 5752, Training Loss : 0.37910, Training Acc : 0.800, Run Time : 0.97
INFO:root:2019-05-11 03:39:27, Epoch : 1, Step : 5753, Training Loss : 0.33380, Training Acc : 0.872, Run Time : 10.72
INFO:root:2019-05-11 03:39:28, Epoch : 1, Step : 5754, Training Loss : 0.38149, Training Acc : 0.856, Run Time : 0.77
INFO:root:2019-05-11 03:39:28, Epoch : 1, Step : 5755, Training Loss : 0.29538, Training Acc : 0.856, Run Time : 0.42
INFO:root:2019-05-11 03:39:29, Epoch : 1, Step : 5756, Training Loss : 0.41279, Training Acc : 0.850, Run Time : 1.05
INFO:root:2019-05-11 03:39:39, Epoch : 1, Step : 5757, Training Loss : 0.31687, Training Acc : 0.811, Run Time : 9.62
INFO:root:2019-05-11 03:39:40, Epoch : 1, Step : 5758, Training Loss : 0.46426, Training Acc : 0.767, Run Time : 1.18
INFO:root:2019-05-11 03:39:42, Epoch : 1, Step : 5759, Training Loss : 0.23828, Training Acc : 0.917, Run Time : 1.56
INFO:root:2019-05-11 03:39:57, Epoch : 1, Step : 5760, Training Loss : 0.23221, Training Acc : 0.883, Run Time : 14.92
INFO:root:2019-05-11 03:39:59, Epoch : 1, Step : 5761, Training Loss : 0.33523, Training Acc : 0.867, Run Time : 1.86
INFO:root:2019-05-11 03:40:19, Epoch : 1, Step : 5762, Training Loss : 0.14421, Training Acc : 0.978, Run Time : 20.44
INFO:root:2019-05-11 03:40:30, Epoch : 1, Step : 5763, Training Loss : 0.31426, Training Acc : 0.878, Run Time : 10.71
INFO:root:2019-05-11 03:40:42, Epoch : 1, Step : 5764, Training Loss : 0.20578, Training Acc : 0.950, Run Time : 12.52
INFO:root:2019-05-11 03:40:43, Epoch : 1, Step : 5765, Training Loss : 0.18291, Training Acc : 0.950, Run Time : 0.87
INFO:root:2019-05-11 03:41:01, Epoch : 1, Step : 5766, Training Loss : 0.20872, Training Acc : 0.917, Run Time : 17.98
INFO:root:2019-05-11 03:41:02, Epoch : 1, Step : 5767, Training Loss : 0.23904, Training Acc : 0.900, Run Time : 1.12
INFO:root:2019-05-11 03:41:03, Epoch : 1, Step : 5768, Training Loss : 0.33558, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 03:41:04, Epoch : 1, Step : 5769, Training Loss : 0.38263, Training Acc : 0.833, Run Time : 1.61
INFO:root:2019-05-11 03:41:21, Epoch : 1, Step : 5770, Training Loss : 0.19714, Training Acc : 0.928, Run Time : 17.28
INFO:root:2019-05-11 03:41:29, Epoch : 1, Step : 5771, Training Loss : 0.27181, Training Acc : 0.883, Run Time : 7.56
INFO:root:2019-05-11 03:41:31, Epoch : 1, Step : 5772, Training Loss : 0.29791, Training Acc : 0.900, Run Time : 1.70
INFO:root:2019-05-11 03:41:45, Epoch : 1, Step : 5773, Training Loss : 0.25574, Training Acc : 0.883, Run Time : 14.13
INFO:root:2019-05-11 03:41:45, Epoch : 1, Step : 5774, Training Loss : 0.28446, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-11 03:41:47, Epoch : 1, Step : 5775, Training Loss : 0.47172, Training Acc : 0.822, Run Time : 1.33
INFO:root:2019-05-11 03:42:10, Epoch : 1, Step : 5776, Training Loss : 0.50048, Training Acc : 0.767, Run Time : 23.88
INFO:root:2019-05-11 03:42:13, Epoch : 1, Step : 5777, Training Loss : 0.38501, Training Acc : 0.861, Run Time : 2.63
INFO:root:2019-05-11 03:42:14, Epoch : 1, Step : 5778, Training Loss : 0.33308, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-11 03:42:16, Epoch : 1, Step : 5779, Training Loss : 0.40881, Training Acc : 0.833, Run Time : 2.45
INFO:root:2019-05-11 03:42:33, Epoch : 1, Step : 5780, Training Loss : 0.30988, Training Acc : 0.878, Run Time : 17.22
INFO:root:2019-05-11 03:42:35, Epoch : 1, Step : 5781, Training Loss : 0.30399, Training Acc : 0.844, Run Time : 2.20
INFO:root:2019-05-11 03:42:59, Epoch : 1, Step : 5782, Training Loss : 0.34744, Training Acc : 0.833, Run Time : 23.71
INFO:root:2019-05-11 03:43:04, Epoch : 1, Step : 5783, Training Loss : 0.30442, Training Acc : 0.883, Run Time : 5.15
INFO:root:2019-05-11 03:43:09, Epoch : 1, Step : 5784, Training Loss : 0.31903, Training Acc : 0.878, Run Time : 5.04
INFO:root:2019-05-11 03:43:10, Epoch : 1, Step : 5785, Training Loss : 0.23211, Training Acc : 0.911, Run Time : 0.52
INFO:root:2019-05-11 03:43:11, Epoch : 1, Step : 5786, Training Loss : 0.26756, Training Acc : 0.906, Run Time : 0.86
INFO:root:2019-05-11 03:43:31, Epoch : 1, Step : 5787, Training Loss : 0.27240, Training Acc : 0.928, Run Time : 20.08
INFO:root:2019-05-11 03:43:38, Epoch : 1, Step : 5788, Training Loss : 0.19416, Training Acc : 0.939, Run Time : 7.35
INFO:root:2019-05-11 03:43:39, Epoch : 1, Step : 5789, Training Loss : 0.16855, Training Acc : 0.961, Run Time : 0.74
INFO:root:2019-05-11 03:43:52, Epoch : 1, Step : 5790, Training Loss : 0.16630, Training Acc : 0.933, Run Time : 13.33
INFO:root:2019-05-11 03:43:53, Epoch : 1, Step : 5791, Training Loss : 0.27144, Training Acc : 0.906, Run Time : 0.64
INFO:root:2019-05-11 03:43:53, Epoch : 1, Step : 5792, Training Loss : 0.18832, Training Acc : 0.989, Run Time : 0.45
INFO:root:2019-05-11 03:44:05, Epoch : 1, Step : 5793, Training Loss : 0.26315, Training Acc : 0.944, Run Time : 11.93
INFO:root:2019-05-11 03:44:06, Epoch : 1, Step : 5794, Training Loss : 0.26600, Training Acc : 0.894, Run Time : 1.00
INFO:root:2019-05-11 03:44:20, Epoch : 1, Step : 5795, Training Loss : 0.19429, Training Acc : 0.944, Run Time : 14.30
INFO:root:2019-05-11 03:44:21, Epoch : 1, Step : 5796, Training Loss : 0.22841, Training Acc : 0.917, Run Time : 0.96
INFO:root:2019-05-11 03:44:38, Epoch : 1, Step : 5797, Training Loss : 0.39803, Training Acc : 0.883, Run Time : 16.46
INFO:root:2019-05-11 03:44:57, Epoch : 1, Step : 5798, Training Loss : 0.28308, Training Acc : 0.911, Run Time : 18.89
INFO:root:2019-05-11 03:45:03, Epoch : 1, Step : 5799, Training Loss : 0.47044, Training Acc : 0.822, Run Time : 6.20
INFO:root:2019-05-11 03:45:03, Epoch : 1, Step : 5800, Training Loss : 0.51578, Training Acc : 0.756, Run Time : 0.48
INFO:root:2019-05-11 03:45:16, Epoch : 1, Step : 5801, Training Loss : 0.44792, Training Acc : 0.778, Run Time : 12.98
INFO:root:2019-05-11 03:45:17, Epoch : 1, Step : 5802, Training Loss : 0.43074, Training Acc : 0.756, Run Time : 0.73
INFO:root:2019-05-11 03:45:18, Epoch : 1, Step : 5803, Training Loss : 0.28201, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-11 03:45:30, Epoch : 1, Step : 5804, Training Loss : 0.29011, Training Acc : 0.872, Run Time : 12.07
INFO:root:2019-05-11 03:45:31, Epoch : 1, Step : 5805, Training Loss : 0.22443, Training Acc : 0.906, Run Time : 1.65
INFO:root:2019-05-11 03:45:32, Epoch : 1, Step : 5806, Training Loss : 0.16693, Training Acc : 0.944, Run Time : 0.41
INFO:root:2019-05-11 03:45:43, Epoch : 1, Step : 5807, Training Loss : 0.13817, Training Acc : 0.961, Run Time : 11.42
INFO:root:2019-05-11 03:46:09, Epoch : 1, Step : 5808, Training Loss : 0.11516, Training Acc : 0.972, Run Time : 25.80
INFO:root:2019-05-11 03:46:18, Epoch : 1, Step : 5809, Training Loss : 0.14467, Training Acc : 0.956, Run Time : 8.88
INFO:root:2019-05-11 03:46:41, Epoch : 1, Step : 5810, Training Loss : 0.14124, Training Acc : 0.933, Run Time : 23.14
INFO:root:2019-05-11 03:47:06, Epoch : 1, Step : 5811, Training Loss : 0.11432, Training Acc : 0.967, Run Time : 24.81
INFO:root:2019-05-11 03:47:09, Epoch : 1, Step : 5812, Training Loss : 0.19324, Training Acc : 0.911, Run Time : 2.90
INFO:root:2019-05-11 03:47:10, Epoch : 1, Step : 5813, Training Loss : 0.13841, Training Acc : 0.950, Run Time : 0.91
INFO:root:2019-05-11 03:47:26, Epoch : 1, Step : 5814, Training Loss : 0.12710, Training Acc : 0.944, Run Time : 16.00
INFO:root:2019-05-11 03:47:27, Epoch : 1, Step : 5815, Training Loss : 0.12845, Training Acc : 0.944, Run Time : 1.91
INFO:root:2019-05-11 03:47:40, Epoch : 1, Step : 5816, Training Loss : 0.15874, Training Acc : 0.922, Run Time : 12.61
INFO:root:2019-05-11 03:47:53, Epoch : 1, Step : 5817, Training Loss : 0.15692, Training Acc : 0.933, Run Time : 13.00
INFO:root:2019-05-11 03:47:54, Epoch : 1, Step : 5818, Training Loss : 0.15370, Training Acc : 0.933, Run Time : 0.82
INFO:root:2019-05-11 03:47:54, Epoch : 1, Step : 5819, Training Loss : 0.13690, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-11 03:47:55, Epoch : 1, Step : 5820, Training Loss : 0.15760, Training Acc : 0.928, Run Time : 0.53
INFO:root:2019-05-11 03:47:55, Epoch : 1, Step : 5821, Training Loss : 0.18133, Training Acc : 0.900, Run Time : 0.42
INFO:root:2019-05-11 03:47:56, Epoch : 1, Step : 5822, Training Loss : 0.16509, Training Acc : 0.928, Run Time : 0.39
INFO:root:2019-05-11 03:47:57, Epoch : 1, Step : 5823, Training Loss : 0.13386, Training Acc : 0.928, Run Time : 0.93
INFO:root:2019-05-11 03:48:22, Epoch : 1, Step : 5824, Training Loss : 0.15948, Training Acc : 0.922, Run Time : 24.98
INFO:root:2019-05-11 03:48:23, Epoch : 1, Step : 5825, Training Loss : 0.13091, Training Acc : 0.933, Run Time : 1.52
INFO:root:2019-05-11 03:48:23, Epoch : 1, Step : 5826, Training Loss : 0.12511, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 03:48:24, Epoch : 1, Step : 5827, Training Loss : 0.12469, Training Acc : 0.950, Run Time : 0.40
INFO:root:2019-05-11 03:48:25, Epoch : 1, Step : 5828, Training Loss : 0.11320, Training Acc : 0.939, Run Time : 1.47
INFO:root:2019-05-11 03:48:39, Epoch : 1, Step : 5829, Training Loss : 0.13259, Training Acc : 0.944, Run Time : 14.04
INFO:root:2019-05-11 03:48:51, Epoch : 1, Step : 5830, Training Loss : 0.12090, Training Acc : 0.961, Run Time : 11.59
INFO:root:2019-05-11 03:48:53, Epoch : 1, Step : 5831, Training Loss : 0.10523, Training Acc : 0.956, Run Time : 1.86
INFO:root:2019-05-11 03:48:53, Epoch : 1, Step : 5832, Training Loss : 0.27739, Training Acc : 0.911, Run Time : 0.63
INFO:root:2019-05-11 03:49:20, Epoch : 1, Step : 5833, Training Loss : 0.19305, Training Acc : 0.950, Run Time : 26.14
INFO:root:2019-05-11 03:49:27, Epoch : 1, Step : 5834, Training Loss : 0.25158, Training Acc : 0.944, Run Time : 7.20
INFO:root:2019-05-11 03:49:27, Epoch : 1, Step : 5835, Training Loss : 0.19355, Training Acc : 0.939, Run Time : 0.47
INFO:root:2019-05-11 03:49:28, Epoch : 1, Step : 5836, Training Loss : 0.17661, Training Acc : 0.950, Run Time : 0.79
INFO:root:2019-05-11 03:49:44, Epoch : 1, Step : 5837, Training Loss : 0.19656, Training Acc : 0.922, Run Time : 16.40
INFO:root:2019-05-11 03:49:45, Epoch : 1, Step : 5838, Training Loss : 0.15886, Training Acc : 0.922, Run Time : 0.89
INFO:root:2019-05-11 03:49:57, Epoch : 1, Step : 5839, Training Loss : 0.14321, Training Acc : 0.911, Run Time : 11.21
INFO:root:2019-05-11 03:49:57, Epoch : 1, Step : 5840, Training Loss : 0.26486, Training Acc : 0.894, Run Time : 0.71
INFO:root:2019-05-11 03:49:58, Epoch : 1, Step : 5841, Training Loss : 0.13727, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 03:49:59, Epoch : 1, Step : 5842, Training Loss : 0.16109, Training Acc : 0.917, Run Time : 1.45
INFO:root:2019-05-11 03:50:11, Epoch : 1, Step : 5843, Training Loss : 0.20120, Training Acc : 0.917, Run Time : 12.28
INFO:root:2019-05-11 03:50:12, Epoch : 1, Step : 5844, Training Loss : 0.38533, Training Acc : 0.850, Run Time : 0.81
INFO:root:2019-05-11 03:50:13, Epoch : 1, Step : 5845, Training Loss : 0.33939, Training Acc : 0.856, Run Time : 1.00
INFO:root:2019-05-11 03:50:45, Epoch : 1, Step : 5846, Training Loss : 0.22323, Training Acc : 0.906, Run Time : 31.86
INFO:root:2019-05-11 03:50:58, Epoch : 1, Step : 5847, Training Loss : 0.38051, Training Acc : 0.839, Run Time : 13.36
INFO:root:2019-05-11 03:51:08, Epoch : 1, Step : 5848, Training Loss : 0.27310, Training Acc : 0.906, Run Time : 10.03
INFO:root:2019-05-11 03:51:29, Epoch : 1, Step : 5849, Training Loss : 0.17261, Training Acc : 0.906, Run Time : 20.82
INFO:root:2019-05-11 03:51:42, Epoch : 1, Step : 5850, Training Loss : 0.20253, Training Acc : 0.906, Run Time : 12.33
INFO:root:2019-05-11 03:52:00, Epoch : 1, Step : 5851, Training Loss : 0.23983, Training Acc : 0.878, Run Time : 18.62
INFO:root:2019-05-11 03:52:20, Epoch : 1, Step : 5852, Training Loss : 0.19121, Training Acc : 0.894, Run Time : 19.40
INFO:root:2019-05-11 03:52:22, Epoch : 1, Step : 5853, Training Loss : 0.18286, Training Acc : 0.911, Run Time : 2.09
INFO:root:2019-05-11 03:52:22, Epoch : 1, Step : 5854, Training Loss : 0.30013, Training Acc : 0.856, Run Time : 0.39
INFO:root:2019-05-11 03:52:35, Epoch : 1, Step : 5855, Training Loss : 0.17719, Training Acc : 0.911, Run Time : 12.49
INFO:root:2019-05-11 03:52:35, Epoch : 1, Step : 5856, Training Loss : 0.17809, Training Acc : 0.917, Run Time : 0.53
INFO:root:2019-05-11 03:52:35, Epoch : 1, Step : 5857, Training Loss : 0.12341, Training Acc : 0.961, Run Time : 0.42
INFO:root:2019-05-11 03:52:36, Epoch : 1, Step : 5858, Training Loss : 0.12204, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-11 03:52:37, Epoch : 1, Step : 5859, Training Loss : 0.13074, Training Acc : 0.944, Run Time : 1.23
INFO:root:2019-05-11 03:52:49, Epoch : 1, Step : 5860, Training Loss : 0.16499, Training Acc : 0.922, Run Time : 11.42
INFO:root:2019-05-11 03:53:01, Epoch : 1, Step : 5861, Training Loss : 0.11283, Training Acc : 0.961, Run Time : 12.38
INFO:root:2019-05-11 03:53:10, Epoch : 1, Step : 5862, Training Loss : 0.11891, Training Acc : 0.933, Run Time : 8.88
INFO:root:2019-05-11 03:53:15, Epoch : 1, Step : 5863, Training Loss : 0.17146, Training Acc : 0.939, Run Time : 4.68
INFO:root:2019-05-11 03:53:25, Epoch : 1, Step : 5864, Training Loss : 0.23411, Training Acc : 0.939, Run Time : 10.37
INFO:root:2019-05-11 03:53:26, Epoch : 1, Step : 5865, Training Loss : 0.13715, Training Acc : 0.956, Run Time : 0.91
INFO:root:2019-05-11 03:53:37, Epoch : 1, Step : 5866, Training Loss : 0.10769, Training Acc : 0.978, Run Time : 11.38
INFO:root:2019-05-11 03:53:39, Epoch : 1, Step : 5867, Training Loss : 0.12355, Training Acc : 0.956, Run Time : 1.72
INFO:root:2019-05-11 03:53:39, Epoch : 1, Step : 5868, Training Loss : 0.11006, Training Acc : 0.956, Run Time : 0.42
INFO:root:2019-05-11 03:53:51, Epoch : 1, Step : 5869, Training Loss : 0.16696, Training Acc : 0.939, Run Time : 12.12
INFO:root:2019-05-11 03:54:04, Epoch : 1, Step : 5870, Training Loss : 0.09380, Training Acc : 0.961, Run Time : 12.97
INFO:root:2019-05-11 03:54:21, Epoch : 1, Step : 5871, Training Loss : 0.22316, Training Acc : 0.939, Run Time : 16.92
INFO:root:2019-05-11 03:54:23, Epoch : 1, Step : 5872, Training Loss : 0.18581, Training Acc : 0.928, Run Time : 1.65
INFO:root:2019-05-11 03:54:23, Epoch : 1, Step : 5873, Training Loss : 0.21798, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 03:54:24, Epoch : 1, Step : 5874, Training Loss : 0.12162, Training Acc : 0.961, Run Time : 0.38
INFO:root:2019-05-11 03:54:24, Epoch : 1, Step : 5875, Training Loss : 0.13082, Training Acc : 0.939, Run Time : 0.63
INFO:root:2019-05-11 03:54:25, Epoch : 1, Step : 5876, Training Loss : 0.18447, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-11 03:54:25, Epoch : 1, Step : 5877, Training Loss : 0.11697, Training Acc : 0.961, Run Time : 0.38
INFO:root:2019-05-11 03:54:26, Epoch : 1, Step : 5878, Training Loss : 0.17407, Training Acc : 0.917, Run Time : 0.74
INFO:root:2019-05-11 03:54:38, Epoch : 1, Step : 5879, Training Loss : 0.17453, Training Acc : 0.917, Run Time : 11.85
INFO:root:2019-05-11 03:54:39, Epoch : 1, Step : 5880, Training Loss : 0.10642, Training Acc : 0.978, Run Time : 0.70
INFO:root:2019-05-11 03:54:39, Epoch : 1, Step : 5881, Training Loss : 0.13510, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-11 03:54:39, Epoch : 1, Step : 5882, Training Loss : 0.14116, Training Acc : 0.961, Run Time : 0.38
INFO:root:2019-05-11 03:54:41, Epoch : 1, Step : 5883, Training Loss : 0.11000, Training Acc : 0.956, Run Time : 1.38
INFO:root:2019-05-11 03:54:53, Epoch : 1, Step : 5884, Training Loss : 0.13679, Training Acc : 0.928, Run Time : 12.59
INFO:root:2019-05-11 03:54:54, Epoch : 1, Step : 5885, Training Loss : 0.18830, Training Acc : 0.933, Run Time : 1.02
INFO:root:2019-05-11 03:54:55, Epoch : 1, Step : 5886, Training Loss : 0.15746, Training Acc : 0.956, Run Time : 0.63
INFO:root:2019-05-11 03:55:16, Epoch : 1, Step : 5887, Training Loss : 0.18709, Training Acc : 0.917, Run Time : 20.93
INFO:root:2019-05-11 03:55:19, Epoch : 1, Step : 5888, Training Loss : 0.10546, Training Acc : 0.961, Run Time : 3.49
INFO:root:2019-05-11 03:55:20, Epoch : 1, Step : 5889, Training Loss : 0.09750, Training Acc : 0.978, Run Time : 0.59
INFO:root:2019-05-11 03:55:21, Epoch : 1, Step : 5890, Training Loss : 0.12303, Training Acc : 0.956, Run Time : 0.85
INFO:root:2019-05-11 03:55:35, Epoch : 1, Step : 5891, Training Loss : 0.11038, Training Acc : 0.950, Run Time : 13.93
INFO:root:2019-05-11 03:55:49, Epoch : 1, Step : 5892, Training Loss : 0.11557, Training Acc : 0.961, Run Time : 14.65
INFO:root:2019-05-11 03:55:51, Epoch : 1, Step : 5893, Training Loss : 0.08925, Training Acc : 0.961, Run Time : 1.98
INFO:root:2019-05-11 03:56:03, Epoch : 1, Step : 5894, Training Loss : 0.11512, Training Acc : 0.956, Run Time : 11.32
INFO:root:2019-05-11 03:56:03, Epoch : 1, Step : 5895, Training Loss : 0.11656, Training Acc : 0.956, Run Time : 0.42
INFO:root:2019-05-11 03:56:04, Epoch : 1, Step : 5896, Training Loss : 0.11023, Training Acc : 0.961, Run Time : 0.44
INFO:root:2019-05-11 03:56:04, Epoch : 1, Step : 5897, Training Loss : 0.12662, Training Acc : 0.961, Run Time : 0.39
INFO:root:2019-05-11 03:56:06, Epoch : 1, Step : 5898, Training Loss : 0.09599, Training Acc : 0.956, Run Time : 1.60
INFO:root:2019-05-11 03:56:26, Epoch : 1, Step : 5899, Training Loss : 0.11103, Training Acc : 0.972, Run Time : 20.91
INFO:root:2019-05-11 03:56:35, Epoch : 1, Step : 5900, Training Loss : 0.10376, Training Acc : 0.967, Run Time : 8.16
INFO:root:2019-05-11 03:56:48, Epoch : 1, Step : 5901, Training Loss : 0.10077, Training Acc : 0.944, Run Time : 13.18
INFO:root:2019-05-11 03:56:50, Epoch : 1, Step : 5902, Training Loss : 0.13294, Training Acc : 0.967, Run Time : 1.83
INFO:root:2019-05-11 03:57:02, Epoch : 1, Step : 5903, Training Loss : 0.10319, Training Acc : 0.967, Run Time : 12.86
INFO:root:2019-05-11 03:57:16, Epoch : 1, Step : 5904, Training Loss : 0.10757, Training Acc : 0.972, Run Time : 13.66
INFO:root:2019-05-11 03:57:21, Epoch : 1, Step : 5905, Training Loss : 0.11371, Training Acc : 0.967, Run Time : 4.90
INFO:root:2019-05-11 03:57:21, Epoch : 1, Step : 5906, Training Loss : 0.11847, Training Acc : 0.967, Run Time : 0.38
INFO:root:2019-05-11 03:57:22, Epoch : 1, Step : 5907, Training Loss : 0.10496, Training Acc : 0.978, Run Time : 0.95
INFO:root:2019-05-11 03:57:47, Epoch : 1, Step : 5908, Training Loss : 0.08458, Training Acc : 0.983, Run Time : 24.68
INFO:root:2019-05-11 03:57:58, Epoch : 1, Step : 5909, Training Loss : 0.22648, Training Acc : 0.917, Run Time : 10.61
INFO:root:2019-05-11 03:58:02, Epoch : 1, Step : 5910, Training Loss : 0.42292, Training Acc : 0.872, Run Time : 3.84
INFO:root:2019-05-11 03:58:03, Epoch : 1, Step : 5911, Training Loss : 0.65750, Training Acc : 0.778, Run Time : 1.03
INFO:root:2019-05-11 03:58:24, Epoch : 1, Step : 5912, Training Loss : 0.83203, Training Acc : 0.750, Run Time : 21.68
INFO:root:2019-05-11 03:58:25, Epoch : 1, Step : 5913, Training Loss : 0.63814, Training Acc : 0.728, Run Time : 1.26
INFO:root:2019-05-11 03:58:27, Epoch : 1, Step : 5914, Training Loss : 0.53584, Training Acc : 0.844, Run Time : 1.24
INFO:root:2019-05-11 03:58:38, Epoch : 1, Step : 5915, Training Loss : 0.56962, Training Acc : 0.833, Run Time : 11.26
INFO:root:2019-05-11 03:58:39, Epoch : 1, Step : 5916, Training Loss : 0.48506, Training Acc : 0.783, Run Time : 1.48
INFO:root:2019-05-11 03:58:40, Epoch : 1, Step : 5917, Training Loss : 0.47219, Training Acc : 0.850, Run Time : 0.43
INFO:root:2019-05-11 03:58:55, Epoch : 1, Step : 5918, Training Loss : 0.46562, Training Acc : 0.844, Run Time : 15.21
INFO:root:2019-05-11 03:58:56, Epoch : 1, Step : 5919, Training Loss : 0.45469, Training Acc : 0.844, Run Time : 0.65
INFO:root:2019-05-11 03:58:56, Epoch : 1, Step : 5920, Training Loss : 0.36579, Training Acc : 0.872, Run Time : 0.37
INFO:root:2019-05-11 03:58:58, Epoch : 1, Step : 5921, Training Loss : 0.48571, Training Acc : 0.817, Run Time : 1.97
INFO:root:2019-05-11 03:59:09, Epoch : 1, Step : 5922, Training Loss : 0.65248, Training Acc : 0.761, Run Time : 10.42
INFO:root:2019-05-11 03:59:09, Epoch : 1, Step : 5923, Training Loss : 0.54978, Training Acc : 0.772, Run Time : 0.41
INFO:root:2019-05-11 03:59:09, Epoch : 1, Step : 5924, Training Loss : 0.51856, Training Acc : 0.772, Run Time : 0.53
INFO:root:2019-05-11 03:59:11, Epoch : 1, Step : 5925, Training Loss : 0.36051, Training Acc : 0.828, Run Time : 1.35
INFO:root:2019-05-11 03:59:21, Epoch : 1, Step : 5926, Training Loss : 0.34056, Training Acc : 0.833, Run Time : 10.38
INFO:root:2019-05-11 03:59:22, Epoch : 1, Step : 5927, Training Loss : 0.39768, Training Acc : 0.817, Run Time : 0.45
INFO:root:2019-05-11 03:59:22, Epoch : 1, Step : 5928, Training Loss : 0.37004, Training Acc : 0.828, Run Time : 0.68
INFO:root:2019-05-11 03:59:23, Epoch : 1, Step : 5929, Training Loss : 0.49386, Training Acc : 0.794, Run Time : 0.76
INFO:root:2019-05-11 03:59:36, Epoch : 1, Step : 5930, Training Loss : 0.38702, Training Acc : 0.817, Run Time : 13.14
INFO:root:2019-05-11 03:59:38, Epoch : 1, Step : 5931, Training Loss : 0.32381, Training Acc : 0.839, Run Time : 1.38
INFO:root:2019-05-11 03:59:38, Epoch : 1, Step : 5932, Training Loss : 0.36108, Training Acc : 0.861, Run Time : 0.63
INFO:root:2019-05-11 03:59:39, Epoch : 1, Step : 5933, Training Loss : 0.33833, Training Acc : 0.861, Run Time : 0.62
INFO:root:2019-05-11 03:59:50, Epoch : 1, Step : 5934, Training Loss : 0.30230, Training Acc : 0.878, Run Time : 11.58
INFO:root:2019-05-11 03:59:51, Epoch : 1, Step : 5935, Training Loss : 0.37169, Training Acc : 0.839, Run Time : 0.97
INFO:root:2019-05-11 03:59:52, Epoch : 1, Step : 5936, Training Loss : 0.30336, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-11 03:59:56, Epoch : 1, Step : 5937, Training Loss : 0.23593, Training Acc : 0.906, Run Time : 4.37
INFO:root:2019-05-11 03:59:58, Epoch : 1, Step : 5938, Training Loss : 0.31963, Training Acc : 0.844, Run Time : 1.72
INFO:root:2019-05-11 04:00:11, Epoch : 1, Step : 5939, Training Loss : 0.33239, Training Acc : 0.828, Run Time : 13.08
INFO:root:2019-05-11 04:00:12, Epoch : 1, Step : 5940, Training Loss : 0.39821, Training Acc : 0.861, Run Time : 1.26
INFO:root:2019-05-11 04:00:13, Epoch : 1, Step : 5941, Training Loss : 0.47261, Training Acc : 0.800, Run Time : 0.38
INFO:root:2019-05-11 04:00:15, Epoch : 1, Step : 5942, Training Loss : 0.46592, Training Acc : 0.878, Run Time : 2.55
INFO:root:2019-05-11 04:00:29, Epoch : 1, Step : 5943, Training Loss : 0.46878, Training Acc : 0.833, Run Time : 14.29
INFO:root:2019-05-11 04:00:47, Epoch : 1, Step : 5944, Training Loss : 0.27858, Training Acc : 0.883, Run Time : 17.48
INFO:root:2019-05-11 04:00:49, Epoch : 1, Step : 5945, Training Loss : 0.20498, Training Acc : 0.906, Run Time : 1.69
INFO:root:2019-05-11 04:00:49, Epoch : 1, Step : 5946, Training Loss : 0.20782, Training Acc : 0.917, Run Time : 0.69
INFO:root:2019-05-11 04:01:02, Epoch : 1, Step : 5947, Training Loss : 0.21898, Training Acc : 0.911, Run Time : 12.53
INFO:root:2019-05-11 04:01:03, Epoch : 1, Step : 5948, Training Loss : 0.14624, Training Acc : 0.922, Run Time : 1.67
INFO:root:2019-05-11 04:01:16, Epoch : 1, Step : 5949, Training Loss : 0.12203, Training Acc : 0.950, Run Time : 12.63
INFO:root:2019-05-11 04:01:18, Epoch : 1, Step : 5950, Training Loss : 0.13316, Training Acc : 0.956, Run Time : 1.47
INFO:root:2019-05-11 04:01:18, Epoch : 1, Step : 5951, Training Loss : 0.11311, Training Acc : 0.956, Run Time : 0.38
INFO:root:2019-05-11 04:01:18, Epoch : 1, Step : 5952, Training Loss : 0.15533, Training Acc : 0.928, Run Time : 0.39
INFO:root:2019-05-11 04:01:35, Epoch : 1, Step : 5953, Training Loss : 0.04925, Training Acc : 0.989, Run Time : 16.33
INFO:root:2019-05-11 04:01:36, Epoch : 1, Step : 5954, Training Loss : 0.09695, Training Acc : 0.972, Run Time : 1.74
INFO:root:2019-05-11 04:01:52, Epoch : 1, Step : 5955, Training Loss : 0.11293, Training Acc : 0.967, Run Time : 15.66
INFO:root:2019-05-11 04:02:14, Epoch : 1, Step : 5956, Training Loss : 0.18044, Training Acc : 0.922, Run Time : 21.69
INFO:root:2019-05-11 04:02:26, Epoch : 1, Step : 5957, Training Loss : 0.15661, Training Acc : 0.939, Run Time : 12.58
INFO:root:2019-05-11 04:02:36, Epoch : 1, Step : 5958, Training Loss : 0.12473, Training Acc : 0.933, Run Time : 9.72
INFO:root:2019-05-11 04:02:57, Epoch : 1, Step : 5959, Training Loss : 0.07232, Training Acc : 0.967, Run Time : 20.94
INFO:root:2019-05-11 04:03:14, Epoch : 1, Step : 5960, Training Loss : 0.07988, Training Acc : 0.978, Run Time : 16.81
INFO:root:2019-05-11 04:03:37, Epoch : 1, Step : 5961, Training Loss : 0.11314, Training Acc : 0.944, Run Time : 23.42
INFO:root:2019-05-11 04:03:45, Epoch : 1, Step : 5962, Training Loss : 0.12391, Training Acc : 0.933, Run Time : 7.39
INFO:root:2019-05-11 04:03:46, Epoch : 1, Step : 5963, Training Loss : 0.09964, Training Acc : 0.961, Run Time : 1.07
INFO:root:2019-05-11 04:03:58, Epoch : 1, Step : 5964, Training Loss : 0.05632, Training Acc : 0.989, Run Time : 11.97
INFO:root:2019-05-11 04:04:00, Epoch : 1, Step : 5965, Training Loss : 0.09493, Training Acc : 0.944, Run Time : 2.52
INFO:root:2019-05-11 04:04:20, Epoch : 1, Step : 5966, Training Loss : 0.08422, Training Acc : 0.972, Run Time : 20.24
INFO:root:2019-05-11 04:04:36, Epoch : 1, Step : 5967, Training Loss : 0.10453, Training Acc : 0.967, Run Time : 15.28
INFO:root:2019-05-11 04:04:47, Epoch : 1, Step : 5968, Training Loss : 0.07306, Training Acc : 0.972, Run Time : 11.12
INFO:root:2019-05-11 04:04:57, Epoch : 1, Step : 5969, Training Loss : 0.12772, Training Acc : 0.939, Run Time : 10.31
INFO:root:2019-05-11 04:05:00, Epoch : 1, Step : 5970, Training Loss : 0.12378, Training Acc : 0.933, Run Time : 2.59
INFO:root:2019-05-11 04:05:11, Epoch : 1, Step : 5971, Training Loss : 0.13270, Training Acc : 0.922, Run Time : 11.00
INFO:root:2019-05-11 04:05:22, Epoch : 1, Step : 5972, Training Loss : 0.13691, Training Acc : 0.928, Run Time : 11.72
INFO:root:2019-05-11 04:05:37, Epoch : 1, Step : 5973, Training Loss : 0.11711, Training Acc : 0.933, Run Time : 14.42
INFO:root:2019-05-11 04:05:38, Epoch : 1, Step : 5974, Training Loss : 0.16019, Training Acc : 0.933, Run Time : 1.35
INFO:root:2019-05-11 04:05:49, Epoch : 1, Step : 5975, Training Loss : 0.06663, Training Acc : 0.983, Run Time : 11.19
INFO:root:2019-05-11 04:05:50, Epoch : 1, Step : 5976, Training Loss : 0.10876, Training Acc : 0.939, Run Time : 0.42
INFO:root:2019-05-11 04:05:52, Epoch : 1, Step : 5977, Training Loss : 0.07362, Training Acc : 0.967, Run Time : 2.02
INFO:root:2019-05-11 04:06:15, Epoch : 1, Step : 5978, Training Loss : 0.06169, Training Acc : 0.989, Run Time : 22.93
INFO:root:2019-05-11 04:06:16, Epoch : 1, Step : 5979, Training Loss : 0.04891, Training Acc : 1.000, Run Time : 1.63
INFO:root:2019-05-11 04:06:17, Epoch : 1, Step : 5980, Training Loss : 0.07105, Training Acc : 0.961, Run Time : 0.38
INFO:root:2019-05-11 04:06:18, Epoch : 1, Step : 5981, Training Loss : 0.03732, Training Acc : 0.994, Run Time : 1.37
INFO:root:2019-05-11 04:06:46, Epoch : 1, Step : 5982, Training Loss : 0.04762, Training Acc : 0.983, Run Time : 27.67
INFO:root:2019-05-11 04:06:52, Epoch : 1, Step : 5983, Training Loss : 0.05914, Training Acc : 0.978, Run Time : 6.08
INFO:root:2019-05-11 04:06:52, Epoch : 1, Step : 5984, Training Loss : 0.07142, Training Acc : 0.967, Run Time : 0.38
INFO:root:2019-05-11 04:06:53, Epoch : 1, Step : 5985, Training Loss : 0.06588, Training Acc : 0.989, Run Time : 0.38
INFO:root:2019-05-11 04:06:54, Epoch : 1, Step : 5986, Training Loss : 0.07044, Training Acc : 0.967, Run Time : 1.49
INFO:root:2019-05-11 04:07:08, Epoch : 1, Step : 5987, Training Loss : 0.05350, Training Acc : 0.983, Run Time : 13.52
INFO:root:2019-05-11 04:07:09, Epoch : 1, Step : 5988, Training Loss : 0.08307, Training Acc : 0.956, Run Time : 1.09
INFO:root:2019-05-11 04:07:11, Epoch : 1, Step : 5989, Training Loss : 0.06802, Training Acc : 0.972, Run Time : 2.35
INFO:root:2019-05-11 04:07:36, Epoch : 1, Step : 5990, Training Loss : 0.06324, Training Acc : 0.978, Run Time : 25.28
INFO:root:2019-05-11 04:07:38, Epoch : 1, Step : 5991, Training Loss : 0.05939, Training Acc : 0.983, Run Time : 1.44
INFO:root:2019-05-11 04:07:38, Epoch : 1, Step : 5992, Training Loss : 0.05326, Training Acc : 0.978, Run Time : 0.41
INFO:root:2019-05-11 04:07:39, Epoch : 1, Step : 5993, Training Loss : 0.06149, Training Acc : 0.983, Run Time : 0.71
INFO:root:2019-05-11 04:07:49, Epoch : 1, Step : 5994, Training Loss : 0.06163, Training Acc : 0.983, Run Time : 9.80
INFO:root:2019-05-11 04:07:50, Epoch : 1, Step : 5995, Training Loss : 0.05123, Training Acc : 0.967, Run Time : 1.31
INFO:root:2019-05-11 04:08:04, Epoch : 1, Step : 5996, Training Loss : 0.08878, Training Acc : 0.961, Run Time : 13.64
INFO:root:2019-05-11 04:08:05, Epoch : 1, Step : 5997, Training Loss : 0.05445, Training Acc : 0.983, Run Time : 1.44
INFO:root:2019-05-11 04:08:06, Epoch : 1, Step : 5998, Training Loss : 0.07703, Training Acc : 0.961, Run Time : 0.41
INFO:root:2019-05-11 04:08:07, Epoch : 1, Step : 5999, Training Loss : 0.05359, Training Acc : 0.978, Run Time : 1.63
INFO:root:2019-05-11 04:08:19, Epoch : 1, Step : 6000, Training Loss : 0.05740, Training Acc : 0.978, Run Time : 11.55
INFO:root:2019-05-11 04:08:20, Epoch : 1, Step : 6001, Training Loss : 0.30230, Training Acc : 0.894, Run Time : 1.34
INFO:root:2019-05-11 04:08:21, Epoch : 1, Step : 6002, Training Loss : 0.55406, Training Acc : 0.806, Run Time : 1.43
INFO:root:2019-05-11 04:08:43, Epoch : 1, Step : 6003, Training Loss : 0.50457, Training Acc : 0.861, Run Time : 21.71
INFO:root:2019-05-11 04:08:47, Epoch : 1, Step : 6004, Training Loss : 0.58279, Training Acc : 0.822, Run Time : 3.38
INFO:root:2019-05-11 04:08:47, Epoch : 1, Step : 6005, Training Loss : 0.37487, Training Acc : 0.883, Run Time : 0.40
INFO:root:2019-05-11 04:08:48, Epoch : 1, Step : 6006, Training Loss : 0.41552, Training Acc : 0.800, Run Time : 0.74
INFO:root:2019-05-11 04:09:04, Epoch : 1, Step : 6007, Training Loss : 0.37064, Training Acc : 0.900, Run Time : 16.55
INFO:root:2019-05-11 04:09:06, Epoch : 1, Step : 6008, Training Loss : 0.86510, Training Acc : 0.789, Run Time : 1.38
INFO:root:2019-05-11 04:09:06, Epoch : 1, Step : 6009, Training Loss : 0.20327, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-11 04:09:07, Epoch : 1, Step : 6010, Training Loss : 0.68948, Training Acc : 0.806, Run Time : 1.00
INFO:root:2019-05-11 04:09:19, Epoch : 1, Step : 6011, Training Loss : 0.36914, Training Acc : 0.872, Run Time : 11.43
INFO:root:2019-05-11 04:09:37, Epoch : 1, Step : 6012, Training Loss : 0.35200, Training Acc : 0.889, Run Time : 18.40
INFO:root:2019-05-11 04:09:51, Epoch : 1, Step : 6013, Training Loss : 0.24201, Training Acc : 0.894, Run Time : 14.34
INFO:root:2019-05-11 04:09:52, Epoch : 1, Step : 6014, Training Loss : 0.26462, Training Acc : 0.900, Run Time : 0.86
INFO:root:2019-05-11 04:09:53, Epoch : 1, Step : 6015, Training Loss : 0.26978, Training Acc : 0.894, Run Time : 0.44
INFO:root:2019-05-11 04:09:54, Epoch : 1, Step : 6016, Training Loss : 0.35061, Training Acc : 0.872, Run Time : 1.24
INFO:root:2019-05-11 04:10:08, Epoch : 1, Step : 6017, Training Loss : 0.10340, Training Acc : 0.944, Run Time : 13.66
INFO:root:2019-05-11 04:10:20, Epoch : 1, Step : 6018, Training Loss : 0.13656, Training Acc : 0.933, Run Time : 12.63
INFO:root:2019-05-11 04:10:21, Epoch : 1, Step : 6019, Training Loss : 0.14559, Training Acc : 0.961, Run Time : 0.85
INFO:root:2019-05-11 04:10:22, Epoch : 1, Step : 6020, Training Loss : 0.21353, Training Acc : 0.917, Run Time : 0.84
INFO:root:2019-05-11 04:10:35, Epoch : 1, Step : 6021, Training Loss : 0.22074, Training Acc : 0.917, Run Time : 12.93
INFO:root:2019-05-11 04:10:50, Epoch : 1, Step : 6022, Training Loss : 0.18933, Training Acc : 0.950, Run Time : 15.02
INFO:root:2019-05-11 04:10:51, Epoch : 1, Step : 6023, Training Loss : 0.24154, Training Acc : 0.928, Run Time : 1.64
INFO:root:2019-05-11 04:11:02, Epoch : 1, Step : 6024, Training Loss : 0.07989, Training Acc : 0.983, Run Time : 10.63
INFO:root:2019-05-11 04:11:14, Epoch : 1, Step : 6025, Training Loss : 0.13799, Training Acc : 0.961, Run Time : 11.51
INFO:root:2019-05-11 04:11:15, Epoch : 1, Step : 6026, Training Loss : 0.12474, Training Acc : 0.956, Run Time : 1.02
INFO:root:2019-05-11 04:11:16, Epoch : 1, Step : 6027, Training Loss : 0.09645, Training Acc : 0.972, Run Time : 1.12
INFO:root:2019-05-11 04:11:27, Epoch : 1, Step : 6028, Training Loss : 0.11942, Training Acc : 0.967, Run Time : 11.26
INFO:root:2019-05-11 04:11:27, Epoch : 1, Step : 6029, Training Loss : 0.21142, Training Acc : 0.928, Run Time : 0.52
INFO:root:2019-05-11 04:11:29, Epoch : 1, Step : 6030, Training Loss : 0.14347, Training Acc : 0.950, Run Time : 1.37
INFO:root:2019-05-11 04:11:50, Epoch : 1, Step : 6031, Training Loss : 0.17531, Training Acc : 0.961, Run Time : 20.76
INFO:root:2019-05-11 04:11:52, Epoch : 1, Step : 6032, Training Loss : 0.21140, Training Acc : 0.922, Run Time : 2.18
INFO:root:2019-05-11 04:11:52, Epoch : 1, Step : 6033, Training Loss : 0.09850, Training Acc : 0.978, Run Time : 0.43
INFO:root:2019-05-11 04:12:11, Epoch : 1, Step : 6034, Training Loss : 0.10685, Training Acc : 0.967, Run Time : 18.47
INFO:root:2019-05-11 04:12:13, Epoch : 1, Step : 6035, Training Loss : 0.21861, Training Acc : 0.933, Run Time : 2.07
INFO:root:2019-05-11 04:12:13, Epoch : 1, Step : 6036, Training Loss : 0.15299, Training Acc : 0.950, Run Time : 0.43
INFO:root:2019-05-11 04:12:25, Epoch : 1, Step : 6037, Training Loss : 0.11314, Training Acc : 0.967, Run Time : 11.32
INFO:root:2019-05-11 04:12:26, Epoch : 1, Step : 6038, Training Loss : 0.18271, Training Acc : 0.922, Run Time : 1.54
INFO:root:2019-05-11 04:12:40, Epoch : 1, Step : 6039, Training Loss : 0.33145, Training Acc : 0.889, Run Time : 13.58
INFO:root:2019-05-11 04:12:42, Epoch : 1, Step : 6040, Training Loss : 0.21700, Training Acc : 0.928, Run Time : 1.97
INFO:root:2019-05-11 04:12:42, Epoch : 1, Step : 6041, Training Loss : 0.23984, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-11 04:12:43, Epoch : 1, Step : 6042, Training Loss : 0.19845, Training Acc : 0.939, Run Time : 1.05
INFO:root:2019-05-11 04:12:56, Epoch : 1, Step : 6043, Training Loss : 0.26441, Training Acc : 0.939, Run Time : 13.07
INFO:root:2019-05-11 04:12:57, Epoch : 1, Step : 6044, Training Loss : 0.30909, Training Acc : 0.906, Run Time : 0.68
INFO:root:2019-05-11 04:12:59, Epoch : 1, Step : 6045, Training Loss : 0.31094, Training Acc : 0.894, Run Time : 1.88
INFO:root:2019-05-11 04:13:14, Epoch : 1, Step : 6046, Training Loss : 0.18585, Training Acc : 0.939, Run Time : 15.16
INFO:root:2019-05-11 04:13:15, Epoch : 1, Step : 6047, Training Loss : 0.14377, Training Acc : 0.950, Run Time : 1.54
INFO:root:2019-05-11 04:13:28, Epoch : 1, Step : 6048, Training Loss : 0.18348, Training Acc : 0.933, Run Time : 12.53
INFO:root:2019-05-11 04:13:29, Epoch : 1, Step : 6049, Training Loss : 0.11288, Training Acc : 0.978, Run Time : 0.67
INFO:root:2019-05-11 04:13:29, Epoch : 1, Step : 6050, Training Loss : 0.14671, Training Acc : 0.933, Run Time : 0.80
INFO:root:2019-05-11 04:14:14, Epoch : 1, Step : 6051, Training Loss : 0.08867, Training Acc : 0.961, Run Time : 44.92
INFO:root:2019-05-11 04:14:30, Epoch : 1, Step : 6052, Training Loss : 0.17740, Training Acc : 0.939, Run Time : 15.15
INFO:root:2019-05-11 04:14:47, Epoch : 1, Step : 6053, Training Loss : 0.19210, Training Acc : 0.944, Run Time : 17.86
INFO:root:2019-05-11 04:15:08, Epoch : 1, Step : 6054, Training Loss : 0.22604, Training Acc : 0.917, Run Time : 20.67
INFO:root:2019-05-11 04:15:30, Epoch : 1, Step : 6055, Training Loss : 0.19731, Training Acc : 0.928, Run Time : 21.73
INFO:root:2019-05-11 04:15:46, Epoch : 1, Step : 6056, Training Loss : 0.38076, Training Acc : 0.850, Run Time : 15.76
INFO:root:2019-05-11 04:15:48, Epoch : 1, Step : 6057, Training Loss : 0.19394, Training Acc : 0.928, Run Time : 2.00
INFO:root:2019-05-11 04:15:48, Epoch : 1, Step : 6058, Training Loss : 0.25260, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-11 04:15:49, Epoch : 1, Step : 6059, Training Loss : 0.21280, Training Acc : 0.917, Run Time : 0.95
INFO:root:2019-05-11 04:16:10, Epoch : 1, Step : 6060, Training Loss : 0.14503, Training Acc : 0.961, Run Time : 21.35
INFO:root:2019-05-11 04:16:28, Epoch : 1, Step : 6061, Training Loss : 0.14933, Training Acc : 0.928, Run Time : 17.33
INFO:root:2019-05-11 04:16:37, Epoch : 1, Step : 6062, Training Loss : 0.14393, Training Acc : 0.956, Run Time : 9.46
INFO:root:2019-05-11 04:16:58, Epoch : 1, Step : 6063, Training Loss : 0.08937, Training Acc : 0.967, Run Time : 20.90
INFO:root:2019-05-11 04:17:08, Epoch : 1, Step : 6064, Training Loss : 0.08056, Training Acc : 0.967, Run Time : 10.47
INFO:root:2019-05-11 04:17:09, Epoch : 1, Step : 6065, Training Loss : 0.08902, Training Acc : 0.972, Run Time : 0.55
INFO:root:2019-05-11 04:17:23, Epoch : 1, Step : 6066, Training Loss : 0.06500, Training Acc : 0.978, Run Time : 13.86
INFO:root:2019-05-11 04:17:23, Epoch : 1, Step : 6067, Training Loss : 0.39602, Training Acc : 0.861, Run Time : 0.42
INFO:root:2019-05-11 04:17:24, Epoch : 1, Step : 6068, Training Loss : 0.27448, Training Acc : 0.900, Run Time : 0.43
INFO:root:2019-05-11 04:17:24, Epoch : 1, Step : 6069, Training Loss : 0.14565, Training Acc : 0.956, Run Time : 0.55
INFO:root:2019-05-11 04:17:25, Epoch : 1, Step : 6070, Training Loss : 0.16591, Training Acc : 0.928, Run Time : 0.69
INFO:root:2019-05-11 04:17:26, Epoch : 1, Step : 6071, Training Loss : 0.37779, Training Acc : 0.872, Run Time : 1.13
INFO:root:2019-05-11 04:17:28, Epoch : 1, Step : 6072, Training Loss : 0.08819, Training Acc : 0.978, Run Time : 1.57
INFO:root:2019-05-11 04:17:41, Epoch : 1, Step : 6073, Training Loss : 0.24160, Training Acc : 0.922, Run Time : 13.71
INFO:root:2019-05-11 04:17:42, Epoch : 1, Step : 6074, Training Loss : 0.05934, Training Acc : 0.983, Run Time : 0.42
INFO:root:2019-05-11 04:17:42, Epoch : 1, Step : 6075, Training Loss : 0.13018, Training Acc : 0.967, Run Time : 0.38
INFO:root:2019-05-11 04:17:42, Epoch : 1, Step : 6076, Training Loss : 0.22732, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 04:17:54, Epoch : 1, Step : 6077, Training Loss : 0.24704, Training Acc : 0.917, Run Time : 11.24
INFO:root:2019-05-11 04:17:54, Epoch : 1, Step : 6078, Training Loss : 0.10056, Training Acc : 0.961, Run Time : 0.63
INFO:root:2019-05-11 04:17:55, Epoch : 1, Step : 6079, Training Loss : 0.36861, Training Acc : 0.900, Run Time : 0.39
INFO:root:2019-05-11 04:18:06, Epoch : 1, Step : 6080, Training Loss : 0.37873, Training Acc : 0.883, Run Time : 11.31
INFO:root:2019-05-11 04:18:07, Epoch : 1, Step : 6081, Training Loss : 0.30460, Training Acc : 0.900, Run Time : 0.68
INFO:root:2019-05-11 04:18:08, Epoch : 1, Step : 6082, Training Loss : 0.20730, Training Acc : 0.906, Run Time : 0.87
INFO:root:2019-05-11 04:18:17, Epoch : 1, Step : 6083, Training Loss : 0.12905, Training Acc : 0.939, Run Time : 8.91
INFO:root:2019-05-11 04:18:17, Epoch : 1, Step : 6084, Training Loss : 0.12581, Training Acc : 0.967, Run Time : 0.41
INFO:root:2019-05-11 04:18:17, Epoch : 1, Step : 6085, Training Loss : 0.17937, Training Acc : 0.922, Run Time : 0.40
INFO:root:2019-05-11 04:18:30, Epoch : 1, Step : 6086, Training Loss : 0.29477, Training Acc : 0.867, Run Time : 12.24
INFO:root:2019-05-11 04:18:31, Epoch : 1, Step : 6087, Training Loss : 0.21350, Training Acc : 0.928, Run Time : 0.99
INFO:root:2019-05-11 04:18:31, Epoch : 1, Step : 6088, Training Loss : 0.17937, Training Acc : 0.950, Run Time : 0.49
INFO:root:2019-05-11 04:18:32, Epoch : 1, Step : 6089, Training Loss : 0.16756, Training Acc : 0.900, Run Time : 1.41
INFO:root:2019-05-11 04:18:42, Epoch : 1, Step : 6090, Training Loss : 0.13654, Training Acc : 0.950, Run Time : 9.66
INFO:root:2019-05-11 04:18:43, Epoch : 1, Step : 6091, Training Loss : 0.22363, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-11 04:18:43, Epoch : 1, Step : 6092, Training Loss : 0.32605, Training Acc : 0.872, Run Time : 0.45
INFO:root:2019-05-11 04:18:44, Epoch : 1, Step : 6093, Training Loss : 0.22770, Training Acc : 0.906, Run Time : 1.52
INFO:root:2019-05-11 04:18:54, Epoch : 1, Step : 6094, Training Loss : 0.17365, Training Acc : 0.922, Run Time : 9.80
INFO:root:2019-05-11 04:18:55, Epoch : 1, Step : 6095, Training Loss : 0.40321, Training Acc : 0.883, Run Time : 0.45
INFO:root:2019-05-11 04:18:55, Epoch : 1, Step : 6096, Training Loss : 0.17246, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 04:19:09, Epoch : 1, Step : 6097, Training Loss : 0.30420, Training Acc : 0.861, Run Time : 13.38
INFO:root:2019-05-11 04:19:10, Epoch : 1, Step : 6098, Training Loss : 0.18408, Training Acc : 0.944, Run Time : 1.09
INFO:root:2019-05-11 04:19:10, Epoch : 1, Step : 6099, Training Loss : 0.12057, Training Acc : 0.956, Run Time : 0.43
INFO:root:2019-05-11 04:19:24, Epoch : 1, Step : 6100, Training Loss : 0.21283, Training Acc : 0.922, Run Time : 13.63
INFO:root:2019-05-11 04:19:25, Epoch : 1, Step : 6101, Training Loss : 0.22144, Training Acc : 0.894, Run Time : 0.99
INFO:root:2019-05-11 04:19:25, Epoch : 1, Step : 6102, Training Loss : 0.18583, Training Acc : 0.906, Run Time : 0.59
INFO:root:2019-05-11 04:19:37, Epoch : 1, Step : 6103, Training Loss : 0.21155, Training Acc : 0.928, Run Time : 11.69
INFO:root:2019-05-11 04:19:38, Epoch : 1, Step : 6104, Training Loss : 0.22011, Training Acc : 0.928, Run Time : 1.00
INFO:root:2019-05-11 04:19:38, Epoch : 1, Step : 6105, Training Loss : 0.17015, Training Acc : 0.922, Run Time : 0.40
INFO:root:2019-05-11 04:19:40, Epoch : 1, Step : 6106, Training Loss : 0.24023, Training Acc : 0.900, Run Time : 1.27
INFO:root:2019-05-11 04:19:52, Epoch : 1, Step : 6107, Training Loss : 0.33417, Training Acc : 0.872, Run Time : 12.69
INFO:root:2019-05-11 04:19:53, Epoch : 1, Step : 6108, Training Loss : 0.28809, Training Acc : 0.878, Run Time : 1.00
INFO:root:2019-05-11 04:20:05, Epoch : 1, Step : 6109, Training Loss : 0.12308, Training Acc : 0.950, Run Time : 11.25
INFO:root:2019-05-11 04:20:05, Epoch : 1, Step : 6110, Training Loss : 0.12738, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-11 04:20:05, Epoch : 1, Step : 6111, Training Loss : 0.13614, Training Acc : 0.950, Run Time : 0.37
INFO:root:2019-05-11 04:20:07, Epoch : 1, Step : 6112, Training Loss : 0.28360, Training Acc : 0.878, Run Time : 1.96
INFO:root:2019-05-11 04:20:16, Epoch : 1, Step : 6113, Training Loss : 0.22490, Training Acc : 0.878, Run Time : 9.15
INFO:root:2019-05-11 04:20:18, Epoch : 1, Step : 6114, Training Loss : 0.19742, Training Acc : 0.950, Run Time : 1.14
INFO:root:2019-05-11 04:20:20, Epoch : 1, Step : 6115, Training Loss : 0.20773, Training Acc : 0.906, Run Time : 2.25
INFO:root:2019-05-11 04:20:31, Epoch : 1, Step : 6116, Training Loss : 0.28784, Training Acc : 0.906, Run Time : 11.07
INFO:root:2019-05-11 04:20:31, Epoch : 1, Step : 6117, Training Loss : 0.19687, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 04:20:32, Epoch : 1, Step : 6118, Training Loss : 0.30739, Training Acc : 0.878, Run Time : 1.14
INFO:root:2019-05-11 04:20:40, Epoch : 1, Step : 6119, Training Loss : 0.13531, Training Acc : 0.956, Run Time : 7.79
INFO:root:2019-05-11 04:20:44, Epoch : 1, Step : 6120, Training Loss : 0.09374, Training Acc : 0.972, Run Time : 4.10
INFO:root:2019-05-11 04:20:46, Epoch : 1, Step : 6121, Training Loss : 0.22815, Training Acc : 0.894, Run Time : 1.71
INFO:root:2019-05-11 04:20:47, Epoch : 1, Step : 6122, Training Loss : 0.15386, Training Acc : 0.950, Run Time : 0.42
INFO:root:2019-05-11 04:20:47, Epoch : 1, Step : 6123, Training Loss : 0.15838, Training Acc : 0.939, Run Time : 0.39
INFO:root:2019-05-11 04:20:48, Epoch : 1, Step : 6124, Training Loss : 0.09320, Training Acc : 0.972, Run Time : 0.80
INFO:root:2019-05-11 04:20:57, Epoch : 1, Step : 6125, Training Loss : 0.47282, Training Acc : 0.822, Run Time : 9.28
INFO:root:2019-05-11 04:20:58, Epoch : 1, Step : 6126, Training Loss : 0.10486, Training Acc : 0.961, Run Time : 1.05
INFO:root:2019-05-11 04:20:58, Epoch : 1, Step : 6127, Training Loss : 0.25075, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-11 04:21:11, Epoch : 1, Step : 6128, Training Loss : 0.16045, Training Acc : 0.939, Run Time : 12.22
INFO:root:2019-05-11 04:21:11, Epoch : 1, Step : 6129, Training Loss : 0.19703, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 04:21:11, Epoch : 1, Step : 6130, Training Loss : 0.23643, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-11 04:21:12, Epoch : 1, Step : 6131, Training Loss : 0.22773, Training Acc : 0.922, Run Time : 0.43
INFO:root:2019-05-11 04:21:13, Epoch : 1, Step : 6132, Training Loss : 0.33656, Training Acc : 0.889, Run Time : 0.92
INFO:root:2019-05-11 04:21:27, Epoch : 1, Step : 6133, Training Loss : 0.17814, Training Acc : 0.922, Run Time : 14.37
INFO:root:2019-05-11 04:21:28, Epoch : 1, Step : 6134, Training Loss : 0.14860, Training Acc : 0.944, Run Time : 1.37
INFO:root:2019-05-11 04:21:29, Epoch : 1, Step : 6135, Training Loss : 0.13317, Training Acc : 0.956, Run Time : 0.42
INFO:root:2019-05-11 04:21:30, Epoch : 1, Step : 6136, Training Loss : 0.14097, Training Acc : 0.967, Run Time : 1.18
INFO:root:2019-05-11 04:21:37, Epoch : 1, Step : 6137, Training Loss : 0.08554, Training Acc : 0.978, Run Time : 7.23
INFO:root:2019-05-11 04:21:38, Epoch : 1, Step : 6138, Training Loss : 0.15316, Training Acc : 0.933, Run Time : 0.65
INFO:root:2019-05-11 04:21:39, Epoch : 1, Step : 6139, Training Loss : 0.14585, Training Acc : 0.939, Run Time : 0.74
INFO:root:2019-05-11 04:21:51, Epoch : 1, Step : 6140, Training Loss : 0.13884, Training Acc : 0.972, Run Time : 12.55
INFO:root:2019-05-11 04:21:52, Epoch : 1, Step : 6141, Training Loss : 0.13752, Training Acc : 0.939, Run Time : 1.04
INFO:root:2019-05-11 04:21:53, Epoch : 1, Step : 6142, Training Loss : 0.16192, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 04:21:54, Epoch : 1, Step : 6143, Training Loss : 0.12295, Training Acc : 0.956, Run Time : 1.70
INFO:root:2019-05-11 04:22:05, Epoch : 1, Step : 6144, Training Loss : 0.12127, Training Acc : 0.961, Run Time : 11.09
INFO:root:2019-05-11 04:22:06, Epoch : 1, Step : 6145, Training Loss : 0.19691, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 04:22:06, Epoch : 1, Step : 6146, Training Loss : 0.24709, Training Acc : 0.900, Run Time : 0.47
INFO:root:2019-05-11 04:22:19, Epoch : 1, Step : 6147, Training Loss : 0.19817, Training Acc : 0.928, Run Time : 12.32
INFO:root:2019-05-11 04:22:19, Epoch : 1, Step : 6148, Training Loss : 0.16897, Training Acc : 0.944, Run Time : 0.40
INFO:root:2019-05-11 04:22:20, Epoch : 1, Step : 6149, Training Loss : 0.36405, Training Acc : 0.867, Run Time : 0.48
INFO:root:2019-05-11 04:22:20, Epoch : 1, Step : 6150, Training Loss : 0.35548, Training Acc : 0.856, Run Time : 0.63
INFO:root:2019-05-11 04:22:27, Epoch : 1, Step : 6151, Training Loss : 0.24442, Training Acc : 0.911, Run Time : 6.94
INFO:root:2019-05-11 04:22:28, Epoch : 1, Step : 6152, Training Loss : 0.20930, Training Acc : 0.928, Run Time : 0.92
INFO:root:2019-05-11 04:22:28, Epoch : 1, Step : 6153, Training Loss : 0.33012, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-11 04:22:29, Epoch : 1, Step : 6154, Training Loss : 0.08666, Training Acc : 0.972, Run Time : 0.39
INFO:root:2019-05-11 04:22:29, Epoch : 1, Step : 6155, Training Loss : 0.10708, Training Acc : 0.972, Run Time : 0.67
INFO:root:2019-05-11 04:22:39, Epoch : 1, Step : 6156, Training Loss : 0.14776, Training Acc : 0.950, Run Time : 9.75
INFO:root:2019-05-11 04:22:41, Epoch : 1, Step : 6157, Training Loss : 0.25285, Training Acc : 0.933, Run Time : 2.02
INFO:root:2019-05-11 04:22:52, Epoch : 1, Step : 6158, Training Loss : 0.12630, Training Acc : 0.961, Run Time : 10.75
INFO:root:2019-05-11 04:22:53, Epoch : 1, Step : 6159, Training Loss : 0.21089, Training Acc : 0.939, Run Time : 0.55
INFO:root:2019-05-11 04:22:53, Epoch : 1, Step : 6160, Training Loss : 0.31469, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-11 04:22:55, Epoch : 1, Step : 6161, Training Loss : 0.45611, Training Acc : 0.794, Run Time : 1.77
INFO:root:2019-05-11 04:23:05, Epoch : 1, Step : 6162, Training Loss : 0.30383, Training Acc : 0.894, Run Time : 9.94
INFO:root:2019-05-11 04:23:05, Epoch : 1, Step : 6163, Training Loss : 0.39099, Training Acc : 0.861, Run Time : 0.46
INFO:root:2019-05-11 04:23:05, Epoch : 1, Step : 6164, Training Loss : 0.29996, Training Acc : 0.911, Run Time : 0.37
INFO:root:2019-05-11 04:23:16, Epoch : 1, Step : 6165, Training Loss : 0.21514, Training Acc : 0.939, Run Time : 10.84
INFO:root:2019-05-11 04:23:17, Epoch : 1, Step : 6166, Training Loss : 0.32366, Training Acc : 0.861, Run Time : 1.13
INFO:root:2019-05-11 04:23:18, Epoch : 1, Step : 6167, Training Loss : 0.14099, Training Acc : 0.967, Run Time : 0.37
INFO:root:2019-05-11 04:23:19, Epoch : 1, Step : 6168, Training Loss : 0.17555, Training Acc : 0.911, Run Time : 1.33
INFO:root:2019-05-11 04:23:27, Epoch : 1, Step : 6169, Training Loss : 0.16121, Training Acc : 0.922, Run Time : 8.15
INFO:root:2019-05-11 04:23:28, Epoch : 1, Step : 6170, Training Loss : 0.21127, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 04:23:28, Epoch : 1, Step : 6171, Training Loss : 0.24027, Training Acc : 0.889, Run Time : 0.37
INFO:root:2019-05-11 04:23:30, Epoch : 1, Step : 6172, Training Loss : 0.20609, Training Acc : 0.906, Run Time : 1.83
INFO:root:2019-05-11 04:23:42, Epoch : 1, Step : 6173, Training Loss : 0.21594, Training Acc : 0.928, Run Time : 11.71
INFO:root:2019-05-11 04:23:43, Epoch : 1, Step : 6174, Training Loss : 0.31788, Training Acc : 0.844, Run Time : 0.94
INFO:root:2019-05-11 04:23:43, Epoch : 1, Step : 6175, Training Loss : 0.19287, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-11 04:23:43, Epoch : 1, Step : 6176, Training Loss : 0.23156, Training Acc : 0.906, Run Time : 0.40
INFO:root:2019-05-11 04:23:44, Epoch : 1, Step : 6177, Training Loss : 0.29038, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-11 04:23:44, Epoch : 1, Step : 6178, Training Loss : 0.19451, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-11 04:23:45, Epoch : 1, Step : 6179, Training Loss : 0.11485, Training Acc : 0.950, Run Time : 0.90
INFO:root:2019-05-11 04:23:58, Epoch : 1, Step : 6180, Training Loss : 0.09139, Training Acc : 0.972, Run Time : 12.62
INFO:root:2019-05-11 04:23:58, Epoch : 1, Step : 6181, Training Loss : 0.18711, Training Acc : 0.933, Run Time : 0.43
INFO:root:2019-05-11 04:23:58, Epoch : 1, Step : 6182, Training Loss : 0.22394, Training Acc : 0.917, Run Time : 0.37
INFO:root:2019-05-11 04:23:59, Epoch : 1, Step : 6183, Training Loss : 0.48579, Training Acc : 0.756, Run Time : 0.38
INFO:root:2019-05-11 04:24:00, Epoch : 1, Step : 6184, Training Loss : 0.49153, Training Acc : 0.767, Run Time : 0.84
INFO:root:2019-05-11 04:24:12, Epoch : 1, Step : 6185, Training Loss : 0.13241, Training Acc : 0.961, Run Time : 12.27
INFO:root:2019-05-11 04:24:13, Epoch : 1, Step : 6186, Training Loss : 0.17603, Training Acc : 0.944, Run Time : 1.10
INFO:root:2019-05-11 04:24:15, Epoch : 1, Step : 6187, Training Loss : 0.29444, Training Acc : 0.883, Run Time : 1.83
INFO:root:2019-05-11 04:24:24, Epoch : 1, Step : 6188, Training Loss : 0.15274, Training Acc : 0.928, Run Time : 8.69
INFO:root:2019-05-11 04:24:25, Epoch : 1, Step : 6189, Training Loss : 0.19891, Training Acc : 0.944, Run Time : 1.77
INFO:root:2019-05-11 04:24:26, Epoch : 1, Step : 6190, Training Loss : 0.23171, Training Acc : 0.900, Run Time : 0.38
INFO:root:2019-05-11 04:24:27, Epoch : 1, Step : 6191, Training Loss : 0.15979, Training Acc : 0.950, Run Time : 0.94
INFO:root:2019-05-11 04:24:40, Epoch : 1, Step : 6192, Training Loss : 0.15784, Training Acc : 0.956, Run Time : 13.20
INFO:root:2019-05-11 04:24:41, Epoch : 1, Step : 6193, Training Loss : 0.22192, Training Acc : 0.911, Run Time : 1.31
INFO:root:2019-05-11 04:24:42, Epoch : 1, Step : 6194, Training Loss : 0.18939, Training Acc : 0.917, Run Time : 0.63
INFO:root:2019-05-11 04:24:42, Epoch : 1, Step : 6195, Training Loss : 0.15319, Training Acc : 0.928, Run Time : 0.43
INFO:root:2019-05-11 04:24:43, Epoch : 1, Step : 6196, Training Loss : 0.12408, Training Acc : 0.967, Run Time : 0.78
INFO:root:2019-05-11 04:24:51, Epoch : 1, Step : 6197, Training Loss : 0.20129, Training Acc : 0.939, Run Time : 7.61
INFO:root:2019-05-11 04:24:52, Epoch : 1, Step : 6198, Training Loss : 0.22621, Training Acc : 0.928, Run Time : 1.07
INFO:root:2019-05-11 04:24:52, Epoch : 1, Step : 6199, Training Loss : 0.39359, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-11 04:24:53, Epoch : 1, Step : 6200, Training Loss : 0.27124, Training Acc : 0.878, Run Time : 0.53
INFO:root:2019-05-11 04:25:02, Epoch : 1, Step : 6201, Training Loss : 0.65530, Training Acc : 0.778, Run Time : 9.28
INFO:root:2019-05-11 04:25:02, Epoch : 1, Step : 6202, Training Loss : 0.77676, Training Acc : 0.683, Run Time : 0.51
INFO:root:2019-05-11 04:25:03, Epoch : 1, Step : 6203, Training Loss : 0.81887, Training Acc : 0.711, Run Time : 0.38
INFO:root:2019-05-11 04:25:04, Epoch : 1, Step : 6204, Training Loss : 0.98180, Training Acc : 0.644, Run Time : 1.34
INFO:root:2019-05-11 04:25:15, Epoch : 1, Step : 6205, Training Loss : 0.94057, Training Acc : 0.633, Run Time : 11.11
INFO:root:2019-05-11 04:25:16, Epoch : 1, Step : 6206, Training Loss : 0.73838, Training Acc : 0.722, Run Time : 0.42
INFO:root:2019-05-11 04:25:16, Epoch : 1, Step : 6207, Training Loss : 0.69851, Training Acc : 0.694, Run Time : 0.63
INFO:root:2019-05-11 04:25:27, Epoch : 1, Step : 6208, Training Loss : 0.48997, Training Acc : 0.756, Run Time : 10.26
INFO:root:2019-05-11 04:25:31, Epoch : 1, Step : 6209, Training Loss : 0.45349, Training Acc : 0.789, Run Time : 4.40
INFO:root:2019-05-11 04:25:32, Epoch : 1, Step : 6210, Training Loss : 0.35483, Training Acc : 0.833, Run Time : 0.65
INFO:root:2019-05-11 04:25:32, Epoch : 1, Step : 6211, Training Loss : 0.30902, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 04:25:33, Epoch : 1, Step : 6212, Training Loss : 0.38210, Training Acc : 0.822, Run Time : 1.41
INFO:root:2019-05-11 04:25:44, Epoch : 1, Step : 6213, Training Loss : 0.34483, Training Acc : 0.856, Run Time : 10.33
INFO:root:2019-05-11 04:25:44, Epoch : 1, Step : 6214, Training Loss : 0.27109, Training Acc : 0.850, Run Time : 0.43
INFO:root:2019-05-11 04:25:44, Epoch : 1, Step : 6215, Training Loss : 0.31820, Training Acc : 0.856, Run Time : 0.38
INFO:root:2019-05-11 04:25:45, Epoch : 1, Step : 6216, Training Loss : 0.33345, Training Acc : 0.878, Run Time : 0.44
INFO:root:2019-05-11 04:25:47, Epoch : 1, Step : 6217, Training Loss : 0.40342, Training Acc : 0.794, Run Time : 2.06
INFO:root:2019-05-11 04:25:56, Epoch : 1, Step : 6218, Training Loss : 0.59578, Training Acc : 0.750, Run Time : 9.45
INFO:root:2019-05-11 04:25:57, Epoch : 1, Step : 6219, Training Loss : 0.31071, Training Acc : 0.839, Run Time : 0.42
INFO:root:2019-05-11 04:25:57, Epoch : 1, Step : 6220, Training Loss : 0.64141, Training Acc : 0.739, Run Time : 0.63
INFO:root:2019-05-11 04:26:07, Epoch : 1, Step : 6221, Training Loss : 0.46530, Training Acc : 0.789, Run Time : 9.51
INFO:root:2019-05-11 04:26:07, Epoch : 1, Step : 6222, Training Loss : 0.46541, Training Acc : 0.761, Run Time : 0.40
INFO:root:2019-05-11 04:26:08, Epoch : 1, Step : 6223, Training Loss : 0.51216, Training Acc : 0.817, Run Time : 0.68
INFO:root:2019-05-11 04:26:08, Epoch : 1, Step : 6224, Training Loss : 0.45902, Training Acc : 0.761, Run Time : 0.38
INFO:root:2019-05-11 04:26:09, Epoch : 1, Step : 6225, Training Loss : 0.45957, Training Acc : 0.728, Run Time : 0.38
INFO:root:2019-05-11 04:26:10, Epoch : 1, Step : 6226, Training Loss : 0.38314, Training Acc : 0.794, Run Time : 1.05
INFO:root:2019-05-11 04:26:19, Epoch : 1, Step : 6227, Training Loss : 0.29547, Training Acc : 0.856, Run Time : 9.48
INFO:root:2019-05-11 04:26:20, Epoch : 1, Step : 6228, Training Loss : 0.38441, Training Acc : 0.783, Run Time : 0.71
INFO:root:2019-05-11 04:26:21, Epoch : 1, Step : 6229, Training Loss : 0.23608, Training Acc : 0.900, Run Time : 0.73
INFO:root:2019-05-11 04:26:31, Epoch : 1, Step : 6230, Training Loss : 0.29229, Training Acc : 0.861, Run Time : 10.49
INFO:root:2019-05-11 04:26:32, Epoch : 1, Step : 6231, Training Loss : 0.20908, Training Acc : 0.906, Run Time : 0.65
INFO:root:2019-05-11 04:26:33, Epoch : 1, Step : 6232, Training Loss : 0.15470, Training Acc : 0.956, Run Time : 0.62
INFO:root:2019-05-11 04:26:43, Epoch : 1, Step : 6233, Training Loss : 0.23939, Training Acc : 0.917, Run Time : 10.71
INFO:root:2019-05-11 04:26:44, Epoch : 1, Step : 6234, Training Loss : 0.29016, Training Acc : 0.889, Run Time : 0.96
INFO:root:2019-05-11 04:26:45, Epoch : 1, Step : 6235, Training Loss : 0.26745, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 04:26:45, Epoch : 1, Step : 6236, Training Loss : 0.23323, Training Acc : 0.917, Run Time : 0.50
INFO:root:2019-05-11 04:26:46, Epoch : 1, Step : 6237, Training Loss : 0.34746, Training Acc : 0.844, Run Time : 0.96
INFO:root:2019-05-11 04:26:46, Epoch : 1, Step : 6238, Training Loss : 0.22487, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 04:26:47, Epoch : 1, Step : 6239, Training Loss : 0.30926, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-11 04:26:47, Epoch : 1, Step : 6240, Training Loss : 0.20370, Training Acc : 0.939, Run Time : 0.40
INFO:root:2019-05-11 04:26:54, Epoch : 1, Step : 6241, Training Loss : 0.27146, Training Acc : 0.894, Run Time : 7.13
INFO:root:2019-05-11 04:26:58, Epoch : 1, Step : 6242, Training Loss : 0.17871, Training Acc : 0.950, Run Time : 4.07
INFO:root:2019-05-11 04:26:59, Epoch : 1, Step : 6243, Training Loss : 0.23853, Training Acc : 0.900, Run Time : 0.58
INFO:root:2019-05-11 04:27:06, Epoch : 1, Step : 6244, Training Loss : 0.34684, Training Acc : 0.856, Run Time : 7.40
INFO:root:2019-05-11 04:27:08, Epoch : 1, Step : 6245, Training Loss : 0.24723, Training Acc : 0.900, Run Time : 1.39
INFO:root:2019-05-11 04:27:19, Epoch : 1, Step : 6246, Training Loss : 0.23379, Training Acc : 0.906, Run Time : 11.13
INFO:root:2019-05-11 04:27:20, Epoch : 1, Step : 6247, Training Loss : 0.29202, Training Acc : 0.900, Run Time : 1.20
INFO:root:2019-05-11 04:27:25, Epoch : 1, Step : 6248, Training Loss : 0.20295, Training Acc : 0.906, Run Time : 4.68
INFO:root:2019-05-11 04:27:25, Epoch : 1, Step : 6249, Training Loss : 0.28762, Training Acc : 0.878, Run Time : 0.43
INFO:root:2019-05-11 04:27:26, Epoch : 1, Step : 6250, Training Loss : 0.22033, Training Acc : 0.933, Run Time : 0.63
INFO:root:2019-05-11 04:27:28, Epoch : 1, Step : 6251, Training Loss : 0.22287, Training Acc : 0.928, Run Time : 2.28
INFO:root:2019-05-11 04:27:29, Epoch : 1, Step : 6252, Training Loss : 0.19072, Training Acc : 0.939, Run Time : 0.88
INFO:root:2019-05-11 04:27:29, Epoch : 1, Step : 6253, Training Loss : 0.16587, Training Acc : 0.956, Run Time : 0.38
INFO:root:2019-05-11 04:27:30, Epoch : 1, Step : 6254, Training Loss : 0.26688, Training Acc : 0.872, Run Time : 0.39
INFO:root:2019-05-11 04:27:31, Epoch : 1, Step : 6255, Training Loss : 0.24388, Training Acc : 0.911, Run Time : 0.94
INFO:root:2019-05-11 04:27:40, Epoch : 1, Step : 6256, Training Loss : 0.21875, Training Acc : 0.922, Run Time : 9.42
INFO:root:2019-05-11 04:27:41, Epoch : 1, Step : 6257, Training Loss : 0.28624, Training Acc : 0.894, Run Time : 0.41
INFO:root:2019-05-11 04:27:41, Epoch : 1, Step : 6258, Training Loss : 0.20391, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-11 04:27:41, Epoch : 1, Step : 6259, Training Loss : 0.16953, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-11 04:27:42, Epoch : 1, Step : 6260, Training Loss : 0.24606, Training Acc : 0.894, Run Time : 1.03
INFO:root:2019-05-11 04:27:55, Epoch : 1, Step : 6261, Training Loss : 0.18741, Training Acc : 0.933, Run Time : 12.55
INFO:root:2019-05-11 04:27:56, Epoch : 1, Step : 6262, Training Loss : 0.23158, Training Acc : 0.906, Run Time : 1.24
INFO:root:2019-05-11 04:27:57, Epoch : 1, Step : 6263, Training Loss : 0.39326, Training Acc : 0.811, Run Time : 0.49
INFO:root:2019-05-11 04:27:58, Epoch : 1, Step : 6264, Training Loss : 0.96642, Training Acc : 0.572, Run Time : 1.23
INFO:root:2019-05-11 04:28:07, Epoch : 1, Step : 6265, Training Loss : 0.48823, Training Acc : 0.794, Run Time : 8.93
INFO:root:2019-05-11 04:28:08, Epoch : 1, Step : 6266, Training Loss : 0.22474, Training Acc : 0.917, Run Time : 0.79
INFO:root:2019-05-11 04:28:08, Epoch : 1, Step : 6267, Training Loss : 0.25287, Training Acc : 0.900, Run Time : 0.37
INFO:root:2019-05-11 04:28:09, Epoch : 1, Step : 6268, Training Loss : 0.22824, Training Acc : 0.883, Run Time : 1.18
INFO:root:2019-05-11 04:28:15, Epoch : 1, Step : 6269, Training Loss : 0.22531, Training Acc : 0.911, Run Time : 5.78
INFO:root:2019-05-11 04:28:15, Epoch : 1, Step : 6270, Training Loss : 0.20947, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-11 04:28:25, Epoch : 1, Step : 6271, Training Loss : 0.29846, Training Acc : 0.867, Run Time : 9.62
INFO:root:2019-05-11 04:28:26, Epoch : 1, Step : 6272, Training Loss : 0.24011, Training Acc : 0.900, Run Time : 0.90
INFO:root:2019-05-11 04:28:26, Epoch : 1, Step : 6273, Training Loss : 0.18333, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 04:28:27, Epoch : 1, Step : 6274, Training Loss : 0.20138, Training Acc : 0.911, Run Time : 1.02
INFO:root:2019-05-11 04:28:34, Epoch : 1, Step : 6275, Training Loss : 0.27730, Training Acc : 0.911, Run Time : 6.22
INFO:root:2019-05-11 04:28:34, Epoch : 1, Step : 6276, Training Loss : 0.25750, Training Acc : 0.922, Run Time : 0.63
INFO:root:2019-05-11 04:28:35, Epoch : 1, Step : 6277, Training Loss : 0.19540, Training Acc : 0.939, Run Time : 0.41
INFO:root:2019-05-11 04:28:35, Epoch : 1, Step : 6278, Training Loss : 0.23364, Training Acc : 0.878, Run Time : 0.67
INFO:root:2019-05-11 04:28:36, Epoch : 1, Step : 6279, Training Loss : 0.42267, Training Acc : 0.850, Run Time : 1.00
INFO:root:2019-05-11 04:28:37, Epoch : 1, Step : 6280, Training Loss : 0.26423, Training Acc : 0.911, Run Time : 0.52
INFO:root:2019-05-11 04:28:37, Epoch : 1, Step : 6281, Training Loss : 0.28650, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-11 04:28:38, Epoch : 1, Step : 6282, Training Loss : 0.21218, Training Acc : 0.917, Run Time : 0.39
INFO:root:2019-05-11 04:28:38, Epoch : 1, Step : 6283, Training Loss : 0.22698, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-11 04:28:47, Epoch : 1, Step : 6284, Training Loss : 0.18959, Training Acc : 0.933, Run Time : 8.79
INFO:root:2019-05-11 04:28:48, Epoch : 1, Step : 6285, Training Loss : 0.21163, Training Acc : 0.917, Run Time : 0.92
INFO:root:2019-05-11 04:28:49, Epoch : 1, Step : 6286, Training Loss : 0.18401, Training Acc : 0.928, Run Time : 1.02
INFO:root:2019-05-11 04:29:00, Epoch : 1, Step : 6287, Training Loss : 0.23089, Training Acc : 0.894, Run Time : 11.47
INFO:root:2019-05-11 04:29:01, Epoch : 1, Step : 6288, Training Loss : 0.25843, Training Acc : 0.906, Run Time : 0.54
INFO:root:2019-05-11 04:29:01, Epoch : 1, Step : 6289, Training Loss : 0.37744, Training Acc : 0.817, Run Time : 0.41
INFO:root:2019-05-11 04:29:03, Epoch : 1, Step : 6290, Training Loss : 0.23756, Training Acc : 0.878, Run Time : 2.01
INFO:root:2019-05-11 04:29:12, Epoch : 1, Step : 6291, Training Loss : 0.25515, Training Acc : 0.894, Run Time : 9.28
INFO:root:2019-05-11 04:29:13, Epoch : 1, Step : 6292, Training Loss : 0.22663, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-11 04:29:13, Epoch : 1, Step : 6293, Training Loss : 0.15726, Training Acc : 0.967, Run Time : 0.44
INFO:root:2019-05-11 04:29:14, Epoch : 1, Step : 6294, Training Loss : 0.19570, Training Acc : 0.917, Run Time : 0.93
INFO:root:2019-05-11 04:29:22, Epoch : 1, Step : 6295, Training Loss : 0.26663, Training Acc : 0.883, Run Time : 8.28
INFO:root:2019-05-11 04:29:23, Epoch : 1, Step : 6296, Training Loss : 0.24711, Training Acc : 0.883, Run Time : 0.60
INFO:root:2019-05-11 04:29:24, Epoch : 1, Step : 6297, Training Loss : 0.22170, Training Acc : 0.911, Run Time : 0.52
INFO:root:2019-05-11 04:29:24, Epoch : 1, Step : 6298, Training Loss : 0.23089, Training Acc : 0.917, Run Time : 0.64
INFO:root:2019-05-11 04:29:34, Epoch : 1, Step : 6299, Training Loss : 0.43212, Training Acc : 0.844, Run Time : 10.10
INFO:root:2019-05-11 04:29:35, Epoch : 1, Step : 6300, Training Loss : 0.24297, Training Acc : 0.928, Run Time : 0.44
INFO:root:2019-05-11 04:29:38, Epoch : 1, Step : 6301, Training Loss : 0.22360, Training Acc : 0.928, Run Time : 2.75
INFO:root:2019-05-11 04:29:47, Epoch : 1, Step : 6302, Training Loss : 0.28047, Training Acc : 0.900, Run Time : 9.49
INFO:root:2019-05-11 04:29:48, Epoch : 1, Step : 6303, Training Loss : 0.28406, Training Acc : 0.889, Run Time : 0.72
INFO:root:2019-05-11 04:29:48, Epoch : 1, Step : 6304, Training Loss : 0.16717, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 04:29:49, Epoch : 1, Step : 6305, Training Loss : 0.25568, Training Acc : 0.906, Run Time : 1.24
INFO:root:2019-05-11 04:29:59, Epoch : 1, Step : 6306, Training Loss : 0.28474, Training Acc : 0.878, Run Time : 9.71
INFO:root:2019-05-11 04:30:00, Epoch : 1, Step : 6307, Training Loss : 0.22992, Training Acc : 0.917, Run Time : 0.57
INFO:root:2019-05-11 04:30:00, Epoch : 1, Step : 6308, Training Loss : 0.18527, Training Acc : 0.950, Run Time : 0.40
INFO:root:2019-05-11 04:30:01, Epoch : 1, Step : 6309, Training Loss : 0.30351, Training Acc : 0.894, Run Time : 1.47
INFO:root:2019-05-11 04:30:12, Epoch : 1, Step : 6310, Training Loss : 0.29558, Training Acc : 0.878, Run Time : 10.52
INFO:root:2019-05-11 04:30:12, Epoch : 1, Step : 6311, Training Loss : 0.17785, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-11 04:30:13, Epoch : 1, Step : 6312, Training Loss : 0.33883, Training Acc : 0.856, Run Time : 0.38
INFO:root:2019-05-11 04:30:13, Epoch : 1, Step : 6313, Training Loss : 0.33446, Training Acc : 0.872, Run Time : 0.61
INFO:root:2019-05-11 04:30:14, Epoch : 1, Step : 6314, Training Loss : 0.23011, Training Acc : 0.917, Run Time : 0.61
INFO:root:2019-05-11 04:30:24, Epoch : 1, Step : 6315, Training Loss : 0.18101, Training Acc : 0.950, Run Time : 10.35
INFO:root:2019-05-11 04:30:25, Epoch : 1, Step : 6316, Training Loss : 0.24732, Training Acc : 0.900, Run Time : 0.79
INFO:root:2019-05-11 04:30:26, Epoch : 1, Step : 6317, Training Loss : 0.20400, Training Acc : 0.950, Run Time : 0.42
INFO:root:2019-05-11 04:30:27, Epoch : 1, Step : 6318, Training Loss : 0.33736, Training Acc : 0.867, Run Time : 0.97
INFO:root:2019-05-11 04:30:37, Epoch : 1, Step : 6319, Training Loss : 0.28899, Training Acc : 0.894, Run Time : 10.06
INFO:root:2019-05-11 04:30:37, Epoch : 1, Step : 6320, Training Loss : 0.25368, Training Acc : 0.917, Run Time : 0.74
INFO:root:2019-05-11 04:30:38, Epoch : 1, Step : 6321, Training Loss : 0.33871, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-11 04:30:38, Epoch : 1, Step : 6322, Training Loss : 0.19303, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 04:30:40, Epoch : 1, Step : 6323, Training Loss : 0.30066, Training Acc : 0.878, Run Time : 1.42
INFO:root:2019-05-11 04:30:49, Epoch : 1, Step : 6324, Training Loss : 0.26820, Training Acc : 0.917, Run Time : 9.32
INFO:root:2019-05-11 04:30:49, Epoch : 1, Step : 6325, Training Loss : 0.25640, Training Acc : 0.922, Run Time : 0.61
INFO:root:2019-05-11 04:30:50, Epoch : 1, Step : 6326, Training Loss : 0.17891, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 04:30:52, Epoch : 1, Step : 6327, Training Loss : 0.29922, Training Acc : 0.906, Run Time : 1.94
INFO:root:2019-05-11 04:31:03, Epoch : 1, Step : 6328, Training Loss : 0.29847, Training Acc : 0.894, Run Time : 11.52
INFO:root:2019-05-11 04:31:05, Epoch : 1, Step : 6329, Training Loss : 0.31028, Training Acc : 0.889, Run Time : 1.47
INFO:root:2019-05-11 04:31:15, Epoch : 1, Step : 6330, Training Loss : 0.55682, Training Acc : 0.789, Run Time : 10.50
INFO:root:2019-05-11 04:31:20, Epoch : 1, Step : 6331, Training Loss : 0.17992, Training Acc : 0.950, Run Time : 4.52
INFO:root:2019-05-11 04:31:20, Epoch : 1, Step : 6332, Training Loss : 0.31729, Training Acc : 0.894, Run Time : 0.37
INFO:root:2019-05-11 04:31:21, Epoch : 1, Step : 6333, Training Loss : 0.32421, Training Acc : 0.894, Run Time : 0.94
INFO:root:2019-05-11 04:31:34, Epoch : 1, Step : 6334, Training Loss : 0.24359, Training Acc : 0.922, Run Time : 12.49
INFO:root:2019-05-11 04:31:34, Epoch : 1, Step : 6335, Training Loss : 0.25629, Training Acc : 0.900, Run Time : 0.57
INFO:root:2019-05-11 04:31:35, Epoch : 1, Step : 6336, Training Loss : 0.23967, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 04:31:36, Epoch : 1, Step : 6337, Training Loss : 0.18792, Training Acc : 0.922, Run Time : 1.21
INFO:root:2019-05-11 04:31:56, Epoch : 1, Step : 6338, Training Loss : 0.22424, Training Acc : 0.928, Run Time : 20.56
INFO:root:2019-05-11 04:31:58, Epoch : 1, Step : 6339, Training Loss : 0.22563, Training Acc : 0.911, Run Time : 1.55
INFO:root:2019-05-11 04:31:58, Epoch : 1, Step : 6340, Training Loss : 0.22269, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 04:31:59, Epoch : 1, Step : 6341, Training Loss : 0.24138, Training Acc : 0.894, Run Time : 0.41
INFO:root:2019-05-11 04:31:59, Epoch : 1, Step : 6342, Training Loss : 0.32082, Training Acc : 0.856, Run Time : 0.43
INFO:root:2019-05-11 04:32:11, Epoch : 1, Step : 6343, Training Loss : 0.19902, Training Acc : 0.906, Run Time : 11.78
INFO:root:2019-05-11 04:32:16, Epoch : 1, Step : 6344, Training Loss : 0.21346, Training Acc : 0.928, Run Time : 5.38
INFO:root:2019-05-11 04:32:17, Epoch : 1, Step : 6345, Training Loss : 0.20901, Training Acc : 0.917, Run Time : 0.49
INFO:root:2019-05-11 04:32:31, Epoch : 1, Step : 6346, Training Loss : 0.21310, Training Acc : 0.906, Run Time : 13.73
INFO:root:2019-05-11 04:32:32, Epoch : 1, Step : 6347, Training Loss : 0.13100, Training Acc : 0.972, Run Time : 1.06
INFO:root:2019-05-11 04:32:32, Epoch : 1, Step : 6348, Training Loss : 0.16486, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 04:32:42, Epoch : 1, Step : 6349, Training Loss : 0.19485, Training Acc : 0.922, Run Time : 10.14
INFO:root:2019-05-11 04:32:43, Epoch : 1, Step : 6350, Training Loss : 0.21174, Training Acc : 0.911, Run Time : 0.71
INFO:root:2019-05-11 04:32:43, Epoch : 1, Step : 6351, Training Loss : 0.17320, Training Acc : 0.933, Run Time : 0.51
INFO:root:2019-05-11 04:32:46, Epoch : 1, Step : 6352, Training Loss : 0.11686, Training Acc : 0.983, Run Time : 2.27
INFO:root:2019-05-11 04:32:56, Epoch : 1, Step : 6353, Training Loss : 0.10662, Training Acc : 0.989, Run Time : 9.99
INFO:root:2019-05-11 04:32:56, Epoch : 1, Step : 6354, Training Loss : 0.12332, Training Acc : 0.972, Run Time : 0.42
INFO:root:2019-05-11 04:32:56, Epoch : 1, Step : 6355, Training Loss : 0.17213, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 04:32:58, Epoch : 1, Step : 6356, Training Loss : 0.13318, Training Acc : 0.972, Run Time : 1.43
INFO:root:2019-05-11 04:33:11, Epoch : 1, Step : 6357, Training Loss : 0.16653, Training Acc : 0.939, Run Time : 13.24
INFO:root:2019-05-11 04:33:12, Epoch : 1, Step : 6358, Training Loss : 0.09214, Training Acc : 0.983, Run Time : 0.80
INFO:root:2019-05-11 04:33:12, Epoch : 1, Step : 6359, Training Loss : 0.17024, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 04:33:25, Epoch : 1, Step : 6360, Training Loss : 0.17136, Training Acc : 0.939, Run Time : 12.74
INFO:root:2019-05-11 04:33:26, Epoch : 1, Step : 6361, Training Loss : 0.22201, Training Acc : 0.900, Run Time : 0.77
INFO:root:2019-05-11 04:33:26, Epoch : 1, Step : 6362, Training Loss : 0.18020, Training Acc : 0.933, Run Time : 0.37
INFO:root:2019-05-11 04:33:28, Epoch : 1, Step : 6363, Training Loss : 0.23449, Training Acc : 0.911, Run Time : 2.06
INFO:root:2019-05-11 04:33:42, Epoch : 1, Step : 6364, Training Loss : 0.22723, Training Acc : 0.900, Run Time : 14.02
INFO:root:2019-05-11 04:33:43, Epoch : 1, Step : 6365, Training Loss : 0.25516, Training Acc : 0.867, Run Time : 1.13
INFO:root:2019-05-11 04:33:45, Epoch : 1, Step : 6366, Training Loss : 0.20048, Training Acc : 0.906, Run Time : 2.07
INFO:root:2019-05-11 04:33:57, Epoch : 1, Step : 6367, Training Loss : 0.25362, Training Acc : 0.872, Run Time : 11.24
INFO:root:2019-05-11 04:33:57, Epoch : 1, Step : 6368, Training Loss : 0.19507, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-11 04:33:57, Epoch : 1, Step : 6369, Training Loss : 0.18890, Training Acc : 0.894, Run Time : 0.44
INFO:root:2019-05-11 04:33:58, Epoch : 1, Step : 6370, Training Loss : 0.21507, Training Acc : 0.900, Run Time : 0.39
INFO:root:2019-05-11 04:34:00, Epoch : 1, Step : 6371, Training Loss : 0.23691, Training Acc : 0.906, Run Time : 1.82
INFO:root:2019-05-11 04:34:09, Epoch : 1, Step : 6372, Training Loss : 0.17557, Training Acc : 0.911, Run Time : 8.90
INFO:root:2019-05-11 04:34:09, Epoch : 1, Step : 6373, Training Loss : 0.12317, Training Acc : 0.972, Run Time : 0.44
INFO:root:2019-05-11 04:34:09, Epoch : 1, Step : 6374, Training Loss : 0.17357, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 04:34:10, Epoch : 1, Step : 6375, Training Loss : 0.12651, Training Acc : 0.950, Run Time : 0.75
INFO:root:2019-05-11 04:34:22, Epoch : 1, Step : 6376, Training Loss : 0.13040, Training Acc : 0.961, Run Time : 11.90
INFO:root:2019-05-11 04:34:23, Epoch : 1, Step : 6377, Training Loss : 0.11581, Training Acc : 0.978, Run Time : 0.60
INFO:root:2019-05-11 04:34:23, Epoch : 1, Step : 6378, Training Loss : 0.11416, Training Acc : 0.972, Run Time : 0.37
INFO:root:2019-05-11 04:34:25, Epoch : 1, Step : 6379, Training Loss : 0.16877, Training Acc : 0.933, Run Time : 2.09
INFO:root:2019-05-11 04:34:37, Epoch : 1, Step : 6380, Training Loss : 0.12960, Training Acc : 0.961, Run Time : 11.39
INFO:root:2019-05-11 04:34:37, Epoch : 1, Step : 6381, Training Loss : 0.10996, Training Acc : 0.972, Run Time : 0.41
INFO:root:2019-05-11 04:34:37, Epoch : 1, Step : 6382, Training Loss : 0.10513, Training Acc : 0.956, Run Time : 0.51
INFO:root:2019-05-11 04:34:39, Epoch : 1, Step : 6383, Training Loss : 0.16342, Training Acc : 0.922, Run Time : 1.46
INFO:root:2019-05-11 04:34:46, Epoch : 1, Step : 6384, Training Loss : 0.13989, Training Acc : 0.944, Run Time : 7.08
INFO:root:2019-05-11 04:34:46, Epoch : 1, Step : 6385, Training Loss : 0.12163, Training Acc : 0.944, Run Time : 0.41
INFO:root:2019-05-11 04:34:47, Epoch : 1, Step : 6386, Training Loss : 0.11384, Training Acc : 0.950, Run Time : 0.93
INFO:root:2019-05-11 04:34:49, Epoch : 1, Step : 6387, Training Loss : 0.19923, Training Acc : 0.939, Run Time : 1.78
INFO:root:2019-05-11 04:34:50, Epoch : 1, Step : 6388, Training Loss : 0.13213, Training Acc : 0.967, Run Time : 0.89
INFO:root:2019-05-11 04:34:59, Epoch : 1, Step : 6389, Training Loss : 0.09626, Training Acc : 0.978, Run Time : 8.97
INFO:root:2019-05-11 04:35:00, Epoch : 1, Step : 6390, Training Loss : 0.15215, Training Acc : 0.956, Run Time : 0.88
INFO:root:2019-05-11 04:35:00, Epoch : 1, Step : 6391, Training Loss : 0.14338, Training Acc : 0.933, Run Time : 0.37
INFO:root:2019-05-11 04:35:02, Epoch : 1, Step : 6392, Training Loss : 0.11240, Training Acc : 0.972, Run Time : 1.77
INFO:root:2019-05-11 04:35:15, Epoch : 1, Step : 6393, Training Loss : 0.14046, Training Acc : 0.933, Run Time : 13.04
INFO:root:2019-05-11 04:35:15, Epoch : 1, Step : 6394, Training Loss : 0.17271, Training Acc : 0.917, Run Time : 0.40
INFO:root:2019-05-11 04:35:16, Epoch : 1, Step : 6395, Training Loss : 0.16331, Training Acc : 0.939, Run Time : 0.50
INFO:root:2019-05-11 04:35:16, Epoch : 1, Step : 6396, Training Loss : 0.20904, Training Acc : 0.894, Run Time : 0.50
INFO:root:2019-05-11 04:35:17, Epoch : 1, Step : 6397, Training Loss : 0.14420, Training Acc : 0.950, Run Time : 0.54
INFO:root:2019-05-11 04:35:19, Epoch : 1, Step : 6398, Training Loss : 0.32752, Training Acc : 0.872, Run Time : 2.20
INFO:root:2019-05-11 04:35:33, Epoch : 1, Step : 6399, Training Loss : 0.33229, Training Acc : 0.867, Run Time : 13.80
INFO:root:2019-05-11 04:35:34, Epoch : 1, Step : 6400, Training Loss : 0.27663, Training Acc : 0.900, Run Time : 0.83
INFO:root:2019-05-11 04:35:35, Epoch : 1, Step : 6401, Training Loss : 0.63641, Training Acc : 0.778, Run Time : 1.23
INFO:root:2019-05-11 04:35:45, Epoch : 1, Step : 6402, Training Loss : 0.61993, Training Acc : 0.800, Run Time : 9.70
INFO:root:2019-05-11 04:35:45, Epoch : 1, Step : 6403, Training Loss : 0.54620, Training Acc : 0.783, Run Time : 0.57
INFO:root:2019-05-11 04:35:46, Epoch : 1, Step : 6404, Training Loss : 0.98058, Training Acc : 0.700, Run Time : 0.43
INFO:root:2019-05-11 04:35:50, Epoch : 1, Step : 6405, Training Loss : 1.15374, Training Acc : 0.628, Run Time : 4.11
INFO:root:2019-05-11 04:35:57, Epoch : 1, Step : 6406, Training Loss : 0.84326, Training Acc : 0.700, Run Time : 7.17
INFO:root:2019-05-11 04:35:58, Epoch : 1, Step : 6407, Training Loss : 0.73097, Training Acc : 0.767, Run Time : 0.89
INFO:root:2019-05-11 04:36:00, Epoch : 1, Step : 6408, Training Loss : 0.50012, Training Acc : 0.806, Run Time : 1.94
INFO:root:2019-05-11 04:36:08, Epoch : 1, Step : 6409, Training Loss : 0.41545, Training Acc : 0.828, Run Time : 8.58
INFO:root:2019-05-11 04:36:10, Epoch : 1, Step : 6410, Training Loss : 0.49401, Training Acc : 0.811, Run Time : 1.85
INFO:root:2019-05-11 04:36:11, Epoch : 1, Step : 6411, Training Loss : 0.39443, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-11 04:36:11, Epoch : 1, Step : 6412, Training Loss : 0.34810, Training Acc : 0.850, Run Time : 0.54
INFO:root:2019-05-11 04:36:17, Epoch : 1, Step : 6413, Training Loss : 0.35748, Training Acc : 0.861, Run Time : 5.50
INFO:root:2019-05-11 04:36:17, Epoch : 1, Step : 6414, Training Loss : 0.35449, Training Acc : 0.817, Run Time : 0.47
INFO:root:2019-05-11 04:36:17, Epoch : 1, Step : 6415, Training Loss : 0.37739, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-11 04:36:19, Epoch : 1, Step : 6416, Training Loss : 0.45608, Training Acc : 0.794, Run Time : 1.47
INFO:root:2019-05-11 04:36:30, Epoch : 1, Step : 6417, Training Loss : 0.35683, Training Acc : 0.867, Run Time : 11.43
INFO:root:2019-05-11 04:36:31, Epoch : 1, Step : 6418, Training Loss : 0.30133, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-11 04:36:31, Epoch : 1, Step : 6419, Training Loss : 0.56038, Training Acc : 0.772, Run Time : 0.46
INFO:root:2019-05-11 04:36:32, Epoch : 1, Step : 6420, Training Loss : 0.57116, Training Acc : 0.778, Run Time : 0.52
INFO:root:2019-05-11 04:36:32, Epoch : 1, Step : 6421, Training Loss : 0.45703, Training Acc : 0.822, Run Time : 0.64
INFO:root:2019-05-11 04:36:43, Epoch : 1, Step : 6422, Training Loss : 0.34120, Training Acc : 0.850, Run Time : 10.80
INFO:root:2019-05-11 04:36:47, Epoch : 1, Step : 6423, Training Loss : 0.39980, Training Acc : 0.833, Run Time : 3.42
INFO:root:2019-05-11 04:36:47, Epoch : 1, Step : 6424, Training Loss : 0.46542, Training Acc : 0.806, Run Time : 0.38
INFO:root:2019-05-11 04:36:47, Epoch : 1, Step : 6425, Training Loss : 0.38655, Training Acc : 0.883, Run Time : 0.42
INFO:root:2019-05-11 04:36:48, Epoch : 1, Step : 6426, Training Loss : 0.51971, Training Acc : 0.833, Run Time : 0.54
INFO:root:2019-05-11 04:36:48, Epoch : 1, Step : 6427, Training Loss : 0.66606, Training Acc : 0.806, Run Time : 0.45
INFO:root:2019-05-11 04:36:49, Epoch : 1, Step : 6428, Training Loss : 0.88169, Training Acc : 0.744, Run Time : 0.37
INFO:root:2019-05-11 04:36:50, Epoch : 1, Step : 6429, Training Loss : 0.68780, Training Acc : 0.706, Run Time : 0.83
INFO:root:2019-05-11 04:36:50, Epoch : 1, Step : 6430, Training Loss : 0.47877, Training Acc : 0.844, Run Time : 0.38
INFO:root:2019-05-11 04:36:51, Epoch : 1, Step : 6431, Training Loss : 0.34573, Training Acc : 0.878, Run Time : 1.21
INFO:root:2019-05-11 04:37:05, Epoch : 1, Step : 6432, Training Loss : 0.17798, Training Acc : 0.956, Run Time : 13.49
INFO:root:2019-05-11 04:37:08, Epoch : 1, Step : 6433, Training Loss : 0.24360, Training Acc : 0.917, Run Time : 2.93
INFO:root:2019-05-11 04:37:08, Epoch : 1, Step : 6434, Training Loss : 0.58927, Training Acc : 0.733, Run Time : 0.38
INFO:root:2019-05-11 04:37:08, Epoch : 1, Step : 6435, Training Loss : 0.43202, Training Acc : 0.806, Run Time : 0.37
INFO:root:2019-05-11 04:37:09, Epoch : 1, Step : 6436, Training Loss : 0.46954, Training Acc : 0.833, Run Time : 0.89
INFO:root:2019-05-11 04:37:20, Epoch : 1, Step : 6437, Training Loss : 0.32731, Training Acc : 0.911, Run Time : 10.91
INFO:root:2019-05-11 04:37:21, Epoch : 1, Step : 6438, Training Loss : 0.44805, Training Acc : 0.811, Run Time : 1.06
INFO:root:2019-05-11 04:37:30, Epoch : 1, Step : 6439, Training Loss : 0.32440, Training Acc : 0.839, Run Time : 8.69
INFO:root:2019-05-11 04:37:41, Epoch : 1, Step : 6440, Training Loss : 0.54577, Training Acc : 0.794, Run Time : 11.41
INFO:root:2019-05-11 04:37:43, Epoch : 1, Step : 6441, Training Loss : 0.38144, Training Acc : 0.844, Run Time : 1.44
INFO:root:2019-05-11 04:37:52, Epoch : 1, Step : 6442, Training Loss : 0.26424, Training Acc : 0.883, Run Time : 9.69
INFO:root:2019-05-11 04:37:53, Epoch : 1, Step : 6443, Training Loss : 0.33391, Training Acc : 0.861, Run Time : 0.80
INFO:root:2019-05-11 04:37:54, Epoch : 1, Step : 6444, Training Loss : 0.27307, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 04:37:54, Epoch : 1, Step : 6445, Training Loss : 0.54388, Training Acc : 0.778, Run Time : 0.38
INFO:root:2019-05-11 04:37:55, Epoch : 1, Step : 6446, Training Loss : 0.31325, Training Acc : 0.889, Run Time : 0.50
INFO:root:2019-05-11 04:38:04, Epoch : 1, Step : 6447, Training Loss : 0.47456, Training Acc : 0.811, Run Time : 9.95
INFO:root:2019-05-11 04:38:05, Epoch : 1, Step : 6448, Training Loss : 0.30680, Training Acc : 0.900, Run Time : 0.55
INFO:root:2019-05-11 04:38:05, Epoch : 1, Step : 6449, Training Loss : 0.20863, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-11 04:38:19, Epoch : 1, Step : 6450, Training Loss : 0.15266, Training Acc : 0.967, Run Time : 13.41
INFO:root:2019-05-11 04:38:20, Epoch : 1, Step : 6451, Training Loss : 0.17539, Training Acc : 0.950, Run Time : 0.80
INFO:root:2019-05-11 04:38:20, Epoch : 1, Step : 6452, Training Loss : 0.22650, Training Acc : 0.911, Run Time : 0.42
INFO:root:2019-05-11 04:38:21, Epoch : 1, Step : 6453, Training Loss : 0.15332, Training Acc : 0.961, Run Time : 1.30
INFO:root:2019-05-11 04:38:33, Epoch : 1, Step : 6454, Training Loss : 0.38708, Training Acc : 0.839, Run Time : 11.62
INFO:root:2019-05-11 04:38:52, Epoch : 1, Step : 6455, Training Loss : 0.60129, Training Acc : 0.806, Run Time : 19.30
INFO:root:2019-05-11 04:38:53, Epoch : 1, Step : 6456, Training Loss : 0.30047, Training Acc : 0.900, Run Time : 0.85
INFO:root:2019-05-11 04:38:54, Epoch : 1, Step : 6457, Training Loss : 0.37846, Training Acc : 0.844, Run Time : 0.43
INFO:root:2019-05-11 04:38:54, Epoch : 1, Step : 6458, Training Loss : 0.18242, Training Acc : 0.911, Run Time : 0.46
INFO:root:2019-05-11 04:38:55, Epoch : 1, Step : 6459, Training Loss : 0.34739, Training Acc : 0.872, Run Time : 0.75
INFO:root:2019-05-11 04:38:56, Epoch : 1, Step : 6460, Training Loss : 0.20642, Training Acc : 0.933, Run Time : 1.23
INFO:root:2019-05-11 04:38:57, Epoch : 1, Step : 6461, Training Loss : 0.13632, Training Acc : 0.972, Run Time : 0.90
INFO:root:2019-05-11 04:39:07, Epoch : 1, Step : 6462, Training Loss : 0.16696, Training Acc : 0.950, Run Time : 10.52
INFO:root:2019-05-11 04:39:09, Epoch : 1, Step : 6463, Training Loss : 0.26563, Training Acc : 0.900, Run Time : 1.34
INFO:root:2019-05-11 04:39:09, Epoch : 1, Step : 6464, Training Loss : 0.33924, Training Acc : 0.872, Run Time : 0.38
INFO:root:2019-05-11 04:39:10, Epoch : 1, Step : 6465, Training Loss : 0.16514, Training Acc : 0.944, Run Time : 0.45
INFO:root:2019-05-11 04:39:10, Epoch : 1, Step : 6466, Training Loss : 0.23725, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-11 04:39:11, Epoch : 1, Step : 6467, Training Loss : 0.42474, Training Acc : 0.828, Run Time : 0.84
INFO:root:2019-05-11 04:39:18, Epoch : 1, Step : 6468, Training Loss : 0.41435, Training Acc : 0.861, Run Time : 7.17
INFO:root:2019-05-11 04:39:19, Epoch : 1, Step : 6469, Training Loss : 0.36054, Training Acc : 0.861, Run Time : 0.88
INFO:root:2019-05-11 04:39:20, Epoch : 1, Step : 6470, Training Loss : 0.41571, Training Acc : 0.817, Run Time : 1.36
INFO:root:2019-05-11 04:39:33, Epoch : 1, Step : 6471, Training Loss : 0.13923, Training Acc : 0.978, Run Time : 12.35
INFO:root:2019-05-11 04:39:33, Epoch : 1, Step : 6472, Training Loss : 0.20563, Training Acc : 0.933, Run Time : 0.73
INFO:root:2019-05-11 04:39:34, Epoch : 1, Step : 6473, Training Loss : 0.49940, Training Acc : 0.839, Run Time : 0.40
INFO:root:2019-05-11 04:39:34, Epoch : 1, Step : 6474, Training Loss : 0.48633, Training Acc : 0.856, Run Time : 0.37
INFO:root:2019-05-11 04:39:35, Epoch : 1, Step : 6475, Training Loss : 0.41435, Training Acc : 0.878, Run Time : 1.10
INFO:root:2019-05-11 04:39:53, Epoch : 1, Step : 6476, Training Loss : 0.23902, Training Acc : 0.889, Run Time : 17.49
INFO:root:2019-05-11 04:39:54, Epoch : 1, Step : 6477, Training Loss : 0.29681, Training Acc : 0.894, Run Time : 1.27
INFO:root:2019-05-11 04:39:55, Epoch : 1, Step : 6478, Training Loss : 0.22816, Training Acc : 0.917, Run Time : 0.83
INFO:root:2019-05-11 04:39:55, Epoch : 1, Step : 6479, Training Loss : 0.27468, Training Acc : 0.894, Run Time : 0.41
INFO:root:2019-05-11 04:40:06, Epoch : 1, Step : 6480, Training Loss : 0.33000, Training Acc : 0.911, Run Time : 10.95
INFO:root:2019-05-11 04:40:09, Epoch : 1, Step : 6481, Training Loss : 0.24448, Training Acc : 0.906, Run Time : 2.65
INFO:root:2019-05-11 04:40:09, Epoch : 1, Step : 6482, Training Loss : 0.27177, Training Acc : 0.889, Run Time : 0.55
INFO:root:2019-05-11 04:40:10, Epoch : 1, Step : 6483, Training Loss : 0.23412, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 04:40:10, Epoch : 1, Step : 6484, Training Loss : 0.15126, Training Acc : 0.972, Run Time : 0.38
INFO:root:2019-05-11 04:40:11, Epoch : 1, Step : 6485, Training Loss : 0.16679, Training Acc : 0.961, Run Time : 0.70
INFO:root:2019-05-11 04:40:18, Epoch : 1, Step : 6486, Training Loss : 0.18376, Training Acc : 0.961, Run Time : 7.54
INFO:root:2019-05-11 04:40:28, Epoch : 1, Step : 6487, Training Loss : 0.18035, Training Acc : 0.950, Run Time : 9.36
INFO:root:2019-05-11 04:40:29, Epoch : 1, Step : 6488, Training Loss : 0.18205, Training Acc : 0.922, Run Time : 1.75
INFO:root:2019-05-11 04:40:37, Epoch : 1, Step : 6489, Training Loss : 0.18988, Training Acc : 0.944, Run Time : 7.66
INFO:root:2019-05-11 04:40:40, Epoch : 1, Step : 6490, Training Loss : 0.23015, Training Acc : 0.911, Run Time : 3.22
INFO:root:2019-05-11 04:40:41, Epoch : 1, Step : 6491, Training Loss : 0.26841, Training Acc : 0.911, Run Time : 0.38
INFO:root:2019-05-11 04:40:42, Epoch : 1, Step : 6492, Training Loss : 0.30632, Training Acc : 0.856, Run Time : 1.33
INFO:root:2019-05-11 04:40:55, Epoch : 1, Step : 6493, Training Loss : 0.42645, Training Acc : 0.844, Run Time : 13.17
INFO:root:2019-05-11 04:41:02, Epoch : 1, Step : 6494, Training Loss : 0.49916, Training Acc : 0.761, Run Time : 6.40
INFO:root:2019-05-11 04:41:02, Epoch : 1, Step : 6495, Training Loss : 0.66381, Training Acc : 0.722, Run Time : 0.38
INFO:root:2019-05-11 04:41:02, Epoch : 1, Step : 6496, Training Loss : 0.46156, Training Acc : 0.800, Run Time : 0.38
INFO:root:2019-05-11 04:41:03, Epoch : 1, Step : 6497, Training Loss : 0.22472, Training Acc : 0.917, Run Time : 0.38
INFO:root:2019-05-11 04:41:07, Epoch : 1, Step : 6498, Training Loss : 0.27535, Training Acc : 0.883, Run Time : 4.48
INFO:root:2019-05-11 04:41:08, Epoch : 1, Step : 6499, Training Loss : 0.20137, Training Acc : 0.939, Run Time : 0.55
INFO:root:2019-05-11 04:41:08, Epoch : 1, Step : 6500, Training Loss : 0.41394, Training Acc : 0.839, Run Time : 0.44
INFO:root:2019-05-11 04:41:10, Epoch : 1, Step : 6501, Training Loss : 0.29602, Training Acc : 0.872, Run Time : 1.47
INFO:root:2019-05-11 04:41:15, Epoch : 1, Step : 6502, Training Loss : 0.38637, Training Acc : 0.839, Run Time : 5.03
INFO:root:2019-05-11 04:41:15, Epoch : 1, Step : 6503, Training Loss : 0.17111, Training Acc : 0.950, Run Time : 0.67
INFO:root:2019-05-11 04:41:16, Epoch : 1, Step : 6504, Training Loss : 0.32826, Training Acc : 0.889, Run Time : 0.43
INFO:root:2019-05-11 04:41:17, Epoch : 1, Step : 6505, Training Loss : 0.23219, Training Acc : 0.928, Run Time : 1.19
INFO:root:2019-05-11 04:41:28, Epoch : 1, Step : 6506, Training Loss : 0.20150, Training Acc : 0.961, Run Time : 11.47
INFO:root:2019-05-11 04:41:29, Epoch : 1, Step : 6507, Training Loss : 0.37416, Training Acc : 0.822, Run Time : 0.56
INFO:root:2019-05-11 04:41:30, Epoch : 1, Step : 6508, Training Loss : 0.43146, Training Acc : 0.833, Run Time : 0.93
INFO:root:2019-05-11 04:41:42, Epoch : 1, Step : 6509, Training Loss : 0.36417, Training Acc : 0.844, Run Time : 11.62
INFO:root:2019-05-11 04:41:42, Epoch : 1, Step : 6510, Training Loss : 0.50574, Training Acc : 0.750, Run Time : 0.41
INFO:root:2019-05-11 04:41:43, Epoch : 1, Step : 6511, Training Loss : 0.42142, Training Acc : 0.811, Run Time : 0.51
INFO:root:2019-05-11 04:41:43, Epoch : 1, Step : 6512, Training Loss : 0.28522, Training Acc : 0.889, Run Time : 0.71
INFO:root:2019-05-11 04:41:52, Epoch : 1, Step : 6513, Training Loss : 0.31697, Training Acc : 0.817, Run Time : 9.18
INFO:root:2019-05-11 04:41:54, Epoch : 1, Step : 6514, Training Loss : 0.31812, Training Acc : 0.856, Run Time : 1.68
INFO:root:2019-05-11 04:41:55, Epoch : 1, Step : 6515, Training Loss : 0.57830, Training Acc : 0.739, Run Time : 0.72
INFO:root:2019-05-11 04:42:07, Epoch : 1, Step : 6516, Training Loss : 0.46510, Training Acc : 0.806, Run Time : 11.91
INFO:root:2019-05-11 04:42:08, Epoch : 1, Step : 6517, Training Loss : 0.48708, Training Acc : 0.800, Run Time : 1.16
INFO:root:2019-05-11 04:42:10, Epoch : 1, Step : 6518, Training Loss : 0.41375, Training Acc : 0.839, Run Time : 2.18
INFO:root:2019-05-11 04:42:23, Epoch : 1, Step : 6519, Training Loss : 0.27390, Training Acc : 0.900, Run Time : 12.72
INFO:root:2019-05-11 04:42:23, Epoch : 1, Step : 6520, Training Loss : 0.25388, Training Acc : 0.939, Run Time : 0.42
INFO:root:2019-05-11 04:42:24, Epoch : 1, Step : 6521, Training Loss : 0.24350, Training Acc : 0.894, Run Time : 0.70
INFO:root:2019-05-11 04:42:24, Epoch : 1, Step : 6522, Training Loss : 0.22275, Training Acc : 0.889, Run Time : 0.38
INFO:root:2019-05-11 04:42:25, Epoch : 1, Step : 6523, Training Loss : 0.16568, Training Acc : 0.944, Run Time : 0.74
INFO:root:2019-05-11 04:42:36, Epoch : 1, Step : 6524, Training Loss : 0.16965, Training Acc : 0.950, Run Time : 10.70
INFO:root:2019-05-11 04:42:36, Epoch : 1, Step : 6525, Training Loss : 0.21452, Training Acc : 0.933, Run Time : 0.66
INFO:root:2019-05-11 04:42:37, Epoch : 1, Step : 6526, Training Loss : 0.14063, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-11 04:42:38, Epoch : 1, Step : 6527, Training Loss : 0.10781, Training Acc : 0.978, Run Time : 1.25
INFO:root:2019-05-11 04:42:48, Epoch : 1, Step : 6528, Training Loss : 0.23235, Training Acc : 0.917, Run Time : 9.85
INFO:root:2019-05-11 04:42:49, Epoch : 1, Step : 6529, Training Loss : 0.21657, Training Acc : 0.922, Run Time : 0.73
INFO:root:2019-05-11 04:42:51, Epoch : 1, Step : 6530, Training Loss : 0.24591, Training Acc : 0.911, Run Time : 2.38
INFO:root:2019-05-11 04:43:02, Epoch : 1, Step : 6531, Training Loss : 0.30934, Training Acc : 0.861, Run Time : 10.63
INFO:root:2019-05-11 04:43:02, Epoch : 1, Step : 6532, Training Loss : 0.17823, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 04:43:02, Epoch : 1, Step : 6533, Training Loss : 0.11728, Training Acc : 0.961, Run Time : 0.47
INFO:root:2019-05-11 04:43:03, Epoch : 1, Step : 6534, Training Loss : 0.15963, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 04:43:03, Epoch : 1, Step : 6535, Training Loss : 0.13419, Training Acc : 0.950, Run Time : 0.58
INFO:root:2019-05-11 04:43:05, Epoch : 1, Step : 6536, Training Loss : 0.07133, Training Acc : 0.989, Run Time : 1.49
INFO:root:2019-05-11 04:43:12, Epoch : 1, Step : 6537, Training Loss : 0.06055, Training Acc : 1.000, Run Time : 6.90
INFO:root:2019-05-11 04:43:13, Epoch : 1, Step : 6538, Training Loss : 0.08589, Training Acc : 0.983, Run Time : 0.74
INFO:root:2019-05-11 04:43:13, Epoch : 1, Step : 6539, Training Loss : 0.07755, Training Acc : 0.989, Run Time : 0.90
INFO:root:2019-05-11 04:43:25, Epoch : 1, Step : 6540, Training Loss : 0.12462, Training Acc : 0.967, Run Time : 11.91
INFO:root:2019-05-11 04:43:26, Epoch : 1, Step : 6541, Training Loss : 0.10568, Training Acc : 0.983, Run Time : 0.44
INFO:root:2019-05-11 04:43:28, Epoch : 1, Step : 6542, Training Loss : 0.10325, Training Acc : 0.983, Run Time : 1.97
INFO:root:2019-05-11 04:43:39, Epoch : 1, Step : 6543, Training Loss : 0.12919, Training Acc : 0.972, Run Time : 10.75
INFO:root:2019-05-11 04:43:39, Epoch : 1, Step : 6544, Training Loss : 0.20668, Training Acc : 0.933, Run Time : 0.57
INFO:root:2019-05-11 04:43:40, Epoch : 1, Step : 6545, Training Loss : 0.11120, Training Acc : 0.967, Run Time : 1.29
INFO:root:2019-05-11 04:43:53, Epoch : 1, Step : 6546, Training Loss : 0.13736, Training Acc : 0.950, Run Time : 12.62
INFO:root:2019-05-11 04:44:02, Epoch : 1, Step : 6547, Training Loss : 0.06621, Training Acc : 0.983, Run Time : 8.80
INFO:root:2019-05-11 04:44:04, Epoch : 1, Step : 6548, Training Loss : 0.10032, Training Acc : 0.956, Run Time : 2.21
INFO:root:2019-05-11 04:44:04, Epoch : 1, Step : 6549, Training Loss : 0.07112, Training Acc : 0.983, Run Time : 0.42
INFO:root:2019-05-11 04:44:05, Epoch : 1, Step : 6550, Training Loss : 0.06559, Training Acc : 0.983, Run Time : 0.53
INFO:root:2019-05-11 04:44:05, Epoch : 1, Step : 6551, Training Loss : 0.13206, Training Acc : 0.950, Run Time : 0.40
INFO:root:2019-05-11 04:44:17, Epoch : 1, Step : 6552, Training Loss : 0.07107, Training Acc : 0.983, Run Time : 11.31
INFO:root:2019-05-11 04:44:17, Epoch : 1, Step : 6553, Training Loss : 0.05894, Training Acc : 0.994, Run Time : 0.65
INFO:root:2019-05-11 04:44:18, Epoch : 1, Step : 6554, Training Loss : 0.06935, Training Acc : 0.989, Run Time : 0.37
INFO:root:2019-05-11 04:44:20, Epoch : 1, Step : 6555, Training Loss : 0.04129, Training Acc : 1.000, Run Time : 1.86
INFO:root:2019-05-11 04:44:28, Epoch : 1, Step : 6556, Training Loss : 0.11328, Training Acc : 0.956, Run Time : 8.89
INFO:root:2019-05-11 04:44:29, Epoch : 1, Step : 6557, Training Loss : 0.12013, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-11 04:44:29, Epoch : 1, Step : 6558, Training Loss : 0.09575, Training Acc : 0.961, Run Time : 0.59
INFO:root:2019-05-11 04:44:31, Epoch : 1, Step : 6559, Training Loss : 0.08908, Training Acc : 0.961, Run Time : 1.73
INFO:root:2019-05-11 04:44:40, Epoch : 1, Step : 6560, Training Loss : 0.11320, Training Acc : 0.961, Run Time : 8.64
INFO:root:2019-05-11 04:44:40, Epoch : 1, Step : 6561, Training Loss : 0.20799, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-11 04:44:41, Epoch : 1, Step : 6562, Training Loss : 0.17766, Training Acc : 0.956, Run Time : 0.38
INFO:root:2019-05-11 04:44:41, Epoch : 1, Step : 6563, Training Loss : 0.24716, Training Acc : 0.922, Run Time : 0.69
INFO:root:2019-05-11 04:44:42, Epoch : 1, Step : 6564, Training Loss : 0.29023, Training Acc : 0.889, Run Time : 0.94
INFO:root:2019-05-11 04:44:43, Epoch : 1, Step : 6565, Training Loss : 0.60899, Training Acc : 0.828, Run Time : 0.38
INFO:root:2019-05-11 04:44:44, Epoch : 1, Step : 6566, Training Loss : 0.46045, Training Acc : 0.850, Run Time : 1.32
INFO:root:2019-05-11 04:44:54, Epoch : 1, Step : 6567, Training Loss : 0.24638, Training Acc : 0.900, Run Time : 10.08
INFO:root:2019-05-11 04:44:55, Epoch : 1, Step : 6568, Training Loss : 0.27443, Training Acc : 0.878, Run Time : 0.74
INFO:root:2019-05-11 04:44:55, Epoch : 1, Step : 6569, Training Loss : 0.14508, Training Acc : 0.956, Run Time : 0.52
INFO:root:2019-05-11 04:45:07, Epoch : 1, Step : 6570, Training Loss : 0.13044, Training Acc : 0.944, Run Time : 11.89
INFO:root:2019-05-11 04:45:08, Epoch : 1, Step : 6571, Training Loss : 0.10009, Training Acc : 0.967, Run Time : 0.76
INFO:root:2019-05-11 04:45:10, Epoch : 1, Step : 6572, Training Loss : 0.25262, Training Acc : 0.883, Run Time : 2.22
INFO:root:2019-05-11 04:45:18, Epoch : 1, Step : 6573, Training Loss : 0.22650, Training Acc : 0.889, Run Time : 7.88
INFO:root:2019-05-11 04:45:29, Epoch : 1, Step : 6574, Training Loss : 0.20061, Training Acc : 0.906, Run Time : 10.78
INFO:root:2019-05-11 04:45:30, Epoch : 1, Step : 6575, Training Loss : 0.20525, Training Acc : 0.894, Run Time : 0.71
INFO:root:2019-05-11 04:45:30, Epoch : 1, Step : 6576, Training Loss : 0.15880, Training Acc : 0.928, Run Time : 0.48
INFO:root:2019-05-11 04:45:32, Epoch : 1, Step : 6577, Training Loss : 0.17022, Training Acc : 0.928, Run Time : 1.55
INFO:root:2019-05-11 04:45:40, Epoch : 1, Step : 6578, Training Loss : 0.09842, Training Acc : 0.967, Run Time : 8.59
INFO:root:2019-05-11 04:45:41, Epoch : 1, Step : 6579, Training Loss : 0.07747, Training Acc : 0.989, Run Time : 0.57
INFO:root:2019-05-11 04:45:41, Epoch : 1, Step : 6580, Training Loss : 0.13592, Training Acc : 0.939, Run Time : 0.41
INFO:root:2019-05-11 04:45:52, Epoch : 1, Step : 6581, Training Loss : 0.16835, Training Acc : 0.939, Run Time : 10.94
INFO:root:2019-05-11 04:45:53, Epoch : 1, Step : 6582, Training Loss : 0.26034, Training Acc : 0.906, Run Time : 0.98
INFO:root:2019-05-11 04:45:53, Epoch : 1, Step : 6583, Training Loss : 0.23640, Training Acc : 0.894, Run Time : 0.37
INFO:root:2019-05-11 04:45:54, Epoch : 1, Step : 6584, Training Loss : 0.16107, Training Acc : 0.944, Run Time : 0.98
INFO:root:2019-05-11 04:46:05, Epoch : 1, Step : 6585, Training Loss : 0.16003, Training Acc : 0.944, Run Time : 10.29
INFO:root:2019-05-11 04:46:06, Epoch : 1, Step : 6586, Training Loss : 0.10979, Training Acc : 0.961, Run Time : 0.93
INFO:root:2019-05-11 04:46:07, Epoch : 1, Step : 6587, Training Loss : 0.15931, Training Acc : 0.928, Run Time : 1.15
INFO:root:2019-05-11 04:46:17, Epoch : 1, Step : 6588, Training Loss : 0.10779, Training Acc : 0.967, Run Time : 10.48
INFO:root:2019-05-11 04:46:18, Epoch : 1, Step : 6589, Training Loss : 0.27523, Training Acc : 0.883, Run Time : 0.54
INFO:root:2019-05-11 04:46:18, Epoch : 1, Step : 6590, Training Loss : 0.29983, Training Acc : 0.867, Run Time : 0.41
INFO:root:2019-05-11 04:46:20, Epoch : 1, Step : 6591, Training Loss : 0.19456, Training Acc : 0.911, Run Time : 1.30
INFO:root:2019-05-11 04:46:31, Epoch : 1, Step : 6592, Training Loss : 0.18569, Training Acc : 0.922, Run Time : 11.05
INFO:root:2019-05-11 04:46:31, Epoch : 1, Step : 6593, Training Loss : 0.26431, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 04:46:32, Epoch : 1, Step : 6594, Training Loss : 0.35061, Training Acc : 0.883, Run Time : 1.28
INFO:root:2019-05-11 04:46:44, Epoch : 1, Step : 6595, Training Loss : 0.18934, Training Acc : 0.950, Run Time : 11.69
INFO:root:2019-05-11 04:46:44, Epoch : 1, Step : 6596, Training Loss : 0.20950, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-11 04:46:45, Epoch : 1, Step : 6597, Training Loss : 0.06666, Training Acc : 0.989, Run Time : 0.38
INFO:root:2019-05-11 04:46:48, Epoch : 1, Step : 6598, Training Loss : 0.13225, Training Acc : 0.944, Run Time : 2.79
INFO:root:2019-05-11 04:47:00, Epoch : 1, Step : 6599, Training Loss : 0.20067, Training Acc : 0.911, Run Time : 12.94
INFO:root:2019-05-11 04:47:01, Epoch : 1, Step : 6600, Training Loss : 0.20959, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-11 04:47:10, Epoch : 1, Step : 6601, Training Loss : 1.43037, Training Acc : 0.544, Run Time : 8.97
INFO:root:2019-05-11 04:47:12, Epoch : 1, Step : 6602, Training Loss : 1.33022, Training Acc : 0.556, Run Time : 2.38
INFO:root:2019-05-11 04:47:23, Epoch : 1, Step : 6603, Training Loss : 1.49614, Training Acc : 0.444, Run Time : 11.04
INFO:root:2019-05-11 04:47:24, Epoch : 1, Step : 6604, Training Loss : 1.28461, Training Acc : 0.500, Run Time : 0.57
INFO:root:2019-05-11 04:47:25, Epoch : 1, Step : 6605, Training Loss : 0.96611, Training Acc : 0.567, Run Time : 0.70
INFO:root:2019-05-11 04:47:25, Epoch : 1, Step : 6606, Training Loss : 1.16110, Training Acc : 0.361, Run Time : 0.40
INFO:root:2019-05-11 04:47:25, Epoch : 1, Step : 6607, Training Loss : 1.05762, Training Acc : 0.456, Run Time : 0.40
INFO:root:2019-05-11 04:47:26, Epoch : 1, Step : 6608, Training Loss : 1.13611, Training Acc : 0.400, Run Time : 0.53
INFO:root:2019-05-11 04:47:26, Epoch : 1, Step : 6609, Training Loss : 0.90541, Training Acc : 0.594, Run Time : 0.38
INFO:root:2019-05-11 04:47:27, Epoch : 1, Step : 6610, Training Loss : 0.70309, Training Acc : 0.611, Run Time : 0.69
INFO:root:2019-05-11 04:47:41, Epoch : 1, Step : 6611, Training Loss : 0.79250, Training Acc : 0.583, Run Time : 13.59
INFO:root:2019-05-11 04:47:41, Epoch : 1, Step : 6612, Training Loss : 0.83123, Training Acc : 0.628, Run Time : 0.75
INFO:root:2019-05-11 04:47:42, Epoch : 1, Step : 6613, Training Loss : 1.19876, Training Acc : 0.389, Run Time : 0.38
INFO:root:2019-05-11 04:47:42, Epoch : 1, Step : 6614, Training Loss : 0.68406, Training Acc : 0.711, Run Time : 0.54
INFO:root:2019-05-11 04:47:55, Epoch : 1, Step : 6615, Training Loss : 0.78868, Training Acc : 0.522, Run Time : 12.87
INFO:root:2019-05-11 04:47:56, Epoch : 1, Step : 6616, Training Loss : 0.64559, Training Acc : 0.694, Run Time : 0.92
INFO:root:2019-05-11 04:47:57, Epoch : 1, Step : 6617, Training Loss : 0.64420, Training Acc : 0.650, Run Time : 1.13
INFO:root:2019-05-11 04:47:58, Epoch : 1, Step : 6618, Training Loss : 0.56823, Training Acc : 0.661, Run Time : 0.85
INFO:root:2019-05-11 04:47:59, Epoch : 1, Step : 6619, Training Loss : 0.37556, Training Acc : 0.883, Run Time : 1.28
INFO:root:2019-05-11 04:48:07, Epoch : 1, Step : 6620, Training Loss : 0.48620, Training Acc : 0.789, Run Time : 8.08
INFO:root:2019-05-11 04:48:08, Epoch : 1, Step : 6621, Training Loss : 0.56361, Training Acc : 0.739, Run Time : 0.59
INFO:root:2019-05-11 04:48:10, Epoch : 1, Step : 6622, Training Loss : 0.57770, Training Acc : 0.739, Run Time : 1.71
INFO:root:2019-05-11 04:48:20, Epoch : 1, Step : 6623, Training Loss : 0.53521, Training Acc : 0.728, Run Time : 10.59
INFO:root:2019-05-11 04:48:21, Epoch : 1, Step : 6624, Training Loss : 0.58599, Training Acc : 0.683, Run Time : 0.93
INFO:root:2019-05-11 04:48:22, Epoch : 1, Step : 6625, Training Loss : 0.68725, Training Acc : 0.544, Run Time : 0.38
INFO:root:2019-05-11 04:48:22, Epoch : 1, Step : 6626, Training Loss : 0.53971, Training Acc : 0.706, Run Time : 0.39
INFO:root:2019-05-11 04:48:33, Epoch : 1, Step : 6627, Training Loss : 0.45216, Training Acc : 0.817, Run Time : 10.73
INFO:root:2019-05-11 04:48:34, Epoch : 1, Step : 6628, Training Loss : 0.49121, Training Acc : 0.772, Run Time : 0.89
INFO:root:2019-05-11 04:48:34, Epoch : 1, Step : 6629, Training Loss : 0.58287, Training Acc : 0.611, Run Time : 0.38
INFO:root:2019-05-11 04:48:35, Epoch : 1, Step : 6630, Training Loss : 0.45581, Training Acc : 0.844, Run Time : 1.39
INFO:root:2019-05-11 04:48:48, Epoch : 1, Step : 6631, Training Loss : 0.44326, Training Acc : 0.839, Run Time : 12.43
INFO:root:2019-05-11 04:48:49, Epoch : 1, Step : 6632, Training Loss : 0.42469, Training Acc : 0.811, Run Time : 0.84
INFO:root:2019-05-11 04:48:49, Epoch : 1, Step : 6633, Training Loss : 0.51247, Training Acc : 0.806, Run Time : 0.37
INFO:root:2019-05-11 04:48:51, Epoch : 1, Step : 6634, Training Loss : 0.41342, Training Acc : 0.867, Run Time : 2.43
INFO:root:2019-05-11 04:49:02, Epoch : 1, Step : 6635, Training Loss : 0.52306, Training Acc : 0.761, Run Time : 11.02
INFO:root:2019-05-11 04:49:03, Epoch : 1, Step : 6636, Training Loss : 0.40174, Training Acc : 0.944, Run Time : 0.85
INFO:root:2019-05-11 04:49:04, Epoch : 1, Step : 6637, Training Loss : 0.46227, Training Acc : 0.761, Run Time : 0.39
INFO:root:2019-05-11 04:49:04, Epoch : 1, Step : 6638, Training Loss : 0.45832, Training Acc : 0.817, Run Time : 0.39
INFO:root:2019-05-11 04:49:04, Epoch : 1, Step : 6639, Training Loss : 0.39135, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-11 04:49:05, Epoch : 1, Step : 6640, Training Loss : 0.31811, Training Acc : 0.900, Run Time : 1.12
INFO:root:2019-05-11 04:49:20, Epoch : 1, Step : 6641, Training Loss : 0.49189, Training Acc : 0.817, Run Time : 14.46
INFO:root:2019-05-11 04:49:21, Epoch : 1, Step : 6642, Training Loss : 0.46966, Training Acc : 0.783, Run Time : 0.89
INFO:root:2019-05-11 04:49:21, Epoch : 1, Step : 6643, Training Loss : 0.33525, Training Acc : 0.861, Run Time : 0.37
INFO:root:2019-05-11 04:49:33, Epoch : 1, Step : 6644, Training Loss : 0.47760, Training Acc : 0.756, Run Time : 11.43
INFO:root:2019-05-11 04:49:33, Epoch : 1, Step : 6645, Training Loss : 0.46579, Training Acc : 0.789, Run Time : 0.72
INFO:root:2019-05-11 04:49:34, Epoch : 1, Step : 6646, Training Loss : 0.43792, Training Acc : 0.794, Run Time : 0.41
INFO:root:2019-05-11 04:49:36, Epoch : 1, Step : 6647, Training Loss : 0.51925, Training Acc : 0.750, Run Time : 1.96
INFO:root:2019-05-11 04:49:47, Epoch : 1, Step : 6648, Training Loss : 0.45241, Training Acc : 0.839, Run Time : 11.11
INFO:root:2019-05-11 04:49:47, Epoch : 1, Step : 6649, Training Loss : 0.47742, Training Acc : 0.767, Run Time : 0.42
INFO:root:2019-05-11 04:49:48, Epoch : 1, Step : 6650, Training Loss : 0.29061, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 04:49:49, Epoch : 1, Step : 6651, Training Loss : 0.44947, Training Acc : 0.794, Run Time : 1.61
INFO:root:2019-05-11 04:50:01, Epoch : 1, Step : 6652, Training Loss : 0.39953, Training Acc : 0.867, Run Time : 11.86
INFO:root:2019-05-11 04:50:02, Epoch : 1, Step : 6653, Training Loss : 0.25194, Training Acc : 0.961, Run Time : 0.40
INFO:root:2019-05-11 04:50:02, Epoch : 1, Step : 6654, Training Loss : 0.47700, Training Acc : 0.739, Run Time : 0.57
INFO:root:2019-05-11 04:50:03, Epoch : 1, Step : 6655, Training Loss : 0.35666, Training Acc : 0.906, Run Time : 1.16
INFO:root:2019-05-11 04:50:14, Epoch : 1, Step : 6656, Training Loss : 0.39254, Training Acc : 0.828, Run Time : 11.05
INFO:root:2019-05-11 04:50:15, Epoch : 1, Step : 6657, Training Loss : 0.31644, Training Acc : 0.944, Run Time : 0.84
INFO:root:2019-05-11 04:50:15, Epoch : 1, Step : 6658, Training Loss : 0.27221, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 04:50:17, Epoch : 1, Step : 6659, Training Loss : 0.39529, Training Acc : 0.856, Run Time : 1.55
INFO:root:2019-05-11 04:50:28, Epoch : 1, Step : 6660, Training Loss : 0.37328, Training Acc : 0.833, Run Time : 10.59
INFO:root:2019-05-11 04:50:29, Epoch : 1, Step : 6661, Training Loss : 0.33222, Training Acc : 0.850, Run Time : 1.50
INFO:root:2019-05-11 04:50:31, Epoch : 1, Step : 6662, Training Loss : 0.33593, Training Acc : 0.883, Run Time : 1.88
INFO:root:2019-05-11 04:50:43, Epoch : 1, Step : 6663, Training Loss : 0.38632, Training Acc : 0.817, Run Time : 12.26
INFO:root:2019-05-11 04:50:44, Epoch : 1, Step : 6664, Training Loss : 0.54659, Training Acc : 0.750, Run Time : 0.40
INFO:root:2019-05-11 04:50:44, Epoch : 1, Step : 6665, Training Loss : 0.40595, Training Acc : 0.839, Run Time : 0.37
INFO:root:2019-05-11 04:50:46, Epoch : 1, Step : 6666, Training Loss : 0.35931, Training Acc : 0.872, Run Time : 1.53
INFO:root:2019-05-11 04:50:58, Epoch : 1, Step : 6667, Training Loss : 0.37953, Training Acc : 0.794, Run Time : 12.31
INFO:root:2019-05-11 04:50:58, Epoch : 1, Step : 6668, Training Loss : 0.55562, Training Acc : 0.717, Run Time : 0.42
INFO:root:2019-05-11 04:50:59, Epoch : 1, Step : 6669, Training Loss : 0.44908, Training Acc : 0.817, Run Time : 0.38
INFO:root:2019-05-11 04:51:00, Epoch : 1, Step : 6670, Training Loss : 0.28881, Training Acc : 0.939, Run Time : 1.76
INFO:root:2019-05-11 04:51:13, Epoch : 1, Step : 6671, Training Loss : 0.45982, Training Acc : 0.839, Run Time : 12.39
INFO:root:2019-05-11 04:51:13, Epoch : 1, Step : 6672, Training Loss : 0.37684, Training Acc : 0.900, Run Time : 0.53
INFO:root:2019-05-11 04:51:14, Epoch : 1, Step : 6673, Training Loss : 0.27642, Training Acc : 0.944, Run Time : 0.39
INFO:root:2019-05-11 04:51:14, Epoch : 1, Step : 6674, Training Loss : 0.24682, Training Acc : 0.933, Run Time : 0.45
INFO:root:2019-05-11 04:51:15, Epoch : 1, Step : 6675, Training Loss : 0.28118, Training Acc : 0.928, Run Time : 0.90
INFO:root:2019-05-11 04:51:31, Epoch : 1, Step : 6676, Training Loss : 0.48227, Training Acc : 0.850, Run Time : 15.65
INFO:root:2019-05-11 04:51:33, Epoch : 1, Step : 6677, Training Loss : 0.35445, Training Acc : 0.844, Run Time : 2.24
INFO:root:2019-05-11 04:51:33, Epoch : 1, Step : 6678, Training Loss : 0.37326, Training Acc : 0.822, Run Time : 0.37
INFO:root:2019-05-11 04:51:34, Epoch : 1, Step : 6679, Training Loss : 0.28435, Training Acc : 0.911, Run Time : 0.89
INFO:root:2019-05-11 04:51:46, Epoch : 1, Step : 6680, Training Loss : 0.24644, Training Acc : 0.933, Run Time : 11.86
INFO:root:2019-05-11 04:51:47, Epoch : 1, Step : 6681, Training Loss : 0.36561, Training Acc : 0.850, Run Time : 0.71
INFO:root:2019-05-11 04:51:48, Epoch : 1, Step : 6682, Training Loss : 0.27393, Training Acc : 0.928, Run Time : 0.80
INFO:root:2019-05-11 04:52:01, Epoch : 1, Step : 6683, Training Loss : 0.30062, Training Acc : 0.894, Run Time : 13.04
INFO:root:2019-05-11 04:52:02, Epoch : 1, Step : 6684, Training Loss : 0.32050, Training Acc : 0.828, Run Time : 1.80
INFO:root:2019-05-11 04:52:03, Epoch : 1, Step : 6685, Training Loss : 0.21737, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-11 04:52:03, Epoch : 1, Step : 6686, Training Loss : 0.29633, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 04:52:04, Epoch : 1, Step : 6687, Training Loss : 0.34563, Training Acc : 0.850, Run Time : 0.53
INFO:root:2019-05-11 04:52:04, Epoch : 1, Step : 6688, Training Loss : 0.25194, Training Acc : 0.933, Run Time : 0.39
INFO:root:2019-05-11 04:52:05, Epoch : 1, Step : 6689, Training Loss : 0.27356, Training Acc : 0.911, Run Time : 1.05
INFO:root:2019-05-11 04:52:15, Epoch : 1, Step : 6690, Training Loss : 0.35348, Training Acc : 0.828, Run Time : 9.57
INFO:root:2019-05-11 04:52:16, Epoch : 1, Step : 6691, Training Loss : 0.24771, Training Acc : 0.928, Run Time : 1.00
INFO:root:2019-05-11 04:52:16, Epoch : 1, Step : 6692, Training Loss : 0.30086, Training Acc : 0.872, Run Time : 0.40
INFO:root:2019-05-11 04:52:17, Epoch : 1, Step : 6693, Training Loss : 0.24749, Training Acc : 0.956, Run Time : 0.73
INFO:root:2019-05-11 04:52:30, Epoch : 1, Step : 6694, Training Loss : 0.21428, Training Acc : 0.944, Run Time : 13.11
INFO:root:2019-05-11 04:52:31, Epoch : 1, Step : 6695, Training Loss : 0.30297, Training Acc : 0.878, Run Time : 0.51
INFO:root:2019-05-11 04:52:31, Epoch : 1, Step : 6696, Training Loss : 0.22380, Training Acc : 0.900, Run Time : 0.62
INFO:root:2019-05-11 04:52:45, Epoch : 1, Step : 6697, Training Loss : 0.32223, Training Acc : 0.900, Run Time : 13.79
INFO:root:2019-05-11 04:52:45, Epoch : 1, Step : 6698, Training Loss : 0.25420, Training Acc : 0.906, Run Time : 0.48
INFO:root:2019-05-11 04:52:46, Epoch : 1, Step : 6699, Training Loss : 0.37107, Training Acc : 0.822, Run Time : 0.38
INFO:root:2019-05-11 04:52:47, Epoch : 1, Step : 6700, Training Loss : 0.29182, Training Acc : 0.917, Run Time : 0.87
INFO:root:2019-05-11 04:52:57, Epoch : 1, Step : 6701, Training Loss : 0.18510, Training Acc : 0.944, Run Time : 10.13
INFO:root:2019-05-11 04:52:57, Epoch : 1, Step : 6702, Training Loss : 0.20722, Training Acc : 0.922, Run Time : 0.52
INFO:root:2019-05-11 04:52:58, Epoch : 1, Step : 6703, Training Loss : 0.32164, Training Acc : 0.844, Run Time : 0.39
INFO:root:2019-05-11 04:52:59, Epoch : 1, Step : 6704, Training Loss : 0.17363, Training Acc : 0.961, Run Time : 1.69
INFO:root:2019-05-11 04:53:17, Epoch : 1, Step : 6705, Training Loss : 0.41079, Training Acc : 0.794, Run Time : 17.47
INFO:root:2019-05-11 04:53:18, Epoch : 1, Step : 6706, Training Loss : 0.21097, Training Acc : 0.922, Run Time : 1.00
INFO:root:2019-05-11 04:53:19, Epoch : 1, Step : 6707, Training Loss : 0.45466, Training Acc : 0.783, Run Time : 0.89
INFO:root:2019-05-11 04:53:19, Epoch : 1, Step : 6708, Training Loss : 0.21887, Training Acc : 0.911, Run Time : 0.68
INFO:root:2019-05-11 04:53:20, Epoch : 1, Step : 6709, Training Loss : 0.35916, Training Acc : 0.839, Run Time : 0.50
INFO:root:2019-05-11 04:53:21, Epoch : 1, Step : 6710, Training Loss : 0.24338, Training Acc : 0.894, Run Time : 0.74
INFO:root:2019-05-11 04:53:32, Epoch : 1, Step : 6711, Training Loss : 0.37251, Training Acc : 0.828, Run Time : 11.33
INFO:root:2019-05-11 04:53:32, Epoch : 1, Step : 6712, Training Loss : 0.21888, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 04:53:33, Epoch : 1, Step : 6713, Training Loss : 0.22483, Training Acc : 0.900, Run Time : 0.38
INFO:root:2019-05-11 04:53:34, Epoch : 1, Step : 6714, Training Loss : 0.36889, Training Acc : 0.839, Run Time : 0.81
INFO:root:2019-05-11 04:53:38, Epoch : 1, Step : 6715, Training Loss : 0.20773, Training Acc : 0.922, Run Time : 4.50
INFO:root:2019-05-11 04:53:39, Epoch : 1, Step : 6716, Training Loss : 0.41263, Training Acc : 0.806, Run Time : 0.91
INFO:root:2019-05-11 04:54:01, Epoch : 1, Step : 6717, Training Loss : 0.57030, Training Acc : 0.744, Run Time : 22.13
INFO:root:2019-05-11 04:54:14, Epoch : 1, Step : 6718, Training Loss : 0.44906, Training Acc : 0.794, Run Time : 12.89
INFO:root:2019-05-11 04:54:19, Epoch : 1, Step : 6719, Training Loss : 0.54859, Training Acc : 0.750, Run Time : 5.35
INFO:root:2019-05-11 04:54:21, Epoch : 1, Step : 6720, Training Loss : 0.22670, Training Acc : 0.922, Run Time : 1.82
INFO:root:2019-05-11 04:54:34, Epoch : 1, Step : 6721, Training Loss : 0.29240, Training Acc : 0.883, Run Time : 12.39
INFO:root:2019-05-11 04:54:53, Epoch : 1, Step : 6722, Training Loss : 0.30597, Training Acc : 0.822, Run Time : 19.15
INFO:root:2019-05-11 04:55:50, Epoch : 1, Step : 6723, Training Loss : 0.14898, Training Acc : 0.950, Run Time : 57.54
INFO:root:2019-05-11 04:56:32, Epoch : 1, Step : 6724, Training Loss : 0.18095, Training Acc : 0.933, Run Time : 41.74
INFO:root:2019-05-11 04:57:31, Epoch : 1, Step : 6725, Training Loss : 0.15964, Training Acc : 0.978, Run Time : 59.28
INFO:root:2019-05-11 04:57:37, Epoch : 1, Step : 6726, Training Loss : 0.19813, Training Acc : 0.933, Run Time : 5.66
INFO:root:2019-05-11 04:57:37, Epoch : 1, Step : 6727, Training Loss : 0.20183, Training Acc : 0.933, Run Time : 0.39
INFO:root:2019-05-11 04:57:39, Epoch : 1, Step : 6728, Training Loss : 0.36259, Training Acc : 0.844, Run Time : 1.67
INFO:root:2019-05-11 04:57:52, Epoch : 1, Step : 6729, Training Loss : 0.21049, Training Acc : 0.933, Run Time : 13.41
INFO:root:2019-05-11 04:57:54, Epoch : 1, Step : 6730, Training Loss : 0.20103, Training Acc : 0.911, Run Time : 1.93
INFO:root:2019-05-11 04:58:34, Epoch : 1, Step : 6731, Training Loss : 0.19304, Training Acc : 0.939, Run Time : 39.58
INFO:root:2019-05-11 04:58:41, Epoch : 1, Step : 6732, Training Loss : 0.22594, Training Acc : 0.906, Run Time : 6.54
INFO:root:2019-05-11 04:58:41, Epoch : 1, Step : 6733, Training Loss : 0.23044, Training Acc : 0.922, Run Time : 0.92
INFO:root:2019-05-11 05:00:03, Epoch : 1, Step : 6734, Training Loss : 0.21164, Training Acc : 0.906, Run Time : 81.14
INFO:root:2019-05-11 05:00:16, Epoch : 1, Step : 6735, Training Loss : 0.30340, Training Acc : 0.883, Run Time : 13.90
INFO:root:2019-05-11 05:00:26, Epoch : 1, Step : 6736, Training Loss : 0.43368, Training Acc : 0.811, Run Time : 9.05
INFO:root:2019-05-11 05:01:16, Epoch : 1, Step : 6737, Training Loss : 0.17654, Training Acc : 0.922, Run Time : 50.64
INFO:root:2019-05-11 05:01:18, Epoch : 1, Step : 6738, Training Loss : 0.22605, Training Acc : 0.894, Run Time : 1.93
INFO:root:2019-05-11 05:01:18, Epoch : 1, Step : 6739, Training Loss : 0.19138, Training Acc : 0.922, Run Time : 0.39
INFO:root:2019-05-11 05:01:33, Epoch : 1, Step : 6740, Training Loss : 0.23603, Training Acc : 0.911, Run Time : 14.17
INFO:root:2019-05-11 05:01:34, Epoch : 1, Step : 6741, Training Loss : 0.35861, Training Acc : 0.844, Run Time : 1.15
INFO:root:2019-05-11 05:01:59, Epoch : 1, Step : 6742, Training Loss : 0.30061, Training Acc : 0.833, Run Time : 25.50
INFO:root:2019-05-11 05:02:06, Epoch : 1, Step : 6743, Training Loss : 0.30353, Training Acc : 0.856, Run Time : 7.19
INFO:root:2019-05-11 05:02:45, Epoch : 1, Step : 6744, Training Loss : 0.30182, Training Acc : 0.861, Run Time : 38.71
INFO:root:2019-05-11 05:03:00, Epoch : 1, Step : 6745, Training Loss : 0.34272, Training Acc : 0.828, Run Time : 14.84
INFO:root:2019-05-11 05:03:24, Epoch : 1, Step : 6746, Training Loss : 0.22894, Training Acc : 0.928, Run Time : 23.83
INFO:root:2019-05-11 05:03:26, Epoch : 1, Step : 6747, Training Loss : 0.11449, Training Acc : 0.967, Run Time : 2.34
INFO:root:2019-05-11 05:03:27, Epoch : 1, Step : 6748, Training Loss : 0.54252, Training Acc : 0.717, Run Time : 0.41
INFO:root:2019-05-11 05:03:27, Epoch : 1, Step : 6749, Training Loss : 0.19747, Training Acc : 0.911, Run Time : 0.68
INFO:root:2019-05-11 05:03:40, Epoch : 1, Step : 6750, Training Loss : 0.18063, Training Acc : 0.939, Run Time : 12.63
INFO:root:2019-05-11 05:03:42, Epoch : 1, Step : 6751, Training Loss : 0.14581, Training Acc : 0.933, Run Time : 1.85
INFO:root:2019-05-11 05:04:41, Epoch : 1, Step : 6752, Training Loss : 0.30615, Training Acc : 0.850, Run Time : 59.64
INFO:root:2019-05-11 05:04:55, Epoch : 1, Step : 6753, Training Loss : 0.24180, Training Acc : 0.911, Run Time : 13.24
INFO:root:2019-05-11 05:05:09, Epoch : 1, Step : 6754, Training Loss : 0.46443, Training Acc : 0.794, Run Time : 14.51
INFO:root:2019-05-11 05:05:18, Epoch : 1, Step : 6755, Training Loss : 0.12818, Training Acc : 0.978, Run Time : 8.36
INFO:root:2019-05-11 05:05:18, Epoch : 1, Step : 6756, Training Loss : 0.27239, Training Acc : 0.872, Run Time : 0.42
INFO:root:2019-05-11 05:05:41, Epoch : 1, Step : 6757, Training Loss : 0.21234, Training Acc : 0.906, Run Time : 23.12
INFO:root:2019-05-11 05:05:43, Epoch : 1, Step : 6758, Training Loss : 0.26408, Training Acc : 0.850, Run Time : 2.05
INFO:root:2019-05-11 05:05:44, Epoch : 1, Step : 6759, Training Loss : 0.41446, Training Acc : 0.800, Run Time : 0.41
INFO:root:2019-05-11 05:05:45, Epoch : 1, Step : 6760, Training Loss : 0.21914, Training Acc : 0.917, Run Time : 1.35
INFO:root:2019-05-11 05:06:25, Epoch : 1, Step : 6761, Training Loss : 0.30824, Training Acc : 0.856, Run Time : 39.85
INFO:root:2019-05-11 05:06:27, Epoch : 1, Step : 6762, Training Loss : 0.25076, Training Acc : 0.911, Run Time : 2.48
INFO:root:2019-05-11 05:06:28, Epoch : 1, Step : 6763, Training Loss : 0.30573, Training Acc : 0.850, Run Time : 0.38
INFO:root:2019-05-11 05:06:29, Epoch : 1, Step : 6764, Training Loss : 0.21215, Training Acc : 0.922, Run Time : 1.34
INFO:root:2019-05-11 05:06:53, Epoch : 1, Step : 6765, Training Loss : 0.22758, Training Acc : 0.917, Run Time : 24.06
INFO:root:2019-05-11 05:06:55, Epoch : 1, Step : 6766, Training Loss : 0.31596, Training Acc : 0.844, Run Time : 1.59
INFO:root:2019-05-11 05:06:55, Epoch : 1, Step : 6767, Training Loss : 0.32902, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-11 05:06:56, Epoch : 1, Step : 6768, Training Loss : 0.23223, Training Acc : 0.889, Run Time : 1.12
INFO:root:2019-05-11 05:07:08, Epoch : 1, Step : 6769, Training Loss : 0.29864, Training Acc : 0.861, Run Time : 12.01
INFO:root:2019-05-11 05:07:09, Epoch : 1, Step : 6770, Training Loss : 0.49373, Training Acc : 0.767, Run Time : 0.81
INFO:root:2019-05-11 05:07:57, Epoch : 1, Step : 6771, Training Loss : 0.33563, Training Acc : 0.844, Run Time : 47.99
INFO:root:2019-05-11 05:08:12, Epoch : 1, Step : 6772, Training Loss : 0.20706, Training Acc : 0.911, Run Time : 15.13
INFO:root:2019-05-11 05:08:30, Epoch : 1, Step : 6773, Training Loss : 0.21063, Training Acc : 0.883, Run Time : 18.18
INFO:root:2019-05-11 05:08:46, Epoch : 1, Step : 6774, Training Loss : 0.25675, Training Acc : 0.867, Run Time : 16.13
INFO:root:2019-05-11 05:08:56, Epoch : 1, Step : 6775, Training Loss : 0.19739, Training Acc : 0.922, Run Time : 9.65
INFO:root:2019-05-11 05:09:22, Epoch : 1, Step : 6776, Training Loss : 0.19213, Training Acc : 0.917, Run Time : 25.94
INFO:root:2019-05-11 05:09:34, Epoch : 1, Step : 6777, Training Loss : 0.23774, Training Acc : 0.889, Run Time : 12.29
INFO:root:2019-05-11 05:09:46, Epoch : 1, Step : 6778, Training Loss : 0.30177, Training Acc : 0.861, Run Time : 12.30
INFO:root:2019-05-11 05:10:00, Epoch : 1, Step : 6779, Training Loss : 0.23000, Training Acc : 0.922, Run Time : 13.85
INFO:root:2019-05-11 05:10:17, Epoch : 1, Step : 6780, Training Loss : 0.29959, Training Acc : 0.861, Run Time : 16.81
INFO:root:2019-05-11 05:10:31, Epoch : 1, Step : 6781, Training Loss : 0.31867, Training Acc : 0.861, Run Time : 13.89
INFO:root:2019-05-11 05:11:25, Epoch : 1, Step : 6782, Training Loss : 0.12292, Training Acc : 0.972, Run Time : 54.09
INFO:root:2019-05-11 05:11:27, Epoch : 1, Step : 6783, Training Loss : 0.21826, Training Acc : 0.933, Run Time : 1.62
INFO:root:2019-05-11 05:11:27, Epoch : 1, Step : 6784, Training Loss : 0.39470, Training Acc : 0.839, Run Time : 0.43
INFO:root:2019-05-11 05:11:55, Epoch : 1, Step : 6785, Training Loss : 0.22651, Training Acc : 0.906, Run Time : 27.59
INFO:root:2019-05-11 05:12:02, Epoch : 1, Step : 6786, Training Loss : 0.45898, Training Acc : 0.872, Run Time : 7.26
INFO:root:2019-05-11 05:12:13, Epoch : 1, Step : 6787, Training Loss : 1.11481, Training Acc : 0.544, Run Time : 11.40
INFO:root:2019-05-11 05:12:14, Epoch : 1, Step : 6788, Training Loss : 0.91124, Training Acc : 0.678, Run Time : 0.74
INFO:root:2019-05-11 05:12:16, Epoch : 1, Step : 6789, Training Loss : 0.76540, Training Acc : 0.672, Run Time : 1.69
INFO:root:2019-05-11 05:12:29, Epoch : 1, Step : 6790, Training Loss : 0.92374, Training Acc : 0.578, Run Time : 12.99
INFO:root:2019-05-11 05:12:32, Epoch : 1, Step : 6791, Training Loss : 0.45825, Training Acc : 0.828, Run Time : 2.86
INFO:root:2019-05-11 05:13:19, Epoch : 1, Step : 6792, Training Loss : 0.28138, Training Acc : 0.889, Run Time : 47.67
INFO:root:2019-05-11 05:13:22, Epoch : 1, Step : 6793, Training Loss : 0.28022, Training Acc : 0.867, Run Time : 2.26
INFO:root:2019-05-11 05:13:22, Epoch : 1, Step : 6794, Training Loss : 0.38037, Training Acc : 0.800, Run Time : 0.38
INFO:root:2019-05-11 05:13:51, Epoch : 1, Step : 6795, Training Loss : 0.38849, Training Acc : 0.839, Run Time : 28.69
INFO:root:2019-05-11 05:13:52, Epoch : 1, Step : 6796, Training Loss : 0.36011, Training Acc : 0.800, Run Time : 1.72
INFO:root:2019-05-11 05:13:53, Epoch : 1, Step : 6797, Training Loss : 0.36355, Training Acc : 0.839, Run Time : 0.47
INFO:root:2019-05-11 05:13:54, Epoch : 1, Step : 6798, Training Loss : 0.29900, Training Acc : 0.867, Run Time : 1.24
INFO:root:2019-05-11 05:14:04, Epoch : 1, Step : 6799, Training Loss : 0.72487, Training Acc : 0.700, Run Time : 9.65
INFO:root:2019-05-11 05:14:04, Epoch : 1, Step : 6800, Training Loss : 0.67653, Training Acc : 0.772, Run Time : 0.53
INFO:root:2019-05-11 05:14:19, Epoch : 1, Step : 6801, Training Loss : 1.58629, Training Acc : 0.422, Run Time : 15.00
INFO:root:2019-05-11 05:14:21, Epoch : 1, Step : 6802, Training Loss : 1.16496, Training Acc : 0.528, Run Time : 1.90
INFO:root:2019-05-11 05:14:48, Epoch : 1, Step : 6803, Training Loss : 1.06208, Training Acc : 0.572, Run Time : 27.03
INFO:root:2019-05-11 05:15:26, Epoch : 1, Step : 6804, Training Loss : 0.92920, Training Acc : 0.628, Run Time : 37.50
INFO:root:2019-05-11 05:15:32, Epoch : 1, Step : 6805, Training Loss : 0.65699, Training Acc : 0.706, Run Time : 6.54
INFO:root:2019-05-11 05:15:33, Epoch : 1, Step : 6806, Training Loss : 0.39104, Training Acc : 0.833, Run Time : 0.41
INFO:root:2019-05-11 05:15:35, Epoch : 1, Step : 6807, Training Loss : 0.38126, Training Acc : 0.856, Run Time : 2.02
INFO:root:2019-05-11 05:15:53, Epoch : 1, Step : 6808, Training Loss : 0.22252, Training Acc : 0.922, Run Time : 18.62
INFO:root:2019-05-11 05:16:38, Epoch : 1, Step : 6809, Training Loss : 0.24206, Training Acc : 0.917, Run Time : 44.84
INFO:root:2019-05-11 05:16:40, Epoch : 1, Step : 6810, Training Loss : 0.20239, Training Acc : 0.933, Run Time : 2.03
INFO:root:2019-05-11 05:16:41, Epoch : 1, Step : 6811, Training Loss : 0.20771, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 05:16:42, Epoch : 1, Step : 6812, Training Loss : 0.28195, Training Acc : 0.917, Run Time : 1.02
INFO:root:2019-05-11 05:16:52, Epoch : 1, Step : 6813, Training Loss : 0.24118, Training Acc : 0.911, Run Time : 10.05
INFO:root:2019-05-11 05:16:53, Epoch : 1, Step : 6814, Training Loss : 0.22107, Training Acc : 0.928, Run Time : 1.02
INFO:root:2019-05-11 05:17:30, Epoch : 1, Step : 6815, Training Loss : 0.20165, Training Acc : 0.922, Run Time : 37.41
INFO:root:2019-05-11 05:17:40, Epoch : 1, Step : 6816, Training Loss : 0.19023, Training Acc : 0.922, Run Time : 9.45
INFO:root:2019-05-11 05:17:41, Epoch : 1, Step : 6817, Training Loss : 0.24188, Training Acc : 0.917, Run Time : 1.64
INFO:root:2019-05-11 05:18:04, Epoch : 1, Step : 6818, Training Loss : 0.18712, Training Acc : 0.928, Run Time : 23.09
INFO:root:2019-05-11 05:18:06, Epoch : 1, Step : 6819, Training Loss : 0.19758, Training Acc : 0.917, Run Time : 2.03
INFO:root:2019-05-11 05:18:07, Epoch : 1, Step : 6820, Training Loss : 0.17021, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 05:18:08, Epoch : 1, Step : 6821, Training Loss : 0.19247, Training Acc : 0.928, Run Time : 1.01
INFO:root:2019-05-11 05:18:19, Epoch : 1, Step : 6822, Training Loss : 0.20566, Training Acc : 0.917, Run Time : 11.03
INFO:root:2019-05-11 05:18:20, Epoch : 1, Step : 6823, Training Loss : 0.21848, Training Acc : 0.911, Run Time : 1.18
INFO:root:2019-05-11 05:18:32, Epoch : 1, Step : 6824, Training Loss : 0.16796, Training Acc : 0.922, Run Time : 12.27
INFO:root:2019-05-11 05:18:48, Epoch : 1, Step : 6825, Training Loss : 0.16288, Training Acc : 0.928, Run Time : 16.07
INFO:root:2019-05-11 05:18:50, Epoch : 1, Step : 6826, Training Loss : 0.18084, Training Acc : 0.922, Run Time : 1.71
INFO:root:2019-05-11 05:18:50, Epoch : 1, Step : 6827, Training Loss : 0.13132, Training Acc : 0.933, Run Time : 0.43
INFO:root:2019-05-11 05:18:51, Epoch : 1, Step : 6828, Training Loss : 0.15743, Training Acc : 0.922, Run Time : 0.77
INFO:root:2019-05-11 05:19:02, Epoch : 1, Step : 6829, Training Loss : 0.17431, Training Acc : 0.922, Run Time : 10.57
INFO:root:2019-05-11 05:19:03, Epoch : 1, Step : 6830, Training Loss : 0.13350, Training Acc : 0.944, Run Time : 1.24
INFO:root:2019-05-11 05:19:16, Epoch : 1, Step : 6831, Training Loss : 0.17765, Training Acc : 0.922, Run Time : 12.99
INFO:root:2019-05-11 05:19:16, Epoch : 1, Step : 6832, Training Loss : 0.13920, Training Acc : 0.944, Run Time : 0.52
INFO:root:2019-05-11 05:19:18, Epoch : 1, Step : 6833, Training Loss : 0.18031, Training Acc : 0.922, Run Time : 1.58
INFO:root:2019-05-11 05:19:29, Epoch : 1, Step : 6834, Training Loss : 0.28171, Training Acc : 0.878, Run Time : 10.68
INFO:root:2019-05-11 05:19:30, Epoch : 1, Step : 6835, Training Loss : 0.15872, Training Acc : 0.933, Run Time : 0.81
INFO:root:2019-05-11 05:19:32, Epoch : 1, Step : 6836, Training Loss : 0.15706, Training Acc : 0.933, Run Time : 2.00
INFO:root:2019-05-11 05:19:41, Epoch : 1, Step : 6837, Training Loss : 0.09662, Training Acc : 0.967, Run Time : 9.83
INFO:root:2019-05-11 05:19:42, Epoch : 1, Step : 6838, Training Loss : 0.12384, Training Acc : 0.939, Run Time : 0.95
INFO:root:2019-05-11 05:19:55, Epoch : 1, Step : 6839, Training Loss : 0.13259, Training Acc : 0.939, Run Time : 12.91
INFO:root:2019-05-11 05:19:58, Epoch : 1, Step : 6840, Training Loss : 0.11578, Training Acc : 0.961, Run Time : 2.46
INFO:root:2019-05-11 05:20:09, Epoch : 1, Step : 6841, Training Loss : 0.12233, Training Acc : 0.950, Run Time : 11.15
INFO:root:2019-05-11 05:20:09, Epoch : 1, Step : 6842, Training Loss : 0.12419, Training Acc : 0.950, Run Time : 0.60
INFO:root:2019-05-11 05:20:12, Epoch : 1, Step : 6843, Training Loss : 0.12813, Training Acc : 0.950, Run Time : 2.05
INFO:root:2019-05-11 05:20:26, Epoch : 1, Step : 6844, Training Loss : 0.11914, Training Acc : 0.967, Run Time : 14.89
INFO:root:2019-05-11 05:20:29, Epoch : 1, Step : 6845, Training Loss : 0.10282, Training Acc : 0.950, Run Time : 2.28
INFO:root:2019-05-11 05:20:41, Epoch : 1, Step : 6846, Training Loss : 0.11018, Training Acc : 0.956, Run Time : 12.51
INFO:root:2019-05-11 05:20:44, Epoch : 1, Step : 6847, Training Loss : 0.10115, Training Acc : 0.967, Run Time : 2.58
INFO:root:2019-05-11 05:20:54, Epoch : 1, Step : 6848, Training Loss : 0.11434, Training Acc : 0.956, Run Time : 10.11
INFO:root:2019-05-11 05:20:56, Epoch : 1, Step : 6849, Training Loss : 0.10136, Training Acc : 0.967, Run Time : 2.25
INFO:root:2019-05-11 05:21:07, Epoch : 1, Step : 6850, Training Loss : 0.10078, Training Acc : 0.967, Run Time : 11.08
INFO:root:2019-05-11 05:21:08, Epoch : 1, Step : 6851, Training Loss : 0.12958, Training Acc : 0.944, Run Time : 0.85
INFO:root:2019-05-11 05:21:10, Epoch : 1, Step : 6852, Training Loss : 0.11935, Training Acc : 0.972, Run Time : 1.56
INFO:root:2019-05-11 05:21:29, Epoch : 1, Step : 6853, Training Loss : 0.10127, Training Acc : 0.978, Run Time : 18.98
INFO:root:2019-05-11 05:21:31, Epoch : 1, Step : 6854, Training Loss : 0.08651, Training Acc : 0.972, Run Time : 2.01
INFO:root:2019-05-11 05:21:32, Epoch : 1, Step : 6855, Training Loss : 0.14767, Training Acc : 0.939, Run Time : 1.34
INFO:root:2019-05-11 05:21:56, Epoch : 1, Step : 6856, Training Loss : 0.11484, Training Acc : 0.944, Run Time : 23.96
INFO:root:2019-05-11 05:22:12, Epoch : 1, Step : 6857, Training Loss : 0.10089, Training Acc : 0.967, Run Time : 16.29
INFO:root:2019-05-11 05:22:31, Epoch : 1, Step : 6858, Training Loss : 0.09601, Training Acc : 0.967, Run Time : 18.90
INFO:root:2019-05-11 05:22:33, Epoch : 1, Step : 6859, Training Loss : 0.08757, Training Acc : 0.972, Run Time : 1.71
INFO:root:2019-05-11 05:22:33, Epoch : 1, Step : 6860, Training Loss : 0.08541, Training Acc : 0.983, Run Time : 0.39
INFO:root:2019-05-11 05:22:37, Epoch : 1, Step : 6861, Training Loss : 0.11936, Training Acc : 0.944, Run Time : 4.16
INFO:root:2019-05-11 05:22:51, Epoch : 1, Step : 6862, Training Loss : 0.11664, Training Acc : 0.967, Run Time : 13.35
INFO:root:2019-05-11 05:23:11, Epoch : 1, Step : 6863, Training Loss : 0.09171, Training Acc : 0.967, Run Time : 20.39
INFO:root:2019-05-11 05:23:13, Epoch : 1, Step : 6864, Training Loss : 0.09947, Training Acc : 0.961, Run Time : 2.37
INFO:root:2019-05-11 05:23:14, Epoch : 1, Step : 6865, Training Loss : 0.10236, Training Acc : 0.961, Run Time : 0.72
INFO:root:2019-05-11 05:23:31, Epoch : 1, Step : 6866, Training Loss : 0.11914, Training Acc : 0.944, Run Time : 16.46
INFO:root:2019-05-11 05:23:39, Epoch : 1, Step : 6867, Training Loss : 0.10861, Training Acc : 0.944, Run Time : 8.33
INFO:root:2019-05-11 05:23:41, Epoch : 1, Step : 6868, Training Loss : 0.10312, Training Acc : 0.961, Run Time : 1.70
INFO:root:2019-05-11 05:24:00, Epoch : 1, Step : 6869, Training Loss : 0.09830, Training Acc : 0.961, Run Time : 19.08
INFO:root:2019-05-11 05:24:11, Epoch : 1, Step : 6870, Training Loss : 0.09463, Training Acc : 0.961, Run Time : 10.99
INFO:root:2019-05-11 05:24:25, Epoch : 1, Step : 6871, Training Loss : 0.11473, Training Acc : 0.939, Run Time : 14.56
INFO:root:2019-05-11 05:24:27, Epoch : 1, Step : 6872, Training Loss : 0.10591, Training Acc : 0.950, Run Time : 1.40
INFO:root:2019-05-11 05:24:27, Epoch : 1, Step : 6873, Training Loss : 0.10579, Training Acc : 0.967, Run Time : 0.58
INFO:root:2019-05-11 05:24:41, Epoch : 1, Step : 6874, Training Loss : 0.08313, Training Acc : 0.978, Run Time : 13.53
INFO:root:2019-05-11 05:25:06, Epoch : 1, Step : 6875, Training Loss : 0.11042, Training Acc : 0.950, Run Time : 24.91
INFO:root:2019-05-11 05:25:08, Epoch : 1, Step : 6876, Training Loss : 0.11144, Training Acc : 0.961, Run Time : 2.51
INFO:root:2019-05-11 05:25:09, Epoch : 1, Step : 6877, Training Loss : 0.07247, Training Acc : 0.978, Run Time : 0.40
INFO:root:2019-05-11 05:25:09, Epoch : 1, Step : 6878, Training Loss : 0.09327, Training Acc : 0.956, Run Time : 0.77
INFO:root:2019-05-11 05:25:22, Epoch : 1, Step : 6879, Training Loss : 0.09133, Training Acc : 0.956, Run Time : 12.15
INFO:root:2019-05-11 05:25:22, Epoch : 1, Step : 6880, Training Loss : 0.08445, Training Acc : 0.972, Run Time : 0.75
INFO:root:2019-05-11 05:25:23, Epoch : 1, Step : 6881, Training Loss : 0.10368, Training Acc : 0.961, Run Time : 0.75
INFO:root:2019-05-11 05:26:05, Epoch : 1, Step : 6882, Training Loss : 0.10420, Training Acc : 0.950, Run Time : 42.24
INFO:root:2019-05-11 05:26:11, Epoch : 1, Step : 6883, Training Loss : 0.08862, Training Acc : 0.967, Run Time : 5.61
INFO:root:2019-05-11 05:26:26, Epoch : 1, Step : 6884, Training Loss : 0.09022, Training Acc : 0.972, Run Time : 15.36
INFO:root:2019-05-11 05:26:28, Epoch : 1, Step : 6885, Training Loss : 0.08019, Training Acc : 0.972, Run Time : 1.35
INFO:root:2019-05-11 05:26:28, Epoch : 1, Step : 6886, Training Loss : 0.08589, Training Acc : 0.967, Run Time : 0.46
INFO:root:2019-05-11 05:26:29, Epoch : 1, Step : 6887, Training Loss : 0.10734, Training Acc : 0.950, Run Time : 1.37
INFO:root:2019-05-11 05:26:41, Epoch : 1, Step : 6888, Training Loss : 0.11979, Training Acc : 0.922, Run Time : 11.58
INFO:root:2019-05-11 05:26:42, Epoch : 1, Step : 6889, Training Loss : 0.08963, Training Acc : 0.956, Run Time : 0.95
INFO:root:2019-05-11 05:26:54, Epoch : 1, Step : 6890, Training Loss : 0.15709, Training Acc : 0.961, Run Time : 11.54
INFO:root:2019-05-11 05:26:54, Epoch : 1, Step : 6891, Training Loss : 0.28751, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-11 05:26:54, Epoch : 1, Step : 6892, Training Loss : 0.32740, Training Acc : 0.894, Run Time : 0.38
INFO:root:2019-05-11 05:26:56, Epoch : 1, Step : 6893, Training Loss : 0.17441, Training Acc : 0.933, Run Time : 1.73
INFO:root:2019-05-11 05:27:10, Epoch : 1, Step : 6894, Training Loss : 0.13749, Training Acc : 0.939, Run Time : 13.87
INFO:root:2019-05-11 05:27:12, Epoch : 1, Step : 6895, Training Loss : 0.26679, Training Acc : 0.878, Run Time : 1.56
INFO:root:2019-05-11 05:27:25, Epoch : 1, Step : 6896, Training Loss : 0.22276, Training Acc : 0.917, Run Time : 12.99
INFO:root:2019-05-11 05:27:25, Epoch : 1, Step : 6897, Training Loss : 0.23171, Training Acc : 0.906, Run Time : 0.96
INFO:root:2019-05-11 05:27:48, Epoch : 1, Step : 6898, Training Loss : 0.24354, Training Acc : 0.911, Run Time : 22.13
INFO:root:2019-05-11 05:27:49, Epoch : 1, Step : 6899, Training Loss : 0.14146, Training Acc : 0.922, Run Time : 1.16
INFO:root:2019-05-11 05:27:50, Epoch : 1, Step : 6900, Training Loss : 0.18925, Training Acc : 0.933, Run Time : 1.22
INFO:root:2019-05-11 05:28:41, Epoch : 1, Step : 6901, Training Loss : 0.13477, Training Acc : 0.950, Run Time : 50.86
INFO:root:2019-05-11 05:28:43, Epoch : 1, Step : 6902, Training Loss : 0.10652, Training Acc : 0.944, Run Time : 2.22
INFO:root:2019-05-11 05:28:45, Epoch : 1, Step : 6903, Training Loss : 0.15001, Training Acc : 0.933, Run Time : 1.89
INFO:root:2019-05-11 05:28:56, Epoch : 1, Step : 6904, Training Loss : 0.12001, Training Acc : 0.944, Run Time : 11.22
INFO:root:2019-05-11 05:28:57, Epoch : 1, Step : 6905, Training Loss : 0.20648, Training Acc : 0.911, Run Time : 0.61
INFO:root:2019-05-11 05:28:57, Epoch : 1, Step : 6906, Training Loss : 0.46556, Training Acc : 0.850, Run Time : 0.44
INFO:root:2019-05-11 05:29:11, Epoch : 1, Step : 6907, Training Loss : 0.57076, Training Acc : 0.833, Run Time : 14.15
INFO:root:2019-05-11 05:29:18, Epoch : 1, Step : 6908, Training Loss : 0.49446, Training Acc : 0.794, Run Time : 6.17
INFO:root:2019-05-11 05:29:46, Epoch : 1, Step : 6909, Training Loss : 0.52275, Training Acc : 0.811, Run Time : 28.13
INFO:root:2019-05-11 05:30:03, Epoch : 1, Step : 6910, Training Loss : 0.64307, Training Acc : 0.783, Run Time : 17.73
INFO:root:2019-05-11 05:30:29, Epoch : 1, Step : 6911, Training Loss : 0.49824, Training Acc : 0.844, Run Time : 25.84
INFO:root:2019-05-11 05:31:39, Epoch : 1, Step : 6912, Training Loss : 0.32075, Training Acc : 0.883, Run Time : 69.47
INFO:root:2019-05-11 05:31:45, Epoch : 1, Step : 6913, Training Loss : 0.38728, Training Acc : 0.833, Run Time : 6.42
INFO:root:2019-05-11 05:31:46, Epoch : 1, Step : 6914, Training Loss : 0.37093, Training Acc : 0.844, Run Time : 0.73
INFO:root:2019-05-11 05:32:03, Epoch : 1, Step : 6915, Training Loss : 0.35292, Training Acc : 0.822, Run Time : 17.59
INFO:root:2019-05-11 05:32:38, Epoch : 1, Step : 6916, Training Loss : 0.37799, Training Acc : 0.844, Run Time : 34.64
INFO:root:2019-05-11 05:32:44, Epoch : 1, Step : 6917, Training Loss : 0.26709, Training Acc : 0.872, Run Time : 6.06
INFO:root:2019-05-11 05:32:45, Epoch : 1, Step : 6918, Training Loss : 0.32007, Training Acc : 0.811, Run Time : 0.46
INFO:root:2019-05-11 05:33:03, Epoch : 1, Step : 6919, Training Loss : 0.32355, Training Acc : 0.867, Run Time : 18.35
INFO:root:2019-05-11 05:33:06, Epoch : 1, Step : 6920, Training Loss : 0.30319, Training Acc : 0.867, Run Time : 2.73
INFO:root:2019-05-11 05:33:30, Epoch : 1, Step : 6921, Training Loss : 0.41773, Training Acc : 0.778, Run Time : 23.92
INFO:root:2019-05-11 05:33:46, Epoch : 1, Step : 6922, Training Loss : 0.33358, Training Acc : 0.878, Run Time : 16.38
INFO:root:2019-05-11 05:33:47, Epoch : 1, Step : 6923, Training Loss : 0.41596, Training Acc : 0.833, Run Time : 0.88
INFO:root:2019-05-11 05:33:54, Epoch : 1, Step : 6924, Training Loss : 0.41613, Training Acc : 0.772, Run Time : 6.83
INFO:root:2019-05-11 05:34:01, Epoch : 1, Step : 6925, Training Loss : 0.33065, Training Acc : 0.861, Run Time : 7.61
INFO:root:2019-05-11 05:34:02, Epoch : 1, Step : 6926, Training Loss : 0.38770, Training Acc : 0.833, Run Time : 0.81
INFO:root:2019-05-11 05:34:04, Epoch : 1, Step : 6927, Training Loss : 0.32275, Training Acc : 0.828, Run Time : 1.90
INFO:root:2019-05-11 05:34:35, Epoch : 1, Step : 6928, Training Loss : 0.40194, Training Acc : 0.839, Run Time : 31.43
INFO:root:2019-05-11 05:34:48, Epoch : 1, Step : 6929, Training Loss : 0.35681, Training Acc : 0.844, Run Time : 13.00
INFO:root:2019-05-11 05:35:03, Epoch : 1, Step : 6930, Training Loss : 0.19500, Training Acc : 0.939, Run Time : 14.32
INFO:root:2019-05-11 05:35:18, Epoch : 1, Step : 6931, Training Loss : 0.32578, Training Acc : 0.883, Run Time : 14.93
INFO:root:2019-05-11 05:35:31, Epoch : 1, Step : 6932, Training Loss : 0.39354, Training Acc : 0.783, Run Time : 13.54
INFO:root:2019-05-11 05:35:49, Epoch : 1, Step : 6933, Training Loss : 0.26310, Training Acc : 0.872, Run Time : 17.82
INFO:root:2019-05-11 05:35:51, Epoch : 1, Step : 6934, Training Loss : 0.47350, Training Acc : 0.789, Run Time : 1.62
INFO:root:2019-05-11 05:35:51, Epoch : 1, Step : 6935, Training Loss : 0.52116, Training Acc : 0.783, Run Time : 0.43
INFO:root:2019-05-11 05:35:52, Epoch : 1, Step : 6936, Training Loss : 0.34857, Training Acc : 0.856, Run Time : 1.19
INFO:root:2019-05-11 05:36:19, Epoch : 1, Step : 6937, Training Loss : 0.48123, Training Acc : 0.772, Run Time : 26.86
INFO:root:2019-05-11 05:36:33, Epoch : 1, Step : 6938, Training Loss : 0.36415, Training Acc : 0.800, Run Time : 13.63
INFO:root:2019-05-11 05:36:45, Epoch : 1, Step : 6939, Training Loss : 0.27809, Training Acc : 0.889, Run Time : 12.34
INFO:root:2019-05-11 05:36:54, Epoch : 1, Step : 6940, Training Loss : 0.49413, Training Acc : 0.789, Run Time : 8.93
INFO:root:2019-05-11 05:37:14, Epoch : 1, Step : 6941, Training Loss : 0.25236, Training Acc : 0.883, Run Time : 20.32
INFO:root:2019-05-11 05:37:46, Epoch : 1, Step : 6942, Training Loss : 0.41142, Training Acc : 0.783, Run Time : 31.57
INFO:root:2019-05-11 05:37:52, Epoch : 1, Step : 6943, Training Loss : 0.38996, Training Acc : 0.822, Run Time : 6.12
INFO:root:2019-05-11 05:37:53, Epoch : 1, Step : 6944, Training Loss : 0.28101, Training Acc : 0.833, Run Time : 0.77
INFO:root:2019-05-11 05:38:05, Epoch : 1, Step : 6945, Training Loss : 0.31536, Training Acc : 0.856, Run Time : 12.13
INFO:root:2019-05-11 05:38:05, Epoch : 1, Step : 6946, Training Loss : 0.42323, Training Acc : 0.783, Run Time : 0.47
INFO:root:2019-05-11 05:38:08, Epoch : 1, Step : 6947, Training Loss : 0.33687, Training Acc : 0.817, Run Time : 2.69
INFO:root:2019-05-11 05:38:20, Epoch : 1, Step : 6948, Training Loss : 0.30147, Training Acc : 0.844, Run Time : 12.27
INFO:root:2019-05-11 05:38:21, Epoch : 1, Step : 6949, Training Loss : 0.43748, Training Acc : 0.772, Run Time : 0.43
INFO:root:2019-05-11 05:38:21, Epoch : 1, Step : 6950, Training Loss : 0.38830, Training Acc : 0.817, Run Time : 0.53
INFO:root:2019-05-11 05:38:35, Epoch : 1, Step : 6951, Training Loss : 0.28244, Training Acc : 0.839, Run Time : 14.14
INFO:root:2019-05-11 05:38:48, Epoch : 1, Step : 6952, Training Loss : 0.28078, Training Acc : 0.872, Run Time : 12.19
INFO:root:2019-05-11 05:38:55, Epoch : 1, Step : 6953, Training Loss : 0.36184, Training Acc : 0.794, Run Time : 7.58
INFO:root:2019-05-11 05:39:40, Epoch : 1, Step : 6954, Training Loss : 0.36958, Training Acc : 0.806, Run Time : 45.22
INFO:root:2019-05-11 05:39:48, Epoch : 1, Step : 6955, Training Loss : 0.28067, Training Acc : 0.872, Run Time : 7.16
INFO:root:2019-05-11 05:40:35, Epoch : 1, Step : 6956, Training Loss : 0.34928, Training Acc : 0.806, Run Time : 47.12
INFO:root:2019-05-11 05:41:14, Epoch : 1, Step : 6957, Training Loss : 0.49761, Training Acc : 0.711, Run Time : 39.24
INFO:root:2019-05-11 05:41:21, Epoch : 1, Step : 6958, Training Loss : 0.29081, Training Acc : 0.872, Run Time : 6.85
INFO:root:2019-05-11 05:41:53, Epoch : 1, Step : 6959, Training Loss : 0.38042, Training Acc : 0.806, Run Time : 32.59
INFO:root:2019-05-11 05:41:56, Epoch : 1, Step : 6960, Training Loss : 0.38906, Training Acc : 0.817, Run Time : 2.17
INFO:root:2019-05-11 05:41:57, Epoch : 1, Step : 6961, Training Loss : 0.27025, Training Acc : 0.867, Run Time : 1.61
INFO:root:2019-05-11 05:42:09, Epoch : 1, Step : 6962, Training Loss : 0.35856, Training Acc : 0.822, Run Time : 11.63
INFO:root:2019-05-11 05:42:33, Epoch : 1, Step : 6963, Training Loss : 0.46446, Training Acc : 0.761, Run Time : 24.42
INFO:root:2019-05-11 05:42:35, Epoch : 1, Step : 6964, Training Loss : 0.37601, Training Acc : 0.822, Run Time : 1.46
INFO:root:2019-05-11 05:42:35, Epoch : 1, Step : 6965, Training Loss : 0.26177, Training Acc : 0.900, Run Time : 0.54
INFO:root:2019-05-11 05:42:37, Epoch : 1, Step : 6966, Training Loss : 0.39593, Training Acc : 0.789, Run Time : 1.57
INFO:root:2019-05-11 05:42:55, Epoch : 1, Step : 6967, Training Loss : 0.41961, Training Acc : 0.789, Run Time : 17.96
INFO:root:2019-05-11 05:43:09, Epoch : 1, Step : 6968, Training Loss : 0.25647, Training Acc : 0.878, Run Time : 14.18
INFO:root:2019-05-11 05:43:20, Epoch : 1, Step : 6969, Training Loss : 0.52102, Training Acc : 0.711, Run Time : 10.94
INFO:root:2019-05-11 05:43:33, Epoch : 1, Step : 6970, Training Loss : 0.28195, Training Acc : 0.894, Run Time : 13.46
INFO:root:2019-05-11 05:43:34, Epoch : 1, Step : 6971, Training Loss : 0.43770, Training Acc : 0.733, Run Time : 1.01
INFO:root:2019-05-11 05:43:36, Epoch : 1, Step : 6972, Training Loss : 0.27854, Training Acc : 0.861, Run Time : 1.62
INFO:root:2019-05-11 05:43:53, Epoch : 1, Step : 6973, Training Loss : 0.35382, Training Acc : 0.839, Run Time : 17.38
INFO:root:2019-05-11 05:43:55, Epoch : 1, Step : 6974, Training Loss : 0.55123, Training Acc : 0.667, Run Time : 1.55
INFO:root:2019-05-11 05:43:55, Epoch : 1, Step : 6975, Training Loss : 0.41630, Training Acc : 0.789, Run Time : 0.43
INFO:root:2019-05-11 05:43:56, Epoch : 1, Step : 6976, Training Loss : 0.31528, Training Acc : 0.811, Run Time : 1.07
INFO:root:2019-05-11 05:44:06, Epoch : 1, Step : 6977, Training Loss : 0.31977, Training Acc : 0.844, Run Time : 9.27
INFO:root:2019-05-11 05:44:06, Epoch : 1, Step : 6978, Training Loss : 0.31763, Training Acc : 0.867, Run Time : 0.46
INFO:root:2019-05-11 05:44:07, Epoch : 1, Step : 6979, Training Loss : 0.44303, Training Acc : 0.739, Run Time : 0.39
INFO:root:2019-05-11 05:44:08, Epoch : 1, Step : 6980, Training Loss : 0.25718, Training Acc : 0.883, Run Time : 1.89
INFO:root:2019-05-11 05:44:20, Epoch : 1, Step : 6981, Training Loss : 0.49082, Training Acc : 0.711, Run Time : 11.55
INFO:root:2019-05-11 05:44:21, Epoch : 1, Step : 6982, Training Loss : 0.26980, Training Acc : 0.844, Run Time : 0.75
INFO:root:2019-05-11 05:44:23, Epoch : 1, Step : 6983, Training Loss : 0.36959, Training Acc : 0.761, Run Time : 2.41
INFO:root:2019-05-11 05:45:03, Epoch : 1, Step : 6984, Training Loss : 0.28431, Training Acc : 0.844, Run Time : 39.61
INFO:root:2019-05-11 05:45:11, Epoch : 1, Step : 6985, Training Loss : 0.34607, Training Acc : 0.794, Run Time : 8.25
INFO:root:2019-05-11 05:46:03, Epoch : 1, Step : 6986, Training Loss : 0.23374, Training Acc : 0.900, Run Time : 51.78
INFO:root:2019-05-11 05:46:10, Epoch : 1, Step : 6987, Training Loss : 0.28266, Training Acc : 0.867, Run Time : 7.21
INFO:root:2019-05-11 05:46:12, Epoch : 1, Step : 6988, Training Loss : 0.23654, Training Acc : 0.900, Run Time : 1.73
INFO:root:2019-05-11 05:46:22, Epoch : 1, Step : 6989, Training Loss : 0.38414, Training Acc : 0.789, Run Time : 10.13
INFO:root:2019-05-11 05:46:23, Epoch : 1, Step : 6990, Training Loss : 0.31442, Training Acc : 0.800, Run Time : 0.75
INFO:root:2019-05-11 05:46:24, Epoch : 1, Step : 6991, Training Loss : 0.28003, Training Acc : 0.872, Run Time : 1.59
INFO:root:2019-05-11 05:46:45, Epoch : 1, Step : 6992, Training Loss : 0.22926, Training Acc : 0.917, Run Time : 20.63
INFO:root:2019-05-11 05:46:47, Epoch : 1, Step : 6993, Training Loss : 0.30666, Training Acc : 0.861, Run Time : 1.67
INFO:root:2019-05-11 05:46:47, Epoch : 1, Step : 6994, Training Loss : 0.22597, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-11 05:46:49, Epoch : 1, Step : 6995, Training Loss : 0.24685, Training Acc : 0.894, Run Time : 1.77
INFO:root:2019-05-11 05:47:33, Epoch : 1, Step : 6996, Training Loss : 0.25271, Training Acc : 0.883, Run Time : 44.48
INFO:root:2019-05-11 05:47:57, Epoch : 1, Step : 6997, Training Loss : 0.36844, Training Acc : 0.833, Run Time : 23.58
INFO:root:2019-05-11 05:48:04, Epoch : 1, Step : 6998, Training Loss : 0.28375, Training Acc : 0.867, Run Time : 6.73
INFO:root:2019-05-11 05:48:04, Epoch : 1, Step : 6999, Training Loss : 0.36487, Training Acc : 0.811, Run Time : 0.57
INFO:root:2019-05-11 05:48:37, Epoch : 1, Step : 7000, Training Loss : 0.36114, Training Acc : 0.822, Run Time : 32.64
INFO:root:2019-05-11 05:49:04, Epoch : 1, Step : 7001, Training Loss : 0.87734, Training Acc : 0.628, Run Time : 27.74
INFO:root:2019-05-11 05:49:06, Epoch : 1, Step : 7002, Training Loss : 0.79124, Training Acc : 0.706, Run Time : 1.94
INFO:root:2019-05-11 05:49:07, Epoch : 1, Step : 7003, Training Loss : 0.60147, Training Acc : 0.778, Run Time : 0.39
INFO:root:2019-05-11 05:49:08, Epoch : 1, Step : 7004, Training Loss : 0.88558, Training Acc : 0.622, Run Time : 1.39
INFO:root:2019-05-11 05:49:30, Epoch : 1, Step : 7005, Training Loss : 0.51081, Training Acc : 0.711, Run Time : 21.75
INFO:root:2019-05-11 05:49:33, Epoch : 1, Step : 7006, Training Loss : 0.38080, Training Acc : 0.806, Run Time : 2.97
INFO:root:2019-05-11 05:49:33, Epoch : 1, Step : 7007, Training Loss : 0.37417, Training Acc : 0.817, Run Time : 0.43
INFO:root:2019-05-11 05:50:49, Epoch : 1, Step : 7008, Training Loss : 0.34934, Training Acc : 0.839, Run Time : 75.96
INFO:root:2019-05-11 05:51:32, Epoch : 1, Step : 7009, Training Loss : 0.53305, Training Acc : 0.750, Run Time : 42.32
INFO:root:2019-05-11 05:51:42, Epoch : 1, Step : 7010, Training Loss : 0.42969, Training Acc : 0.778, Run Time : 10.62
INFO:root:2019-05-11 05:51:44, Epoch : 1, Step : 7011, Training Loss : 0.44372, Training Acc : 0.789, Run Time : 1.33
INFO:root:2019-05-11 05:52:05, Epoch : 1, Step : 7012, Training Loss : 0.35197, Training Acc : 0.817, Run Time : 20.97
INFO:root:2019-05-11 05:52:49, Epoch : 1, Step : 7013, Training Loss : 0.60403, Training Acc : 0.744, Run Time : 44.92
INFO:root:2019-05-11 05:52:54, Epoch : 1, Step : 7014, Training Loss : 0.33088, Training Acc : 0.872, Run Time : 4.33
INFO:root:2019-05-11 05:52:54, Epoch : 1, Step : 7015, Training Loss : 0.60663, Training Acc : 0.778, Run Time : 0.38
INFO:root:2019-05-11 05:52:57, Epoch : 1, Step : 7016, Training Loss : 0.46019, Training Acc : 0.806, Run Time : 2.29
INFO:root:2019-05-11 05:53:07, Epoch : 1, Step : 7017, Training Loss : 0.51640, Training Acc : 0.817, Run Time : 10.59
INFO:root:2019-05-11 05:53:09, Epoch : 1, Step : 7018, Training Loss : 0.56219, Training Acc : 0.794, Run Time : 2.08
INFO:root:2019-05-11 05:53:22, Epoch : 1, Step : 7019, Training Loss : 0.51411, Training Acc : 0.761, Run Time : 12.64
INFO:root:2019-05-11 05:53:23, Epoch : 1, Step : 7020, Training Loss : 0.41545, Training Acc : 0.828, Run Time : 0.98
INFO:root:2019-05-11 05:53:25, Epoch : 1, Step : 7021, Training Loss : 0.44584, Training Acc : 0.794, Run Time : 1.91
INFO:root:2019-05-11 05:54:03, Epoch : 1, Step : 7022, Training Loss : 0.44900, Training Acc : 0.800, Run Time : 38.40
INFO:root:2019-05-11 05:54:16, Epoch : 1, Step : 7023, Training Loss : 0.39718, Training Acc : 0.811, Run Time : 12.67
INFO:root:2019-05-11 05:54:32, Epoch : 1, Step : 7024, Training Loss : 0.56902, Training Acc : 0.728, Run Time : 16.27
INFO:root:2019-05-11 05:55:06, Epoch : 1, Step : 7025, Training Loss : 0.56176, Training Acc : 0.733, Run Time : 33.90
INFO:root:2019-05-11 05:55:18, Epoch : 1, Step : 7026, Training Loss : 0.42018, Training Acc : 0.839, Run Time : 12.43
INFO:root:2019-05-11 05:55:46, Epoch : 1, Step : 7027, Training Loss : 0.46705, Training Acc : 0.806, Run Time : 27.19
INFO:root:2019-05-11 05:55:53, Epoch : 1, Step : 7028, Training Loss : 0.40734, Training Acc : 0.811, Run Time : 7.05
INFO:root:2019-05-11 05:56:28, Epoch : 1, Step : 7029, Training Loss : 0.20242, Training Acc : 0.933, Run Time : 34.89
INFO:root:2019-05-11 05:56:35, Epoch : 1, Step : 7030, Training Loss : 0.31356, Training Acc : 0.844, Run Time : 7.56
INFO:root:2019-05-11 05:56:54, Epoch : 1, Step : 7031, Training Loss : 0.40327, Training Acc : 0.800, Run Time : 18.80
INFO:root:2019-05-11 05:56:55, Epoch : 1, Step : 7032, Training Loss : 0.45602, Training Acc : 0.800, Run Time : 1.31
INFO:root:2019-05-11 05:57:49, Epoch : 1, Step : 7033, Training Loss : 0.34997, Training Acc : 0.800, Run Time : 53.66
INFO:root:2019-05-11 05:57:52, Epoch : 1, Step : 7034, Training Loss : 0.38857, Training Acc : 0.817, Run Time : 3.61
INFO:root:2019-05-11 05:58:04, Epoch : 1, Step : 7035, Training Loss : 0.45421, Training Acc : 0.756, Run Time : 11.57
INFO:root:2019-05-11 05:58:05, Epoch : 1, Step : 7036, Training Loss : 0.46694, Training Acc : 0.778, Run Time : 1.31
INFO:root:2019-05-11 05:58:17, Epoch : 1, Step : 7037, Training Loss : 0.42983, Training Acc : 0.811, Run Time : 11.77
INFO:root:2019-05-11 05:58:18, Epoch : 1, Step : 7038, Training Loss : 0.49676, Training Acc : 0.739, Run Time : 0.43
INFO:root:2019-05-11 05:58:18, Epoch : 1, Step : 7039, Training Loss : 0.40129, Training Acc : 0.811, Run Time : 0.41
INFO:root:2019-05-11 05:58:20, Epoch : 1, Step : 7040, Training Loss : 0.25887, Training Acc : 0.911, Run Time : 1.84
INFO:root:2019-05-11 05:59:11, Epoch : 1, Step : 7041, Training Loss : 0.38188, Training Acc : 0.806, Run Time : 51.22
INFO:root:2019-05-11 05:59:48, Epoch : 1, Step : 7042, Training Loss : 0.21228, Training Acc : 0.917, Run Time : 37.23
INFO:root:2019-05-11 06:00:20, Epoch : 1, Step : 7043, Training Loss : 0.32749, Training Acc : 0.839, Run Time : 31.42
INFO:root:2019-05-11 06:00:28, Epoch : 1, Step : 7044, Training Loss : 0.49901, Training Acc : 0.739, Run Time : 8.61
INFO:root:2019-05-11 06:00:29, Epoch : 1, Step : 7045, Training Loss : 0.48587, Training Acc : 0.783, Run Time : 0.42
INFO:root:2019-05-11 06:00:31, Epoch : 1, Step : 7046, Training Loss : 0.41282, Training Acc : 0.778, Run Time : 1.88
INFO:root:2019-05-11 06:00:43, Epoch : 1, Step : 7047, Training Loss : 0.37852, Training Acc : 0.811, Run Time : 12.45
INFO:root:2019-05-11 06:00:44, Epoch : 1, Step : 7048, Training Loss : 0.30386, Training Acc : 0.867, Run Time : 0.83
INFO:root:2019-05-11 06:00:57, Epoch : 1, Step : 7049, Training Loss : 0.32492, Training Acc : 0.861, Run Time : 13.66
INFO:root:2019-05-11 06:01:00, Epoch : 1, Step : 7050, Training Loss : 0.26659, Training Acc : 0.900, Run Time : 2.36
INFO:root:2019-05-11 06:02:05, Epoch : 1, Step : 7051, Training Loss : 0.22928, Training Acc : 0.894, Run Time : 65.40
INFO:root:2019-05-11 06:02:27, Epoch : 1, Step : 7052, Training Loss : 0.27544, Training Acc : 0.889, Run Time : 21.62
INFO:root:2019-05-11 06:02:33, Epoch : 1, Step : 7053, Training Loss : 0.32840, Training Acc : 0.861, Run Time : 5.64
INFO:root:2019-05-11 06:02:33, Epoch : 1, Step : 7054, Training Loss : 0.33576, Training Acc : 0.850, Run Time : 0.44
INFO:root:2019-05-11 06:02:35, Epoch : 1, Step : 7055, Training Loss : 0.36659, Training Acc : 0.839, Run Time : 2.30
INFO:root:2019-05-11 06:03:14, Epoch : 1, Step : 7056, Training Loss : 0.46855, Training Acc : 0.783, Run Time : 39.02
INFO:root:2019-05-11 06:03:23, Epoch : 1, Step : 7057, Training Loss : 0.34208, Training Acc : 0.833, Run Time : 8.73
INFO:root:2019-05-11 06:03:46, Epoch : 1, Step : 7058, Training Loss : 0.23994, Training Acc : 0.917, Run Time : 23.29
INFO:root:2019-05-11 06:04:45, Epoch : 1, Step : 7059, Training Loss : 0.17537, Training Acc : 0.933, Run Time : 58.22
INFO:root:2019-05-11 06:04:54, Epoch : 1, Step : 7060, Training Loss : 0.30275, Training Acc : 0.900, Run Time : 9.77
INFO:root:2019-05-11 06:05:14, Epoch : 1, Step : 7061, Training Loss : 0.33482, Training Acc : 0.878, Run Time : 20.11
INFO:root:2019-05-11 06:05:46, Epoch : 1, Step : 7062, Training Loss : 0.25341, Training Acc : 0.906, Run Time : 31.38
INFO:root:2019-05-11 06:05:48, Epoch : 1, Step : 7063, Training Loss : 0.37255, Training Acc : 0.878, Run Time : 2.53
INFO:root:2019-05-11 06:05:51, Epoch : 1, Step : 7064, Training Loss : 0.39898, Training Acc : 0.878, Run Time : 2.36
INFO:root:2019-05-11 06:06:22, Epoch : 1, Step : 7065, Training Loss : 0.27655, Training Acc : 0.911, Run Time : 31.10
INFO:root:2019-05-11 06:06:24, Epoch : 1, Step : 7066, Training Loss : 0.16663, Training Acc : 0.944, Run Time : 2.20
INFO:root:2019-05-11 06:06:24, Epoch : 1, Step : 7067, Training Loss : 0.32390, Training Acc : 0.867, Run Time : 0.39
INFO:root:2019-05-11 06:07:32, Epoch : 1, Step : 7068, Training Loss : 0.27916, Training Acc : 0.922, Run Time : 67.39
INFO:root:2019-05-11 06:08:22, Epoch : 1, Step : 7069, Training Loss : 0.21748, Training Acc : 0.922, Run Time : 50.44
INFO:root:2019-05-11 06:08:29, Epoch : 1, Step : 7070, Training Loss : 0.12885, Training Acc : 0.950, Run Time : 6.47
INFO:root:2019-05-11 06:08:29, Epoch : 1, Step : 7071, Training Loss : 0.16321, Training Acc : 0.944, Run Time : 0.64
INFO:root:2019-05-11 06:08:31, Epoch : 1, Step : 7072, Training Loss : 0.14672, Training Acc : 0.956, Run Time : 2.09
INFO:root:2019-05-11 06:09:15, Epoch : 1, Step : 7073, Training Loss : 0.23076, Training Acc : 0.928, Run Time : 43.58
INFO:root:2019-05-11 06:09:30, Epoch : 1, Step : 7074, Training Loss : 0.18228, Training Acc : 0.933, Run Time : 15.16
INFO:root:2019-05-11 06:10:01, Epoch : 1, Step : 7075, Training Loss : 0.15076, Training Acc : 0.950, Run Time : 30.64
INFO:root:2019-05-11 06:10:13, Epoch : 1, Step : 7076, Training Loss : 0.19306, Training Acc : 0.939, Run Time : 12.69
INFO:root:2019-05-11 06:10:32, Epoch : 1, Step : 7077, Training Loss : 0.18505, Training Acc : 0.950, Run Time : 18.82
INFO:root:2019-05-11 06:10:45, Epoch : 1, Step : 7078, Training Loss : 0.19757, Training Acc : 0.956, Run Time : 12.71
INFO:root:2019-05-11 06:12:08, Epoch : 1, Step : 7079, Training Loss : 0.28823, Training Acc : 0.856, Run Time : 83.02
INFO:root:2019-05-11 06:13:00, Epoch : 1, Step : 7080, Training Loss : 0.24263, Training Acc : 0.894, Run Time : 51.66
INFO:root:2019-05-11 06:13:07, Epoch : 1, Step : 7081, Training Loss : 0.29646, Training Acc : 0.900, Run Time : 7.27
INFO:root:2019-05-11 06:13:08, Epoch : 1, Step : 7082, Training Loss : 0.15200, Training Acc : 0.956, Run Time : 0.63
INFO:root:2019-05-11 06:13:48, Epoch : 1, Step : 7083, Training Loss : 0.20118, Training Acc : 0.922, Run Time : 40.11
INFO:root:2019-05-11 06:14:22, Epoch : 1, Step : 7084, Training Loss : 0.28025, Training Acc : 0.861, Run Time : 34.05
INFO:root:2019-05-11 06:14:24, Epoch : 1, Step : 7085, Training Loss : 0.21947, Training Acc : 0.906, Run Time : 1.96
INFO:root:2019-05-11 06:14:24, Epoch : 1, Step : 7086, Training Loss : 0.39796, Training Acc : 0.817, Run Time : 0.44
INFO:root:2019-05-11 06:14:27, Epoch : 1, Step : 7087, Training Loss : 0.50851, Training Acc : 0.711, Run Time : 2.43
INFO:root:2019-05-11 06:15:39, Epoch : 1, Step : 7088, Training Loss : 0.23017, Training Acc : 0.894, Run Time : 72.77
INFO:root:2019-05-11 06:15:45, Epoch : 1, Step : 7089, Training Loss : 0.17332, Training Acc : 0.939, Run Time : 5.95
INFO:root:2019-05-11 06:15:46, Epoch : 1, Step : 7090, Training Loss : 0.18654, Training Acc : 0.950, Run Time : 0.77
INFO:root:2019-05-11 06:16:36, Epoch : 1, Step : 7091, Training Loss : 0.20945, Training Acc : 0.917, Run Time : 50.00
INFO:root:2019-05-11 06:16:43, Epoch : 1, Step : 7092, Training Loss : 0.25018, Training Acc : 0.906, Run Time : 6.49
INFO:root:2019-05-11 06:16:44, Epoch : 1, Step : 7093, Training Loss : 0.20679, Training Acc : 0.922, Run Time : 1.81
INFO:root:2019-05-11 06:16:58, Epoch : 1, Step : 7094, Training Loss : 0.16012, Training Acc : 0.922, Run Time : 13.63
INFO:root:2019-05-11 06:17:33, Epoch : 1, Step : 7095, Training Loss : 0.30428, Training Acc : 0.889, Run Time : 35.09
INFO:root:2019-05-11 06:17:47, Epoch : 1, Step : 7096, Training Loss : 0.16593, Training Acc : 0.944, Run Time : 14.12
INFO:root:2019-05-11 06:17:49, Epoch : 1, Step : 7097, Training Loss : 0.23211, Training Acc : 0.878, Run Time : 1.77
INFO:root:2019-05-11 06:18:08, Epoch : 1, Step : 7098, Training Loss : 0.20984, Training Acc : 0.928, Run Time : 19.25
INFO:root:2019-05-11 06:18:16, Epoch : 1, Step : 7099, Training Loss : 0.22519, Training Acc : 0.911, Run Time : 8.14
INFO:root:2019-05-11 06:18:58, Epoch : 1, Step : 7100, Training Loss : 0.29086, Training Acc : 0.861, Run Time : 41.43
INFO:root:2019-05-11 06:19:15, Epoch : 1, Step : 7101, Training Loss : 0.20033, Training Acc : 0.922, Run Time : 17.03
INFO:root:2019-05-11 06:19:16, Epoch : 1, Step : 7102, Training Loss : 0.31262, Training Acc : 0.856, Run Time : 1.06
INFO:root:2019-05-11 06:19:17, Epoch : 1, Step : 7103, Training Loss : 0.29140, Training Acc : 0.861, Run Time : 1.33
INFO:root:2019-05-11 06:19:34, Epoch : 1, Step : 7104, Training Loss : 0.45339, Training Acc : 0.806, Run Time : 17.23
INFO:root:2019-05-11 06:19:49, Epoch : 1, Step : 7105, Training Loss : 0.41591, Training Acc : 0.772, Run Time : 14.25
INFO:root:2019-05-11 06:19:59, Epoch : 1, Step : 7106, Training Loss : 0.33805, Training Acc : 0.833, Run Time : 10.40
INFO:root:2019-05-11 06:20:21, Epoch : 1, Step : 7107, Training Loss : 0.41937, Training Acc : 0.806, Run Time : 21.71
INFO:root:2019-05-11 06:20:22, Epoch : 1, Step : 7108, Training Loss : 0.31914, Training Acc : 0.856, Run Time : 1.63
INFO:root:2019-05-11 06:20:24, Epoch : 1, Step : 7109, Training Loss : 0.46615, Training Acc : 0.800, Run Time : 1.41
INFO:root:2019-05-11 06:20:34, Epoch : 1, Step : 7110, Training Loss : 0.42282, Training Acc : 0.806, Run Time : 9.76
INFO:root:2019-05-11 06:20:35, Epoch : 1, Step : 7111, Training Loss : 0.42980, Training Acc : 0.761, Run Time : 0.99
INFO:root:2019-05-11 06:20:50, Epoch : 1, Step : 7112, Training Loss : 0.24960, Training Acc : 0.883, Run Time : 15.03
INFO:root:2019-05-11 06:20:51, Epoch : 1, Step : 7113, Training Loss : 0.35301, Training Acc : 0.800, Run Time : 1.58
INFO:root:2019-05-11 06:21:09, Epoch : 1, Step : 7114, Training Loss : 0.28488, Training Acc : 0.856, Run Time : 17.47
INFO:root:2019-05-11 06:21:10, Epoch : 1, Step : 7115, Training Loss : 0.37691, Training Acc : 0.839, Run Time : 1.75
INFO:root:2019-05-11 06:21:11, Epoch : 1, Step : 7116, Training Loss : 0.33370, Training Acc : 0.844, Run Time : 0.38
INFO:root:2019-05-11 06:21:12, Epoch : 1, Step : 7117, Training Loss : 0.43958, Training Acc : 0.789, Run Time : 1.43
INFO:root:2019-05-11 06:22:08, Epoch : 1, Step : 7118, Training Loss : 0.22711, Training Acc : 0.900, Run Time : 55.40
INFO:root:2019-05-11 06:22:14, Epoch : 1, Step : 7119, Training Loss : 0.19840, Training Acc : 0.922, Run Time : 6.09
INFO:root:2019-05-11 06:22:14, Epoch : 1, Step : 7120, Training Loss : 0.21977, Training Acc : 0.944, Run Time : 0.59
INFO:root:2019-05-11 06:22:52, Epoch : 1, Step : 7121, Training Loss : 0.18400, Training Acc : 0.900, Run Time : 37.95
INFO:root:2019-05-11 06:22:59, Epoch : 1, Step : 7122, Training Loss : 0.19196, Training Acc : 0.939, Run Time : 7.09
INFO:root:2019-05-11 06:23:00, Epoch : 1, Step : 7123, Training Loss : 0.21643, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-11 06:23:20, Epoch : 1, Step : 7124, Training Loss : 0.17373, Training Acc : 0.933, Run Time : 19.71
INFO:root:2019-05-11 06:23:22, Epoch : 1, Step : 7125, Training Loss : 0.14737, Training Acc : 0.967, Run Time : 2.31
INFO:root:2019-05-11 06:23:23, Epoch : 1, Step : 7126, Training Loss : 0.39835, Training Acc : 0.850, Run Time : 1.42
INFO:root:2019-05-11 06:23:38, Epoch : 1, Step : 7127, Training Loss : 0.20903, Training Acc : 0.922, Run Time : 15.21
INFO:root:2019-05-11 06:23:54, Epoch : 1, Step : 7128, Training Loss : 0.27613, Training Acc : 0.900, Run Time : 15.32
INFO:root:2019-05-11 06:24:09, Epoch : 1, Step : 7129, Training Loss : 0.25923, Training Acc : 0.894, Run Time : 14.93
INFO:root:2019-05-11 06:24:48, Epoch : 1, Step : 7130, Training Loss : 0.39738, Training Acc : 0.800, Run Time : 39.35
INFO:root:2019-05-11 06:24:56, Epoch : 1, Step : 7131, Training Loss : 0.31480, Training Acc : 0.828, Run Time : 8.36
INFO:root:2019-05-11 06:25:29, Epoch : 1, Step : 7132, Training Loss : 0.27170, Training Acc : 0.906, Run Time : 32.87
INFO:root:2019-05-11 06:25:41, Epoch : 1, Step : 7133, Training Loss : 0.29783, Training Acc : 0.861, Run Time : 11.94
INFO:root:2019-05-11 06:26:01, Epoch : 1, Step : 7134, Training Loss : 0.24332, Training Acc : 0.900, Run Time : 20.08
INFO:root:2019-05-11 06:26:06, Epoch : 1, Step : 7135, Training Loss : 0.22696, Training Acc : 0.900, Run Time : 5.02
INFO:root:2019-05-11 06:26:08, Epoch : 1, Step : 7136, Training Loss : 0.17091, Training Acc : 0.906, Run Time : 1.62
INFO:root:2019-05-11 06:26:18, Epoch : 1, Step : 7137, Training Loss : 0.21383, Training Acc : 0.894, Run Time : 9.95
INFO:root:2019-05-11 06:26:18, Epoch : 1, Step : 7138, Training Loss : 0.25443, Training Acc : 0.861, Run Time : 0.54
INFO:root:2019-05-11 06:26:21, Epoch : 1, Step : 7139, Training Loss : 0.22688, Training Acc : 0.900, Run Time : 2.65
INFO:root:2019-05-11 06:26:38, Epoch : 1, Step : 7140, Training Loss : 0.39843, Training Acc : 0.811, Run Time : 16.49
INFO:root:2019-05-11 06:26:56, Epoch : 1, Step : 7141, Training Loss : 0.39771, Training Acc : 0.806, Run Time : 18.84
INFO:root:2019-05-11 06:27:23, Epoch : 1, Step : 7142, Training Loss : 0.16960, Training Acc : 0.922, Run Time : 26.77
INFO:root:2019-05-11 06:27:48, Epoch : 1, Step : 7143, Training Loss : 0.19637, Training Acc : 0.906, Run Time : 24.32
INFO:root:2019-05-11 06:27:56, Epoch : 1, Step : 7144, Training Loss : 0.13427, Training Acc : 0.944, Run Time : 8.91
INFO:root:2019-05-11 06:28:11, Epoch : 1, Step : 7145, Training Loss : 0.15347, Training Acc : 0.950, Run Time : 14.32
INFO:root:2019-05-11 06:28:12, Epoch : 1, Step : 7146, Training Loss : 0.21309, Training Acc : 0.900, Run Time : 1.62
INFO:root:2019-05-11 06:28:13, Epoch : 1, Step : 7147, Training Loss : 0.11814, Training Acc : 0.978, Run Time : 0.42
INFO:root:2019-05-11 06:28:14, Epoch : 1, Step : 7148, Training Loss : 0.30028, Training Acc : 0.872, Run Time : 1.27
INFO:root:2019-05-11 06:28:25, Epoch : 1, Step : 7149, Training Loss : 0.53925, Training Acc : 0.767, Run Time : 10.87
INFO:root:2019-05-11 06:28:27, Epoch : 1, Step : 7150, Training Loss : 0.31818, Training Acc : 0.850, Run Time : 1.60
INFO:root:2019-05-11 06:28:36, Epoch : 1, Step : 7151, Training Loss : 0.31760, Training Acc : 0.861, Run Time : 9.82
INFO:root:2019-05-11 06:28:38, Epoch : 1, Step : 7152, Training Loss : 0.43191, Training Acc : 0.783, Run Time : 1.33
INFO:root:2019-05-11 06:28:57, Epoch : 1, Step : 7153, Training Loss : 0.46548, Training Acc : 0.789, Run Time : 19.33
INFO:root:2019-05-11 06:28:59, Epoch : 1, Step : 7154, Training Loss : 0.48744, Training Acc : 0.783, Run Time : 1.64
INFO:root:2019-05-11 06:28:59, Epoch : 1, Step : 7155, Training Loss : 0.39202, Training Acc : 0.833, Run Time : 0.45
INFO:root:2019-05-11 06:29:10, Epoch : 1, Step : 7156, Training Loss : 0.69368, Training Acc : 0.733, Run Time : 10.73
INFO:root:2019-05-11 06:29:10, Epoch : 1, Step : 7157, Training Loss : 0.53594, Training Acc : 0.794, Run Time : 0.47
INFO:root:2019-05-11 06:29:11, Epoch : 1, Step : 7158, Training Loss : 0.36988, Training Acc : 0.811, Run Time : 0.42
INFO:root:2019-05-11 06:29:25, Epoch : 1, Step : 7159, Training Loss : 0.36922, Training Acc : 0.861, Run Time : 14.15
INFO:root:2019-05-11 06:29:37, Epoch : 1, Step : 7160, Training Loss : 0.46658, Training Acc : 0.789, Run Time : 12.55
INFO:root:2019-05-11 06:29:54, Epoch : 1, Step : 7161, Training Loss : 0.10698, Training Acc : 0.978, Run Time : 16.27
INFO:root:2019-05-11 06:29:54, Epoch : 1, Step : 7162, Training Loss : 0.31451, Training Acc : 0.861, Run Time : 0.51
INFO:root:2019-05-11 06:29:56, Epoch : 1, Step : 7163, Training Loss : 0.44165, Training Acc : 0.828, Run Time : 1.63
INFO:root:2019-05-11 06:30:06, Epoch : 1, Step : 7164, Training Loss : 0.26313, Training Acc : 0.928, Run Time : 10.45
INFO:root:2019-05-11 06:30:07, Epoch : 1, Step : 7165, Training Loss : 0.18199, Training Acc : 0.944, Run Time : 0.68
INFO:root:2019-05-11 06:30:18, Epoch : 1, Step : 7166, Training Loss : 0.20162, Training Acc : 0.911, Run Time : 11.37
INFO:root:2019-05-11 06:30:19, Epoch : 1, Step : 7167, Training Loss : 0.23194, Training Acc : 0.889, Run Time : 1.05
INFO:root:2019-05-11 06:30:38, Epoch : 1, Step : 7168, Training Loss : 0.19564, Training Acc : 0.911, Run Time : 18.27
INFO:root:2019-05-11 06:30:59, Epoch : 1, Step : 7169, Training Loss : 0.25047, Training Acc : 0.906, Run Time : 20.93
INFO:root:2019-05-11 06:31:07, Epoch : 1, Step : 7170, Training Loss : 0.18988, Training Acc : 0.917, Run Time : 8.14
INFO:root:2019-05-11 06:31:46, Epoch : 1, Step : 7171, Training Loss : 0.19463, Training Acc : 0.917, Run Time : 39.14
INFO:root:2019-05-11 06:31:52, Epoch : 1, Step : 7172, Training Loss : 0.11619, Training Acc : 0.961, Run Time : 6.33
INFO:root:2019-05-11 06:32:08, Epoch : 1, Step : 7173, Training Loss : 0.17060, Training Acc : 0.922, Run Time : 15.49
INFO:root:2019-05-11 06:32:09, Epoch : 1, Step : 7174, Training Loss : 0.13945, Training Acc : 0.950, Run Time : 1.55
INFO:root:2019-05-11 06:32:10, Epoch : 1, Step : 7175, Training Loss : 0.23849, Training Acc : 0.906, Run Time : 0.44
INFO:root:2019-05-11 06:32:11, Epoch : 1, Step : 7176, Training Loss : 0.15806, Training Acc : 0.928, Run Time : 1.41
INFO:root:2019-05-11 06:32:24, Epoch : 1, Step : 7177, Training Loss : 0.14825, Training Acc : 0.928, Run Time : 12.41
INFO:root:2019-05-11 06:32:24, Epoch : 1, Step : 7178, Training Loss : 0.12083, Training Acc : 0.978, Run Time : 0.84
INFO:root:2019-05-11 06:32:26, Epoch : 1, Step : 7179, Training Loss : 0.20090, Training Acc : 0.900, Run Time : 1.73
INFO:root:2019-05-11 06:33:23, Epoch : 1, Step : 7180, Training Loss : 0.14488, Training Acc : 0.967, Run Time : 56.78
INFO:root:2019-05-11 06:33:41, Epoch : 1, Step : 7181, Training Loss : 0.16461, Training Acc : 0.944, Run Time : 17.72
INFO:root:2019-05-11 06:33:45, Epoch : 1, Step : 7182, Training Loss : 0.13317, Training Acc : 0.956, Run Time : 4.47
INFO:root:2019-05-11 06:33:46, Epoch : 1, Step : 7183, Training Loss : 0.16120, Training Acc : 0.944, Run Time : 0.64
INFO:root:2019-05-11 06:33:48, Epoch : 1, Step : 7184, Training Loss : 0.12373, Training Acc : 0.972, Run Time : 1.86
INFO:root:2019-05-11 06:34:04, Epoch : 1, Step : 7185, Training Loss : 0.12843, Training Acc : 0.944, Run Time : 16.50
INFO:root:2019-05-11 06:34:06, Epoch : 1, Step : 7186, Training Loss : 0.13743, Training Acc : 0.922, Run Time : 1.92
INFO:root:2019-05-11 06:34:06, Epoch : 1, Step : 7187, Training Loss : 0.12670, Training Acc : 0.961, Run Time : 0.41
INFO:root:2019-05-11 06:34:19, Epoch : 1, Step : 7188, Training Loss : 0.14558, Training Acc : 0.950, Run Time : 13.07
INFO:root:2019-05-11 06:34:20, Epoch : 1, Step : 7189, Training Loss : 0.22679, Training Acc : 0.900, Run Time : 0.63
INFO:root:2019-05-11 06:34:20, Epoch : 1, Step : 7190, Training Loss : 0.41117, Training Acc : 0.806, Run Time : 0.38
INFO:root:2019-05-11 06:34:33, Epoch : 1, Step : 7191, Training Loss : 0.29023, Training Acc : 0.861, Run Time : 12.66
INFO:root:2019-05-11 06:34:35, Epoch : 1, Step : 7192, Training Loss : 0.50946, Training Acc : 0.733, Run Time : 1.82
INFO:root:2019-05-11 06:34:35, Epoch : 1, Step : 7193, Training Loss : 0.44418, Training Acc : 0.761, Run Time : 0.38
INFO:root:2019-05-11 06:34:52, Epoch : 1, Step : 7194, Training Loss : 0.42104, Training Acc : 0.811, Run Time : 17.18
INFO:root:2019-05-11 06:34:58, Epoch : 1, Step : 7195, Training Loss : 0.36240, Training Acc : 0.822, Run Time : 5.28
INFO:root:2019-05-11 06:34:58, Epoch : 1, Step : 7196, Training Loss : 0.34417, Training Acc : 0.856, Run Time : 0.45
INFO:root:2019-05-11 06:35:09, Epoch : 1, Step : 7197, Training Loss : 0.30178, Training Acc : 0.867, Run Time : 11.21
INFO:root:2019-05-11 06:35:10, Epoch : 1, Step : 7198, Training Loss : 0.42602, Training Acc : 0.789, Run Time : 0.43
INFO:root:2019-05-11 06:35:10, Epoch : 1, Step : 7199, Training Loss : 0.34448, Training Acc : 0.839, Run Time : 0.42
INFO:root:2019-05-11 06:35:12, Epoch : 1, Step : 7200, Training Loss : 0.30107, Training Acc : 0.861, Run Time : 1.95
INFO:root:2019-05-11 06:35:37, Epoch : 1, Step : 7201, Training Loss : 0.59984, Training Acc : 0.722, Run Time : 24.79
INFO:root:2019-05-11 06:36:03, Epoch : 1, Step : 7202, Training Loss : 0.75309, Training Acc : 0.689, Run Time : 26.22
INFO:root:2019-05-11 06:36:05, Epoch : 1, Step : 7203, Training Loss : 0.51515, Training Acc : 0.750, Run Time : 1.71
INFO:root:2019-05-11 06:36:06, Epoch : 1, Step : 7204, Training Loss : 0.61793, Training Acc : 0.706, Run Time : 0.63
INFO:root:2019-05-11 06:36:19, Epoch : 1, Step : 7205, Training Loss : 0.76311, Training Acc : 0.694, Run Time : 13.88
INFO:root:2019-05-11 06:36:49, Epoch : 1, Step : 7206, Training Loss : 0.42279, Training Acc : 0.817, Run Time : 29.33
INFO:root:2019-05-11 06:37:05, Epoch : 1, Step : 7207, Training Loss : 0.82843, Training Acc : 0.644, Run Time : 15.92
INFO:root:2019-05-11 06:37:19, Epoch : 1, Step : 7208, Training Loss : 0.51160, Training Acc : 0.789, Run Time : 14.35
INFO:root:2019-05-11 06:37:26, Epoch : 1, Step : 7209, Training Loss : 0.35968, Training Acc : 0.794, Run Time : 7.24
INFO:root:2019-05-11 06:37:29, Epoch : 1, Step : 7210, Training Loss : 0.29765, Training Acc : 0.883, Run Time : 2.62
INFO:root:2019-05-11 06:37:29, Epoch : 1, Step : 7211, Training Loss : 0.27428, Training Acc : 0.844, Run Time : 0.38
INFO:root:2019-05-11 06:37:31, Epoch : 1, Step : 7212, Training Loss : 0.20849, Training Acc : 0.917, Run Time : 1.74
INFO:root:2019-05-11 06:37:49, Epoch : 1, Step : 7213, Training Loss : 0.19207, Training Acc : 0.944, Run Time : 17.75
INFO:root:2019-05-11 06:37:57, Epoch : 1, Step : 7214, Training Loss : 0.16878, Training Acc : 0.956, Run Time : 7.77
INFO:root:2019-05-11 06:37:59, Epoch : 1, Step : 7215, Training Loss : 0.29666, Training Acc : 0.878, Run Time : 2.13
INFO:root:2019-05-11 06:38:30, Epoch : 1, Step : 7216, Training Loss : 0.21476, Training Acc : 0.922, Run Time : 31.56
INFO:root:2019-05-11 06:38:37, Epoch : 1, Step : 7217, Training Loss : 0.18632, Training Acc : 0.944, Run Time : 7.04
INFO:root:2019-05-11 06:39:23, Epoch : 1, Step : 7218, Training Loss : 0.09891, Training Acc : 0.978, Run Time : 46.20
INFO:root:2019-05-11 06:39:45, Epoch : 1, Step : 7219, Training Loss : 0.16808, Training Acc : 0.961, Run Time : 21.33
INFO:root:2019-05-11 06:39:47, Epoch : 1, Step : 7220, Training Loss : 0.21870, Training Acc : 0.922, Run Time : 1.74
INFO:root:2019-05-11 06:39:47, Epoch : 1, Step : 7221, Training Loss : 0.13686, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-11 06:40:01, Epoch : 1, Step : 7222, Training Loss : 0.14425, Training Acc : 0.950, Run Time : 14.38
INFO:root:2019-05-11 06:40:21, Epoch : 1, Step : 7223, Training Loss : 0.22829, Training Acc : 0.928, Run Time : 20.12
INFO:root:2019-05-11 06:40:23, Epoch : 1, Step : 7224, Training Loss : 0.31474, Training Acc : 0.872, Run Time : 1.46
INFO:root:2019-05-11 06:40:23, Epoch : 1, Step : 7225, Training Loss : 0.38858, Training Acc : 0.867, Run Time : 0.44
INFO:root:2019-05-11 06:40:25, Epoch : 1, Step : 7226, Training Loss : 0.33873, Training Acc : 0.856, Run Time : 1.12
INFO:root:2019-05-11 06:40:49, Epoch : 1, Step : 7227, Training Loss : 0.26914, Training Acc : 0.906, Run Time : 24.50
INFO:root:2019-05-11 06:40:51, Epoch : 1, Step : 7228, Training Loss : 0.27771, Training Acc : 0.872, Run Time : 2.20
INFO:root:2019-05-11 06:40:52, Epoch : 1, Step : 7229, Training Loss : 0.22996, Training Acc : 0.889, Run Time : 0.42
INFO:root:2019-05-11 06:40:53, Epoch : 1, Step : 7230, Training Loss : 0.30441, Training Acc : 0.856, Run Time : 1.43
INFO:root:2019-05-11 06:41:41, Epoch : 1, Step : 7231, Training Loss : 0.24796, Training Acc : 0.894, Run Time : 47.83
INFO:root:2019-05-11 06:42:14, Epoch : 1, Step : 7232, Training Loss : 0.22930, Training Acc : 0.906, Run Time : 33.05
INFO:root:2019-05-11 06:42:27, Epoch : 1, Step : 7233, Training Loss : 0.20726, Training Acc : 0.900, Run Time : 12.72
INFO:root:2019-05-11 06:42:28, Epoch : 1, Step : 7234, Training Loss : 0.19161, Training Acc : 0.939, Run Time : 0.86
INFO:root:2019-05-11 06:42:29, Epoch : 1, Step : 7235, Training Loss : 0.18040, Training Acc : 0.928, Run Time : 1.76
INFO:root:2019-05-11 06:42:39, Epoch : 1, Step : 7236, Training Loss : 0.17120, Training Acc : 0.917, Run Time : 9.35
INFO:root:2019-05-11 06:42:39, Epoch : 1, Step : 7237, Training Loss : 0.16391, Training Acc : 0.917, Run Time : 0.76
INFO:root:2019-05-11 06:42:41, Epoch : 1, Step : 7238, Training Loss : 0.25051, Training Acc : 0.922, Run Time : 1.75
INFO:root:2019-05-11 06:42:51, Epoch : 1, Step : 7239, Training Loss : 0.19248, Training Acc : 0.928, Run Time : 10.05
INFO:root:2019-05-11 06:42:54, Epoch : 1, Step : 7240, Training Loss : 0.11868, Training Acc : 0.950, Run Time : 2.56
INFO:root:2019-05-11 06:43:03, Epoch : 1, Step : 7241, Training Loss : 0.13629, Training Acc : 0.961, Run Time : 9.38
INFO:root:2019-05-11 06:43:04, Epoch : 1, Step : 7242, Training Loss : 0.14981, Training Acc : 0.944, Run Time : 0.94
INFO:root:2019-05-11 06:43:18, Epoch : 1, Step : 7243, Training Loss : 0.16192, Training Acc : 0.911, Run Time : 14.19
INFO:root:2019-05-11 06:43:20, Epoch : 1, Step : 7244, Training Loss : 0.17834, Training Acc : 0.922, Run Time : 1.83
INFO:root:2019-05-11 06:43:21, Epoch : 1, Step : 7245, Training Loss : 0.21986, Training Acc : 0.900, Run Time : 0.44
INFO:root:2019-05-11 06:43:35, Epoch : 1, Step : 7246, Training Loss : 0.21105, Training Acc : 0.900, Run Time : 14.67
INFO:root:2019-05-11 06:43:42, Epoch : 1, Step : 7247, Training Loss : 0.16286, Training Acc : 0.922, Run Time : 6.51
INFO:root:2019-05-11 06:43:42, Epoch : 1, Step : 7248, Training Loss : 0.29721, Training Acc : 0.856, Run Time : 0.44
INFO:root:2019-05-11 06:43:56, Epoch : 1, Step : 7249, Training Loss : 0.19519, Training Acc : 0.917, Run Time : 14.16
INFO:root:2019-05-11 06:43:58, Epoch : 1, Step : 7250, Training Loss : 0.19231, Training Acc : 0.911, Run Time : 1.48
INFO:root:2019-05-11 06:44:21, Epoch : 1, Step : 7251, Training Loss : 0.15788, Training Acc : 0.933, Run Time : 22.93
INFO:root:2019-05-11 06:44:36, Epoch : 1, Step : 7252, Training Loss : 0.12834, Training Acc : 0.961, Run Time : 15.03
INFO:root:2019-05-11 06:44:37, Epoch : 1, Step : 7253, Training Loss : 0.17111, Training Acc : 0.911, Run Time : 1.39
INFO:root:2019-05-11 06:44:50, Epoch : 1, Step : 7254, Training Loss : 0.16546, Training Acc : 0.939, Run Time : 12.85
INFO:root:2019-05-11 06:44:52, Epoch : 1, Step : 7255, Training Loss : 0.13103, Training Acc : 0.956, Run Time : 1.82
INFO:root:2019-05-11 06:45:02, Epoch : 1, Step : 7256, Training Loss : 0.08240, Training Acc : 0.978, Run Time : 10.50
INFO:root:2019-05-11 06:45:03, Epoch : 1, Step : 7257, Training Loss : 0.15774, Training Acc : 0.917, Run Time : 0.54
INFO:root:2019-05-11 06:45:05, Epoch : 1, Step : 7258, Training Loss : 0.08744, Training Acc : 0.972, Run Time : 1.85
INFO:root:2019-05-11 06:45:21, Epoch : 1, Step : 7259, Training Loss : 0.17793, Training Acc : 0.928, Run Time : 15.87
INFO:root:2019-05-11 06:45:22, Epoch : 1, Step : 7260, Training Loss : 0.09180, Training Acc : 0.983, Run Time : 1.63
INFO:root:2019-05-11 06:45:23, Epoch : 1, Step : 7261, Training Loss : 0.12914, Training Acc : 0.956, Run Time : 0.48
INFO:root:2019-05-11 06:45:34, Epoch : 1, Step : 7262, Training Loss : 0.21095, Training Acc : 0.917, Run Time : 11.17
INFO:root:2019-05-11 06:45:35, Epoch : 1, Step : 7263, Training Loss : 0.11146, Training Acc : 0.961, Run Time : 1.09
INFO:root:2019-05-11 06:45:42, Epoch : 1, Step : 7264, Training Loss : 0.08836, Training Acc : 0.983, Run Time : 7.48
INFO:root:2019-05-11 06:45:48, Epoch : 1, Step : 7265, Training Loss : 0.13714, Training Acc : 0.933, Run Time : 5.21
INFO:root:2019-05-11 06:45:48, Epoch : 1, Step : 7266, Training Loss : 0.12544, Training Acc : 0.944, Run Time : 0.58
INFO:root:2019-05-11 06:46:00, Epoch : 1, Step : 7267, Training Loss : 0.14201, Training Acc : 0.967, Run Time : 11.35
INFO:root:2019-05-11 06:46:00, Epoch : 1, Step : 7268, Training Loss : 0.04564, Training Acc : 1.000, Run Time : 0.48
INFO:root:2019-05-11 06:46:00, Epoch : 1, Step : 7269, Training Loss : 0.13198, Training Acc : 0.956, Run Time : 0.46
INFO:root:2019-05-11 06:46:19, Epoch : 1, Step : 7270, Training Loss : 0.07678, Training Acc : 0.978, Run Time : 18.54
INFO:root:2019-05-11 06:46:21, Epoch : 1, Step : 7271, Training Loss : 0.21303, Training Acc : 0.900, Run Time : 1.83
INFO:root:2019-05-11 06:46:21, Epoch : 1, Step : 7272, Training Loss : 0.08907, Training Acc : 0.967, Run Time : 0.42
INFO:root:2019-05-11 06:46:32, Epoch : 1, Step : 7273, Training Loss : 0.14803, Training Acc : 0.961, Run Time : 10.80
INFO:root:2019-05-11 06:46:47, Epoch : 1, Step : 7274, Training Loss : 0.09949, Training Acc : 0.983, Run Time : 14.46
INFO:root:2019-05-11 06:46:49, Epoch : 1, Step : 7275, Training Loss : 0.08568, Training Acc : 0.972, Run Time : 2.35
INFO:root:2019-05-11 06:47:06, Epoch : 1, Step : 7276, Training Loss : 0.09205, Training Acc : 0.972, Run Time : 17.41
INFO:root:2019-05-11 06:47:19, Epoch : 1, Step : 7277, Training Loss : 0.15605, Training Acc : 0.944, Run Time : 12.81
INFO:root:2019-05-11 06:47:42, Epoch : 1, Step : 7278, Training Loss : 0.18226, Training Acc : 0.933, Run Time : 22.48
INFO:root:2019-05-11 06:48:10, Epoch : 1, Step : 7279, Training Loss : 0.12023, Training Acc : 0.956, Run Time : 27.93
INFO:root:2019-05-11 06:48:11, Epoch : 1, Step : 7280, Training Loss : 0.16138, Training Acc : 0.933, Run Time : 1.91
INFO:root:2019-05-11 06:48:12, Epoch : 1, Step : 7281, Training Loss : 0.17326, Training Acc : 0.944, Run Time : 0.41
INFO:root:2019-05-11 06:48:13, Epoch : 1, Step : 7282, Training Loss : 0.21794, Training Acc : 0.928, Run Time : 1.39
INFO:root:2019-05-11 06:48:35, Epoch : 1, Step : 7283, Training Loss : 0.21093, Training Acc : 0.939, Run Time : 21.44
INFO:root:2019-05-11 06:48:43, Epoch : 1, Step : 7284, Training Loss : 0.10424, Training Acc : 0.972, Run Time : 7.89
INFO:root:2019-05-11 06:49:22, Epoch : 1, Step : 7285, Training Loss : 0.25463, Training Acc : 0.906, Run Time : 39.81
INFO:root:2019-05-11 06:49:29, Epoch : 1, Step : 7286, Training Loss : 0.33904, Training Acc : 0.894, Run Time : 6.33
INFO:root:2019-05-11 06:49:29, Epoch : 1, Step : 7287, Training Loss : 0.24616, Training Acc : 0.933, Run Time : 0.42
INFO:root:2019-05-11 06:50:00, Epoch : 1, Step : 7288, Training Loss : 0.24829, Training Acc : 0.922, Run Time : 30.51
INFO:root:2019-05-11 06:50:07, Epoch : 1, Step : 7289, Training Loss : 0.24387, Training Acc : 0.917, Run Time : 7.18
INFO:root:2019-05-11 06:50:07, Epoch : 1, Step : 7290, Training Loss : 0.20640, Training Acc : 0.944, Run Time : 0.42
INFO:root:2019-05-11 06:50:09, Epoch : 1, Step : 7291, Training Loss : 0.20151, Training Acc : 0.917, Run Time : 1.45
INFO:root:2019-05-11 06:50:24, Epoch : 1, Step : 7292, Training Loss : 0.20076, Training Acc : 0.917, Run Time : 14.99
INFO:root:2019-05-11 06:50:27, Epoch : 1, Step : 7293, Training Loss : 0.11615, Training Acc : 0.967, Run Time : 3.08
INFO:root:2019-05-11 06:50:40, Epoch : 1, Step : 7294, Training Loss : 0.17631, Training Acc : 0.928, Run Time : 13.10
INFO:root:2019-05-11 06:50:41, Epoch : 1, Step : 7295, Training Loss : 0.18140, Training Acc : 0.906, Run Time : 1.17
INFO:root:2019-05-11 06:51:06, Epoch : 1, Step : 7296, Training Loss : 0.22913, Training Acc : 0.922, Run Time : 24.51
INFO:root:2019-05-11 06:51:07, Epoch : 1, Step : 7297, Training Loss : 0.18671, Training Acc : 0.917, Run Time : 1.75
INFO:root:2019-05-11 06:51:08, Epoch : 1, Step : 7298, Training Loss : 0.21908, Training Acc : 0.911, Run Time : 0.42
INFO:root:2019-05-11 06:51:09, Epoch : 1, Step : 7299, Training Loss : 0.57989, Training Acc : 0.789, Run Time : 1.09
INFO:root:2019-05-11 06:51:29, Epoch : 1, Step : 7300, Training Loss : 0.47669, Training Acc : 0.811, Run Time : 20.27
INFO:root:2019-05-11 06:51:38, Epoch : 1, Step : 7301, Training Loss : 0.44670, Training Acc : 0.794, Run Time : 8.43
INFO:root:2019-05-11 06:51:49, Epoch : 1, Step : 7302, Training Loss : 0.43156, Training Acc : 0.839, Run Time : 11.98
INFO:root:2019-05-11 06:51:50, Epoch : 1, Step : 7303, Training Loss : 0.78350, Training Acc : 0.672, Run Time : 0.78
INFO:root:2019-05-11 06:51:52, Epoch : 1, Step : 7304, Training Loss : 0.73527, Training Acc : 0.772, Run Time : 1.55
INFO:root:2019-05-11 06:52:02, Epoch : 1, Step : 7305, Training Loss : 0.32205, Training Acc : 0.861, Run Time : 10.51
INFO:root:2019-05-11 06:52:04, Epoch : 1, Step : 7306, Training Loss : 0.25780, Training Acc : 0.894, Run Time : 1.98
INFO:root:2019-05-11 06:52:25, Epoch : 1, Step : 7307, Training Loss : 0.23267, Training Acc : 0.889, Run Time : 21.18
INFO:root:2019-05-11 06:52:27, Epoch : 1, Step : 7308, Training Loss : 0.36028, Training Acc : 0.856, Run Time : 1.84
INFO:root:2019-05-11 06:52:28, Epoch : 1, Step : 7309, Training Loss : 0.43263, Training Acc : 0.828, Run Time : 1.11
INFO:root:2019-05-11 06:52:39, Epoch : 1, Step : 7310, Training Loss : 0.52707, Training Acc : 0.817, Run Time : 10.09
INFO:root:2019-05-11 06:52:42, Epoch : 1, Step : 7311, Training Loss : 0.36672, Training Acc : 0.850, Run Time : 3.02
INFO:root:2019-05-11 06:52:53, Epoch : 1, Step : 7312, Training Loss : 0.33432, Training Acc : 0.867, Run Time : 11.72
INFO:root:2019-05-11 06:52:54, Epoch : 1, Step : 7313, Training Loss : 0.20954, Training Acc : 0.928, Run Time : 0.90
INFO:root:2019-05-11 06:52:56, Epoch : 1, Step : 7314, Training Loss : 0.32049, Training Acc : 0.872, Run Time : 1.59
INFO:root:2019-05-11 06:53:06, Epoch : 1, Step : 7315, Training Loss : 0.35355, Training Acc : 0.878, Run Time : 9.76
INFO:root:2019-05-11 06:53:08, Epoch : 1, Step : 7316, Training Loss : 0.48823, Training Acc : 0.811, Run Time : 2.59
INFO:root:2019-05-11 06:53:53, Epoch : 1, Step : 7317, Training Loss : 0.32862, Training Acc : 0.894, Run Time : 44.81
INFO:root:2019-05-11 06:54:15, Epoch : 1, Step : 7318, Training Loss : 0.32528, Training Acc : 0.906, Run Time : 21.62
INFO:root:2019-05-11 06:54:40, Epoch : 1, Step : 7319, Training Loss : 0.39836, Training Acc : 0.867, Run Time : 25.42
INFO:root:2019-05-11 06:54:56, Epoch : 1, Step : 7320, Training Loss : 0.29718, Training Acc : 0.933, Run Time : 15.66
INFO:root:2019-05-11 06:55:26, Epoch : 1, Step : 7321, Training Loss : 0.21888, Training Acc : 0.922, Run Time : 30.07
INFO:root:2019-05-11 06:55:28, Epoch : 1, Step : 7322, Training Loss : 0.19647, Training Acc : 0.939, Run Time : 1.93
INFO:root:2019-05-11 06:55:29, Epoch : 1, Step : 7323, Training Loss : 0.17275, Training Acc : 0.944, Run Time : 1.43
INFO:root:2019-05-11 06:55:50, Epoch : 1, Step : 7324, Training Loss : 0.35453, Training Acc : 0.844, Run Time : 21.15
INFO:root:2019-05-11 06:55:53, Epoch : 1, Step : 7325, Training Loss : 0.20667, Training Acc : 0.928, Run Time : 2.67
INFO:root:2019-05-11 06:55:53, Epoch : 1, Step : 7326, Training Loss : 0.27421, Training Acc : 0.878, Run Time : 0.39
INFO:root:2019-05-11 06:56:07, Epoch : 1, Step : 7327, Training Loss : 0.25627, Training Acc : 0.894, Run Time : 14.05
INFO:root:2019-05-11 06:56:08, Epoch : 1, Step : 7328, Training Loss : 0.23091, Training Acc : 0.911, Run Time : 0.96
INFO:root:2019-05-11 06:56:10, Epoch : 1, Step : 7329, Training Loss : 0.25292, Training Acc : 0.861, Run Time : 1.79
INFO:root:2019-05-11 06:56:22, Epoch : 1, Step : 7330, Training Loss : 0.18711, Training Acc : 0.933, Run Time : 11.66
INFO:root:2019-05-11 06:56:24, Epoch : 1, Step : 7331, Training Loss : 0.22698, Training Acc : 0.922, Run Time : 2.60
INFO:root:2019-05-11 06:56:42, Epoch : 1, Step : 7332, Training Loss : 0.24951, Training Acc : 0.883, Run Time : 17.99
INFO:root:2019-05-11 06:56:56, Epoch : 1, Step : 7333, Training Loss : 0.23327, Training Acc : 0.894, Run Time : 13.45
INFO:root:2019-05-11 06:56:57, Epoch : 1, Step : 7334, Training Loss : 0.21402, Training Acc : 0.906, Run Time : 0.94
INFO:root:2019-05-11 06:56:58, Epoch : 1, Step : 7335, Training Loss : 0.25486, Training Acc : 0.867, Run Time : 1.44
INFO:root:2019-05-11 06:57:11, Epoch : 1, Step : 7336, Training Loss : 0.21651, Training Acc : 0.911, Run Time : 13.32
INFO:root:2019-05-11 06:57:12, Epoch : 1, Step : 7337, Training Loss : 0.16978, Training Acc : 0.922, Run Time : 0.64
INFO:root:2019-05-11 06:57:14, Epoch : 1, Step : 7338, Training Loss : 0.18241, Training Acc : 0.928, Run Time : 1.54
INFO:root:2019-05-11 06:57:42, Epoch : 1, Step : 7339, Training Loss : 0.20455, Training Acc : 0.911, Run Time : 28.71
INFO:root:2019-05-11 06:57:51, Epoch : 1, Step : 7340, Training Loss : 0.29523, Training Acc : 0.889, Run Time : 8.36
INFO:root:2019-05-11 06:58:12, Epoch : 1, Step : 7341, Training Loss : 0.34100, Training Acc : 0.850, Run Time : 21.26
INFO:root:2019-05-11 06:58:27, Epoch : 1, Step : 7342, Training Loss : 0.17260, Training Acc : 0.928, Run Time : 15.20
INFO:root:2019-05-11 06:58:28, Epoch : 1, Step : 7343, Training Loss : 0.19093, Training Acc : 0.894, Run Time : 1.01
INFO:root:2019-05-11 06:58:29, Epoch : 1, Step : 7344, Training Loss : 0.09613, Training Acc : 0.967, Run Time : 0.89
INFO:root:2019-05-11 06:58:41, Epoch : 1, Step : 7345, Training Loss : 0.18017, Training Acc : 0.922, Run Time : 12.27
INFO:root:2019-05-11 06:59:24, Epoch : 1, Step : 7346, Training Loss : 0.23096, Training Acc : 0.900, Run Time : 42.17
INFO:root:2019-05-11 06:59:33, Epoch : 1, Step : 7347, Training Loss : 0.23238, Training Acc : 0.894, Run Time : 9.92
INFO:root:2019-05-11 06:59:45, Epoch : 1, Step : 7348, Training Loss : 0.32873, Training Acc : 0.850, Run Time : 11.61
INFO:root:2019-05-11 06:59:46, Epoch : 1, Step : 7349, Training Loss : 0.25521, Training Acc : 0.883, Run Time : 1.02
INFO:root:2019-05-11 06:59:56, Epoch : 1, Step : 7350, Training Loss : 0.14246, Training Acc : 0.961, Run Time : 10.22
INFO:root:2019-05-11 06:59:57, Epoch : 1, Step : 7351, Training Loss : 0.26861, Training Acc : 0.894, Run Time : 1.10
INFO:root:2019-05-11 06:59:58, Epoch : 1, Step : 7352, Training Loss : 0.32900, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-11 06:59:59, Epoch : 1, Step : 7353, Training Loss : 0.41960, Training Acc : 0.811, Run Time : 1.30
INFO:root:2019-05-11 07:00:09, Epoch : 1, Step : 7354, Training Loss : 0.48418, Training Acc : 0.806, Run Time : 9.66
INFO:root:2019-05-11 07:00:09, Epoch : 1, Step : 7355, Training Loss : 0.40548, Training Acc : 0.822, Run Time : 0.59
INFO:root:2019-05-11 07:00:11, Epoch : 1, Step : 7356, Training Loss : 0.56145, Training Acc : 0.767, Run Time : 1.58
INFO:root:2019-05-11 07:00:29, Epoch : 1, Step : 7357, Training Loss : 0.42729, Training Acc : 0.817, Run Time : 17.86
INFO:root:2019-05-11 07:00:30, Epoch : 1, Step : 7358, Training Loss : 0.28597, Training Acc : 0.867, Run Time : 1.59
INFO:root:2019-05-11 07:00:31, Epoch : 1, Step : 7359, Training Loss : 0.36042, Training Acc : 0.850, Run Time : 0.41
INFO:root:2019-05-11 07:00:48, Epoch : 1, Step : 7360, Training Loss : 0.38956, Training Acc : 0.828, Run Time : 17.16
INFO:root:2019-05-11 07:00:50, Epoch : 1, Step : 7361, Training Loss : 0.26254, Training Acc : 0.889, Run Time : 2.56
INFO:root:2019-05-11 07:00:51, Epoch : 1, Step : 7362, Training Loss : 0.32581, Training Acc : 0.833, Run Time : 0.40
INFO:root:2019-05-11 07:01:02, Epoch : 1, Step : 7363, Training Loss : 0.47301, Training Acc : 0.817, Run Time : 10.87
INFO:root:2019-05-11 07:01:03, Epoch : 1, Step : 7364, Training Loss : 0.37851, Training Acc : 0.800, Run Time : 1.08
INFO:root:2019-05-11 07:01:17, Epoch : 1, Step : 7365, Training Loss : 0.39760, Training Acc : 0.811, Run Time : 14.65
INFO:root:2019-05-11 07:01:19, Epoch : 1, Step : 7366, Training Loss : 0.38939, Training Acc : 0.844, Run Time : 1.38
INFO:root:2019-05-11 07:01:32, Epoch : 1, Step : 7367, Training Loss : 0.33727, Training Acc : 0.817, Run Time : 13.33
INFO:root:2019-05-11 07:01:34, Epoch : 1, Step : 7368, Training Loss : 0.33953, Training Acc : 0.833, Run Time : 1.44
INFO:root:2019-05-11 07:01:45, Epoch : 1, Step : 7369, Training Loss : 0.42183, Training Acc : 0.772, Run Time : 11.77
INFO:root:2019-05-11 07:01:47, Epoch : 1, Step : 7370, Training Loss : 0.30056, Training Acc : 0.883, Run Time : 1.68
INFO:root:2019-05-11 07:02:18, Epoch : 1, Step : 7371, Training Loss : 0.32940, Training Acc : 0.867, Run Time : 30.62
INFO:root:2019-05-11 07:02:25, Epoch : 1, Step : 7372, Training Loss : 0.47486, Training Acc : 0.789, Run Time : 7.39
INFO:root:2019-05-11 07:03:00, Epoch : 1, Step : 7373, Training Loss : 0.57058, Training Acc : 0.783, Run Time : 34.40
INFO:root:2019-05-11 07:03:21, Epoch : 1, Step : 7374, Training Loss : 0.37977, Training Acc : 0.828, Run Time : 21.68
INFO:root:2019-05-11 07:03:41, Epoch : 1, Step : 7375, Training Loss : 0.37477, Training Acc : 0.811, Run Time : 19.76
INFO:root:2019-05-11 07:03:51, Epoch : 1, Step : 7376, Training Loss : 0.26410, Training Acc : 0.872, Run Time : 9.86
INFO:root:2019-05-11 07:05:06, Epoch : 1, Step : 7377, Training Loss : 0.34758, Training Acc : 0.839, Run Time : 75.19
INFO:root:2019-05-11 07:05:23, Epoch : 1, Step : 7378, Training Loss : 0.38449, Training Acc : 0.811, Run Time : 17.22
INFO:root:2019-05-11 07:05:25, Epoch : 1, Step : 7379, Training Loss : 0.24380, Training Acc : 0.900, Run Time : 1.56
INFO:root:2019-05-11 07:05:25, Epoch : 1, Step : 7380, Training Loss : 0.30480, Training Acc : 0.850, Run Time : 0.42
INFO:root:2019-05-11 07:05:27, Epoch : 1, Step : 7381, Training Loss : 0.33244, Training Acc : 0.872, Run Time : 1.67
INFO:root:2019-05-11 07:05:39, Epoch : 1, Step : 7382, Training Loss : 0.24125, Training Acc : 0.872, Run Time : 12.18
INFO:root:2019-05-11 07:05:40, Epoch : 1, Step : 7383, Training Loss : 0.26650, Training Acc : 0.894, Run Time : 0.70
INFO:root:2019-05-11 07:05:42, Epoch : 1, Step : 7384, Training Loss : 0.23782, Training Acc : 0.878, Run Time : 1.99
INFO:root:2019-05-11 07:06:08, Epoch : 1, Step : 7385, Training Loss : 0.21090, Training Acc : 0.922, Run Time : 26.40
INFO:root:2019-05-11 07:06:19, Epoch : 1, Step : 7386, Training Loss : 0.18305, Training Acc : 0.939, Run Time : 10.63
INFO:root:2019-05-11 07:06:31, Epoch : 1, Step : 7387, Training Loss : 0.19952, Training Acc : 0.900, Run Time : 12.14
INFO:root:2019-05-11 07:06:56, Epoch : 1, Step : 7388, Training Loss : 0.19088, Training Acc : 0.911, Run Time : 25.26
INFO:root:2019-05-11 07:07:22, Epoch : 1, Step : 7389, Training Loss : 0.29723, Training Acc : 0.878, Run Time : 25.73
INFO:root:2019-05-11 07:07:23, Epoch : 1, Step : 7390, Training Loss : 0.15030, Training Acc : 0.956, Run Time : 1.35
INFO:root:2019-05-11 07:07:24, Epoch : 1, Step : 7391, Training Loss : 0.23986, Training Acc : 0.889, Run Time : 1.08
INFO:root:2019-05-11 07:07:42, Epoch : 1, Step : 7392, Training Loss : 0.29433, Training Acc : 0.883, Run Time : 17.94
INFO:root:2019-05-11 07:07:44, Epoch : 1, Step : 7393, Training Loss : 0.32726, Training Acc : 0.867, Run Time : 1.97
INFO:root:2019-05-11 07:07:45, Epoch : 1, Step : 7394, Training Loss : 0.32351, Training Acc : 0.867, Run Time : 0.42
INFO:root:2019-05-11 07:07:46, Epoch : 1, Step : 7395, Training Loss : 0.36183, Training Acc : 0.839, Run Time : 1.12
INFO:root:2019-05-11 07:07:57, Epoch : 1, Step : 7396, Training Loss : 0.20521, Training Acc : 0.933, Run Time : 10.93
INFO:root:2019-05-11 07:07:57, Epoch : 1, Step : 7397, Training Loss : 0.22222, Training Acc : 0.911, Run Time : 0.43
INFO:root:2019-05-11 07:07:58, Epoch : 1, Step : 7398, Training Loss : 0.28396, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-11 07:07:59, Epoch : 1, Step : 7399, Training Loss : 0.21272, Training Acc : 0.917, Run Time : 1.96
INFO:root:2019-05-11 07:08:23, Epoch : 1, Step : 7400, Training Loss : 0.19335, Training Acc : 0.939, Run Time : 24.01
INFO:root:2019-05-11 07:08:27, Epoch : 1, Step : 7401, Training Loss : 0.12844, Training Acc : 0.956, Run Time : 3.01
INFO:root:2019-05-11 07:08:37, Epoch : 1, Step : 7402, Training Loss : 0.15446, Training Acc : 0.933, Run Time : 10.91
INFO:root:2019-05-11 07:08:39, Epoch : 1, Step : 7403, Training Loss : 0.22457, Training Acc : 0.900, Run Time : 1.25
INFO:root:2019-05-11 07:08:49, Epoch : 1, Step : 7404, Training Loss : 0.27850, Training Acc : 0.850, Run Time : 10.52
INFO:root:2019-05-11 07:08:50, Epoch : 1, Step : 7405, Training Loss : 0.27772, Training Acc : 0.883, Run Time : 0.64
INFO:root:2019-05-11 07:08:50, Epoch : 1, Step : 7406, Training Loss : 0.24332, Training Acc : 0.872, Run Time : 0.66
INFO:root:2019-05-11 07:09:09, Epoch : 1, Step : 7407, Training Loss : 0.36695, Training Acc : 0.811, Run Time : 18.89
INFO:root:2019-05-11 07:09:12, Epoch : 1, Step : 7408, Training Loss : 0.35827, Training Acc : 0.844, Run Time : 2.58
INFO:root:2019-05-11 07:09:14, Epoch : 1, Step : 7409, Training Loss : 0.42471, Training Acc : 0.856, Run Time : 1.79
INFO:root:2019-05-11 07:09:26, Epoch : 1, Step : 7410, Training Loss : 0.31350, Training Acc : 0.889, Run Time : 12.07
INFO:root:2019-05-11 07:09:27, Epoch : 1, Step : 7411, Training Loss : 0.43495, Training Acc : 0.839, Run Time : 0.82
INFO:root:2019-05-11 07:09:29, Epoch : 1, Step : 7412, Training Loss : 0.51220, Training Acc : 0.817, Run Time : 2.32
INFO:root:2019-05-11 07:09:52, Epoch : 1, Step : 7413, Training Loss : 0.58584, Training Acc : 0.722, Run Time : 23.15
INFO:root:2019-05-11 07:09:55, Epoch : 1, Step : 7414, Training Loss : 0.36239, Training Acc : 0.872, Run Time : 2.81
INFO:root:2019-05-11 07:10:22, Epoch : 1, Step : 7415, Training Loss : 0.21986, Training Acc : 0.928, Run Time : 27.39
INFO:root:2019-05-11 07:10:41, Epoch : 1, Step : 7416, Training Loss : 0.21699, Training Acc : 0.906, Run Time : 18.81
INFO:root:2019-05-11 07:10:43, Epoch : 1, Step : 7417, Training Loss : 0.14719, Training Acc : 0.961, Run Time : 1.83
INFO:root:2019-05-11 07:10:45, Epoch : 1, Step : 7418, Training Loss : 0.23209, Training Acc : 0.911, Run Time : 1.63
INFO:root:2019-05-11 07:11:03, Epoch : 1, Step : 7419, Training Loss : 0.22344, Training Acc : 0.917, Run Time : 18.41
INFO:root:2019-05-11 07:11:05, Epoch : 1, Step : 7420, Training Loss : 0.24106, Training Acc : 0.911, Run Time : 1.60
INFO:root:2019-05-11 07:11:05, Epoch : 1, Step : 7421, Training Loss : 0.17499, Training Acc : 0.944, Run Time : 0.39
INFO:root:2019-05-11 07:11:06, Epoch : 1, Step : 7422, Training Loss : 0.24756, Training Acc : 0.889, Run Time : 1.36
INFO:root:2019-05-11 07:11:19, Epoch : 1, Step : 7423, Training Loss : 0.27249, Training Acc : 0.872, Run Time : 12.21
INFO:root:2019-05-11 07:11:30, Epoch : 1, Step : 7424, Training Loss : 0.17220, Training Acc : 0.944, Run Time : 11.08
INFO:root:2019-05-11 07:11:31, Epoch : 1, Step : 7425, Training Loss : 0.35583, Training Acc : 0.867, Run Time : 1.86
INFO:root:2019-05-11 07:11:53, Epoch : 1, Step : 7426, Training Loss : 0.18615, Training Acc : 0.939, Run Time : 21.95
INFO:root:2019-05-11 07:12:00, Epoch : 1, Step : 7427, Training Loss : 0.39783, Training Acc : 0.867, Run Time : 6.50
INFO:root:2019-05-11 07:12:02, Epoch : 1, Step : 7428, Training Loss : 0.21141, Training Acc : 0.917, Run Time : 2.06
INFO:root:2019-05-11 07:12:13, Epoch : 1, Step : 7429, Training Loss : 0.16604, Training Acc : 0.944, Run Time : 11.45
INFO:root:2019-05-11 07:12:14, Epoch : 1, Step : 7430, Training Loss : 0.14032, Training Acc : 0.956, Run Time : 0.79
INFO:root:2019-05-11 07:12:16, Epoch : 1, Step : 7431, Training Loss : 0.17233, Training Acc : 0.950, Run Time : 2.26
INFO:root:2019-05-11 07:13:14, Epoch : 1, Step : 7432, Training Loss : 0.22894, Training Acc : 0.883, Run Time : 57.21
INFO:root:2019-05-11 07:13:28, Epoch : 1, Step : 7433, Training Loss : 0.15868, Training Acc : 0.950, Run Time : 14.51
INFO:root:2019-05-11 07:13:42, Epoch : 1, Step : 7434, Training Loss : 0.22609, Training Acc : 0.917, Run Time : 13.80
INFO:root:2019-05-11 07:14:16, Epoch : 1, Step : 7435, Training Loss : 0.23831, Training Acc : 0.917, Run Time : 33.79
INFO:root:2019-05-11 07:14:54, Epoch : 1, Step : 7436, Training Loss : 0.17816, Training Acc : 0.928, Run Time : 37.95
INFO:root:2019-05-11 07:15:04, Epoch : 1, Step : 7437, Training Loss : 0.22137, Training Acc : 0.917, Run Time : 10.41
INFO:root:2019-05-11 07:15:16, Epoch : 1, Step : 7438, Training Loss : 0.21670, Training Acc : 0.928, Run Time : 11.50
INFO:root:2019-05-11 07:15:16, Epoch : 1, Step : 7439, Training Loss : 0.13826, Training Acc : 0.939, Run Time : 0.43
INFO:root:2019-05-11 07:15:17, Epoch : 1, Step : 7440, Training Loss : 0.12932, Training Acc : 0.956, Run Time : 0.43
INFO:root:2019-05-11 07:15:30, Epoch : 1, Step : 7441, Training Loss : 0.19880, Training Acc : 0.922, Run Time : 13.37
INFO:root:2019-05-11 07:15:30, Epoch : 1, Step : 7442, Training Loss : 0.17408, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-11 07:15:31, Epoch : 1, Step : 7443, Training Loss : 0.06045, Training Acc : 1.000, Run Time : 0.39
INFO:root:2019-05-11 07:15:33, Epoch : 1, Step : 7444, Training Loss : 0.09608, Training Acc : 0.978, Run Time : 2.26
INFO:root:2019-05-11 07:15:59, Epoch : 1, Step : 7445, Training Loss : 0.14514, Training Acc : 0.961, Run Time : 26.20
INFO:root:2019-05-11 07:16:04, Epoch : 1, Step : 7446, Training Loss : 0.18786, Training Acc : 0.922, Run Time : 5.26
INFO:root:2019-05-11 07:16:05, Epoch : 1, Step : 7447, Training Loss : 0.08327, Training Acc : 0.978, Run Time : 0.64
INFO:root:2019-05-11 07:16:07, Epoch : 1, Step : 7448, Training Loss : 0.15668, Training Acc : 0.956, Run Time : 2.03
INFO:root:2019-05-11 07:16:43, Epoch : 1, Step : 7449, Training Loss : 0.18072, Training Acc : 0.922, Run Time : 35.69
INFO:root:2019-05-11 07:16:49, Epoch : 1, Step : 7450, Training Loss : 0.13009, Training Acc : 0.972, Run Time : 6.21
INFO:root:2019-05-11 07:17:02, Epoch : 1, Step : 7451, Training Loss : 0.21286, Training Acc : 0.911, Run Time : 12.97
INFO:root:2019-05-11 07:17:16, Epoch : 1, Step : 7452, Training Loss : 0.21276, Training Acc : 0.917, Run Time : 13.99
INFO:root:2019-05-11 07:17:21, Epoch : 1, Step : 7453, Training Loss : 0.05039, Training Acc : 0.989, Run Time : 5.49
INFO:root:2019-05-11 07:17:22, Epoch : 1, Step : 7454, Training Loss : 0.13990, Training Acc : 0.956, Run Time : 0.57
INFO:root:2019-05-11 07:17:41, Epoch : 1, Step : 7455, Training Loss : 0.18524, Training Acc : 0.939, Run Time : 19.04
INFO:root:2019-05-11 07:17:58, Epoch : 1, Step : 7456, Training Loss : 0.22040, Training Acc : 0.911, Run Time : 16.43
INFO:root:2019-05-11 07:18:03, Epoch : 1, Step : 7457, Training Loss : 0.12589, Training Acc : 0.961, Run Time : 5.68
INFO:root:2019-05-11 07:18:07, Epoch : 1, Step : 7458, Training Loss : 0.10887, Training Acc : 0.972, Run Time : 4.14
INFO:root:2019-05-11 07:18:37, Epoch : 1, Step : 7459, Training Loss : 0.12413, Training Acc : 0.956, Run Time : 29.27
INFO:root:2019-05-11 07:18:42, Epoch : 1, Step : 7460, Training Loss : 0.27128, Training Acc : 0.894, Run Time : 5.51
INFO:root:2019-05-11 07:18:43, Epoch : 1, Step : 7461, Training Loss : 0.03509, Training Acc : 1.000, Run Time : 0.43
INFO:root:2019-05-11 07:18:44, Epoch : 1, Step : 7462, Training Loss : 0.08393, Training Acc : 0.978, Run Time : 1.58
INFO:root:2019-05-11 07:18:56, Epoch : 1, Step : 7463, Training Loss : 0.09017, Training Acc : 0.983, Run Time : 11.84
INFO:root:2019-05-11 07:18:57, Epoch : 1, Step : 7464, Training Loss : 0.13894, Training Acc : 0.972, Run Time : 0.54
INFO:root:2019-05-11 07:19:08, Epoch : 1, Step : 7465, Training Loss : 0.25157, Training Acc : 0.906, Run Time : 11.83
INFO:root:2019-05-11 07:19:09, Epoch : 1, Step : 7466, Training Loss : 0.31273, Training Acc : 0.872, Run Time : 0.42
INFO:root:2019-05-11 07:19:09, Epoch : 1, Step : 7467, Training Loss : 0.63392, Training Acc : 0.806, Run Time : 0.50
INFO:root:2019-05-11 07:19:21, Epoch : 1, Step : 7468, Training Loss : 0.28605, Training Acc : 0.900, Run Time : 11.78
INFO:root:2019-05-11 07:19:23, Epoch : 1, Step : 7469, Training Loss : 0.33412, Training Acc : 0.889, Run Time : 2.22
INFO:root:2019-05-11 07:19:34, Epoch : 1, Step : 7470, Training Loss : 0.16622, Training Acc : 0.922, Run Time : 10.38
INFO:root:2019-05-11 07:19:34, Epoch : 1, Step : 7471, Training Loss : 0.33442, Training Acc : 0.861, Run Time : 0.44
INFO:root:2019-05-11 07:19:35, Epoch : 1, Step : 7472, Training Loss : 0.35892, Training Acc : 0.878, Run Time : 0.44
INFO:root:2019-05-11 07:19:36, Epoch : 1, Step : 7473, Training Loss : 0.28439, Training Acc : 0.894, Run Time : 1.66
INFO:root:2019-05-11 07:19:51, Epoch : 1, Step : 7474, Training Loss : 0.27802, Training Acc : 0.889, Run Time : 14.70
INFO:root:2019-05-11 07:19:53, Epoch : 1, Step : 7475, Training Loss : 0.25930, Training Acc : 0.906, Run Time : 1.71
INFO:root:2019-05-11 07:19:53, Epoch : 1, Step : 7476, Training Loss : 0.28102, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-11 07:19:55, Epoch : 1, Step : 7477, Training Loss : 0.32337, Training Acc : 0.872, Run Time : 2.14
INFO:root:2019-05-11 07:20:14, Epoch : 1, Step : 7478, Training Loss : 0.23796, Training Acc : 0.917, Run Time : 19.16
INFO:root:2019-05-11 07:20:16, Epoch : 1, Step : 7479, Training Loss : 0.55113, Training Acc : 0.783, Run Time : 1.47
INFO:root:2019-05-11 07:20:16, Epoch : 1, Step : 7480, Training Loss : 0.37472, Training Acc : 0.861, Run Time : 0.41
INFO:root:2019-05-11 07:20:31, Epoch : 1, Step : 7481, Training Loss : 0.30462, Training Acc : 0.856, Run Time : 14.57
INFO:root:2019-05-11 07:20:49, Epoch : 1, Step : 7482, Training Loss : 0.28490, Training Acc : 0.889, Run Time : 18.60
INFO:root:2019-05-11 07:21:42, Epoch : 1, Step : 7483, Training Loss : 0.29829, Training Acc : 0.894, Run Time : 53.01
INFO:root:2019-05-11 07:21:48, Epoch : 1, Step : 7484, Training Loss : 0.19819, Training Acc : 0.933, Run Time : 5.64
INFO:root:2019-05-11 07:21:49, Epoch : 1, Step : 7485, Training Loss : 0.23441, Training Acc : 0.872, Run Time : 0.54
INFO:root:2019-05-11 07:22:03, Epoch : 1, Step : 7486, Training Loss : 0.19119, Training Acc : 0.911, Run Time : 14.03
INFO:root:2019-05-11 07:22:03, Epoch : 1, Step : 7487, Training Loss : 0.22418, Training Acc : 0.906, Run Time : 0.89
INFO:root:2019-05-11 07:22:05, Epoch : 1, Step : 7488, Training Loss : 0.27323, Training Acc : 0.906, Run Time : 1.54
INFO:root:2019-05-11 07:22:15, Epoch : 1, Step : 7489, Training Loss : 0.14497, Training Acc : 0.950, Run Time : 10.36
INFO:root:2019-05-11 07:22:16, Epoch : 1, Step : 7490, Training Loss : 0.24147, Training Acc : 0.883, Run Time : 0.47
INFO:root:2019-05-11 07:22:16, Epoch : 1, Step : 7491, Training Loss : 0.20377, Training Acc : 0.911, Run Time : 0.40
INFO:root:2019-05-11 07:22:18, Epoch : 1, Step : 7492, Training Loss : 0.26612, Training Acc : 0.878, Run Time : 2.17
INFO:root:2019-05-11 07:22:29, Epoch : 1, Step : 7493, Training Loss : 0.17007, Training Acc : 0.944, Run Time : 10.95
INFO:root:2019-05-11 07:22:30, Epoch : 1, Step : 7494, Training Loss : 0.18958, Training Acc : 0.922, Run Time : 0.59
INFO:root:2019-05-11 07:22:32, Epoch : 1, Step : 7495, Training Loss : 0.13126, Training Acc : 0.961, Run Time : 1.77
INFO:root:2019-05-11 07:22:53, Epoch : 1, Step : 7496, Training Loss : 0.10697, Training Acc : 0.961, Run Time : 21.37
INFO:root:2019-05-11 07:22:55, Epoch : 1, Step : 7497, Training Loss : 0.11102, Training Acc : 0.961, Run Time : 2.04
INFO:root:2019-05-11 07:22:56, Epoch : 1, Step : 7498, Training Loss : 0.14184, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-11 07:23:12, Epoch : 1, Step : 7499, Training Loss : 0.21466, Training Acc : 0.911, Run Time : 16.60
INFO:root:2019-05-11 07:24:15, Epoch : 1, Step : 7500, Training Loss : 0.14693, Training Acc : 0.939, Run Time : 63.23
INFO:root:2019-05-11 07:24:34, Epoch : 1, Step : 7501, Training Loss : 0.16645, Training Acc : 0.950, Run Time : 18.47
INFO:root:2019-05-11 07:24:45, Epoch : 1, Step : 7502, Training Loss : 0.26946, Training Acc : 0.900, Run Time : 11.43
INFO:root:2019-05-11 07:25:00, Epoch : 1, Step : 7503, Training Loss : 0.25791, Training Acc : 0.883, Run Time : 14.76
INFO:root:2019-05-11 07:25:11, Epoch : 1, Step : 7504, Training Loss : 0.31785, Training Acc : 0.867, Run Time : 10.47
INFO:root:2019-05-11 07:25:27, Epoch : 1, Step : 7505, Training Loss : 0.20122, Training Acc : 0.939, Run Time : 16.19
INFO:root:2019-05-11 07:25:29, Epoch : 1, Step : 7506, Training Loss : 0.18384, Training Acc : 0.933, Run Time : 1.97
INFO:root:2019-05-11 07:25:29, Epoch : 1, Step : 7507, Training Loss : 0.25072, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-11 07:25:30, Epoch : 1, Step : 7508, Training Loss : 0.11348, Training Acc : 0.967, Run Time : 1.22
INFO:root:2019-05-11 07:25:41, Epoch : 1, Step : 7509, Training Loss : 0.09877, Training Acc : 0.956, Run Time : 11.12
INFO:root:2019-05-11 07:25:55, Epoch : 1, Step : 7510, Training Loss : 0.22293, Training Acc : 0.922, Run Time : 13.92
INFO:root:2019-05-11 07:25:57, Epoch : 1, Step : 7511, Training Loss : 0.19252, Training Acc : 0.922, Run Time : 1.83
INFO:root:2019-05-11 07:25:58, Epoch : 1, Step : 7512, Training Loss : 0.28015, Training Acc : 0.878, Run Time : 1.35
INFO:root:2019-05-11 07:26:29, Epoch : 1, Step : 7513, Training Loss : 0.31820, Training Acc : 0.833, Run Time : 31.00
INFO:root:2019-05-11 07:26:31, Epoch : 1, Step : 7514, Training Loss : 0.19732, Training Acc : 0.922, Run Time : 1.57
INFO:root:2019-05-11 07:26:32, Epoch : 1, Step : 7515, Training Loss : 0.21756, Training Acc : 0.900, Run Time : 0.98
INFO:root:2019-05-11 07:26:42, Epoch : 1, Step : 7516, Training Loss : 0.12728, Training Acc : 0.956, Run Time : 9.76
INFO:root:2019-05-11 07:26:43, Epoch : 1, Step : 7517, Training Loss : 0.19900, Training Acc : 0.922, Run Time : 0.92
INFO:root:2019-05-11 07:26:56, Epoch : 1, Step : 7518, Training Loss : 0.16018, Training Acc : 0.950, Run Time : 13.28
INFO:root:2019-05-11 07:26:58, Epoch : 1, Step : 7519, Training Loss : 0.21057, Training Acc : 0.917, Run Time : 1.83
INFO:root:2019-05-11 07:27:10, Epoch : 1, Step : 7520, Training Loss : 0.23848, Training Acc : 0.906, Run Time : 12.34
INFO:root:2019-05-11 07:27:12, Epoch : 1, Step : 7521, Training Loss : 0.42090, Training Acc : 0.817, Run Time : 2.04
INFO:root:2019-05-11 07:27:22, Epoch : 1, Step : 7522, Training Loss : 0.25111, Training Acc : 0.889, Run Time : 9.88
INFO:root:2019-05-11 07:27:23, Epoch : 1, Step : 7523, Training Loss : 0.11531, Training Acc : 0.961, Run Time : 0.46
INFO:root:2019-05-11 07:27:25, Epoch : 1, Step : 7524, Training Loss : 0.08010, Training Acc : 0.972, Run Time : 2.33
INFO:root:2019-05-11 07:27:46, Epoch : 1, Step : 7525, Training Loss : 0.21871, Training Acc : 0.911, Run Time : 21.25
INFO:root:2019-05-11 07:27:48, Epoch : 1, Step : 7526, Training Loss : 0.10771, Training Acc : 0.967, Run Time : 1.73
INFO:root:2019-05-11 07:27:48, Epoch : 1, Step : 7527, Training Loss : 0.14748, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-11 07:28:00, Epoch : 1, Step : 7528, Training Loss : 0.17212, Training Acc : 0.928, Run Time : 11.45
INFO:root:2019-05-11 07:28:01, Epoch : 1, Step : 7529, Training Loss : 0.15121, Training Acc : 0.956, Run Time : 0.91
INFO:root:2019-05-11 07:28:03, Epoch : 1, Step : 7530, Training Loss : 0.17409, Training Acc : 0.939, Run Time : 2.10
INFO:root:2019-05-11 07:28:19, Epoch : 1, Step : 7531, Training Loss : 0.28510, Training Acc : 0.894, Run Time : 16.70
INFO:root:2019-05-11 07:28:31, Epoch : 1, Step : 7532, Training Loss : 0.28750, Training Acc : 0.878, Run Time : 11.47
INFO:root:2019-05-11 07:28:51, Epoch : 1, Step : 7533, Training Loss : 0.36763, Training Acc : 0.833, Run Time : 19.88
INFO:root:2019-05-11 07:28:53, Epoch : 1, Step : 7534, Training Loss : 0.32372, Training Acc : 0.883, Run Time : 2.07
INFO:root:2019-05-11 07:28:53, Epoch : 1, Step : 7535, Training Loss : 0.30245, Training Acc : 0.861, Run Time : 0.40
INFO:root:2019-05-11 07:28:54, Epoch : 1, Step : 7536, Training Loss : 0.19025, Training Acc : 0.922, Run Time : 1.19
INFO:root:2019-05-11 07:29:09, Epoch : 1, Step : 7537, Training Loss : 0.15922, Training Acc : 0.922, Run Time : 14.69
INFO:root:2019-05-11 07:29:11, Epoch : 1, Step : 7538, Training Loss : 0.14767, Training Acc : 0.944, Run Time : 2.08
INFO:root:2019-05-11 07:29:12, Epoch : 1, Step : 7539, Training Loss : 0.14830, Training Acc : 0.956, Run Time : 0.40
INFO:root:2019-05-11 07:29:13, Epoch : 1, Step : 7540, Training Loss : 0.23404, Training Acc : 0.889, Run Time : 1.50
INFO:root:2019-05-11 07:29:44, Epoch : 1, Step : 7541, Training Loss : 0.19735, Training Acc : 0.900, Run Time : 30.46
INFO:root:2019-05-11 07:29:46, Epoch : 1, Step : 7542, Training Loss : 0.38972, Training Acc : 0.844, Run Time : 2.65
INFO:root:2019-05-11 07:29:49, Epoch : 1, Step : 7543, Training Loss : 0.21370, Training Acc : 0.944, Run Time : 2.49
INFO:root:2019-05-11 07:30:06, Epoch : 1, Step : 7544, Training Loss : 0.34160, Training Acc : 0.872, Run Time : 16.87
INFO:root:2019-05-11 07:30:25, Epoch : 1, Step : 7545, Training Loss : 0.55912, Training Acc : 0.800, Run Time : 19.67
INFO:root:2019-05-11 07:30:34, Epoch : 1, Step : 7546, Training Loss : 0.52748, Training Acc : 0.767, Run Time : 8.34
INFO:root:2019-05-11 07:30:34, Epoch : 1, Step : 7547, Training Loss : 0.53952, Training Acc : 0.789, Run Time : 0.69
INFO:root:2019-05-11 07:30:36, Epoch : 1, Step : 7548, Training Loss : 0.36923, Training Acc : 0.800, Run Time : 2.18
INFO:root:2019-05-11 07:31:05, Epoch : 1, Step : 7549, Training Loss : 0.23447, Training Acc : 0.922, Run Time : 28.27
INFO:root:2019-05-11 07:31:13, Epoch : 1, Step : 7550, Training Loss : 0.14825, Training Acc : 0.933, Run Time : 8.35
INFO:root:2019-05-11 07:31:15, Epoch : 1, Step : 7551, Training Loss : 0.22431, Training Acc : 0.894, Run Time : 1.56
INFO:root:2019-05-11 07:31:36, Epoch : 1, Step : 7552, Training Loss : 0.33182, Training Acc : 0.844, Run Time : 21.61
INFO:root:2019-05-11 07:31:38, Epoch : 1, Step : 7553, Training Loss : 0.36759, Training Acc : 0.811, Run Time : 1.64
INFO:root:2019-05-11 07:31:38, Epoch : 1, Step : 7554, Training Loss : 0.57678, Training Acc : 0.806, Run Time : 0.44
INFO:root:2019-05-11 07:32:16, Epoch : 1, Step : 7555, Training Loss : 0.23020, Training Acc : 0.900, Run Time : 37.41
INFO:root:2019-05-11 07:32:57, Epoch : 1, Step : 7556, Training Loss : 0.19121, Training Acc : 0.900, Run Time : 41.39
INFO:root:2019-05-11 07:33:13, Epoch : 1, Step : 7557, Training Loss : 0.07248, Training Acc : 0.983, Run Time : 15.69
INFO:root:2019-05-11 07:33:21, Epoch : 1, Step : 7558, Training Loss : 0.30371, Training Acc : 0.850, Run Time : 7.92
INFO:root:2019-05-11 07:33:44, Epoch : 1, Step : 7559, Training Loss : 0.16831, Training Acc : 0.961, Run Time : 23.62
INFO:root:2019-05-11 07:33:51, Epoch : 1, Step : 7560, Training Loss : 0.41840, Training Acc : 0.856, Run Time : 6.62
INFO:root:2019-05-11 07:33:51, Epoch : 1, Step : 7561, Training Loss : 0.10416, Training Acc : 0.967, Run Time : 0.39
INFO:root:2019-05-11 07:33:53, Epoch : 1, Step : 7562, Training Loss : 0.06334, Training Acc : 0.983, Run Time : 1.91
INFO:root:2019-05-11 07:34:08, Epoch : 1, Step : 7563, Training Loss : 0.12332, Training Acc : 0.961, Run Time : 14.98
INFO:root:2019-05-11 07:34:22, Epoch : 1, Step : 7564, Training Loss : 0.13564, Training Acc : 0.928, Run Time : 13.85
INFO:root:2019-05-11 07:34:42, Epoch : 1, Step : 7565, Training Loss : 0.18361, Training Acc : 0.917, Run Time : 19.97
INFO:root:2019-05-11 07:34:49, Epoch : 1, Step : 7566, Training Loss : 0.13235, Training Acc : 0.967, Run Time : 6.75
INFO:root:2019-05-11 07:35:13, Epoch : 1, Step : 7567, Training Loss : 0.17747, Training Acc : 0.922, Run Time : 24.62
INFO:root:2019-05-11 07:35:15, Epoch : 1, Step : 7568, Training Loss : 0.14252, Training Acc : 0.950, Run Time : 1.28
INFO:root:2019-05-11 07:35:16, Epoch : 1, Step : 7569, Training Loss : 0.20695, Training Acc : 0.922, Run Time : 1.14
INFO:root:2019-05-11 07:35:27, Epoch : 1, Step : 7570, Training Loss : 0.57195, Training Acc : 0.767, Run Time : 10.99
INFO:root:2019-05-11 07:35:40, Epoch : 1, Step : 7571, Training Loss : 0.46215, Training Acc : 0.794, Run Time : 13.20
INFO:root:2019-05-11 07:35:42, Epoch : 1, Step : 7572, Training Loss : 0.55609, Training Acc : 0.744, Run Time : 1.76
INFO:root:2019-05-11 07:35:57, Epoch : 1, Step : 7573, Training Loss : 0.13452, Training Acc : 0.967, Run Time : 15.09
INFO:root:2019-05-11 07:36:09, Epoch : 1, Step : 7574, Training Loss : 0.18306, Training Acc : 0.933, Run Time : 11.74
INFO:root:2019-05-11 07:36:24, Epoch : 1, Step : 7575, Training Loss : 0.15456, Training Acc : 0.944, Run Time : 15.80
INFO:root:2019-05-11 07:36:37, Epoch : 1, Step : 7576, Training Loss : 0.13442, Training Acc : 0.961, Run Time : 12.33
INFO:root:2019-05-11 07:36:58, Epoch : 1, Step : 7577, Training Loss : 0.11464, Training Acc : 0.950, Run Time : 20.74
INFO:root:2019-05-11 07:37:05, Epoch : 1, Step : 7578, Training Loss : 0.25711, Training Acc : 0.906, Run Time : 7.12
INFO:root:2019-05-11 07:37:53, Epoch : 1, Step : 7579, Training Loss : 0.20218, Training Acc : 0.900, Run Time : 47.90
INFO:root:2019-05-11 07:38:03, Epoch : 1, Step : 7580, Training Loss : 0.18547, Training Acc : 0.917, Run Time : 10.10
INFO:root:2019-05-11 07:38:29, Epoch : 1, Step : 7581, Training Loss : 0.23908, Training Acc : 0.883, Run Time : 26.70
INFO:root:2019-05-11 07:38:36, Epoch : 1, Step : 7582, Training Loss : 0.18464, Training Acc : 0.917, Run Time : 6.34
INFO:root:2019-05-11 07:38:36, Epoch : 1, Step : 7583, Training Loss : 0.20285, Training Acc : 0.917, Run Time : 0.58
INFO:root:2019-05-11 07:38:48, Epoch : 1, Step : 7584, Training Loss : 0.08016, Training Acc : 0.983, Run Time : 12.10
INFO:root:2019-05-11 07:38:49, Epoch : 1, Step : 7585, Training Loss : 0.14321, Training Acc : 0.944, Run Time : 0.43
INFO:root:2019-05-11 07:38:51, Epoch : 1, Step : 7586, Training Loss : 0.14943, Training Acc : 0.944, Run Time : 1.88
INFO:root:2019-05-11 07:39:03, Epoch : 1, Step : 7587, Training Loss : 0.19275, Training Acc : 0.917, Run Time : 11.87
INFO:root:2019-05-11 07:39:04, Epoch : 1, Step : 7588, Training Loss : 0.26174, Training Acc : 0.900, Run Time : 1.63
INFO:root:2019-05-11 07:39:14, Epoch : 1, Step : 7589, Training Loss : 0.19155, Training Acc : 0.911, Run Time : 10.24
INFO:root:2019-05-11 07:39:15, Epoch : 1, Step : 7590, Training Loss : 0.17376, Training Acc : 0.928, Run Time : 0.66
INFO:root:2019-05-11 07:39:17, Epoch : 1, Step : 7591, Training Loss : 0.28326, Training Acc : 0.883, Run Time : 1.96
INFO:root:2019-05-11 07:39:27, Epoch : 1, Step : 7592, Training Loss : 0.52006, Training Acc : 0.767, Run Time : 10.31
INFO:root:2019-05-11 07:39:28, Epoch : 1, Step : 7593, Training Loss : 0.40615, Training Acc : 0.828, Run Time : 0.80
INFO:root:2019-05-11 07:39:30, Epoch : 1, Step : 7594, Training Loss : 0.32091, Training Acc : 0.872, Run Time : 1.92
INFO:root:2019-05-11 07:40:21, Epoch : 1, Step : 7595, Training Loss : 0.47849, Training Acc : 0.811, Run Time : 50.53
INFO:root:2019-05-11 07:40:48, Epoch : 1, Step : 7596, Training Loss : 0.26764, Training Acc : 0.883, Run Time : 26.94
INFO:root:2019-05-11 07:41:13, Epoch : 1, Step : 7597, Training Loss : 0.25371, Training Acc : 0.861, Run Time : 25.51
INFO:root:2019-05-11 07:41:15, Epoch : 1, Step : 7598, Training Loss : 0.23758, Training Acc : 0.894, Run Time : 1.50
INFO:root:2019-05-11 07:41:15, Epoch : 1, Step : 7599, Training Loss : 0.47568, Training Acc : 0.783, Run Time : 0.47
INFO:root:2019-05-11 07:41:29, Epoch : 1, Step : 7600, Training Loss : 0.60752, Training Acc : 0.756, Run Time : 14.01
INFO:root:2019-05-11 07:41:42, Epoch : 1, Step : 7601, Training Loss : 0.25132, Training Acc : 0.883, Run Time : 13.04
INFO:root:2019-05-11 07:41:43, Epoch : 1, Step : 7602, Training Loss : 0.37687, Training Acc : 0.839, Run Time : 0.55
INFO:root:2019-05-11 07:41:44, Epoch : 1, Step : 7603, Training Loss : 0.49734, Training Acc : 0.794, Run Time : 1.57
INFO:root:2019-05-11 07:42:03, Epoch : 1, Step : 7604, Training Loss : 0.33792, Training Acc : 0.883, Run Time : 18.61
INFO:root:2019-05-11 07:42:04, Epoch : 1, Step : 7605, Training Loss : 0.74819, Training Acc : 0.750, Run Time : 1.42
INFO:root:2019-05-11 07:42:05, Epoch : 1, Step : 7606, Training Loss : 0.57728, Training Acc : 0.794, Run Time : 0.97
INFO:root:2019-05-11 07:42:16, Epoch : 1, Step : 7607, Training Loss : 0.45014, Training Acc : 0.794, Run Time : 10.44
INFO:root:2019-05-11 07:42:27, Epoch : 1, Step : 7608, Training Loss : 0.20913, Training Acc : 0.917, Run Time : 10.98
INFO:root:2019-05-11 07:42:28, Epoch : 1, Step : 7609, Training Loss : 0.21000, Training Acc : 0.928, Run Time : 1.38
INFO:root:2019-05-11 07:42:28, Epoch : 1, Step : 7610, Training Loss : 0.18309, Training Acc : 0.944, Run Time : 0.46
INFO:root:2019-05-11 07:42:30, Epoch : 1, Step : 7611, Training Loss : 0.40796, Training Acc : 0.839, Run Time : 1.27
INFO:root:2019-05-11 07:42:50, Epoch : 1, Step : 7612, Training Loss : 0.44260, Training Acc : 0.800, Run Time : 20.66
INFO:root:2019-05-11 07:43:15, Epoch : 1, Step : 7613, Training Loss : 0.46098, Training Acc : 0.778, Run Time : 24.40
INFO:root:2019-05-11 07:43:21, Epoch : 1, Step : 7614, Training Loss : 0.39952, Training Acc : 0.833, Run Time : 5.84
INFO:root:2019-05-11 07:43:21, Epoch : 1, Step : 7615, Training Loss : 0.31123, Training Acc : 0.883, Run Time : 0.60
INFO:root:2019-05-11 07:43:45, Epoch : 1, Step : 7616, Training Loss : 0.16274, Training Acc : 0.944, Run Time : 23.61
INFO:root:2019-05-11 07:43:47, Epoch : 1, Step : 7617, Training Loss : 0.15862, Training Acc : 0.967, Run Time : 2.59
INFO:root:2019-05-11 07:44:01, Epoch : 1, Step : 7618, Training Loss : 0.24700, Training Acc : 0.889, Run Time : 13.86
INFO:root:2019-05-11 07:44:03, Epoch : 1, Step : 7619, Training Loss : 0.22265, Training Acc : 0.894, Run Time : 2.02
INFO:root:2019-05-11 07:44:14, Epoch : 1, Step : 7620, Training Loss : 0.29972, Training Acc : 0.856, Run Time : 10.96
INFO:root:2019-05-11 07:44:15, Epoch : 1, Step : 7621, Training Loss : 0.57060, Training Acc : 0.728, Run Time : 0.66
INFO:root:2019-05-11 07:44:17, Epoch : 1, Step : 7622, Training Loss : 0.38967, Training Acc : 0.844, Run Time : 2.09
INFO:root:2019-05-11 07:44:28, Epoch : 1, Step : 7623, Training Loss : 0.34155, Training Acc : 0.817, Run Time : 11.39
INFO:root:2019-05-11 07:44:29, Epoch : 1, Step : 7624, Training Loss : 0.28068, Training Acc : 0.878, Run Time : 0.42
INFO:root:2019-05-11 07:44:29, Epoch : 1, Step : 7625, Training Loss : 0.22947, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-11 07:44:31, Epoch : 1, Step : 7626, Training Loss : 0.26074, Training Acc : 0.883, Run Time : 1.70
INFO:root:2019-05-11 07:44:41, Epoch : 1, Step : 7627, Training Loss : 0.19697, Training Acc : 0.933, Run Time : 10.32
INFO:root:2019-05-11 07:44:42, Epoch : 1, Step : 7628, Training Loss : 0.21936, Training Acc : 0.900, Run Time : 0.66
INFO:root:2019-05-11 07:44:44, Epoch : 1, Step : 7629, Training Loss : 0.20544, Training Acc : 0.950, Run Time : 1.86
INFO:root:2019-05-11 07:44:55, Epoch : 1, Step : 7630, Training Loss : 0.22959, Training Acc : 0.911, Run Time : 11.30
INFO:root:2019-05-11 07:44:56, Epoch : 1, Step : 7631, Training Loss : 0.16665, Training Acc : 0.933, Run Time : 0.92
INFO:root:2019-05-11 07:45:08, Epoch : 1, Step : 7632, Training Loss : 0.29648, Training Acc : 0.850, Run Time : 11.90
INFO:root:2019-05-11 07:45:09, Epoch : 1, Step : 7633, Training Loss : 0.45423, Training Acc : 0.750, Run Time : 0.91
INFO:root:2019-05-11 07:45:23, Epoch : 1, Step : 7634, Training Loss : 0.41989, Training Acc : 0.828, Run Time : 14.11
INFO:root:2019-05-11 07:46:33, Epoch : 1, Step : 7635, Training Loss : 0.33577, Training Acc : 0.839, Run Time : 70.02
INFO:root:2019-05-11 07:47:05, Epoch : 1, Step : 7636, Training Loss : 0.47277, Training Acc : 0.772, Run Time : 32.32
INFO:root:2019-05-11 07:47:07, Epoch : 1, Step : 7637, Training Loss : 0.19466, Training Acc : 0.922, Run Time : 1.68
INFO:root:2019-05-11 07:47:07, Epoch : 1, Step : 7638, Training Loss : 0.13660, Training Acc : 0.961, Run Time : 0.41
INFO:root:2019-05-11 07:47:09, Epoch : 1, Step : 7639, Training Loss : 0.14615, Training Acc : 0.933, Run Time : 1.41
INFO:root:2019-05-11 07:47:37, Epoch : 1, Step : 7640, Training Loss : 0.12525, Training Acc : 0.961, Run Time : 28.08
INFO:root:2019-05-11 07:48:36, Epoch : 1, Step : 7641, Training Loss : 0.24665, Training Acc : 0.928, Run Time : 58.66
INFO:root:2019-05-11 07:49:12, Epoch : 1, Step : 7642, Training Loss : 0.39384, Training Acc : 0.861, Run Time : 36.06
INFO:root:2019-05-11 07:49:28, Epoch : 1, Step : 7643, Training Loss : 0.36530, Training Acc : 0.844, Run Time : 16.41
INFO:root:2019-05-11 07:49:28, Epoch : 1, Step : 7644, Training Loss : 0.29504, Training Acc : 0.872, Run Time : 0.50
INFO:root:2019-05-11 07:49:29, Epoch : 1, Step : 7645, Training Loss : 0.09625, Training Acc : 0.961, Run Time : 0.41
INFO:root:2019-05-11 07:49:43, Epoch : 1, Step : 7646, Training Loss : 0.18019, Training Acc : 0.922, Run Time : 13.95
INFO:root:2019-05-11 07:49:45, Epoch : 1, Step : 7647, Training Loss : 0.12633, Training Acc : 0.956, Run Time : 1.92
INFO:root:2019-05-11 07:49:57, Epoch : 1, Step : 7648, Training Loss : 0.47751, Training Acc : 0.828, Run Time : 12.50
INFO:root:2019-05-11 07:49:58, Epoch : 1, Step : 7649, Training Loss : 0.29236, Training Acc : 0.889, Run Time : 0.62
INFO:root:2019-05-11 07:50:01, Epoch : 1, Step : 7650, Training Loss : 0.48310, Training Acc : 0.806, Run Time : 3.59
INFO:root:2019-05-11 07:50:10, Epoch : 1, Step : 7651, Training Loss : 0.21022, Training Acc : 0.917, Run Time : 8.74
INFO:root:2019-05-11 07:50:42, Epoch : 1, Step : 7652, Training Loss : 0.33475, Training Acc : 0.872, Run Time : 31.48
INFO:root:2019-05-11 07:50:43, Epoch : 1, Step : 7653, Training Loss : 0.20453, Training Acc : 0.917, Run Time : 1.56
INFO:root:2019-05-11 07:50:44, Epoch : 1, Step : 7654, Training Loss : 0.44112, Training Acc : 0.794, Run Time : 0.45
INFO:root:2019-05-11 07:51:04, Epoch : 1, Step : 7655, Training Loss : 0.40421, Training Acc : 0.817, Run Time : 20.79
INFO:root:2019-05-11 07:51:07, Epoch : 1, Step : 7656, Training Loss : 0.32318, Training Acc : 0.867, Run Time : 2.29
INFO:root:2019-05-11 07:51:07, Epoch : 1, Step : 7657, Training Loss : 0.24297, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-11 07:51:18, Epoch : 1, Step : 7658, Training Loss : 0.19787, Training Acc : 0.933, Run Time : 10.52
INFO:root:2019-05-11 07:51:19, Epoch : 1, Step : 7659, Training Loss : 0.59231, Training Acc : 0.772, Run Time : 0.99
INFO:root:2019-05-11 07:51:20, Epoch : 1, Step : 7660, Training Loss : 0.53248, Training Acc : 0.833, Run Time : 1.60
INFO:root:2019-05-11 07:51:31, Epoch : 1, Step : 7661, Training Loss : 0.55914, Training Acc : 0.800, Run Time : 10.73
INFO:root:2019-05-11 07:51:34, Epoch : 1, Step : 7662, Training Loss : 1.01571, Training Acc : 0.717, Run Time : 2.54
INFO:root:2019-05-11 07:52:06, Epoch : 1, Step : 7663, Training Loss : 0.78417, Training Acc : 0.800, Run Time : 32.90
INFO:root:2019-05-11 07:52:24, Epoch : 1, Step : 7664, Training Loss : 0.67331, Training Acc : 0.800, Run Time : 17.94
INFO:root:2019-05-11 07:52:32, Epoch : 1, Step : 7665, Training Loss : 0.63533, Training Acc : 0.778, Run Time : 7.22
INFO:root:2019-05-11 07:52:43, Epoch : 1, Step : 7666, Training Loss : 0.26656, Training Acc : 0.894, Run Time : 11.73
INFO:root:2019-05-11 07:52:44, Epoch : 1, Step : 7667, Training Loss : 0.31398, Training Acc : 0.856, Run Time : 0.66
INFO:root:2019-05-11 07:52:44, Epoch : 1, Step : 7668, Training Loss : 0.38539, Training Acc : 0.794, Run Time : 0.38
INFO:root:2019-05-11 07:53:04, Epoch : 1, Step : 7669, Training Loss : 0.33300, Training Acc : 0.844, Run Time : 19.31
INFO:root:2019-05-11 07:53:06, Epoch : 1, Step : 7670, Training Loss : 0.27959, Training Acc : 0.861, Run Time : 2.44
INFO:root:2019-05-11 07:53:07, Epoch : 1, Step : 7671, Training Loss : 0.34586, Training Acc : 0.806, Run Time : 0.40
INFO:root:2019-05-11 07:53:07, Epoch : 1, Step : 7672, Training Loss : 0.35951, Training Acc : 0.867, Run Time : 0.53
INFO:root:2019-05-11 07:53:18, Epoch : 1, Step : 7673, Training Loss : 0.42319, Training Acc : 0.806, Run Time : 10.75
INFO:root:2019-05-11 07:53:30, Epoch : 1, Step : 7674, Training Loss : 0.34004, Training Acc : 0.822, Run Time : 11.81
INFO:root:2019-05-11 07:53:31, Epoch : 1, Step : 7675, Training Loss : 0.35950, Training Acc : 0.806, Run Time : 1.03
INFO:root:2019-05-11 07:53:32, Epoch : 1, Step : 7676, Training Loss : 0.35716, Training Acc : 0.822, Run Time : 0.91
INFO:root:2019-05-11 07:53:43, Epoch : 1, Step : 7677, Training Loss : 0.29541, Training Acc : 0.872, Run Time : 11.46
INFO:root:2019-05-11 07:53:43, Epoch : 1, Step : 7678, Training Loss : 0.24633, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-11 07:53:44, Epoch : 1, Step : 7679, Training Loss : 0.23211, Training Acc : 0.922, Run Time : 0.45
INFO:root:2019-05-11 07:53:59, Epoch : 1, Step : 7680, Training Loss : 0.20791, Training Acc : 0.911, Run Time : 14.72
INFO:root:2019-05-11 07:54:06, Epoch : 1, Step : 7681, Training Loss : 0.12369, Training Acc : 0.983, Run Time : 7.11
INFO:root:2019-05-11 07:54:45, Epoch : 1, Step : 7682, Training Loss : 0.22728, Training Acc : 0.900, Run Time : 39.62
INFO:root:2019-05-11 07:54:50, Epoch : 1, Step : 7683, Training Loss : 0.13098, Training Acc : 0.950, Run Time : 4.79
INFO:root:2019-05-11 07:54:51, Epoch : 1, Step : 7684, Training Loss : 0.18163, Training Acc : 0.933, Run Time : 0.55
INFO:root:2019-05-11 07:55:22, Epoch : 1, Step : 7685, Training Loss : 0.22933, Training Acc : 0.906, Run Time : 31.68
INFO:root:2019-05-11 07:55:25, Epoch : 1, Step : 7686, Training Loss : 0.15047, Training Acc : 0.944, Run Time : 2.47
INFO:root:2019-05-11 07:56:03, Epoch : 1, Step : 7687, Training Loss : 0.21552, Training Acc : 0.900, Run Time : 37.71
INFO:root:2019-05-11 07:56:08, Epoch : 1, Step : 7688, Training Loss : 0.17265, Training Acc : 0.944, Run Time : 5.56
INFO:root:2019-05-11 07:56:09, Epoch : 1, Step : 7689, Training Loss : 0.21386, Training Acc : 0.894, Run Time : 0.58
INFO:root:2019-05-11 07:56:21, Epoch : 1, Step : 7690, Training Loss : 0.24184, Training Acc : 0.917, Run Time : 12.80
INFO:root:2019-05-11 07:56:24, Epoch : 1, Step : 7691, Training Loss : 0.50437, Training Acc : 0.772, Run Time : 2.04
INFO:root:2019-05-11 07:56:36, Epoch : 1, Step : 7692, Training Loss : 0.55545, Training Acc : 0.728, Run Time : 12.36
INFO:root:2019-05-11 07:57:36, Epoch : 1, Step : 7693, Training Loss : 0.53831, Training Acc : 0.767, Run Time : 60.01
INFO:root:2019-05-11 07:57:43, Epoch : 1, Step : 7694, Training Loss : 0.35286, Training Acc : 0.850, Run Time : 6.81
INFO:root:2019-05-11 07:58:13, Epoch : 1, Step : 7695, Training Loss : 0.47083, Training Acc : 0.822, Run Time : 30.70
INFO:root:2019-05-11 07:58:27, Epoch : 1, Step : 7696, Training Loss : 0.39778, Training Acc : 0.822, Run Time : 13.77
INFO:root:2019-05-11 07:58:28, Epoch : 1, Step : 7697, Training Loss : 0.11663, Training Acc : 0.978, Run Time : 0.67
INFO:root:2019-05-11 07:58:30, Epoch : 1, Step : 7698, Training Loss : 0.29280, Training Acc : 0.872, Run Time : 1.76
INFO:root:2019-05-11 07:58:40, Epoch : 1, Step : 7699, Training Loss : 0.29072, Training Acc : 0.906, Run Time : 10.50
INFO:root:2019-05-11 07:58:41, Epoch : 1, Step : 7700, Training Loss : 0.23199, Training Acc : 0.917, Run Time : 0.75
INFO:root:2019-05-11 07:59:02, Epoch : 1, Step : 7701, Training Loss : 0.16619, Training Acc : 0.944, Run Time : 21.31
INFO:root:2019-05-11 07:59:14, Epoch : 1, Step : 7702, Training Loss : 0.23845, Training Acc : 0.889, Run Time : 12.12
INFO:root:2019-05-11 07:59:57, Epoch : 1, Step : 7703, Training Loss : 0.19084, Training Acc : 0.906, Run Time : 42.86
INFO:root:2019-05-11 08:00:04, Epoch : 1, Step : 7704, Training Loss : 0.24352, Training Acc : 0.906, Run Time : 6.89
INFO:root:2019-05-11 08:00:05, Epoch : 1, Step : 7705, Training Loss : 0.07060, Training Acc : 0.983, Run Time : 0.57
INFO:root:2019-05-11 08:00:15, Epoch : 1, Step : 7706, Training Loss : 0.15903, Training Acc : 0.933, Run Time : 10.57
INFO:root:2019-05-11 08:00:17, Epoch : 1, Step : 7707, Training Loss : 0.08349, Training Acc : 0.983, Run Time : 1.44
INFO:root:2019-05-11 08:00:28, Epoch : 1, Step : 7708, Training Loss : 0.08860, Training Acc : 0.972, Run Time : 11.34
INFO:root:2019-05-11 08:00:28, Epoch : 1, Step : 7709, Training Loss : 0.10437, Training Acc : 0.967, Run Time : 0.45
INFO:root:2019-05-11 08:00:29, Epoch : 1, Step : 7710, Training Loss : 0.08955, Training Acc : 0.967, Run Time : 0.38
INFO:root:2019-05-11 08:00:30, Epoch : 1, Step : 7711, Training Loss : 0.14809, Training Acc : 0.944, Run Time : 1.71
INFO:root:2019-05-11 08:00:43, Epoch : 1, Step : 7712, Training Loss : 0.39903, Training Acc : 0.861, Run Time : 12.42
INFO:root:2019-05-11 08:00:56, Epoch : 1, Step : 7713, Training Loss : 0.64230, Training Acc : 0.711, Run Time : 12.91
INFO:root:2019-05-11 08:01:24, Epoch : 1, Step : 7714, Training Loss : 0.65509, Training Acc : 0.700, Run Time : 28.64
INFO:root:2019-05-11 08:01:30, Epoch : 1, Step : 7715, Training Loss : 0.17765, Training Acc : 0.933, Run Time : 5.90
INFO:root:2019-05-11 08:01:43, Epoch : 1, Step : 7716, Training Loss : 0.12380, Training Acc : 0.961, Run Time : 12.57
INFO:root:2019-05-11 08:01:43, Epoch : 1, Step : 7717, Training Loss : 0.35169, Training Acc : 0.867, Run Time : 0.42
INFO:root:2019-05-11 08:01:44, Epoch : 1, Step : 7718, Training Loss : 0.43824, Training Acc : 0.828, Run Time : 0.81
INFO:root:2019-05-11 08:01:57, Epoch : 1, Step : 7719, Training Loss : 0.41541, Training Acc : 0.811, Run Time : 12.94
INFO:root:2019-05-11 08:01:58, Epoch : 1, Step : 7720, Training Loss : 0.31080, Training Acc : 0.861, Run Time : 1.20
INFO:root:2019-05-11 08:02:00, Epoch : 1, Step : 7721, Training Loss : 0.22549, Training Acc : 0.928, Run Time : 1.56
INFO:root:2019-05-11 08:02:34, Epoch : 1, Step : 7722, Training Loss : 0.24440, Training Acc : 0.867, Run Time : 34.46
INFO:root:2019-05-11 08:02:40, Epoch : 1, Step : 7723, Training Loss : 0.25961, Training Acc : 0.900, Run Time : 5.48
INFO:root:2019-05-11 08:02:55, Epoch : 1, Step : 7724, Training Loss : 0.25290, Training Acc : 0.889, Run Time : 14.78
INFO:root:2019-05-11 08:03:07, Epoch : 1, Step : 7725, Training Loss : 0.18775, Training Acc : 0.911, Run Time : 12.06
INFO:root:2019-05-11 08:03:13, Epoch : 1, Step : 7726, Training Loss : 0.13681, Training Acc : 0.961, Run Time : 6.66
INFO:root:2019-05-11 08:03:15, Epoch : 1, Step : 7727, Training Loss : 0.12696, Training Acc : 0.956, Run Time : 1.81
INFO:root:2019-05-11 08:04:11, Epoch : 1, Step : 7728, Training Loss : 0.08873, Training Acc : 0.978, Run Time : 56.00
INFO:root:2019-05-11 08:04:24, Epoch : 1, Step : 7729, Training Loss : 0.19097, Training Acc : 0.922, Run Time : 13.21
INFO:root:2019-05-11 08:04:33, Epoch : 1, Step : 7730, Training Loss : 0.15078, Training Acc : 0.933, Run Time : 8.26
INFO:root:2019-05-11 08:05:18, Epoch : 1, Step : 7731, Training Loss : 0.11721, Training Acc : 0.950, Run Time : 45.81
INFO:root:2019-05-11 08:05:20, Epoch : 1, Step : 7732, Training Loss : 0.09303, Training Acc : 0.994, Run Time : 1.80
INFO:root:2019-05-11 08:05:21, Epoch : 1, Step : 7733, Training Loss : 0.09158, Training Acc : 0.972, Run Time : 0.41
INFO:root:2019-05-11 08:05:43, Epoch : 1, Step : 7734, Training Loss : 0.09494, Training Acc : 0.989, Run Time : 22.83
INFO:root:2019-05-11 08:05:56, Epoch : 1, Step : 7735, Training Loss : 0.11086, Training Acc : 0.972, Run Time : 12.48
INFO:root:2019-05-11 08:06:34, Epoch : 1, Step : 7736, Training Loss : 0.10504, Training Acc : 0.978, Run Time : 37.75
INFO:root:2019-05-11 08:06:41, Epoch : 1, Step : 7737, Training Loss : 0.11043, Training Acc : 0.956, Run Time : 7.36
INFO:root:2019-05-11 08:06:57, Epoch : 1, Step : 7738, Training Loss : 0.16328, Training Acc : 0.939, Run Time : 16.10
INFO:root:2019-05-11 08:06:59, Epoch : 1, Step : 7739, Training Loss : 0.11318, Training Acc : 0.967, Run Time : 2.04
INFO:root:2019-05-11 08:07:00, Epoch : 1, Step : 7740, Training Loss : 0.08163, Training Acc : 0.983, Run Time : 0.45
INFO:root:2019-05-11 08:07:01, Epoch : 1, Step : 7741, Training Loss : 0.11343, Training Acc : 0.967, Run Time : 1.21
INFO:root:2019-05-11 08:07:12, Epoch : 1, Step : 7742, Training Loss : 0.09402, Training Acc : 0.978, Run Time : 10.94
INFO:root:2019-05-11 08:07:12, Epoch : 1, Step : 7743, Training Loss : 0.07428, Training Acc : 0.983, Run Time : 0.56
INFO:root:2019-05-11 08:07:14, Epoch : 1, Step : 7744, Training Loss : 0.06054, Training Acc : 0.983, Run Time : 1.97
INFO:root:2019-05-11 08:07:30, Epoch : 1, Step : 7745, Training Loss : 0.13815, Training Acc : 0.933, Run Time : 16.11
INFO:root:2019-05-11 08:07:38, Epoch : 1, Step : 7746, Training Loss : 0.12952, Training Acc : 0.933, Run Time : 7.61
INFO:root:2019-05-11 08:07:40, Epoch : 1, Step : 7747, Training Loss : 0.06973, Training Acc : 0.989, Run Time : 1.73
INFO:root:2019-05-11 08:07:50, Epoch : 1, Step : 7748, Training Loss : 0.03848, Training Acc : 1.000, Run Time : 10.07
INFO:root:2019-05-11 08:07:52, Epoch : 1, Step : 7749, Training Loss : 0.03083, Training Acc : 1.000, Run Time : 2.20
INFO:root:2019-05-11 08:08:06, Epoch : 1, Step : 7750, Training Loss : 0.14407, Training Acc : 0.933, Run Time : 13.62
INFO:root:2019-05-11 08:08:09, Epoch : 1, Step : 7751, Training Loss : 0.15124, Training Acc : 0.928, Run Time : 3.35
INFO:root:2019-05-11 08:08:09, Epoch : 1, Step : 7752, Training Loss : 0.11686, Training Acc : 0.978, Run Time : 0.38
INFO:root:2019-05-11 08:08:11, Epoch : 1, Step : 7753, Training Loss : 0.15555, Training Acc : 0.939, Run Time : 1.59
INFO:root:2019-05-11 08:08:24, Epoch : 1, Step : 7754, Training Loss : 0.12566, Training Acc : 0.950, Run Time : 12.78
INFO:root:2019-05-11 08:08:36, Epoch : 1, Step : 7755, Training Loss : 0.09362, Training Acc : 0.967, Run Time : 11.86
INFO:root:2019-05-11 08:08:37, Epoch : 1, Step : 7756, Training Loss : 0.08533, Training Acc : 0.983, Run Time : 1.14
INFO:root:2019-05-11 08:08:39, Epoch : 1, Step : 7757, Training Loss : 0.08625, Training Acc : 0.978, Run Time : 1.96
INFO:root:2019-05-11 08:08:51, Epoch : 1, Step : 7758, Training Loss : 0.04254, Training Acc : 0.994, Run Time : 12.34
INFO:root:2019-05-11 08:08:55, Epoch : 1, Step : 7759, Training Loss : 0.08740, Training Acc : 0.967, Run Time : 3.87
INFO:root:2019-05-11 08:09:02, Epoch : 1, Step : 7760, Training Loss : 0.06610, Training Acc : 0.983, Run Time : 7.33
INFO:root:2019-05-11 08:09:03, Epoch : 1, Step : 7761, Training Loss : 0.07511, Training Acc : 0.983, Run Time : 0.43
INFO:root:2019-05-11 08:09:04, Epoch : 1, Step : 7762, Training Loss : 0.05012, Training Acc : 0.994, Run Time : 1.49
INFO:root:2019-05-11 08:09:32, Epoch : 1, Step : 7763, Training Loss : 0.06637, Training Acc : 0.972, Run Time : 28.01
INFO:root:2019-05-11 08:09:34, Epoch : 1, Step : 7764, Training Loss : 0.07253, Training Acc : 0.978, Run Time : 2.09
INFO:root:2019-05-11 08:09:35, Epoch : 1, Step : 7765, Training Loss : 0.10690, Training Acc : 0.972, Run Time : 0.56
INFO:root:2019-05-11 08:09:57, Epoch : 1, Step : 7766, Training Loss : 0.06316, Training Acc : 0.983, Run Time : 21.81
INFO:root:2019-05-11 08:10:02, Epoch : 1, Step : 7767, Training Loss : 0.11398, Training Acc : 0.956, Run Time : 5.43
INFO:root:2019-05-11 08:10:03, Epoch : 1, Step : 7768, Training Loss : 0.13346, Training Acc : 0.939, Run Time : 0.48
INFO:root:2019-05-11 08:10:29, Epoch : 1, Step : 7769, Training Loss : 0.04647, Training Acc : 0.994, Run Time : 26.25
INFO:root:2019-05-11 08:10:34, Epoch : 1, Step : 7770, Training Loss : 0.08815, Training Acc : 0.978, Run Time : 5.40
INFO:root:2019-05-11 08:10:40, Epoch : 1, Step : 7771, Training Loss : 0.24240, Training Acc : 0.928, Run Time : 5.45
INFO:root:2019-05-11 08:10:47, Epoch : 1, Step : 7772, Training Loss : 0.25356, Training Acc : 0.917, Run Time : 7.59
INFO:root:2019-05-11 08:11:05, Epoch : 1, Step : 7773, Training Loss : 0.17853, Training Acc : 0.933, Run Time : 17.91
INFO:root:2019-05-11 08:11:48, Epoch : 1, Step : 7774, Training Loss : 0.16394, Training Acc : 0.956, Run Time : 42.97
INFO:root:2019-05-11 08:12:03, Epoch : 1, Step : 7775, Training Loss : 0.10824, Training Acc : 0.950, Run Time : 14.51
INFO:root:2019-05-11 08:12:16, Epoch : 1, Step : 7776, Training Loss : 0.20254, Training Acc : 0.911, Run Time : 13.19
INFO:root:2019-05-11 08:12:24, Epoch : 1, Step : 7777, Training Loss : 0.16127, Training Acc : 0.933, Run Time : 8.60
INFO:root:2019-05-11 08:12:25, Epoch : 1, Step : 7778, Training Loss : 0.18124, Training Acc : 0.922, Run Time : 0.48
INFO:root:2019-05-11 08:12:27, Epoch : 1, Step : 7779, Training Loss : 0.18250, Training Acc : 0.928, Run Time : 1.86
INFO:root:2019-05-11 08:12:51, Epoch : 1, Step : 7780, Training Loss : 0.09920, Training Acc : 0.967, Run Time : 24.63
INFO:root:2019-05-11 08:12:57, Epoch : 1, Step : 7781, Training Loss : 0.25498, Training Acc : 0.883, Run Time : 5.40
INFO:root:2019-05-11 08:13:09, Epoch : 1, Step : 7782, Training Loss : 0.13032, Training Acc : 0.956, Run Time : 12.53
INFO:root:2019-05-11 08:13:11, Epoch : 1, Step : 7783, Training Loss : 0.08428, Training Acc : 0.961, Run Time : 1.62
INFO:root:2019-05-11 08:13:25, Epoch : 1, Step : 7784, Training Loss : 0.17305, Training Acc : 0.933, Run Time : 13.64
INFO:root:2019-05-11 08:13:32, Epoch : 1, Step : 7785, Training Loss : 0.39445, Training Acc : 0.861, Run Time : 7.45
INFO:root:2019-05-11 08:13:33, Epoch : 1, Step : 7786, Training Loss : 0.30804, Training Acc : 0.867, Run Time : 1.44
INFO:root:2019-05-11 08:13:34, Epoch : 1, Step : 7787, Training Loss : 0.27913, Training Acc : 0.922, Run Time : 0.45
INFO:root:2019-05-11 08:13:35, Epoch : 1, Step : 7788, Training Loss : 0.35756, Training Acc : 0.878, Run Time : 1.45
INFO:root:2019-05-11 08:14:27, Epoch : 1, Step : 7789, Training Loss : 0.31413, Training Acc : 0.878, Run Time : 51.57
INFO:root:2019-05-11 08:14:34, Epoch : 1, Step : 7790, Training Loss : 0.17203, Training Acc : 0.928, Run Time : 7.55
INFO:root:2019-05-11 08:15:22, Epoch : 1, Step : 7791, Training Loss : 0.15998, Training Acc : 0.928, Run Time : 47.65
INFO:root:2019-05-11 08:15:31, Epoch : 1, Step : 7792, Training Loss : 0.22563, Training Acc : 0.900, Run Time : 9.31
INFO:root:2019-05-11 08:15:32, Epoch : 1, Step : 7793, Training Loss : 0.21244, Training Acc : 0.894, Run Time : 0.43
INFO:root:2019-05-11 08:15:34, Epoch : 1, Step : 7794, Training Loss : 0.35911, Training Acc : 0.867, Run Time : 1.96
INFO:root:2019-05-11 08:15:45, Epoch : 1, Step : 7795, Training Loss : 0.15623, Training Acc : 0.944, Run Time : 10.71
INFO:root:2019-05-11 08:15:45, Epoch : 1, Step : 7796, Training Loss : 0.06729, Training Acc : 0.994, Run Time : 0.50
INFO:root:2019-05-11 08:15:47, Epoch : 1, Step : 7797, Training Loss : 0.17731, Training Acc : 0.967, Run Time : 1.71
INFO:root:2019-05-11 08:15:57, Epoch : 1, Step : 7798, Training Loss : 0.23830, Training Acc : 0.894, Run Time : 9.81
INFO:root:2019-05-11 08:15:57, Epoch : 1, Step : 7799, Training Loss : 0.40003, Training Acc : 0.828, Run Time : 0.53
INFO:root:2019-05-11 08:15:57, Epoch : 1, Step : 7800, Training Loss : 0.33266, Training Acc : 0.856, Run Time : 0.42
INFO:root:2019-05-11 08:16:10, Epoch : 1, Step : 7801, Training Loss : 1.54010, Training Acc : 0.500, Run Time : 12.06
INFO:root:2019-05-11 08:16:10, Epoch : 1, Step : 7802, Training Loss : 1.35752, Training Acc : 0.544, Run Time : 0.70
INFO:root:2019-05-11 08:16:12, Epoch : 1, Step : 7803, Training Loss : 0.89664, Training Acc : 0.622, Run Time : 1.67
INFO:root:2019-05-11 08:16:22, Epoch : 1, Step : 7804, Training Loss : 0.71856, Training Acc : 0.706, Run Time : 10.59
INFO:root:2019-05-11 08:16:38, Epoch : 1, Step : 7805, Training Loss : 0.70272, Training Acc : 0.756, Run Time : 15.70
INFO:root:2019-05-11 08:16:39, Epoch : 1, Step : 7806, Training Loss : 0.57608, Training Acc : 0.778, Run Time : 1.18
INFO:root:2019-05-11 08:16:40, Epoch : 1, Step : 7807, Training Loss : 0.68885, Training Acc : 0.711, Run Time : 1.05
INFO:root:2019-05-11 08:16:50, Epoch : 1, Step : 7808, Training Loss : 0.32199, Training Acc : 0.844, Run Time : 9.70
INFO:root:2019-05-11 08:17:14, Epoch : 1, Step : 7809, Training Loss : 0.23140, Training Acc : 0.900, Run Time : 23.55
INFO:root:2019-05-11 08:17:26, Epoch : 1, Step : 7810, Training Loss : 0.16106, Training Acc : 0.950, Run Time : 12.38
INFO:root:2019-05-11 08:17:32, Epoch : 1, Step : 7811, Training Loss : 0.12169, Training Acc : 0.956, Run Time : 5.67
INFO:root:2019-05-11 08:17:34, Epoch : 1, Step : 7812, Training Loss : 0.13697, Training Acc : 0.939, Run Time : 2.34
INFO:root:2019-05-11 08:18:01, Epoch : 1, Step : 7813, Training Loss : 0.12582, Training Acc : 0.961, Run Time : 26.58
INFO:root:2019-05-11 08:18:09, Epoch : 1, Step : 7814, Training Loss : 0.15857, Training Acc : 0.944, Run Time : 8.16
INFO:root:2019-05-11 08:18:10, Epoch : 1, Step : 7815, Training Loss : 0.15515, Training Acc : 0.939, Run Time : 1.51
INFO:root:2019-05-11 08:18:29, Epoch : 1, Step : 7816, Training Loss : 0.18689, Training Acc : 0.906, Run Time : 18.39
INFO:root:2019-05-11 08:18:30, Epoch : 1, Step : 7817, Training Loss : 0.24095, Training Acc : 0.939, Run Time : 1.57
INFO:root:2019-05-11 08:18:31, Epoch : 1, Step : 7818, Training Loss : 0.19779, Training Acc : 0.939, Run Time : 0.44
INFO:root:2019-05-11 08:18:42, Epoch : 1, Step : 7819, Training Loss : 0.14142, Training Acc : 0.950, Run Time : 11.45
INFO:root:2019-05-11 08:18:43, Epoch : 1, Step : 7820, Training Loss : 0.27016, Training Acc : 0.933, Run Time : 1.31
INFO:root:2019-05-11 08:18:44, Epoch : 1, Step : 7821, Training Loss : 0.21925, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 08:18:45, Epoch : 1, Step : 7822, Training Loss : 0.16786, Training Acc : 0.928, Run Time : 1.40
INFO:root:2019-05-11 08:18:55, Epoch : 1, Step : 7823, Training Loss : 0.14245, Training Acc : 0.944, Run Time : 9.44
INFO:root:2019-05-11 08:18:55, Epoch : 1, Step : 7824, Training Loss : 0.28329, Training Acc : 0.900, Run Time : 0.66
INFO:root:2019-05-11 08:18:57, Epoch : 1, Step : 7825, Training Loss : 0.13674, Training Acc : 0.939, Run Time : 1.56
INFO:root:2019-05-11 08:19:08, Epoch : 1, Step : 7826, Training Loss : 0.22415, Training Acc : 0.917, Run Time : 11.51
INFO:root:2019-05-11 08:19:09, Epoch : 1, Step : 7827, Training Loss : 0.22268, Training Acc : 0.922, Run Time : 0.90
INFO:root:2019-05-11 08:19:21, Epoch : 1, Step : 7828, Training Loss : 0.19976, Training Acc : 0.917, Run Time : 12.15
INFO:root:2019-05-11 08:19:23, Epoch : 1, Step : 7829, Training Loss : 0.18331, Training Acc : 0.950, Run Time : 1.36
INFO:root:2019-05-11 08:19:23, Epoch : 1, Step : 7830, Training Loss : 0.69496, Training Acc : 0.856, Run Time : 0.42
INFO:root:2019-05-11 08:19:32, Epoch : 1, Step : 7831, Training Loss : 0.36353, Training Acc : 0.894, Run Time : 8.87
INFO:root:2019-05-11 08:19:38, Epoch : 1, Step : 7832, Training Loss : 0.22730, Training Acc : 0.917, Run Time : 5.47
INFO:root:2019-05-11 08:19:38, Epoch : 1, Step : 7833, Training Loss : 0.47058, Training Acc : 0.872, Run Time : 0.74
INFO:root:2019-05-11 08:20:07, Epoch : 1, Step : 7834, Training Loss : 0.46726, Training Acc : 0.883, Run Time : 29.06
INFO:root:2019-05-11 08:20:09, Epoch : 1, Step : 7835, Training Loss : 0.96831, Training Acc : 0.778, Run Time : 1.49
INFO:root:2019-05-11 08:20:09, Epoch : 1, Step : 7836, Training Loss : 0.55643, Training Acc : 0.833, Run Time : 0.46
INFO:root:2019-05-11 08:20:11, Epoch : 1, Step : 7837, Training Loss : 0.57827, Training Acc : 0.833, Run Time : 1.51
INFO:root:2019-05-11 08:20:22, Epoch : 1, Step : 7838, Training Loss : 0.61421, Training Acc : 0.833, Run Time : 11.05
INFO:root:2019-05-11 08:20:23, Epoch : 1, Step : 7839, Training Loss : 0.14837, Training Acc : 0.950, Run Time : 0.75
INFO:root:2019-05-11 08:20:24, Epoch : 1, Step : 7840, Training Loss : 0.35396, Training Acc : 0.889, Run Time : 1.56
INFO:root:2019-05-11 08:20:44, Epoch : 1, Step : 7841, Training Loss : 0.28736, Training Acc : 0.906, Run Time : 19.53
INFO:root:2019-05-11 08:20:50, Epoch : 1, Step : 7842, Training Loss : 0.53545, Training Acc : 0.817, Run Time : 6.61
INFO:root:2019-05-11 08:20:52, Epoch : 1, Step : 7843, Training Loss : 0.28319, Training Acc : 0.889, Run Time : 1.98
INFO:root:2019-05-11 08:21:03, Epoch : 1, Step : 7844, Training Loss : 0.40963, Training Acc : 0.833, Run Time : 10.79
INFO:root:2019-05-11 08:21:04, Epoch : 1, Step : 7845, Training Loss : 0.42633, Training Acc : 0.828, Run Time : 0.60
INFO:root:2019-05-11 08:21:04, Epoch : 1, Step : 7846, Training Loss : 0.27267, Training Acc : 0.878, Run Time : 0.41
INFO:root:2019-05-11 08:21:21, Epoch : 1, Step : 7847, Training Loss : 0.36356, Training Acc : 0.867, Run Time : 17.19
INFO:root:2019-05-11 08:21:23, Epoch : 1, Step : 7848, Training Loss : 0.34281, Training Acc : 0.861, Run Time : 1.55
INFO:root:2019-05-11 08:21:23, Epoch : 1, Step : 7849, Training Loss : 0.37153, Training Acc : 0.861, Run Time : 0.43
INFO:root:2019-05-11 08:21:38, Epoch : 1, Step : 7850, Training Loss : 0.29309, Training Acc : 0.867, Run Time : 15.18
INFO:root:2019-05-11 08:21:52, Epoch : 1, Step : 7851, Training Loss : 0.50589, Training Acc : 0.811, Run Time : 13.26
INFO:root:2019-05-11 08:21:53, Epoch : 1, Step : 7852, Training Loss : 0.66020, Training Acc : 0.789, Run Time : 1.21
INFO:root:2019-05-11 08:21:54, Epoch : 1, Step : 7853, Training Loss : 0.40049, Training Acc : 0.822, Run Time : 0.92
INFO:root:2019-05-11 08:22:06, Epoch : 1, Step : 7854, Training Loss : 0.32231, Training Acc : 0.861, Run Time : 12.28
INFO:root:2019-05-11 08:22:07, Epoch : 1, Step : 7855, Training Loss : 0.34024, Training Acc : 0.850, Run Time : 0.98
INFO:root:2019-05-11 08:22:08, Epoch : 1, Step : 7856, Training Loss : 0.44716, Training Acc : 0.811, Run Time : 0.96
INFO:root:2019-05-11 08:22:21, Epoch : 1, Step : 7857, Training Loss : 0.31748, Training Acc : 0.856, Run Time : 13.36
INFO:root:2019-05-11 08:22:23, Epoch : 1, Step : 7858, Training Loss : 0.39890, Training Acc : 0.811, Run Time : 1.70
INFO:root:2019-05-11 08:22:50, Epoch : 1, Step : 7859, Training Loss : 0.45001, Training Acc : 0.806, Run Time : 27.19
INFO:root:2019-05-11 08:23:11, Epoch : 1, Step : 7860, Training Loss : 0.45754, Training Acc : 0.806, Run Time : 20.60
INFO:root:2019-05-11 08:23:29, Epoch : 1, Step : 7861, Training Loss : 0.52846, Training Acc : 0.761, Run Time : 18.03
INFO:root:2019-05-11 08:23:36, Epoch : 1, Step : 7862, Training Loss : 0.46090, Training Acc : 0.783, Run Time : 7.34
INFO:root:2019-05-11 08:23:37, Epoch : 1, Step : 7863, Training Loss : 0.42090, Training Acc : 0.817, Run Time : 0.71
INFO:root:2019-05-11 08:23:39, Epoch : 1, Step : 7864, Training Loss : 0.40755, Training Acc : 0.828, Run Time : 1.67
INFO:root:2019-05-11 08:23:52, Epoch : 1, Step : 7865, Training Loss : 0.32721, Training Acc : 0.861, Run Time : 12.81
INFO:root:2019-05-11 08:23:52, Epoch : 1, Step : 7866, Training Loss : 0.35669, Training Acc : 0.800, Run Time : 0.78
INFO:root:2019-05-11 08:24:04, Epoch : 1, Step : 7867, Training Loss : 0.36394, Training Acc : 0.872, Run Time : 11.83
INFO:root:2019-05-11 08:24:06, Epoch : 1, Step : 7868, Training Loss : 0.32370, Training Acc : 0.878, Run Time : 1.72
INFO:root:2019-05-11 08:24:27, Epoch : 1, Step : 7869, Training Loss : 0.28134, Training Acc : 0.889, Run Time : 20.72
INFO:root:2019-05-11 08:24:28, Epoch : 1, Step : 7870, Training Loss : 0.35949, Training Acc : 0.878, Run Time : 1.64
INFO:root:2019-05-11 08:24:39, Epoch : 1, Step : 7871, Training Loss : 0.36447, Training Acc : 0.822, Run Time : 10.92
INFO:root:2019-05-11 08:24:51, Epoch : 1, Step : 7872, Training Loss : 0.26795, Training Acc : 0.928, Run Time : 12.17
INFO:root:2019-05-11 08:24:52, Epoch : 1, Step : 7873, Training Loss : 0.26837, Training Acc : 0.922, Run Time : 1.13
INFO:root:2019-05-11 08:24:53, Epoch : 1, Step : 7874, Training Loss : 0.18159, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 08:24:54, Epoch : 1, Step : 7875, Training Loss : 0.22773, Training Acc : 0.917, Run Time : 1.61
INFO:root:2019-05-11 08:25:06, Epoch : 1, Step : 7876, Training Loss : 0.28641, Training Acc : 0.883, Run Time : 11.90
INFO:root:2019-05-11 08:25:08, Epoch : 1, Step : 7877, Training Loss : 0.17450, Training Acc : 0.939, Run Time : 1.41
INFO:root:2019-05-11 08:25:19, Epoch : 1, Step : 7878, Training Loss : 0.30216, Training Acc : 0.906, Run Time : 11.13
INFO:root:2019-05-11 08:25:31, Epoch : 1, Step : 7879, Training Loss : 0.28898, Training Acc : 0.872, Run Time : 12.09
INFO:root:2019-05-11 08:25:32, Epoch : 1, Step : 7880, Training Loss : 0.21765, Training Acc : 0.889, Run Time : 0.92
INFO:root:2019-05-11 08:25:32, Epoch : 1, Step : 7881, Training Loss : 0.14869, Training Acc : 0.950, Run Time : 0.37
INFO:root:2019-05-11 08:25:33, Epoch : 1, Step : 7882, Training Loss : 0.13015, Training Acc : 0.961, Run Time : 0.85
INFO:root:2019-05-11 08:25:46, Epoch : 1, Step : 7883, Training Loss : 0.18866, Training Acc : 0.944, Run Time : 13.18
INFO:root:2019-05-11 08:25:47, Epoch : 1, Step : 7884, Training Loss : 0.13056, Training Acc : 0.956, Run Time : 0.51
INFO:root:2019-05-11 08:25:47, Epoch : 1, Step : 7885, Training Loss : 0.19508, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 08:25:49, Epoch : 1, Step : 7886, Training Loss : 0.10374, Training Acc : 0.978, Run Time : 1.38
INFO:root:2019-05-11 08:26:10, Epoch : 1, Step : 7887, Training Loss : 0.17246, Training Acc : 0.933, Run Time : 21.02
INFO:root:2019-05-11 08:26:32, Epoch : 1, Step : 7888, Training Loss : 0.16465, Training Acc : 0.939, Run Time : 22.60
INFO:root:2019-05-11 08:26:51, Epoch : 1, Step : 7889, Training Loss : 0.13927, Training Acc : 0.961, Run Time : 18.67
INFO:root:2019-05-11 08:26:52, Epoch : 1, Step : 7890, Training Loss : 0.14218, Training Acc : 0.956, Run Time : 1.51
INFO:root:2019-05-11 08:26:53, Epoch : 1, Step : 7891, Training Loss : 0.16281, Training Acc : 0.944, Run Time : 0.40
INFO:root:2019-05-11 08:26:54, Epoch : 1, Step : 7892, Training Loss : 0.12858, Training Acc : 0.972, Run Time : 1.34
INFO:root:2019-05-11 08:27:28, Epoch : 1, Step : 7893, Training Loss : 0.14918, Training Acc : 0.961, Run Time : 33.99
INFO:root:2019-05-11 08:27:34, Epoch : 1, Step : 7894, Training Loss : 0.14491, Training Acc : 0.956, Run Time : 5.86
INFO:root:2019-05-11 08:27:34, Epoch : 1, Step : 7895, Training Loss : 0.10833, Training Acc : 0.967, Run Time : 0.41
INFO:root:2019-05-11 08:27:46, Epoch : 1, Step : 7896, Training Loss : 0.17303, Training Acc : 0.933, Run Time : 11.81
INFO:root:2019-05-11 08:27:47, Epoch : 1, Step : 7897, Training Loss : 0.15317, Training Acc : 0.939, Run Time : 0.47
INFO:root:2019-05-11 08:27:47, Epoch : 1, Step : 7898, Training Loss : 0.14343, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-11 08:27:49, Epoch : 1, Step : 7899, Training Loss : 0.12925, Training Acc : 0.944, Run Time : 1.92
INFO:root:2019-05-11 08:28:05, Epoch : 1, Step : 7900, Training Loss : 0.12166, Training Acc : 0.956, Run Time : 15.59
INFO:root:2019-05-11 08:28:46, Epoch : 1, Step : 7901, Training Loss : 0.20813, Training Acc : 0.922, Run Time : 41.70
INFO:root:2019-05-11 08:28:54, Epoch : 1, Step : 7902, Training Loss : 0.16753, Training Acc : 0.933, Run Time : 7.72
INFO:root:2019-05-11 08:29:07, Epoch : 1, Step : 7903, Training Loss : 0.13542, Training Acc : 0.950, Run Time : 12.60
INFO:root:2019-05-11 08:29:07, Epoch : 1, Step : 7904, Training Loss : 0.13949, Training Acc : 0.944, Run Time : 0.73
INFO:root:2019-05-11 08:29:09, Epoch : 1, Step : 7905, Training Loss : 0.18657, Training Acc : 0.911, Run Time : 1.86
INFO:root:2019-05-11 08:29:32, Epoch : 1, Step : 7906, Training Loss : 0.14209, Training Acc : 0.950, Run Time : 22.89
INFO:root:2019-05-11 08:29:34, Epoch : 1, Step : 7907, Training Loss : 0.17777, Training Acc : 0.922, Run Time : 1.70
INFO:root:2019-05-11 08:29:34, Epoch : 1, Step : 7908, Training Loss : 0.15137, Training Acc : 0.939, Run Time : 0.40
INFO:root:2019-05-11 08:29:37, Epoch : 1, Step : 7909, Training Loss : 0.20826, Training Acc : 0.922, Run Time : 3.08
INFO:root:2019-05-11 08:29:50, Epoch : 1, Step : 7910, Training Loss : 0.19510, Training Acc : 0.928, Run Time : 12.29
INFO:root:2019-05-11 08:29:52, Epoch : 1, Step : 7911, Training Loss : 0.22303, Training Acc : 0.911, Run Time : 2.35
INFO:root:2019-05-11 08:30:04, Epoch : 1, Step : 7912, Training Loss : 0.21510, Training Acc : 0.906, Run Time : 12.36
INFO:root:2019-05-11 08:30:05, Epoch : 1, Step : 7913, Training Loss : 0.20241, Training Acc : 0.894, Run Time : 0.77
INFO:root:2019-05-11 08:31:09, Epoch : 1, Step : 7914, Training Loss : 0.18811, Training Acc : 0.911, Run Time : 64.13
INFO:root:2019-05-11 08:31:19, Epoch : 1, Step : 7915, Training Loss : 0.18633, Training Acc : 0.922, Run Time : 10.06
INFO:root:2019-05-11 08:31:21, Epoch : 1, Step : 7916, Training Loss : 0.19955, Training Acc : 0.917, Run Time : 1.50
INFO:root:2019-05-11 08:31:56, Epoch : 1, Step : 7917, Training Loss : 0.16892, Training Acc : 0.944, Run Time : 35.00
INFO:root:2019-05-11 08:32:08, Epoch : 1, Step : 7918, Training Loss : 0.21067, Training Acc : 0.922, Run Time : 12.14
INFO:root:2019-05-11 08:32:32, Epoch : 1, Step : 7919, Training Loss : 0.24310, Training Acc : 0.900, Run Time : 24.47
INFO:root:2019-05-11 08:32:36, Epoch : 1, Step : 7920, Training Loss : 0.19547, Training Acc : 0.928, Run Time : 3.80
INFO:root:2019-05-11 08:32:55, Epoch : 1, Step : 7921, Training Loss : 0.20846, Training Acc : 0.922, Run Time : 18.62
INFO:root:2019-05-11 08:32:57, Epoch : 1, Step : 7922, Training Loss : 0.21832, Training Acc : 0.906, Run Time : 1.76
INFO:root:2019-05-11 08:32:57, Epoch : 1, Step : 7923, Training Loss : 0.23395, Training Acc : 0.917, Run Time : 0.44
INFO:root:2019-05-11 08:32:58, Epoch : 1, Step : 7924, Training Loss : 0.16182, Training Acc : 0.944, Run Time : 1.25
INFO:root:2019-05-11 08:33:09, Epoch : 1, Step : 7925, Training Loss : 0.14082, Training Acc : 0.933, Run Time : 11.18
INFO:root:2019-05-11 08:33:10, Epoch : 1, Step : 7926, Training Loss : 0.15048, Training Acc : 0.939, Run Time : 0.49
INFO:root:2019-05-11 08:33:12, Epoch : 1, Step : 7927, Training Loss : 0.15198, Training Acc : 0.944, Run Time : 1.98
INFO:root:2019-05-11 08:33:25, Epoch : 1, Step : 7928, Training Loss : 0.17292, Training Acc : 0.922, Run Time : 12.97
INFO:root:2019-05-11 08:33:25, Epoch : 1, Step : 7929, Training Loss : 0.11225, Training Acc : 0.956, Run Time : 0.47
INFO:root:2019-05-11 08:33:27, Epoch : 1, Step : 7930, Training Loss : 0.11114, Training Acc : 0.972, Run Time : 1.88
INFO:root:2019-05-11 08:34:05, Epoch : 1, Step : 7931, Training Loss : 0.11576, Training Acc : 0.956, Run Time : 37.65
INFO:root:2019-05-11 08:34:13, Epoch : 1, Step : 7932, Training Loss : 0.13161, Training Acc : 0.956, Run Time : 7.73
INFO:root:2019-05-11 08:34:40, Epoch : 1, Step : 7933, Training Loss : 0.14406, Training Acc : 0.944, Run Time : 27.16
INFO:root:2019-05-11 08:34:59, Epoch : 1, Step : 7934, Training Loss : 0.11646, Training Acc : 0.967, Run Time : 18.89
INFO:root:2019-05-11 08:35:00, Epoch : 1, Step : 7935, Training Loss : 0.14736, Training Acc : 0.956, Run Time : 1.65
INFO:root:2019-05-11 08:35:02, Epoch : 1, Step : 7936, Training Loss : 0.12350, Training Acc : 0.967, Run Time : 1.41
INFO:root:2019-05-11 08:35:27, Epoch : 1, Step : 7937, Training Loss : 0.10030, Training Acc : 0.972, Run Time : 25.22
INFO:root:2019-05-11 08:35:38, Epoch : 1, Step : 7938, Training Loss : 0.19597, Training Acc : 0.917, Run Time : 11.03
INFO:root:2019-05-11 08:36:15, Epoch : 1, Step : 7939, Training Loss : 0.13900, Training Acc : 0.956, Run Time : 37.49
INFO:root:2019-05-11 08:36:25, Epoch : 1, Step : 7940, Training Loss : 0.16696, Training Acc : 0.939, Run Time : 9.96
INFO:root:2019-05-11 08:36:48, Epoch : 1, Step : 7941, Training Loss : 0.09798, Training Acc : 0.950, Run Time : 22.14
INFO:root:2019-05-11 08:37:19, Epoch : 1, Step : 7942, Training Loss : 0.07809, Training Acc : 0.978, Run Time : 31.23
INFO:root:2019-05-11 08:37:26, Epoch : 1, Step : 7943, Training Loss : 0.06547, Training Acc : 0.978, Run Time : 7.46
INFO:root:2019-05-11 08:38:05, Epoch : 1, Step : 7944, Training Loss : 0.05119, Training Acc : 0.978, Run Time : 38.89
INFO:root:2019-05-11 08:38:11, Epoch : 1, Step : 7945, Training Loss : 0.03274, Training Acc : 1.000, Run Time : 6.35
INFO:root:2019-05-11 08:38:12, Epoch : 1, Step : 7946, Training Loss : 0.05304, Training Acc : 0.994, Run Time : 0.42
INFO:root:2019-05-11 08:38:14, Epoch : 1, Step : 7947, Training Loss : 0.07253, Training Acc : 0.972, Run Time : 2.06
INFO:root:2019-05-11 08:39:02, Epoch : 1, Step : 7948, Training Loss : 0.06736, Training Acc : 0.978, Run Time : 48.21
INFO:root:2019-05-11 08:39:07, Epoch : 1, Step : 7949, Training Loss : 0.06415, Training Acc : 0.989, Run Time : 5.31
INFO:root:2019-05-11 08:39:10, Epoch : 1, Step : 7950, Training Loss : 0.06100, Training Acc : 0.994, Run Time : 2.24
INFO:root:2019-05-11 08:39:33, Epoch : 1, Step : 7951, Training Loss : 0.06788, Training Acc : 0.972, Run Time : 23.44
INFO:root:2019-05-11 08:39:56, Epoch : 1, Step : 7952, Training Loss : 0.08256, Training Acc : 0.961, Run Time : 23.02
INFO:root:2019-05-11 08:40:22, Epoch : 1, Step : 7953, Training Loss : 0.09816, Training Acc : 0.956, Run Time : 25.73
INFO:root:2019-05-11 08:40:28, Epoch : 1, Step : 7954, Training Loss : 0.36539, Training Acc : 0.900, Run Time : 5.88
INFO:root:2019-05-11 08:40:28, Epoch : 1, Step : 7955, Training Loss : 0.33055, Training Acc : 0.894, Run Time : 0.66
INFO:root:2019-05-11 08:40:50, Epoch : 1, Step : 7956, Training Loss : 0.30831, Training Acc : 0.878, Run Time : 21.70
INFO:root:2019-05-11 08:40:52, Epoch : 1, Step : 7957, Training Loss : 0.21144, Training Acc : 0.911, Run Time : 1.62
INFO:root:2019-05-11 08:40:52, Epoch : 1, Step : 7958, Training Loss : 0.17237, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 08:40:53, Epoch : 1, Step : 7959, Training Loss : 0.13856, Training Acc : 0.928, Run Time : 1.15
INFO:root:2019-05-11 08:41:04, Epoch : 1, Step : 7960, Training Loss : 0.10515, Training Acc : 0.950, Run Time : 10.64
INFO:root:2019-05-11 08:41:04, Epoch : 1, Step : 7961, Training Loss : 0.09693, Training Acc : 0.983, Run Time : 0.53
INFO:root:2019-05-11 08:41:05, Epoch : 1, Step : 7962, Training Loss : 0.12347, Training Acc : 0.950, Run Time : 0.40
INFO:root:2019-05-11 08:41:06, Epoch : 1, Step : 7963, Training Loss : 0.10387, Training Acc : 0.961, Run Time : 1.67
INFO:root:2019-05-11 08:41:36, Epoch : 1, Step : 7964, Training Loss : 0.10471, Training Acc : 0.972, Run Time : 29.33
INFO:root:2019-05-11 08:42:03, Epoch : 1, Step : 7965, Training Loss : 0.10293, Training Acc : 0.978, Run Time : 26.98
INFO:root:2019-05-11 08:42:05, Epoch : 1, Step : 7966, Training Loss : 0.06237, Training Acc : 0.989, Run Time : 1.79
INFO:root:2019-05-11 08:42:05, Epoch : 1, Step : 7967, Training Loss : 0.11103, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 08:42:07, Epoch : 1, Step : 7968, Training Loss : 0.12702, Training Acc : 0.967, Run Time : 1.97
INFO:root:2019-05-11 08:42:16, Epoch : 1, Step : 7969, Training Loss : 0.16404, Training Acc : 0.950, Run Time : 9.05
INFO:root:2019-05-11 08:42:17, Epoch : 1, Step : 7970, Training Loss : 0.17075, Training Acc : 0.956, Run Time : 0.65
INFO:root:2019-05-11 08:42:17, Epoch : 1, Step : 7971, Training Loss : 0.20669, Training Acc : 0.950, Run Time : 0.42
INFO:root:2019-05-11 08:42:19, Epoch : 1, Step : 7972, Training Loss : 0.13570, Training Acc : 0.950, Run Time : 1.94
INFO:root:2019-05-11 08:42:35, Epoch : 1, Step : 7973, Training Loss : 0.16053, Training Acc : 0.928, Run Time : 15.54
INFO:root:2019-05-11 08:42:36, Epoch : 1, Step : 7974, Training Loss : 0.14734, Training Acc : 0.939, Run Time : 1.47
INFO:root:2019-05-11 08:42:37, Epoch : 1, Step : 7975, Training Loss : 0.08995, Training Acc : 0.956, Run Time : 0.97
INFO:root:2019-05-11 08:42:38, Epoch : 1, Step : 7976, Training Loss : 0.08348, Training Acc : 0.961, Run Time : 1.43
INFO:root:2019-05-11 08:42:50, Epoch : 1, Step : 7977, Training Loss : 0.16353, Training Acc : 0.939, Run Time : 11.15
INFO:root:2019-05-11 08:42:52, Epoch : 1, Step : 7978, Training Loss : 0.11439, Training Acc : 0.956, Run Time : 1.99
INFO:root:2019-05-11 08:43:05, Epoch : 1, Step : 7979, Training Loss : 0.04724, Training Acc : 0.994, Run Time : 13.79
INFO:root:2019-05-11 08:43:08, Epoch : 1, Step : 7980, Training Loss : 0.11143, Training Acc : 0.956, Run Time : 3.16
INFO:root:2019-05-11 08:43:26, Epoch : 1, Step : 7981, Training Loss : 0.10016, Training Acc : 0.950, Run Time : 18.00
INFO:root:2019-05-11 08:43:38, Epoch : 1, Step : 7982, Training Loss : 0.10066, Training Acc : 0.956, Run Time : 11.69
INFO:root:2019-05-11 08:43:51, Epoch : 1, Step : 7983, Training Loss : 0.21034, Training Acc : 0.894, Run Time : 12.93
INFO:root:2019-05-11 08:43:52, Epoch : 1, Step : 7984, Training Loss : 0.10441, Training Acc : 0.961, Run Time : 1.29
INFO:root:2019-05-11 08:44:03, Epoch : 1, Step : 7985, Training Loss : 0.11884, Training Acc : 0.944, Run Time : 11.01
INFO:root:2019-05-11 08:44:04, Epoch : 1, Step : 7986, Training Loss : 0.10297, Training Acc : 0.950, Run Time : 0.47
INFO:root:2019-05-11 08:44:04, Epoch : 1, Step : 7987, Training Loss : 0.15509, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 08:44:07, Epoch : 1, Step : 7988, Training Loss : 0.16263, Training Acc : 0.944, Run Time : 3.06
INFO:root:2019-05-11 08:44:34, Epoch : 1, Step : 7989, Training Loss : 0.13799, Training Acc : 0.933, Run Time : 26.92
INFO:root:2019-05-11 08:44:36, Epoch : 1, Step : 7990, Training Loss : 0.15477, Training Acc : 0.911, Run Time : 1.45
INFO:root:2019-05-11 08:44:36, Epoch : 1, Step : 7991, Training Loss : 0.16306, Training Acc : 0.922, Run Time : 0.40
INFO:root:2019-05-11 08:44:48, Epoch : 1, Step : 7992, Training Loss : 0.20582, Training Acc : 0.911, Run Time : 11.46
INFO:root:2019-05-11 08:44:49, Epoch : 1, Step : 7993, Training Loss : 0.20027, Training Acc : 0.922, Run Time : 1.03
INFO:root:2019-05-11 08:44:51, Epoch : 1, Step : 7994, Training Loss : 0.11454, Training Acc : 0.950, Run Time : 2.26
INFO:root:2019-05-11 08:45:41, Epoch : 1, Step : 7995, Training Loss : 0.12005, Training Acc : 0.956, Run Time : 50.61
INFO:root:2019-05-11 08:45:48, Epoch : 1, Step : 7996, Training Loss : 0.19898, Training Acc : 0.906, Run Time : 6.49
INFO:root:2019-05-11 08:46:20, Epoch : 1, Step : 7997, Training Loss : 0.12006, Training Acc : 0.967, Run Time : 32.36
INFO:root:2019-05-11 08:46:26, Epoch : 1, Step : 7998, Training Loss : 0.12548, Training Acc : 0.961, Run Time : 5.66
INFO:root:2019-05-11 08:46:27, Epoch : 1, Step : 7999, Training Loss : 0.13527, Training Acc : 0.939, Run Time : 0.69
INFO:root:2019-05-11 08:46:51, Epoch : 1, Step : 8000, Training Loss : 0.15559, Training Acc : 0.922, Run Time : 23.88
INFO:root:2019-05-11 08:47:10, Epoch : 1, Step : 8001, Training Loss : 0.27639, Training Acc : 0.872, Run Time : 19.78
INFO:root:2019-05-11 08:47:14, Epoch : 1, Step : 8002, Training Loss : 0.19782, Training Acc : 0.922, Run Time : 4.12
INFO:root:2019-05-11 08:47:15, Epoch : 1, Step : 8003, Training Loss : 0.21104, Training Acc : 0.917, Run Time : 0.43
INFO:root:2019-05-11 08:48:15, Epoch : 1, Step : 8004, Training Loss : 0.15812, Training Acc : 0.928, Run Time : 59.80
INFO:root:2019-05-11 08:49:26, Epoch : 1, Step : 8005, Training Loss : 0.17374, Training Acc : 0.939, Run Time : 71.51
INFO:root:2019-05-11 08:49:29, Epoch : 1, Step : 8006, Training Loss : 0.25325, Training Acc : 0.900, Run Time : 2.86
INFO:root:2019-05-11 08:49:29, Epoch : 1, Step : 8007, Training Loss : 0.15930, Training Acc : 0.939, Run Time : 0.40
INFO:root:2019-05-11 08:49:31, Epoch : 1, Step : 8008, Training Loss : 0.16443, Training Acc : 0.928, Run Time : 1.17
INFO:root:2019-05-11 08:49:46, Epoch : 1, Step : 8009, Training Loss : 0.22296, Training Acc : 0.883, Run Time : 15.80
INFO:root:2019-05-11 08:50:08, Epoch : 1, Step : 8010, Training Loss : 0.23707, Training Acc : 0.900, Run Time : 21.11
INFO:root:2019-05-11 08:50:34, Epoch : 1, Step : 8011, Training Loss : 0.22976, Training Acc : 0.911, Run Time : 26.63
INFO:root:2019-05-11 08:50:40, Epoch : 1, Step : 8012, Training Loss : 0.19656, Training Acc : 0.911, Run Time : 5.49
INFO:root:2019-05-11 08:50:40, Epoch : 1, Step : 8013, Training Loss : 0.19432, Training Acc : 0.922, Run Time : 0.44
INFO:root:2019-05-11 08:50:42, Epoch : 1, Step : 8014, Training Loss : 0.23285, Training Acc : 0.889, Run Time : 1.89
INFO:root:2019-05-11 08:51:06, Epoch : 1, Step : 8015, Training Loss : 0.16491, Training Acc : 0.933, Run Time : 24.44
INFO:root:2019-05-11 08:51:48, Epoch : 1, Step : 8016, Training Loss : 0.12644, Training Acc : 0.944, Run Time : 41.90
INFO:root:2019-05-11 08:52:16, Epoch : 1, Step : 8017, Training Loss : 0.21027, Training Acc : 0.944, Run Time : 27.33
INFO:root:2019-05-11 08:52:34, Epoch : 1, Step : 8018, Training Loss : 0.20478, Training Acc : 0.922, Run Time : 18.07
INFO:root:2019-05-11 08:52:36, Epoch : 1, Step : 8019, Training Loss : 0.14941, Training Acc : 0.950, Run Time : 1.84
INFO:root:2019-05-11 08:52:36, Epoch : 1, Step : 8020, Training Loss : 0.20630, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 08:53:44, Epoch : 1, Step : 8021, Training Loss : 0.21595, Training Acc : 0.911, Run Time : 67.76
INFO:root:2019-05-11 08:54:25, Epoch : 1, Step : 8022, Training Loss : 0.21382, Training Acc : 0.917, Run Time : 41.20
INFO:root:2019-05-11 08:55:09, Epoch : 1, Step : 8023, Training Loss : 0.20443, Training Acc : 0.928, Run Time : 43.98
INFO:root:2019-05-11 08:55:29, Epoch : 1, Step : 8024, Training Loss : 0.24392, Training Acc : 0.906, Run Time : 20.58
INFO:root:2019-05-11 08:56:10, Epoch : 1, Step : 8025, Training Loss : 0.15825, Training Acc : 0.944, Run Time : 40.58
INFO:root:2019-05-11 08:56:31, Epoch : 1, Step : 8026, Training Loss : 0.22500, Training Acc : 0.922, Run Time : 21.34
INFO:root:2019-05-11 08:56:38, Epoch : 1, Step : 8027, Training Loss : 0.32518, Training Acc : 0.856, Run Time : 6.21
INFO:root:2019-05-11 08:56:38, Epoch : 1, Step : 8028, Training Loss : 0.19697, Training Acc : 0.911, Run Time : 0.67
INFO:root:2019-05-11 08:56:39, Epoch : 1, Step : 8029, Training Loss : 0.11401, Training Acc : 0.956, Run Time : 0.98
INFO:root:2019-05-11 08:57:03, Epoch : 1, Step : 8030, Training Loss : 0.11558, Training Acc : 0.956, Run Time : 24.16
INFO:root:2019-05-11 08:57:11, Epoch : 1, Step : 8031, Training Loss : 0.19314, Training Acc : 0.917, Run Time : 7.86
INFO:root:2019-05-11 08:57:14, Epoch : 1, Step : 8032, Training Loss : 0.14421, Training Acc : 0.928, Run Time : 2.81
INFO:root:2019-05-11 08:57:40, Epoch : 1, Step : 8033, Training Loss : 0.21974, Training Acc : 0.917, Run Time : 25.84
INFO:root:2019-05-11 08:57:47, Epoch : 1, Step : 8034, Training Loss : 0.17165, Training Acc : 0.933, Run Time : 6.83
INFO:root:2019-05-11 08:58:01, Epoch : 1, Step : 8035, Training Loss : 0.19511, Training Acc : 0.922, Run Time : 14.10
INFO:root:2019-05-11 08:58:01, Epoch : 1, Step : 8036, Training Loss : 0.16196, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-11 08:58:02, Epoch : 1, Step : 8037, Training Loss : 0.20822, Training Acc : 0.939, Run Time : 0.38
INFO:root:2019-05-11 08:58:03, Epoch : 1, Step : 8038, Training Loss : 0.23433, Training Acc : 0.894, Run Time : 1.75
INFO:root:2019-05-11 08:58:15, Epoch : 1, Step : 8039, Training Loss : 0.22212, Training Acc : 0.906, Run Time : 11.31
INFO:root:2019-05-11 08:58:27, Epoch : 1, Step : 8040, Training Loss : 0.22529, Training Acc : 0.917, Run Time : 12.43
INFO:root:2019-05-11 08:58:46, Epoch : 1, Step : 8041, Training Loss : 0.28168, Training Acc : 0.900, Run Time : 18.50
INFO:root:2019-05-11 08:58:58, Epoch : 1, Step : 8042, Training Loss : 0.26775, Training Acc : 0.872, Run Time : 12.60
INFO:root:2019-05-11 08:59:07, Epoch : 1, Step : 8043, Training Loss : 0.27133, Training Acc : 0.889, Run Time : 8.54
INFO:root:2019-05-11 08:59:19, Epoch : 1, Step : 8044, Training Loss : 0.27459, Training Acc : 0.878, Run Time : 12.35
INFO:root:2019-05-11 08:59:20, Epoch : 1, Step : 8045, Training Loss : 0.24467, Training Acc : 0.900, Run Time : 1.02
INFO:root:2019-05-11 08:59:27, Epoch : 1, Step : 8046, Training Loss : 0.26177, Training Acc : 0.906, Run Time : 7.17
INFO:root:2019-05-11 08:59:32, Epoch : 1, Step : 8047, Training Loss : 0.22024, Training Acc : 0.911, Run Time : 4.29
INFO:root:2019-05-11 08:59:32, Epoch : 1, Step : 8048, Training Loss : 0.27202, Training Acc : 0.906, Run Time : 0.65
INFO:root:2019-05-11 08:59:47, Epoch : 1, Step : 8049, Training Loss : 0.17064, Training Acc : 0.933, Run Time : 14.47
INFO:root:2019-05-11 08:59:48, Epoch : 1, Step : 8050, Training Loss : 0.18568, Training Acc : 0.933, Run Time : 1.00
INFO:root:2019-05-11 08:59:50, Epoch : 1, Step : 8051, Training Loss : 0.23650, Training Acc : 0.917, Run Time : 2.28
INFO:root:2019-05-11 09:00:00, Epoch : 1, Step : 8052, Training Loss : 0.25736, Training Acc : 0.889, Run Time : 10.27
INFO:root:2019-05-11 09:00:27, Epoch : 1, Step : 8053, Training Loss : 0.21669, Training Acc : 0.928, Run Time : 26.36
INFO:root:2019-05-11 09:00:48, Epoch : 1, Step : 8054, Training Loss : 0.22165, Training Acc : 0.911, Run Time : 21.15
INFO:root:2019-05-11 09:01:04, Epoch : 1, Step : 8055, Training Loss : 0.25102, Training Acc : 0.878, Run Time : 15.75
INFO:root:2019-05-11 09:01:10, Epoch : 1, Step : 8056, Training Loss : 0.23479, Training Acc : 0.906, Run Time : 6.65
INFO:root:2019-05-11 09:01:21, Epoch : 1, Step : 8057, Training Loss : 0.31184, Training Acc : 0.867, Run Time : 11.17
INFO:root:2019-05-11 09:01:22, Epoch : 1, Step : 8058, Training Loss : 0.24234, Training Acc : 0.878, Run Time : 0.67
INFO:root:2019-05-11 09:01:24, Epoch : 1, Step : 8059, Training Loss : 0.24628, Training Acc : 0.933, Run Time : 1.88
INFO:root:2019-05-11 09:01:34, Epoch : 1, Step : 8060, Training Loss : 0.19378, Training Acc : 0.922, Run Time : 10.55
INFO:root:2019-05-11 09:01:37, Epoch : 1, Step : 8061, Training Loss : 0.20020, Training Acc : 0.911, Run Time : 2.45
INFO:root:2019-05-11 09:02:05, Epoch : 1, Step : 8062, Training Loss : 0.23112, Training Acc : 0.922, Run Time : 28.11
INFO:root:2019-05-11 09:02:39, Epoch : 1, Step : 8063, Training Loss : 0.22105, Training Acc : 0.917, Run Time : 33.60
INFO:root:2019-05-11 09:02:59, Epoch : 1, Step : 8064, Training Loss : 0.26973, Training Acc : 0.900, Run Time : 20.24
INFO:root:2019-05-11 09:03:00, Epoch : 1, Step : 8065, Training Loss : 0.21579, Training Acc : 0.894, Run Time : 1.28
INFO:root:2019-05-11 09:03:01, Epoch : 1, Step : 8066, Training Loss : 0.23504, Training Acc : 0.917, Run Time : 0.85
INFO:root:2019-05-11 09:03:10, Epoch : 1, Step : 8067, Training Loss : 0.28905, Training Acc : 0.872, Run Time : 9.35
INFO:root:2019-05-11 09:03:12, Epoch : 1, Step : 8068, Training Loss : 0.23604, Training Acc : 0.883, Run Time : 1.41
INFO:root:2019-05-11 09:03:12, Epoch : 1, Step : 8069, Training Loss : 0.22024, Training Acc : 0.917, Run Time : 0.54
INFO:root:2019-05-11 09:03:51, Epoch : 1, Step : 8070, Training Loss : 0.21415, Training Acc : 0.911, Run Time : 38.93
INFO:root:2019-05-11 09:03:53, Epoch : 1, Step : 8071, Training Loss : 0.15506, Training Acc : 0.939, Run Time : 1.49
INFO:root:2019-05-11 09:03:53, Epoch : 1, Step : 8072, Training Loss : 0.25412, Training Acc : 0.911, Run Time : 0.73
INFO:root:2019-05-11 09:04:16, Epoch : 1, Step : 8073, Training Loss : 0.17811, Training Acc : 0.939, Run Time : 22.71
INFO:root:2019-05-11 09:04:23, Epoch : 1, Step : 8074, Training Loss : 0.18799, Training Acc : 0.928, Run Time : 6.45
INFO:root:2019-05-11 09:04:25, Epoch : 1, Step : 8075, Training Loss : 0.23488, Training Acc : 0.894, Run Time : 2.06
INFO:root:2019-05-11 09:04:51, Epoch : 1, Step : 8076, Training Loss : 0.19351, Training Acc : 0.917, Run Time : 26.21
INFO:root:2019-05-11 09:05:00, Epoch : 1, Step : 8077, Training Loss : 0.22535, Training Acc : 0.906, Run Time : 8.77
INFO:root:2019-05-11 09:05:00, Epoch : 1, Step : 8078, Training Loss : 0.18502, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 09:05:01, Epoch : 1, Step : 8079, Training Loss : 0.17044, Training Acc : 0.922, Run Time : 1.37
INFO:root:2019-05-11 09:05:15, Epoch : 1, Step : 8080, Training Loss : 0.24383, Training Acc : 0.906, Run Time : 13.67
INFO:root:2019-05-11 09:05:16, Epoch : 1, Step : 8081, Training Loss : 0.19577, Training Acc : 0.900, Run Time : 0.57
INFO:root:2019-05-11 09:05:16, Epoch : 1, Step : 8082, Training Loss : 0.20678, Training Acc : 0.922, Run Time : 0.45
INFO:root:2019-05-11 09:05:45, Epoch : 1, Step : 8083, Training Loss : 0.18962, Training Acc : 0.922, Run Time : 29.31
INFO:root:2019-05-11 09:06:02, Epoch : 1, Step : 8084, Training Loss : 0.25504, Training Acc : 0.911, Run Time : 16.11
INFO:root:2019-05-11 09:06:07, Epoch : 1, Step : 8085, Training Loss : 0.20517, Training Acc : 0.900, Run Time : 5.04
INFO:root:2019-05-11 09:06:07, Epoch : 1, Step : 8086, Training Loss : 0.23683, Training Acc : 0.894, Run Time : 0.59
INFO:root:2019-05-11 09:06:09, Epoch : 1, Step : 8087, Training Loss : 0.19721, Training Acc : 0.922, Run Time : 1.88
INFO:root:2019-05-11 09:06:23, Epoch : 1, Step : 8088, Training Loss : 0.25196, Training Acc : 0.872, Run Time : 14.38
INFO:root:2019-05-11 09:06:36, Epoch : 1, Step : 8089, Training Loss : 0.18498, Training Acc : 0.906, Run Time : 12.68
INFO:root:2019-05-11 09:06:44, Epoch : 1, Step : 8090, Training Loss : 0.40081, Training Acc : 0.839, Run Time : 7.80
INFO:root:2019-05-11 09:06:46, Epoch : 1, Step : 8091, Training Loss : 0.40281, Training Acc : 0.844, Run Time : 1.69
INFO:root:2019-05-11 09:06:58, Epoch : 1, Step : 8092, Training Loss : 0.23398, Training Acc : 0.900, Run Time : 12.46
INFO:root:2019-05-11 09:06:59, Epoch : 1, Step : 8093, Training Loss : 0.41546, Training Acc : 0.806, Run Time : 0.89
INFO:root:2019-05-11 09:07:01, Epoch : 1, Step : 8094, Training Loss : 0.29120, Training Acc : 0.889, Run Time : 1.78
INFO:root:2019-05-11 09:07:14, Epoch : 1, Step : 8095, Training Loss : 0.20691, Training Acc : 0.911, Run Time : 12.84
INFO:root:2019-05-11 09:07:34, Epoch : 1, Step : 8096, Training Loss : 0.27253, Training Acc : 0.883, Run Time : 20.54
INFO:root:2019-05-11 09:07:57, Epoch : 1, Step : 8097, Training Loss : 0.28075, Training Acc : 0.883, Run Time : 22.46
INFO:root:2019-05-11 09:08:03, Epoch : 1, Step : 8098, Training Loss : 0.23119, Training Acc : 0.889, Run Time : 5.98
INFO:root:2019-05-11 09:08:06, Epoch : 1, Step : 8099, Training Loss : 0.17947, Training Acc : 0.928, Run Time : 3.61
INFO:root:2019-05-11 09:08:24, Epoch : 1, Step : 8100, Training Loss : 0.26844, Training Acc : 0.906, Run Time : 17.57
INFO:root:2019-05-11 09:08:36, Epoch : 1, Step : 8101, Training Loss : 0.28107, Training Acc : 0.922, Run Time : 12.73
INFO:root:2019-05-11 09:08:48, Epoch : 1, Step : 8102, Training Loss : 0.29283, Training Acc : 0.872, Run Time : 11.54
INFO:root:2019-05-11 09:08:49, Epoch : 1, Step : 8103, Training Loss : 0.19335, Training Acc : 0.917, Run Time : 1.15
INFO:root:2019-05-11 09:08:51, Epoch : 1, Step : 8104, Training Loss : 0.28174, Training Acc : 0.878, Run Time : 1.46
INFO:root:2019-05-11 09:09:17, Epoch : 1, Step : 8105, Training Loss : 0.31118, Training Acc : 0.906, Run Time : 26.81
INFO:root:2019-05-11 09:09:23, Epoch : 1, Step : 8106, Training Loss : 0.21618, Training Acc : 0.928, Run Time : 5.86
INFO:root:2019-05-11 09:09:24, Epoch : 1, Step : 8107, Training Loss : 0.29984, Training Acc : 0.872, Run Time : 0.77
INFO:root:2019-05-11 09:09:36, Epoch : 1, Step : 8108, Training Loss : 0.16418, Training Acc : 0.944, Run Time : 11.96
INFO:root:2019-05-11 09:09:37, Epoch : 1, Step : 8109, Training Loss : 0.15059, Training Acc : 0.944, Run Time : 0.58
INFO:root:2019-05-11 09:09:37, Epoch : 1, Step : 8110, Training Loss : 0.19104, Training Acc : 0.933, Run Time : 0.40
INFO:root:2019-05-11 09:09:39, Epoch : 1, Step : 8111, Training Loss : 0.22035, Training Acc : 0.906, Run Time : 2.44
INFO:root:2019-05-11 09:10:02, Epoch : 1, Step : 8112, Training Loss : 0.23746, Training Acc : 0.894, Run Time : 22.38
INFO:root:2019-05-11 09:10:03, Epoch : 1, Step : 8113, Training Loss : 0.23535, Training Acc : 0.900, Run Time : 1.37
INFO:root:2019-05-11 09:10:04, Epoch : 1, Step : 8114, Training Loss : 0.23003, Training Acc : 0.889, Run Time : 0.53
INFO:root:2019-05-11 09:10:05, Epoch : 1, Step : 8115, Training Loss : 0.23529, Training Acc : 0.883, Run Time : 1.08
INFO:root:2019-05-11 09:10:15, Epoch : 1, Step : 8116, Training Loss : 0.19783, Training Acc : 0.917, Run Time : 10.71
INFO:root:2019-05-11 09:10:17, Epoch : 1, Step : 8117, Training Loss : 0.23221, Training Acc : 0.867, Run Time : 1.32
INFO:root:2019-05-11 09:10:29, Epoch : 1, Step : 8118, Training Loss : 0.16165, Training Acc : 0.922, Run Time : 11.87
INFO:root:2019-05-11 09:10:29, Epoch : 1, Step : 8119, Training Loss : 0.12257, Training Acc : 0.961, Run Time : 0.60
INFO:root:2019-05-11 09:10:31, Epoch : 1, Step : 8120, Training Loss : 0.17090, Training Acc : 0.917, Run Time : 1.52
INFO:root:2019-05-11 09:10:51, Epoch : 1, Step : 8121, Training Loss : 0.22029, Training Acc : 0.906, Run Time : 20.52
INFO:root:2019-05-11 09:10:53, Epoch : 1, Step : 8122, Training Loss : 0.18645, Training Acc : 0.922, Run Time : 1.33
INFO:root:2019-05-11 09:10:53, Epoch : 1, Step : 8123, Training Loss : 0.22396, Training Acc : 0.917, Run Time : 0.45
INFO:root:2019-05-11 09:10:54, Epoch : 1, Step : 8124, Training Loss : 0.32292, Training Acc : 0.867, Run Time : 1.24
INFO:root:2019-05-11 09:11:05, Epoch : 1, Step : 8125, Training Loss : 0.25483, Training Acc : 0.867, Run Time : 11.17
INFO:root:2019-05-11 09:11:09, Epoch : 1, Step : 8126, Training Loss : 0.26646, Training Acc : 0.878, Run Time : 3.55
INFO:root:2019-05-11 09:11:21, Epoch : 1, Step : 8127, Training Loss : 0.29119, Training Acc : 0.850, Run Time : 11.47
INFO:root:2019-05-11 09:11:21, Epoch : 1, Step : 8128, Training Loss : 0.32822, Training Acc : 0.850, Run Time : 0.71
INFO:root:2019-05-11 09:11:23, Epoch : 1, Step : 8129, Training Loss : 0.26729, Training Acc : 0.839, Run Time : 2.23
INFO:root:2019-05-11 09:11:35, Epoch : 1, Step : 8130, Training Loss : 0.19560, Training Acc : 0.917, Run Time : 11.12
INFO:root:2019-05-11 09:11:35, Epoch : 1, Step : 8131, Training Loss : 0.27045, Training Acc : 0.889, Run Time : 0.93
INFO:root:2019-05-11 09:11:51, Epoch : 1, Step : 8132, Training Loss : 0.25357, Training Acc : 0.883, Run Time : 15.81
INFO:root:2019-05-11 09:11:56, Epoch : 1, Step : 8133, Training Loss : 0.26381, Training Acc : 0.867, Run Time : 4.94
INFO:root:2019-05-11 09:11:57, Epoch : 1, Step : 8134, Training Loss : 0.24330, Training Acc : 0.867, Run Time : 0.41
INFO:root:2019-05-11 09:11:58, Epoch : 1, Step : 8135, Training Loss : 0.34760, Training Acc : 0.822, Run Time : 1.74
INFO:root:2019-05-11 09:12:09, Epoch : 1, Step : 8136, Training Loss : 0.31270, Training Acc : 0.817, Run Time : 10.47
INFO:root:2019-05-11 09:12:10, Epoch : 1, Step : 8137, Training Loss : 0.30838, Training Acc : 0.828, Run Time : 0.78
INFO:root:2019-05-11 09:12:39, Epoch : 1, Step : 8138, Training Loss : 0.28031, Training Acc : 0.867, Run Time : 29.18
INFO:root:2019-05-11 09:13:01, Epoch : 1, Step : 8139, Training Loss : 0.23522, Training Acc : 0.894, Run Time : 22.23
INFO:root:2019-05-11 09:13:07, Epoch : 1, Step : 8140, Training Loss : 0.19323, Training Acc : 0.894, Run Time : 6.17
INFO:root:2019-05-11 09:13:19, Epoch : 1, Step : 8141, Training Loss : 0.27289, Training Acc : 0.856, Run Time : 11.53
INFO:root:2019-05-11 09:13:21, Epoch : 1, Step : 8142, Training Loss : 0.20514, Training Acc : 0.900, Run Time : 1.87
INFO:root:2019-05-11 09:13:42, Epoch : 1, Step : 8143, Training Loss : 0.20062, Training Acc : 0.900, Run Time : 21.02
INFO:root:2019-05-11 09:13:58, Epoch : 1, Step : 8144, Training Loss : 0.19809, Training Acc : 0.933, Run Time : 16.75
INFO:root:2019-05-11 09:14:10, Epoch : 1, Step : 8145, Training Loss : 0.20618, Training Acc : 0.917, Run Time : 11.34
INFO:root:2019-05-11 09:14:24, Epoch : 1, Step : 8146, Training Loss : 0.22120, Training Acc : 0.928, Run Time : 14.34
INFO:root:2019-05-11 09:14:25, Epoch : 1, Step : 8147, Training Loss : 0.17906, Training Acc : 0.922, Run Time : 0.91
INFO:root:2019-05-11 09:14:49, Epoch : 1, Step : 8148, Training Loss : 0.14830, Training Acc : 0.961, Run Time : 24.16
INFO:root:2019-05-11 09:14:58, Epoch : 1, Step : 8149, Training Loss : 0.24817, Training Acc : 0.889, Run Time : 8.53
INFO:root:2019-05-11 09:14:58, Epoch : 1, Step : 8150, Training Loss : 0.19192, Training Acc : 0.933, Run Time : 0.49
INFO:root:2019-05-11 09:15:00, Epoch : 1, Step : 8151, Training Loss : 0.19327, Training Acc : 0.911, Run Time : 1.75
INFO:root:2019-05-11 09:15:13, Epoch : 1, Step : 8152, Training Loss : 0.21999, Training Acc : 0.867, Run Time : 13.35
INFO:root:2019-05-11 09:15:45, Epoch : 1, Step : 8153, Training Loss : 0.24624, Training Acc : 0.883, Run Time : 31.63
INFO:root:2019-05-11 09:15:51, Epoch : 1, Step : 8154, Training Loss : 0.28695, Training Acc : 0.856, Run Time : 6.50
INFO:root:2019-05-11 09:16:14, Epoch : 1, Step : 8155, Training Loss : 0.25144, Training Acc : 0.878, Run Time : 22.65
INFO:root:2019-05-11 09:16:16, Epoch : 1, Step : 8156, Training Loss : 0.29282, Training Acc : 0.856, Run Time : 1.93
INFO:root:2019-05-11 09:16:16, Epoch : 1, Step : 8157, Training Loss : 0.17929, Training Acc : 0.917, Run Time : 0.39
INFO:root:2019-05-11 09:16:18, Epoch : 1, Step : 8158, Training Loss : 0.24316, Training Acc : 0.900, Run Time : 1.41
INFO:root:2019-05-11 09:16:28, Epoch : 1, Step : 8159, Training Loss : 0.26729, Training Acc : 0.878, Run Time : 9.92
INFO:root:2019-05-11 09:16:30, Epoch : 1, Step : 8160, Training Loss : 0.18847, Training Acc : 0.944, Run Time : 2.33
INFO:root:2019-05-11 09:16:41, Epoch : 1, Step : 8161, Training Loss : 0.12517, Training Acc : 0.956, Run Time : 11.45
INFO:root:2019-05-11 09:16:42, Epoch : 1, Step : 8162, Training Loss : 0.12599, Training Acc : 0.961, Run Time : 0.60
INFO:root:2019-05-11 09:16:44, Epoch : 1, Step : 8163, Training Loss : 0.11213, Training Acc : 0.967, Run Time : 1.88
INFO:root:2019-05-11 09:16:54, Epoch : 1, Step : 8164, Training Loss : 0.08376, Training Acc : 0.978, Run Time : 10.56
INFO:root:2019-05-11 09:16:55, Epoch : 1, Step : 8165, Training Loss : 0.08779, Training Acc : 0.967, Run Time : 0.64
INFO:root:2019-05-11 09:16:56, Epoch : 1, Step : 8166, Training Loss : 0.11056, Training Acc : 0.944, Run Time : 1.17
INFO:root:2019-05-11 09:17:19, Epoch : 1, Step : 8167, Training Loss : 0.12215, Training Acc : 0.939, Run Time : 22.28
INFO:root:2019-05-11 09:17:21, Epoch : 1, Step : 8168, Training Loss : 0.14069, Training Acc : 0.950, Run Time : 1.98
INFO:root:2019-05-11 09:17:22, Epoch : 1, Step : 8169, Training Loss : 0.16425, Training Acc : 0.928, Run Time : 1.74
INFO:root:2019-05-11 09:17:39, Epoch : 1, Step : 8170, Training Loss : 0.11884, Training Acc : 0.956, Run Time : 16.46
INFO:root:2019-05-11 09:17:40, Epoch : 1, Step : 8171, Training Loss : 0.11995, Training Acc : 0.950, Run Time : 1.46
INFO:root:2019-05-11 09:17:41, Epoch : 1, Step : 8172, Training Loss : 0.17716, Training Acc : 0.917, Run Time : 0.41
INFO:root:2019-05-11 09:17:42, Epoch : 1, Step : 8173, Training Loss : 0.20182, Training Acc : 0.917, Run Time : 1.33
INFO:root:2019-05-11 09:17:52, Epoch : 1, Step : 8174, Training Loss : 0.21326, Training Acc : 0.906, Run Time : 10.36
INFO:root:2019-05-11 09:17:53, Epoch : 1, Step : 8175, Training Loss : 0.09814, Training Acc : 0.978, Run Time : 0.97
INFO:root:2019-05-11 09:18:08, Epoch : 1, Step : 8176, Training Loss : 0.18731, Training Acc : 0.906, Run Time : 14.61
INFO:root:2019-05-11 09:18:20, Epoch : 1, Step : 8177, Training Loss : 0.09018, Training Acc : 0.978, Run Time : 12.17
INFO:root:2019-05-11 09:18:42, Epoch : 1, Step : 8178, Training Loss : 0.13018, Training Acc : 0.939, Run Time : 21.90
INFO:root:2019-05-11 09:18:57, Epoch : 1, Step : 8179, Training Loss : 0.15685, Training Acc : 0.928, Run Time : 14.78
INFO:root:2019-05-11 09:19:53, Epoch : 1, Step : 8180, Training Loss : 0.11546, Training Acc : 0.950, Run Time : 56.31
INFO:root:2019-05-11 09:19:55, Epoch : 1, Step : 8181, Training Loss : 0.11627, Training Acc : 0.950, Run Time : 1.56
INFO:root:2019-05-11 09:19:55, Epoch : 1, Step : 8182, Training Loss : 0.14424, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 09:19:56, Epoch : 1, Step : 8183, Training Loss : 0.09468, Training Acc : 0.961, Run Time : 1.34
INFO:root:2019-05-11 09:20:10, Epoch : 1, Step : 8184, Training Loss : 0.08447, Training Acc : 0.961, Run Time : 13.82
INFO:root:2019-05-11 09:20:13, Epoch : 1, Step : 8185, Training Loss : 0.08715, Training Acc : 0.978, Run Time : 2.50
INFO:root:2019-05-11 09:20:29, Epoch : 1, Step : 8186, Training Loss : 0.07527, Training Acc : 0.978, Run Time : 16.41
INFO:root:2019-05-11 09:20:30, Epoch : 1, Step : 8187, Training Loss : 0.07912, Training Acc : 0.972, Run Time : 1.31
INFO:root:2019-05-11 09:20:32, Epoch : 1, Step : 8188, Training Loss : 0.07797, Training Acc : 0.983, Run Time : 1.44
INFO:root:2019-05-11 09:20:43, Epoch : 1, Step : 8189, Training Loss : 0.19675, Training Acc : 0.922, Run Time : 11.13
INFO:root:2019-05-11 09:21:08, Epoch : 1, Step : 8190, Training Loss : 0.16637, Training Acc : 0.917, Run Time : 25.45
INFO:root:2019-05-11 09:21:10, Epoch : 1, Step : 8191, Training Loss : 0.20334, Training Acc : 0.928, Run Time : 1.74
INFO:root:2019-05-11 09:21:11, Epoch : 1, Step : 8192, Training Loss : 0.23291, Training Acc : 0.894, Run Time : 0.42
INFO:root:2019-05-11 09:21:12, Epoch : 1, Step : 8193, Training Loss : 0.35310, Training Acc : 0.906, Run Time : 1.24
INFO:root:2019-05-11 09:21:28, Epoch : 1, Step : 8194, Training Loss : 0.33967, Training Acc : 0.883, Run Time : 16.20
INFO:root:2019-05-11 09:21:52, Epoch : 1, Step : 8195, Training Loss : 0.14579, Training Acc : 0.944, Run Time : 24.23
INFO:root:2019-05-11 09:21:55, Epoch : 1, Step : 8196, Training Loss : 0.17603, Training Acc : 0.933, Run Time : 2.36
INFO:root:2019-05-11 09:21:56, Epoch : 1, Step : 8197, Training Loss : 0.24759, Training Acc : 0.906, Run Time : 1.81
INFO:root:2019-05-11 09:22:09, Epoch : 1, Step : 8198, Training Loss : 0.22395, Training Acc : 0.900, Run Time : 12.58
INFO:root:2019-05-11 09:22:10, Epoch : 1, Step : 8199, Training Loss : 0.11035, Training Acc : 0.961, Run Time : 1.00
INFO:root:2019-05-11 09:22:13, Epoch : 1, Step : 8200, Training Loss : 0.19641, Training Acc : 0.917, Run Time : 2.84
INFO:root:2019-05-11 09:22:42, Epoch : 1, Step : 8201, Training Loss : 0.28234, Training Acc : 0.867, Run Time : 29.45
INFO:root:2019-05-11 09:22:59, Epoch : 1, Step : 8202, Training Loss : 0.25116, Training Acc : 0.894, Run Time : 17.21
INFO:root:2019-05-11 09:23:08, Epoch : 1, Step : 8203, Training Loss : 0.65138, Training Acc : 0.733, Run Time : 8.50
INFO:root:2019-05-11 09:23:19, Epoch : 1, Step : 8204, Training Loss : 0.58105, Training Acc : 0.778, Run Time : 10.78
INFO:root:2019-05-11 09:23:19, Epoch : 1, Step : 8205, Training Loss : 0.56320, Training Acc : 0.761, Run Time : 0.59
INFO:root:2019-05-11 09:23:21, Epoch : 1, Step : 8206, Training Loss : 0.44581, Training Acc : 0.833, Run Time : 1.60
INFO:root:2019-05-11 09:23:31, Epoch : 1, Step : 8207, Training Loss : 0.38621, Training Acc : 0.811, Run Time : 9.93
INFO:root:2019-05-11 09:23:31, Epoch : 1, Step : 8208, Training Loss : 0.36611, Training Acc : 0.867, Run Time : 0.50
INFO:root:2019-05-11 09:23:33, Epoch : 1, Step : 8209, Training Loss : 0.25136, Training Acc : 0.883, Run Time : 2.08
INFO:root:2019-05-11 09:23:44, Epoch : 1, Step : 8210, Training Loss : 0.32232, Training Acc : 0.856, Run Time : 11.04
INFO:root:2019-05-11 09:23:45, Epoch : 1, Step : 8211, Training Loss : 0.21961, Training Acc : 0.894, Run Time : 0.65
INFO:root:2019-05-11 09:23:47, Epoch : 1, Step : 8212, Training Loss : 0.13587, Training Acc : 0.956, Run Time : 1.78
INFO:root:2019-05-11 09:24:08, Epoch : 1, Step : 8213, Training Loss : 0.34749, Training Acc : 0.861, Run Time : 21.48
INFO:root:2019-05-11 09:24:11, Epoch : 1, Step : 8214, Training Loss : 0.23357, Training Acc : 0.906, Run Time : 2.76
INFO:root:2019-05-11 09:24:12, Epoch : 1, Step : 8215, Training Loss : 0.20872, Training Acc : 0.906, Run Time : 0.41
INFO:root:2019-05-11 09:24:12, Epoch : 1, Step : 8216, Training Loss : 0.25123, Training Acc : 0.889, Run Time : 0.62
INFO:root:2019-05-11 09:24:26, Epoch : 1, Step : 8217, Training Loss : 0.21436, Training Acc : 0.928, Run Time : 13.50
INFO:root:2019-05-11 09:24:26, Epoch : 1, Step : 8218, Training Loss : 0.16262, Training Acc : 0.956, Run Time : 0.62
INFO:root:2019-05-11 09:24:27, Epoch : 1, Step : 8219, Training Loss : 0.24982, Training Acc : 0.900, Run Time : 0.41
INFO:root:2019-05-11 09:25:05, Epoch : 1, Step : 8220, Training Loss : 0.20741, Training Acc : 0.917, Run Time : 38.60
INFO:root:2019-05-11 09:25:17, Epoch : 1, Step : 8221, Training Loss : 0.23020, Training Acc : 0.922, Run Time : 11.37
INFO:root:2019-05-11 09:25:35, Epoch : 1, Step : 8222, Training Loss : 0.27854, Training Acc : 0.872, Run Time : 18.68
INFO:root:2019-05-11 09:25:41, Epoch : 1, Step : 8223, Training Loss : 0.17704, Training Acc : 0.939, Run Time : 5.38
INFO:root:2019-05-11 09:25:41, Epoch : 1, Step : 8224, Training Loss : 0.10506, Training Acc : 0.983, Run Time : 0.45
INFO:root:2019-05-11 09:25:58, Epoch : 1, Step : 8225, Training Loss : 0.14960, Training Acc : 0.950, Run Time : 16.59
INFO:root:2019-05-11 09:26:07, Epoch : 1, Step : 8226, Training Loss : 0.19030, Training Acc : 0.933, Run Time : 8.85
INFO:root:2019-05-11 09:26:18, Epoch : 1, Step : 8227, Training Loss : 0.09955, Training Acc : 0.967, Run Time : 11.42
INFO:root:2019-05-11 09:26:19, Epoch : 1, Step : 8228, Training Loss : 0.16455, Training Acc : 0.944, Run Time : 1.22
INFO:root:2019-05-11 09:26:20, Epoch : 1, Step : 8229, Training Loss : 0.06904, Training Acc : 0.989, Run Time : 0.44
INFO:root:2019-05-11 09:26:21, Epoch : 1, Step : 8230, Training Loss : 0.08496, Training Acc : 0.972, Run Time : 1.34
INFO:root:2019-05-11 09:26:32, Epoch : 1, Step : 8231, Training Loss : 0.08001, Training Acc : 0.989, Run Time : 10.83
INFO:root:2019-05-11 09:26:32, Epoch : 1, Step : 8232, Training Loss : 0.04612, Training Acc : 0.989, Run Time : 0.62
INFO:root:2019-05-11 09:26:34, Epoch : 1, Step : 8233, Training Loss : 0.08871, Training Acc : 0.972, Run Time : 1.85
INFO:root:2019-05-11 09:27:19, Epoch : 1, Step : 8234, Training Loss : 0.06835, Training Acc : 0.989, Run Time : 45.06
INFO:root:2019-05-11 09:27:24, Epoch : 1, Step : 8235, Training Loss : 0.13898, Training Acc : 0.928, Run Time : 5.02
INFO:root:2019-05-11 09:27:25, Epoch : 1, Step : 8236, Training Loss : 0.11583, Training Acc : 0.956, Run Time : 0.58
INFO:root:2019-05-11 09:28:01, Epoch : 1, Step : 8237, Training Loss : 0.09318, Training Acc : 0.972, Run Time : 35.89
INFO:root:2019-05-11 09:28:07, Epoch : 1, Step : 8238, Training Loss : 0.06336, Training Acc : 0.978, Run Time : 5.95
INFO:root:2019-05-11 09:28:07, Epoch : 1, Step : 8239, Training Loss : 0.07834, Training Acc : 0.972, Run Time : 0.66
INFO:root:2019-05-11 09:28:25, Epoch : 1, Step : 8240, Training Loss : 0.04792, Training Acc : 0.989, Run Time : 17.65
INFO:root:2019-05-11 09:28:38, Epoch : 1, Step : 8241, Training Loss : 0.18191, Training Acc : 0.933, Run Time : 13.00
INFO:root:2019-05-11 09:28:55, Epoch : 1, Step : 8242, Training Loss : 0.18836, Training Acc : 0.911, Run Time : 16.75
INFO:root:2019-05-11 09:28:56, Epoch : 1, Step : 8243, Training Loss : 0.05630, Training Acc : 0.989, Run Time : 1.37
INFO:root:2019-05-11 09:28:58, Epoch : 1, Step : 8244, Training Loss : 0.06962, Training Acc : 0.972, Run Time : 1.66
INFO:root:2019-05-11 09:29:17, Epoch : 1, Step : 8245, Training Loss : 0.18217, Training Acc : 0.928, Run Time : 19.01
INFO:root:2019-05-11 09:29:19, Epoch : 1, Step : 8246, Training Loss : 0.07407, Training Acc : 0.967, Run Time : 1.66
INFO:root:2019-05-11 09:29:19, Epoch : 1, Step : 8247, Training Loss : 0.04335, Training Acc : 0.989, Run Time : 0.41
INFO:root:2019-05-11 09:30:03, Epoch : 1, Step : 8248, Training Loss : 0.07727, Training Acc : 0.961, Run Time : 43.59
INFO:root:2019-05-11 09:30:25, Epoch : 1, Step : 8249, Training Loss : 0.11271, Training Acc : 0.939, Run Time : 22.70
INFO:root:2019-05-11 09:30:27, Epoch : 1, Step : 8250, Training Loss : 0.09483, Training Acc : 0.983, Run Time : 2.13
INFO:root:2019-05-11 09:30:28, Epoch : 1, Step : 8251, Training Loss : 0.09044, Training Acc : 0.972, Run Time : 0.41
INFO:root:2019-05-11 09:30:37, Epoch : 1, Step : 8252, Training Loss : 0.26793, Training Acc : 0.883, Run Time : 9.56
INFO:root:2019-05-11 09:30:38, Epoch : 1, Step : 8253, Training Loss : 0.09362, Training Acc : 0.956, Run Time : 0.80
INFO:root:2019-05-11 09:30:39, Epoch : 1, Step : 8254, Training Loss : 0.04969, Training Acc : 0.994, Run Time : 0.38
INFO:root:2019-05-11 09:31:04, Epoch : 1, Step : 8255, Training Loss : 0.07091, Training Acc : 0.978, Run Time : 25.10
INFO:root:2019-05-11 09:31:09, Epoch : 1, Step : 8256, Training Loss : 0.07036, Training Acc : 0.983, Run Time : 4.88
INFO:root:2019-05-11 09:31:11, Epoch : 1, Step : 8257, Training Loss : 0.05174, Training Acc : 0.994, Run Time : 2.07
INFO:root:2019-05-11 09:31:35, Epoch : 1, Step : 8258, Training Loss : 0.15502, Training Acc : 0.939, Run Time : 24.53
INFO:root:2019-05-11 09:31:37, Epoch : 1, Step : 8259, Training Loss : 0.08172, Training Acc : 0.983, Run Time : 1.94
INFO:root:2019-05-11 09:31:38, Epoch : 1, Step : 8260, Training Loss : 0.07896, Training Acc : 0.978, Run Time : 1.33
INFO:root:2019-05-11 09:32:00, Epoch : 1, Step : 8261, Training Loss : 0.13327, Training Acc : 0.944, Run Time : 21.22
INFO:root:2019-05-11 09:32:12, Epoch : 1, Step : 8262, Training Loss : 0.15477, Training Acc : 0.917, Run Time : 12.03
INFO:root:2019-05-11 09:32:21, Epoch : 1, Step : 8263, Training Loss : 0.18300, Training Acc : 0.911, Run Time : 9.23
INFO:root:2019-05-11 09:32:37, Epoch : 1, Step : 8264, Training Loss : 0.06199, Training Acc : 0.978, Run Time : 16.20
INFO:root:2019-05-11 09:32:39, Epoch : 1, Step : 8265, Training Loss : 0.10625, Training Acc : 0.956, Run Time : 2.22
INFO:root:2019-05-11 09:32:52, Epoch : 1, Step : 8266, Training Loss : 0.11324, Training Acc : 0.956, Run Time : 12.26
INFO:root:2019-05-11 09:33:07, Epoch : 1, Step : 8267, Training Loss : 0.04738, Training Acc : 0.989, Run Time : 15.20
INFO:root:2019-05-11 09:33:08, Epoch : 1, Step : 8268, Training Loss : 0.05707, Training Acc : 0.994, Run Time : 1.11
INFO:root:2019-05-11 09:33:21, Epoch : 1, Step : 8269, Training Loss : 0.05771, Training Acc : 0.978, Run Time : 12.60
INFO:root:2019-05-11 09:33:23, Epoch : 1, Step : 8270, Training Loss : 0.08148, Training Acc : 0.972, Run Time : 2.96
INFO:root:2019-05-11 09:33:35, Epoch : 1, Step : 8271, Training Loss : 0.10710, Training Acc : 0.956, Run Time : 11.17
INFO:root:2019-05-11 09:33:36, Epoch : 1, Step : 8272, Training Loss : 0.11478, Training Acc : 0.967, Run Time : 1.02
INFO:root:2019-05-11 09:33:37, Epoch : 1, Step : 8273, Training Loss : 0.11368, Training Acc : 0.967, Run Time : 1.83
INFO:root:2019-05-11 09:33:51, Epoch : 1, Step : 8274, Training Loss : 0.13041, Training Acc : 0.956, Run Time : 13.60
INFO:root:2019-05-11 09:33:54, Epoch : 1, Step : 8275, Training Loss : 0.17394, Training Acc : 0.939, Run Time : 2.84
INFO:root:2019-05-11 09:34:51, Epoch : 1, Step : 8276, Training Loss : 0.09241, Training Acc : 0.967, Run Time : 56.67
INFO:root:2019-05-11 09:34:58, Epoch : 1, Step : 8277, Training Loss : 0.09708, Training Acc : 0.961, Run Time : 7.89
INFO:root:2019-05-11 09:35:11, Epoch : 1, Step : 8278, Training Loss : 0.12186, Training Acc : 0.944, Run Time : 12.72
INFO:root:2019-05-11 09:35:12, Epoch : 1, Step : 8279, Training Loss : 0.11110, Training Acc : 0.950, Run Time : 0.48
INFO:root:2019-05-11 09:35:13, Epoch : 1, Step : 8280, Training Loss : 0.09617, Training Acc : 0.967, Run Time : 1.65
INFO:root:2019-05-11 09:36:38, Epoch : 1, Step : 8281, Training Loss : 0.14596, Training Acc : 0.933, Run Time : 84.38
INFO:root:2019-05-11 09:36:51, Epoch : 1, Step : 8282, Training Loss : 0.18427, Training Acc : 0.911, Run Time : 13.24
INFO:root:2019-05-11 09:37:26, Epoch : 1, Step : 8283, Training Loss : 0.24783, Training Acc : 0.911, Run Time : 35.07
INFO:root:2019-05-11 09:37:28, Epoch : 1, Step : 8284, Training Loss : 0.27885, Training Acc : 0.889, Run Time : 1.96
INFO:root:2019-05-11 09:37:28, Epoch : 1, Step : 8285, Training Loss : 0.23800, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 09:37:44, Epoch : 1, Step : 8286, Training Loss : 0.18080, Training Acc : 0.950, Run Time : 15.56
INFO:root:2019-05-11 09:37:45, Epoch : 1, Step : 8287, Training Loss : 0.19159, Training Acc : 0.911, Run Time : 0.97
INFO:root:2019-05-11 09:38:02, Epoch : 1, Step : 8288, Training Loss : 0.08669, Training Acc : 0.956, Run Time : 16.76
INFO:root:2019-05-11 09:38:19, Epoch : 1, Step : 8289, Training Loss : 0.12329, Training Acc : 0.961, Run Time : 16.97
INFO:root:2019-05-11 09:39:44, Epoch : 1, Step : 8290, Training Loss : 0.13252, Training Acc : 0.939, Run Time : 84.94
INFO:root:2019-05-11 09:40:00, Epoch : 1, Step : 8291, Training Loss : 0.21513, Training Acc : 0.894, Run Time : 16.31
INFO:root:2019-05-11 09:40:51, Epoch : 1, Step : 8292, Training Loss : 0.16326, Training Acc : 0.928, Run Time : 50.88
INFO:root:2019-05-11 09:41:02, Epoch : 1, Step : 8293, Training Loss : 0.13843, Training Acc : 0.950, Run Time : 11.27
INFO:root:2019-05-11 09:41:33, Epoch : 1, Step : 8294, Training Loss : 0.10184, Training Acc : 0.956, Run Time : 30.71
INFO:root:2019-05-11 09:41:40, Epoch : 1, Step : 8295, Training Loss : 0.19746, Training Acc : 0.922, Run Time : 6.84
INFO:root:2019-05-11 09:42:26, Epoch : 1, Step : 8296, Training Loss : 0.21840, Training Acc : 0.883, Run Time : 46.33
INFO:root:2019-05-11 09:42:45, Epoch : 1, Step : 8297, Training Loss : 0.07289, Training Acc : 0.967, Run Time : 19.34
INFO:root:2019-05-11 09:42:47, Epoch : 1, Step : 8298, Training Loss : 0.27665, Training Acc : 0.878, Run Time : 1.69
INFO:root:2019-05-11 09:42:47, Epoch : 1, Step : 8299, Training Loss : 0.26165, Training Acc : 0.872, Run Time : 0.41
INFO:root:2019-05-11 09:42:49, Epoch : 1, Step : 8300, Training Loss : 0.10968, Training Acc : 0.944, Run Time : 1.18
INFO:root:2019-05-11 09:43:00, Epoch : 1, Step : 8301, Training Loss : 0.17988, Training Acc : 0.933, Run Time : 11.16
INFO:root:2019-05-11 09:43:00, Epoch : 1, Step : 8302, Training Loss : 0.21010, Training Acc : 0.894, Run Time : 0.45
INFO:root:2019-05-11 09:43:02, Epoch : 1, Step : 8303, Training Loss : 0.11358, Training Acc : 0.967, Run Time : 2.24
INFO:root:2019-05-11 09:43:58, Epoch : 1, Step : 8304, Training Loss : 0.12323, Training Acc : 0.933, Run Time : 55.52
INFO:root:2019-05-11 09:44:05, Epoch : 1, Step : 8305, Training Loss : 0.15409, Training Acc : 0.939, Run Time : 6.87
INFO:root:2019-05-11 09:44:07, Epoch : 1, Step : 8306, Training Loss : 0.20217, Training Acc : 0.894, Run Time : 2.22
INFO:root:2019-05-11 09:44:22, Epoch : 1, Step : 8307, Training Loss : 0.06890, Training Acc : 0.983, Run Time : 14.60
INFO:root:2019-05-11 09:45:22, Epoch : 1, Step : 8308, Training Loss : 0.49254, Training Acc : 0.839, Run Time : 60.34
INFO:root:2019-05-11 09:45:57, Epoch : 1, Step : 8309, Training Loss : 0.17848, Training Acc : 0.944, Run Time : 34.98
INFO:root:2019-05-11 09:46:21, Epoch : 1, Step : 8310, Training Loss : 0.10359, Training Acc : 0.961, Run Time : 24.22
INFO:root:2019-05-11 09:46:49, Epoch : 1, Step : 8311, Training Loss : 0.19875, Training Acc : 0.961, Run Time : 27.63
INFO:root:2019-05-11 09:46:56, Epoch : 1, Step : 8312, Training Loss : 0.08734, Training Acc : 0.978, Run Time : 6.90
INFO:root:2019-05-11 09:47:08, Epoch : 1, Step : 8313, Training Loss : 0.06105, Training Acc : 1.000, Run Time : 12.54
INFO:root:2019-05-11 09:47:11, Epoch : 1, Step : 8314, Training Loss : 0.06553, Training Acc : 0.972, Run Time : 2.71
INFO:root:2019-05-11 09:48:09, Epoch : 1, Step : 8315, Training Loss : 0.05893, Training Acc : 0.983, Run Time : 57.66
INFO:root:2019-05-11 09:48:50, Epoch : 1, Step : 8316, Training Loss : 0.05891, Training Acc : 0.983, Run Time : 41.19
INFO:root:2019-05-11 09:48:51, Epoch : 1, Step : 8317, Training Loss : 0.10144, Training Acc : 0.961, Run Time : 1.52
INFO:root:2019-05-11 09:48:52, Epoch : 1, Step : 8318, Training Loss : 0.25958, Training Acc : 0.856, Run Time : 0.41
INFO:root:2019-05-11 09:48:53, Epoch : 1, Step : 8319, Training Loss : 0.13057, Training Acc : 0.950, Run Time : 1.63
INFO:root:2019-05-11 09:49:07, Epoch : 1, Step : 8320, Training Loss : 0.17655, Training Acc : 0.939, Run Time : 13.61
INFO:root:2019-05-11 09:49:08, Epoch : 1, Step : 8321, Training Loss : 0.12858, Training Acc : 0.944, Run Time : 0.57
INFO:root:2019-05-11 09:49:08, Epoch : 1, Step : 8322, Training Loss : 0.05498, Training Acc : 0.978, Run Time : 0.45
INFO:root:2019-05-11 09:49:26, Epoch : 1, Step : 8323, Training Loss : 0.06628, Training Acc : 0.972, Run Time : 17.57
INFO:root:2019-05-11 09:49:27, Epoch : 1, Step : 8324, Training Loss : 0.04793, Training Acc : 0.989, Run Time : 1.67
INFO:root:2019-05-11 09:49:28, Epoch : 1, Step : 8325, Training Loss : 0.03532, Training Acc : 1.000, Run Time : 0.38
INFO:root:2019-05-11 09:49:41, Epoch : 1, Step : 8326, Training Loss : 0.03322, Training Acc : 0.989, Run Time : 13.48
INFO:root:2019-05-11 09:49:43, Epoch : 1, Step : 8327, Training Loss : 0.02793, Training Acc : 0.994, Run Time : 1.57
INFO:root:2019-05-11 09:49:56, Epoch : 1, Step : 8328, Training Loss : 0.07345, Training Acc : 0.978, Run Time : 13.68
INFO:root:2019-05-11 09:49:57, Epoch : 1, Step : 8329, Training Loss : 0.03255, Training Acc : 0.994, Run Time : 0.56
INFO:root:2019-05-11 09:49:59, Epoch : 1, Step : 8330, Training Loss : 0.21675, Training Acc : 0.922, Run Time : 1.74
INFO:root:2019-05-11 09:50:15, Epoch : 1, Step : 8331, Training Loss : 0.02717, Training Acc : 0.994, Run Time : 16.09
INFO:root:2019-05-11 09:50:23, Epoch : 1, Step : 8332, Training Loss : 0.04270, Training Acc : 0.989, Run Time : 8.26
INFO:root:2019-05-11 09:51:07, Epoch : 1, Step : 8333, Training Loss : 0.05674, Training Acc : 0.983, Run Time : 44.38
INFO:root:2019-05-11 09:51:34, Epoch : 1, Step : 8334, Training Loss : 0.14700, Training Acc : 0.928, Run Time : 26.55
INFO:root:2019-05-11 09:51:40, Epoch : 1, Step : 8335, Training Loss : 0.09721, Training Acc : 0.961, Run Time : 6.20
INFO:root:2019-05-11 09:51:41, Epoch : 1, Step : 8336, Training Loss : 0.07108, Training Acc : 0.972, Run Time : 0.54
INFO:root:2019-05-11 09:51:57, Epoch : 1, Step : 8337, Training Loss : 0.07528, Training Acc : 0.967, Run Time : 16.26
INFO:root:2019-05-11 09:53:03, Epoch : 1, Step : 8338, Training Loss : 0.05461, Training Acc : 0.978, Run Time : 66.19
INFO:root:2019-05-11 09:53:20, Epoch : 1, Step : 8339, Training Loss : 0.03188, Training Acc : 0.994, Run Time : 16.70
INFO:root:2019-05-11 09:53:20, Epoch : 1, Step : 8340, Training Loss : 0.02403, Training Acc : 1.000, Run Time : 0.45
INFO:root:2019-05-11 09:53:21, Epoch : 1, Step : 8341, Training Loss : 0.03146, Training Acc : 1.000, Run Time : 0.38
INFO:root:2019-05-11 09:53:22, Epoch : 1, Step : 8342, Training Loss : 0.05153, Training Acc : 0.983, Run Time : 1.56
INFO:root:2019-05-11 09:53:33, Epoch : 1, Step : 8343, Training Loss : 0.07239, Training Acc : 0.972, Run Time : 11.27
INFO:root:2019-05-11 09:53:36, Epoch : 1, Step : 8344, Training Loss : 0.03551, Training Acc : 0.989, Run Time : 2.86
INFO:root:2019-05-11 09:54:22, Epoch : 1, Step : 8345, Training Loss : 0.08982, Training Acc : 0.956, Run Time : 46.17
INFO:root:2019-05-11 09:54:30, Epoch : 1, Step : 8346, Training Loss : 0.04570, Training Acc : 0.989, Run Time : 7.06
INFO:root:2019-05-11 09:54:59, Epoch : 1, Step : 8347, Training Loss : 0.03028, Training Acc : 0.994, Run Time : 29.37
INFO:root:2019-05-11 09:55:17, Epoch : 1, Step : 8348, Training Loss : 0.05039, Training Acc : 0.978, Run Time : 18.15
INFO:root:2019-05-11 09:55:19, Epoch : 1, Step : 8349, Training Loss : 0.08445, Training Acc : 0.961, Run Time : 2.40
INFO:root:2019-05-11 09:55:21, Epoch : 1, Step : 8350, Training Loss : 0.04369, Training Acc : 0.989, Run Time : 1.58
INFO:root:2019-05-11 09:55:33, Epoch : 1, Step : 8351, Training Loss : 0.02300, Training Acc : 1.000, Run Time : 12.19
INFO:root:2019-05-11 09:55:36, Epoch : 1, Step : 8352, Training Loss : 0.05479, Training Acc : 0.989, Run Time : 2.28
INFO:root:2019-05-11 09:55:47, Epoch : 1, Step : 8353, Training Loss : 0.02327, Training Acc : 0.994, Run Time : 11.96
INFO:root:2019-05-11 09:55:50, Epoch : 1, Step : 8354, Training Loss : 0.02558, Training Acc : 0.994, Run Time : 2.28
INFO:root:2019-05-11 09:56:15, Epoch : 1, Step : 8355, Training Loss : 0.04056, Training Acc : 0.989, Run Time : 25.63
INFO:root:2019-05-11 09:56:22, Epoch : 1, Step : 8356, Training Loss : 0.02475, Training Acc : 0.994, Run Time : 6.20
INFO:root:2019-05-11 09:56:22, Epoch : 1, Step : 8357, Training Loss : 0.01611, Training Acc : 1.000, Run Time : 0.65
INFO:root:2019-05-11 09:56:24, Epoch : 1, Step : 8358, Training Loss : 0.07968, Training Acc : 0.967, Run Time : 1.56
INFO:root:2019-05-11 09:57:11, Epoch : 1, Step : 8359, Training Loss : 0.09029, Training Acc : 0.961, Run Time : 47.49
INFO:root:2019-05-11 09:57:35, Epoch : 1, Step : 8360, Training Loss : 0.04209, Training Acc : 1.000, Run Time : 23.89
INFO:root:2019-05-11 09:57:49, Epoch : 1, Step : 8361, Training Loss : 0.02833, Training Acc : 1.000, Run Time : 13.94
INFO:root:2019-05-11 09:58:07, Epoch : 1, Step : 8362, Training Loss : 0.04620, Training Acc : 0.989, Run Time : 18.33
INFO:root:2019-05-11 09:58:41, Epoch : 1, Step : 8363, Training Loss : 0.09528, Training Acc : 0.972, Run Time : 33.26
INFO:root:2019-05-11 09:58:42, Epoch : 1, Step : 8364, Training Loss : 0.13891, Training Acc : 0.944, Run Time : 1.52
INFO:root:2019-05-11 09:58:43, Epoch : 1, Step : 8365, Training Loss : 0.07546, Training Acc : 0.983, Run Time : 0.42
INFO:root:2019-05-11 09:58:44, Epoch : 1, Step : 8366, Training Loss : 0.15289, Training Acc : 0.944, Run Time : 1.51
INFO:root:2019-05-11 09:59:12, Epoch : 1, Step : 8367, Training Loss : 0.04845, Training Acc : 0.989, Run Time : 28.14
INFO:root:2019-05-11 09:59:43, Epoch : 1, Step : 8368, Training Loss : 0.12362, Training Acc : 0.933, Run Time : 31.13
INFO:root:2019-05-11 10:00:06, Epoch : 1, Step : 8369, Training Loss : 0.04262, Training Acc : 0.989, Run Time : 22.87
INFO:root:2019-05-11 10:00:08, Epoch : 1, Step : 8370, Training Loss : 0.11159, Training Acc : 0.978, Run Time : 1.51
INFO:root:2019-05-11 10:00:08, Epoch : 1, Step : 8371, Training Loss : 0.09590, Training Acc : 0.956, Run Time : 0.38
INFO:root:2019-05-11 10:00:10, Epoch : 1, Step : 8372, Training Loss : 0.07246, Training Acc : 0.978, Run Time : 1.40
INFO:root:2019-05-11 10:00:51, Epoch : 1, Step : 8373, Training Loss : 0.13015, Training Acc : 0.939, Run Time : 41.47
INFO:root:2019-05-11 10:00:56, Epoch : 1, Step : 8374, Training Loss : 0.08278, Training Acc : 0.972, Run Time : 4.90
INFO:root:2019-05-11 10:00:58, Epoch : 1, Step : 8375, Training Loss : 0.03534, Training Acc : 0.989, Run Time : 2.15
INFO:root:2019-05-11 10:01:09, Epoch : 1, Step : 8376, Training Loss : 0.04059, Training Acc : 0.978, Run Time : 11.32
INFO:root:2019-05-11 10:01:10, Epoch : 1, Step : 8377, Training Loss : 0.04095, Training Acc : 0.983, Run Time : 0.41
INFO:root:2019-05-11 10:01:10, Epoch : 1, Step : 8378, Training Loss : 0.04977, Training Acc : 0.978, Run Time : 0.42
INFO:root:2019-05-11 10:01:31, Epoch : 1, Step : 8379, Training Loss : 0.03921, Training Acc : 0.989, Run Time : 20.45
INFO:root:2019-05-11 10:01:33, Epoch : 1, Step : 8380, Training Loss : 0.11200, Training Acc : 0.961, Run Time : 2.04
INFO:root:2019-05-11 10:01:34, Epoch : 1, Step : 8381, Training Loss : 0.13820, Training Acc : 0.939, Run Time : 1.24
INFO:root:2019-05-11 10:01:45, Epoch : 1, Step : 8382, Training Loss : 0.14915, Training Acc : 0.922, Run Time : 10.82
INFO:root:2019-05-11 10:01:46, Epoch : 1, Step : 8383, Training Loss : 0.19011, Training Acc : 0.922, Run Time : 0.94
INFO:root:2019-05-11 10:01:54, Epoch : 1, Step : 8384, Training Loss : 0.19756, Training Acc : 0.894, Run Time : 8.22
INFO:root:2019-05-11 10:02:07, Epoch : 1, Step : 8385, Training Loss : 0.26150, Training Acc : 0.894, Run Time : 13.39
INFO:root:2019-05-11 10:02:24, Epoch : 1, Step : 8386, Training Loss : 0.04902, Training Acc : 0.983, Run Time : 16.33
INFO:root:2019-05-11 10:02:33, Epoch : 1, Step : 8387, Training Loss : 0.11581, Training Acc : 0.950, Run Time : 8.85
INFO:root:2019-05-11 10:02:44, Epoch : 1, Step : 8388, Training Loss : 0.15324, Training Acc : 0.939, Run Time : 11.95
INFO:root:2019-05-11 10:02:45, Epoch : 1, Step : 8389, Training Loss : 0.07401, Training Acc : 0.967, Run Time : 0.87
INFO:root:2019-05-11 10:02:47, Epoch : 1, Step : 8390, Training Loss : 0.02676, Training Acc : 0.989, Run Time : 1.90
INFO:root:2019-05-11 10:03:03, Epoch : 1, Step : 8391, Training Loss : 0.12322, Training Acc : 0.939, Run Time : 15.38
INFO:root:2019-05-11 10:03:25, Epoch : 1, Step : 8392, Training Loss : 0.07871, Training Acc : 0.978, Run Time : 22.84
INFO:root:2019-05-11 10:03:48, Epoch : 1, Step : 8393, Training Loss : 0.05818, Training Acc : 0.978, Run Time : 22.26
INFO:root:2019-05-11 10:04:20, Epoch : 1, Step : 8394, Training Loss : 0.11724, Training Acc : 0.961, Run Time : 31.83
INFO:root:2019-05-11 10:04:22, Epoch : 1, Step : 8395, Training Loss : 0.13610, Training Acc : 0.950, Run Time : 1.99
INFO:root:2019-05-11 10:04:22, Epoch : 1, Step : 8396, Training Loss : 0.11952, Training Acc : 0.950, Run Time : 0.44
INFO:root:2019-05-11 10:04:45, Epoch : 1, Step : 8397, Training Loss : 0.11276, Training Acc : 0.950, Run Time : 23.06
INFO:root:2019-05-11 10:04:47, Epoch : 1, Step : 8398, Training Loss : 0.06038, Training Acc : 0.989, Run Time : 1.78
INFO:root:2019-05-11 10:04:47, Epoch : 1, Step : 8399, Training Loss : 0.10699, Training Acc : 0.961, Run Time : 0.41
INFO:root:2019-05-11 10:04:48, Epoch : 1, Step : 8400, Training Loss : 0.12117, Training Acc : 0.950, Run Time : 1.15
INFO:root:2019-05-11 10:04:58, Epoch : 1, Step : 8401, Training Loss : 0.47215, Training Acc : 0.783, Run Time : 9.68
INFO:root:2019-05-11 10:04:59, Epoch : 1, Step : 8402, Training Loss : 0.48363, Training Acc : 0.811, Run Time : 0.60
INFO:root:2019-05-11 10:05:01, Epoch : 1, Step : 8403, Training Loss : 0.39484, Training Acc : 0.850, Run Time : 2.19
INFO:root:2019-05-11 10:05:19, Epoch : 1, Step : 8404, Training Loss : 0.50682, Training Acc : 0.817, Run Time : 18.55
INFO:root:2019-05-11 10:05:21, Epoch : 1, Step : 8405, Training Loss : 0.45862, Training Acc : 0.861, Run Time : 1.42
INFO:root:2019-05-11 10:05:21, Epoch : 1, Step : 8406, Training Loss : 0.33445, Training Acc : 0.833, Run Time : 0.39
INFO:root:2019-05-11 10:05:47, Epoch : 1, Step : 8407, Training Loss : 0.25671, Training Acc : 0.894, Run Time : 25.44
INFO:root:2019-05-11 10:06:02, Epoch : 1, Step : 8408, Training Loss : 0.30026, Training Acc : 0.878, Run Time : 15.15
INFO:root:2019-05-11 10:06:21, Epoch : 1, Step : 8409, Training Loss : 0.21918, Training Acc : 0.911, Run Time : 19.07
INFO:root:2019-05-11 10:06:41, Epoch : 1, Step : 8410, Training Loss : 0.18824, Training Acc : 0.917, Run Time : 19.74
INFO:root:2019-05-11 10:06:55, Epoch : 1, Step : 8411, Training Loss : 0.21584, Training Acc : 0.917, Run Time : 14.49
INFO:root:2019-05-11 10:07:07, Epoch : 1, Step : 8412, Training Loss : 0.13637, Training Acc : 0.933, Run Time : 12.03
INFO:root:2019-05-11 10:07:09, Epoch : 1, Step : 8413, Training Loss : 0.12084, Training Acc : 0.939, Run Time : 1.66
INFO:root:2019-05-11 10:07:18, Epoch : 1, Step : 8414, Training Loss : 0.12922, Training Acc : 0.950, Run Time : 9.58
INFO:root:2019-05-11 10:07:19, Epoch : 1, Step : 8415, Training Loss : 0.13086, Training Acc : 0.944, Run Time : 0.58
INFO:root:2019-05-11 10:07:19, Epoch : 1, Step : 8416, Training Loss : 0.14181, Training Acc : 0.944, Run Time : 0.41
INFO:root:2019-05-11 10:07:33, Epoch : 1, Step : 8417, Training Loss : 0.13030, Training Acc : 0.939, Run Time : 13.42
INFO:root:2019-05-11 10:07:49, Epoch : 1, Step : 8418, Training Loss : 0.11050, Training Acc : 0.956, Run Time : 16.62
INFO:root:2019-05-11 10:07:52, Epoch : 1, Step : 8419, Training Loss : 0.09746, Training Acc : 0.967, Run Time : 2.10
INFO:root:2019-05-11 10:07:53, Epoch : 1, Step : 8420, Training Loss : 0.10224, Training Acc : 0.967, Run Time : 1.30
INFO:root:2019-05-11 10:08:07, Epoch : 1, Step : 8421, Training Loss : 0.11985, Training Acc : 0.950, Run Time : 14.20
INFO:root:2019-05-11 10:08:16, Epoch : 1, Step : 8422, Training Loss : 0.09560, Training Acc : 0.967, Run Time : 8.66
INFO:root:2019-05-11 10:08:30, Epoch : 1, Step : 8423, Training Loss : 0.09893, Training Acc : 0.956, Run Time : 14.30
INFO:root:2019-05-11 10:08:31, Epoch : 1, Step : 8424, Training Loss : 0.11206, Training Acc : 0.939, Run Time : 0.87
INFO:root:2019-05-11 10:08:32, Epoch : 1, Step : 8425, Training Loss : 0.05558, Training Acc : 0.978, Run Time : 1.44
INFO:root:2019-05-11 10:08:51, Epoch : 1, Step : 8426, Training Loss : 0.23816, Training Acc : 0.933, Run Time : 18.90
INFO:root:2019-05-11 10:08:53, Epoch : 1, Step : 8427, Training Loss : 0.67494, Training Acc : 0.822, Run Time : 1.94
INFO:root:2019-05-11 10:08:54, Epoch : 1, Step : 8428, Training Loss : 0.63258, Training Acc : 0.833, Run Time : 1.28
INFO:root:2019-05-11 10:09:04, Epoch : 1, Step : 8429, Training Loss : 0.58565, Training Acc : 0.850, Run Time : 9.60
INFO:root:2019-05-11 10:09:05, Epoch : 1, Step : 8430, Training Loss : 0.59654, Training Acc : 0.833, Run Time : 0.48
INFO:root:2019-05-11 10:09:07, Epoch : 1, Step : 8431, Training Loss : 0.14542, Training Acc : 0.956, Run Time : 2.09
INFO:root:2019-05-11 10:09:21, Epoch : 1, Step : 8432, Training Loss : 0.21373, Training Acc : 0.900, Run Time : 14.26
INFO:root:2019-05-11 10:09:43, Epoch : 1, Step : 8433, Training Loss : 0.26114, Training Acc : 0.872, Run Time : 22.42
INFO:root:2019-05-11 10:10:02, Epoch : 1, Step : 8434, Training Loss : 0.27443, Training Acc : 0.894, Run Time : 18.30
INFO:root:2019-05-11 10:10:02, Epoch : 1, Step : 8435, Training Loss : 0.39050, Training Acc : 0.839, Run Time : 0.84
INFO:root:2019-05-11 10:10:05, Epoch : 1, Step : 8436, Training Loss : 0.21922, Training Acc : 0.911, Run Time : 2.81
INFO:root:2019-05-11 10:10:38, Epoch : 1, Step : 8437, Training Loss : 0.20686, Training Acc : 0.889, Run Time : 32.76
INFO:root:2019-05-11 10:10:40, Epoch : 1, Step : 8438, Training Loss : 0.11685, Training Acc : 0.950, Run Time : 2.18
INFO:root:2019-05-11 10:10:41, Epoch : 1, Step : 8439, Training Loss : 0.26689, Training Acc : 0.883, Run Time : 0.46
INFO:root:2019-05-11 10:11:05, Epoch : 1, Step : 8440, Training Loss : 0.30709, Training Acc : 0.861, Run Time : 24.58
INFO:root:2019-05-11 10:11:26, Epoch : 1, Step : 8441, Training Loss : 0.25650, Training Acc : 0.883, Run Time : 20.63
INFO:root:2019-05-11 10:12:01, Epoch : 1, Step : 8442, Training Loss : 0.23616, Training Acc : 0.906, Run Time : 35.07
INFO:root:2019-05-11 10:12:03, Epoch : 1, Step : 8443, Training Loss : 0.20513, Training Acc : 0.894, Run Time : 2.25
INFO:root:2019-05-11 10:12:04, Epoch : 1, Step : 8444, Training Loss : 0.55569, Training Acc : 0.767, Run Time : 0.38
INFO:root:2019-05-11 10:12:29, Epoch : 1, Step : 8445, Training Loss : 0.20200, Training Acc : 0.894, Run Time : 25.02
INFO:root:2019-05-11 10:12:32, Epoch : 1, Step : 8446, Training Loss : 0.26718, Training Acc : 0.867, Run Time : 3.26
INFO:root:2019-05-11 10:12:32, Epoch : 1, Step : 8447, Training Loss : 0.13738, Training Acc : 0.961, Run Time : 0.63
INFO:root:2019-05-11 10:12:57, Epoch : 1, Step : 8448, Training Loss : 0.23116, Training Acc : 0.894, Run Time : 24.42
INFO:root:2019-05-11 10:13:02, Epoch : 1, Step : 8449, Training Loss : 0.16093, Training Acc : 0.939, Run Time : 5.35
INFO:root:2019-05-11 10:13:03, Epoch : 1, Step : 8450, Training Loss : 0.28994, Training Acc : 0.872, Run Time : 0.72
INFO:root:2019-05-11 10:13:18, Epoch : 1, Step : 8451, Training Loss : 0.24141, Training Acc : 0.889, Run Time : 15.55
INFO:root:2019-05-11 10:13:20, Epoch : 1, Step : 8452, Training Loss : 0.21149, Training Acc : 0.911, Run Time : 1.23
INFO:root:2019-05-11 10:13:20, Epoch : 1, Step : 8453, Training Loss : 0.26323, Training Acc : 0.883, Run Time : 0.38
INFO:root:2019-05-11 10:13:23, Epoch : 1, Step : 8454, Training Loss : 0.19352, Training Acc : 0.933, Run Time : 2.41
INFO:root:2019-05-11 10:13:49, Epoch : 1, Step : 8455, Training Loss : 0.29327, Training Acc : 0.872, Run Time : 26.70
INFO:root:2019-05-11 10:13:51, Epoch : 1, Step : 8456, Training Loss : 0.32653, Training Acc : 0.878, Run Time : 2.16
INFO:root:2019-05-11 10:13:52, Epoch : 1, Step : 8457, Training Loss : 0.20492, Training Acc : 0.911, Run Time : 1.03
INFO:root:2019-05-11 10:14:06, Epoch : 1, Step : 8458, Training Loss : 0.18623, Training Acc : 0.939, Run Time : 13.93
INFO:root:2019-05-11 10:14:19, Epoch : 1, Step : 8459, Training Loss : 0.29248, Training Acc : 0.889, Run Time : 12.97
INFO:root:2019-05-11 10:14:39, Epoch : 1, Step : 8460, Training Loss : 0.16992, Training Acc : 0.939, Run Time : 19.36
INFO:root:2019-05-11 10:14:53, Epoch : 1, Step : 8461, Training Loss : 0.15806, Training Acc : 0.922, Run Time : 14.29
INFO:root:2019-05-11 10:15:33, Epoch : 1, Step : 8462, Training Loss : 0.19038, Training Acc : 0.900, Run Time : 39.91
INFO:root:2019-05-11 10:15:34, Epoch : 1, Step : 8463, Training Loss : 0.21440, Training Acc : 0.900, Run Time : 1.53
INFO:root:2019-05-11 10:15:35, Epoch : 1, Step : 8464, Training Loss : 0.27909, Training Acc : 0.850, Run Time : 0.41
INFO:root:2019-05-11 10:15:36, Epoch : 1, Step : 8465, Training Loss : 0.21724, Training Acc : 0.906, Run Time : 1.11
INFO:root:2019-05-11 10:15:49, Epoch : 1, Step : 8466, Training Loss : 0.23125, Training Acc : 0.889, Run Time : 13.55
INFO:root:2019-05-11 10:16:07, Epoch : 1, Step : 8467, Training Loss : 0.24669, Training Acc : 0.906, Run Time : 17.28
INFO:root:2019-05-11 10:16:08, Epoch : 1, Step : 8468, Training Loss : 0.22534, Training Acc : 0.917, Run Time : 1.31
INFO:root:2019-05-11 10:16:08, Epoch : 1, Step : 8469, Training Loss : 0.18454, Training Acc : 0.900, Run Time : 0.41
INFO:root:2019-05-11 10:16:10, Epoch : 1, Step : 8470, Training Loss : 0.18897, Training Acc : 0.928, Run Time : 1.50
INFO:root:2019-05-11 10:16:21, Epoch : 1, Step : 8471, Training Loss : 0.16561, Training Acc : 0.933, Run Time : 11.50
INFO:root:2019-05-11 10:16:23, Epoch : 1, Step : 8472, Training Loss : 0.16270, Training Acc : 0.917, Run Time : 1.52
INFO:root:2019-05-11 10:16:45, Epoch : 1, Step : 8473, Training Loss : 0.23222, Training Acc : 0.906, Run Time : 21.59
INFO:root:2019-05-11 10:16:52, Epoch : 1, Step : 8474, Training Loss : 0.17845, Training Acc : 0.906, Run Time : 7.64
INFO:root:2019-05-11 10:17:03, Epoch : 1, Step : 8475, Training Loss : 0.23849, Training Acc : 0.878, Run Time : 10.78
INFO:root:2019-05-11 10:17:08, Epoch : 1, Step : 8476, Training Loss : 0.18097, Training Acc : 0.928, Run Time : 4.85
INFO:root:2019-05-11 10:17:18, Epoch : 1, Step : 8477, Training Loss : 0.22567, Training Acc : 0.889, Run Time : 9.66
INFO:root:2019-05-11 10:17:36, Epoch : 1, Step : 8478, Training Loss : 0.18174, Training Acc : 0.928, Run Time : 18.06
INFO:root:2019-05-11 10:17:43, Epoch : 1, Step : 8479, Training Loss : 0.18500, Training Acc : 0.928, Run Time : 7.02
INFO:root:2019-05-11 10:17:44, Epoch : 1, Step : 8480, Training Loss : 0.39631, Training Acc : 0.811, Run Time : 1.84
INFO:root:2019-05-11 10:18:13, Epoch : 1, Step : 8481, Training Loss : 0.18934, Training Acc : 0.900, Run Time : 28.51
INFO:root:2019-05-11 10:18:15, Epoch : 1, Step : 8482, Training Loss : 0.20383, Training Acc : 0.911, Run Time : 1.69
INFO:root:2019-05-11 10:18:15, Epoch : 1, Step : 8483, Training Loss : 0.19357, Training Acc : 0.911, Run Time : 0.41
INFO:root:2019-05-11 10:18:25, Epoch : 1, Step : 8484, Training Loss : 0.15688, Training Acc : 0.933, Run Time : 9.64
INFO:root:2019-05-11 10:18:25, Epoch : 1, Step : 8485, Training Loss : 0.16708, Training Acc : 0.939, Run Time : 0.42
INFO:root:2019-05-11 10:18:27, Epoch : 1, Step : 8486, Training Loss : 0.16348, Training Acc : 0.922, Run Time : 1.66
INFO:root:2019-05-11 10:18:48, Epoch : 1, Step : 8487, Training Loss : 0.16489, Training Acc : 0.939, Run Time : 20.74
INFO:root:2019-05-11 10:18:49, Epoch : 1, Step : 8488, Training Loss : 0.17994, Training Acc : 0.922, Run Time : 1.71
INFO:root:2019-05-11 10:18:50, Epoch : 1, Step : 8489, Training Loss : 0.12242, Training Acc : 0.956, Run Time : 0.48
INFO:root:2019-05-11 10:19:01, Epoch : 1, Step : 8490, Training Loss : 0.15764, Training Acc : 0.944, Run Time : 11.55
INFO:root:2019-05-11 10:19:02, Epoch : 1, Step : 8491, Training Loss : 0.14569, Training Acc : 0.944, Run Time : 1.02
INFO:root:2019-05-11 10:19:14, Epoch : 1, Step : 8492, Training Loss : 0.13076, Training Acc : 0.944, Run Time : 11.42
INFO:root:2019-05-11 10:19:26, Epoch : 1, Step : 8493, Training Loss : 0.15629, Training Acc : 0.939, Run Time : 12.33
INFO:root:2019-05-11 10:19:27, Epoch : 1, Step : 8494, Training Loss : 0.19895, Training Acc : 0.894, Run Time : 1.12
INFO:root:2019-05-11 10:19:28, Epoch : 1, Step : 8495, Training Loss : 0.17652, Training Acc : 0.922, Run Time : 0.42
INFO:root:2019-05-11 10:19:29, Epoch : 1, Step : 8496, Training Loss : 0.14110, Training Acc : 0.950, Run Time : 1.25
INFO:root:2019-05-11 10:19:46, Epoch : 1, Step : 8497, Training Loss : 0.18154, Training Acc : 0.911, Run Time : 17.07
INFO:root:2019-05-11 10:19:47, Epoch : 1, Step : 8498, Training Loss : 0.16198, Training Acc : 0.950, Run Time : 1.21
INFO:root:2019-05-11 10:19:48, Epoch : 1, Step : 8499, Training Loss : 0.14386, Training Acc : 0.944, Run Time : 1.00
INFO:root:2019-05-11 10:19:59, Epoch : 1, Step : 8500, Training Loss : 0.17616, Training Acc : 0.928, Run Time : 10.86
INFO:root:2019-05-11 10:20:01, Epoch : 1, Step : 8501, Training Loss : 0.14899, Training Acc : 0.928, Run Time : 1.90
INFO:root:2019-05-11 10:20:42, Epoch : 1, Step : 8502, Training Loss : 0.17851, Training Acc : 0.928, Run Time : 40.75
INFO:root:2019-05-11 10:20:46, Epoch : 1, Step : 8503, Training Loss : 0.13927, Training Acc : 0.944, Run Time : 4.23
INFO:root:2019-05-11 10:20:58, Epoch : 1, Step : 8504, Training Loss : 0.13000, Training Acc : 0.933, Run Time : 11.77
INFO:root:2019-05-11 10:20:59, Epoch : 1, Step : 8505, Training Loss : 0.13915, Training Acc : 0.928, Run Time : 1.19
INFO:root:2019-05-11 10:20:59, Epoch : 1, Step : 8506, Training Loss : 0.15975, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 10:21:00, Epoch : 1, Step : 8507, Training Loss : 0.10886, Training Acc : 0.961, Run Time : 1.18
INFO:root:2019-05-11 10:21:12, Epoch : 1, Step : 8508, Training Loss : 0.12414, Training Acc : 0.939, Run Time : 11.31
INFO:root:2019-05-11 10:21:12, Epoch : 1, Step : 8509, Training Loss : 0.10901, Training Acc : 0.961, Run Time : 0.61
INFO:root:2019-05-11 10:21:14, Epoch : 1, Step : 8510, Training Loss : 0.14970, Training Acc : 0.922, Run Time : 1.81
INFO:root:2019-05-11 10:21:25, Epoch : 1, Step : 8511, Training Loss : 0.14074, Training Acc : 0.933, Run Time : 10.48
INFO:root:2019-05-11 10:21:25, Epoch : 1, Step : 8512, Training Loss : 0.14587, Training Acc : 0.933, Run Time : 0.46
INFO:root:2019-05-11 10:21:25, Epoch : 1, Step : 8513, Training Loss : 0.09901, Training Acc : 0.939, Run Time : 0.47
INFO:root:2019-05-11 10:21:50, Epoch : 1, Step : 8514, Training Loss : 0.11873, Training Acc : 0.950, Run Time : 24.98
INFO:root:2019-05-11 10:21:53, Epoch : 1, Step : 8515, Training Loss : 0.13546, Training Acc : 0.928, Run Time : 2.10
INFO:root:2019-05-11 10:21:53, Epoch : 1, Step : 8516, Training Loss : 0.09874, Training Acc : 0.944, Run Time : 0.38
INFO:root:2019-05-11 10:21:54, Epoch : 1, Step : 8517, Training Loss : 0.16267, Training Acc : 0.900, Run Time : 0.93
INFO:root:2019-05-11 10:22:02, Epoch : 1, Step : 8518, Training Loss : 0.11220, Training Acc : 0.939, Run Time : 8.13
INFO:root:2019-05-11 10:22:03, Epoch : 1, Step : 8519, Training Loss : 0.15987, Training Acc : 0.906, Run Time : 1.48
INFO:root:2019-05-11 10:22:18, Epoch : 1, Step : 8520, Training Loss : 0.11062, Training Acc : 0.961, Run Time : 14.55
INFO:root:2019-05-11 10:22:20, Epoch : 1, Step : 8521, Training Loss : 0.11938, Training Acc : 0.950, Run Time : 1.47
INFO:root:2019-05-11 10:22:20, Epoch : 1, Step : 8522, Training Loss : 0.11946, Training Acc : 0.961, Run Time : 0.41
INFO:root:2019-05-11 10:22:22, Epoch : 1, Step : 8523, Training Loss : 0.86609, Training Acc : 0.828, Run Time : 1.71
INFO:root:2019-05-11 10:22:37, Epoch : 1, Step : 8524, Training Loss : 0.29854, Training Acc : 0.889, Run Time : 15.27
INFO:root:2019-05-11 10:22:46, Epoch : 1, Step : 8525, Training Loss : 0.44820, Training Acc : 0.867, Run Time : 9.48
INFO:root:2019-05-11 10:22:48, Epoch : 1, Step : 8526, Training Loss : 0.22917, Training Acc : 0.922, Run Time : 1.42
INFO:root:2019-05-11 10:23:01, Epoch : 1, Step : 8527, Training Loss : 0.64887, Training Acc : 0.878, Run Time : 12.73
INFO:root:2019-05-11 10:23:01, Epoch : 1, Step : 8528, Training Loss : 0.15359, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-11 10:23:01, Epoch : 1, Step : 8529, Training Loss : 0.17701, Training Acc : 0.928, Run Time : 0.39
INFO:root:2019-05-11 10:23:05, Epoch : 1, Step : 8530, Training Loss : 0.23594, Training Acc : 0.939, Run Time : 3.50
INFO:root:2019-05-11 10:23:12, Epoch : 1, Step : 8531, Training Loss : 0.14020, Training Acc : 0.956, Run Time : 7.44
INFO:root:2019-05-11 10:23:13, Epoch : 1, Step : 8532, Training Loss : 0.14010, Training Acc : 0.950, Run Time : 0.74
INFO:root:2019-05-11 10:23:31, Epoch : 1, Step : 8533, Training Loss : 0.21733, Training Acc : 0.928, Run Time : 17.52
INFO:root:2019-05-11 10:23:32, Epoch : 1, Step : 8534, Training Loss : 0.32408, Training Acc : 0.867, Run Time : 1.81
INFO:root:2019-05-11 10:23:33, Epoch : 1, Step : 8535, Training Loss : 0.27896, Training Acc : 0.878, Run Time : 0.38
INFO:root:2019-05-11 10:23:34, Epoch : 1, Step : 8536, Training Loss : 0.33162, Training Acc : 0.872, Run Time : 1.37
INFO:root:2019-05-11 10:23:46, Epoch : 1, Step : 8537, Training Loss : 0.15916, Training Acc : 0.939, Run Time : 12.26
INFO:root:2019-05-11 10:23:47, Epoch : 1, Step : 8538, Training Loss : 0.08022, Training Acc : 0.983, Run Time : 0.52
INFO:root:2019-05-11 10:23:49, Epoch : 1, Step : 8539, Training Loss : 0.14587, Training Acc : 0.944, Run Time : 1.93
INFO:root:2019-05-11 10:23:57, Epoch : 1, Step : 8540, Training Loss : 0.15396, Training Acc : 0.950, Run Time : 8.58
INFO:root:2019-05-11 10:23:58, Epoch : 1, Step : 8541, Training Loss : 0.23272, Training Acc : 0.922, Run Time : 0.79
INFO:root:2019-05-11 10:24:13, Epoch : 1, Step : 8542, Training Loss : 0.25005, Training Acc : 0.939, Run Time : 14.68
INFO:root:2019-05-11 10:24:34, Epoch : 1, Step : 8543, Training Loss : 0.21513, Training Acc : 0.933, Run Time : 20.85
INFO:root:2019-05-11 10:24:39, Epoch : 1, Step : 8544, Training Loss : 0.23711, Training Acc : 0.922, Run Time : 5.45
INFO:root:2019-05-11 10:24:40, Epoch : 1, Step : 8545, Training Loss : 0.07305, Training Acc : 0.983, Run Time : 0.42
INFO:root:2019-05-11 10:24:42, Epoch : 1, Step : 8546, Training Loss : 0.13690, Training Acc : 0.950, Run Time : 1.93
INFO:root:2019-05-11 10:24:53, Epoch : 1, Step : 8547, Training Loss : 0.22921, Training Acc : 0.933, Run Time : 11.10
INFO:root:2019-05-11 10:24:55, Epoch : 1, Step : 8548, Training Loss : 0.61188, Training Acc : 0.828, Run Time : 2.09
INFO:root:2019-05-11 10:25:08, Epoch : 1, Step : 8549, Training Loss : 0.50213, Training Acc : 0.828, Run Time : 13.28
INFO:root:2019-05-11 10:25:24, Epoch : 1, Step : 8550, Training Loss : 0.77769, Training Acc : 0.794, Run Time : 15.80
INFO:root:2019-05-11 10:25:43, Epoch : 1, Step : 8551, Training Loss : 0.13782, Training Acc : 0.967, Run Time : 18.87
INFO:root:2019-05-11 10:25:44, Epoch : 1, Step : 8552, Training Loss : 0.36104, Training Acc : 0.911, Run Time : 1.71
INFO:root:2019-05-11 10:25:45, Epoch : 1, Step : 8553, Training Loss : 0.23826, Training Acc : 0.928, Run Time : 1.03
INFO:root:2019-05-11 10:25:56, Epoch : 1, Step : 8554, Training Loss : 0.19926, Training Acc : 0.956, Run Time : 10.93
INFO:root:2019-05-11 10:26:08, Epoch : 1, Step : 8555, Training Loss : 0.29477, Training Acc : 0.872, Run Time : 11.35
INFO:root:2019-05-11 10:26:09, Epoch : 1, Step : 8556, Training Loss : 0.16221, Training Acc : 0.961, Run Time : 1.24
INFO:root:2019-05-11 10:26:09, Epoch : 1, Step : 8557, Training Loss : 0.22729, Training Acc : 0.928, Run Time : 0.45
INFO:root:2019-05-11 10:26:11, Epoch : 1, Step : 8558, Training Loss : 0.28163, Training Acc : 0.894, Run Time : 1.24
INFO:root:2019-05-11 10:26:31, Epoch : 1, Step : 8559, Training Loss : 0.24303, Training Acc : 0.900, Run Time : 20.81
INFO:root:2019-05-11 10:26:33, Epoch : 1, Step : 8560, Training Loss : 0.15625, Training Acc : 0.956, Run Time : 1.87
INFO:root:2019-05-11 10:26:34, Epoch : 1, Step : 8561, Training Loss : 0.18268, Training Acc : 0.939, Run Time : 0.45
INFO:root:2019-05-11 10:27:02, Epoch : 1, Step : 8562, Training Loss : 0.11059, Training Acc : 0.967, Run Time : 28.41
INFO:root:2019-05-11 10:27:04, Epoch : 1, Step : 8563, Training Loss : 0.15682, Training Acc : 0.956, Run Time : 1.82
INFO:root:2019-05-11 10:27:04, Epoch : 1, Step : 8564, Training Loss : 0.14921, Training Acc : 0.956, Run Time : 0.42
INFO:root:2019-05-11 10:27:11, Epoch : 1, Step : 8565, Training Loss : 0.13661, Training Acc : 0.944, Run Time : 6.69
INFO:root:2019-05-11 10:27:17, Epoch : 1, Step : 8566, Training Loss : 0.21576, Training Acc : 0.911, Run Time : 5.58
INFO:root:2019-05-11 10:27:18, Epoch : 1, Step : 8567, Training Loss : 0.38503, Training Acc : 0.811, Run Time : 1.70
INFO:root:2019-05-11 10:27:44, Epoch : 1, Step : 8568, Training Loss : 0.37373, Training Acc : 0.828, Run Time : 26.05
INFO:root:2019-05-11 10:27:46, Epoch : 1, Step : 8569, Training Loss : 0.31477, Training Acc : 0.839, Run Time : 1.38
INFO:root:2019-05-11 10:27:46, Epoch : 1, Step : 8570, Training Loss : 0.22020, Training Acc : 0.917, Run Time : 0.40
INFO:root:2019-05-11 10:27:48, Epoch : 1, Step : 8571, Training Loss : 0.16684, Training Acc : 0.933, Run Time : 1.40
INFO:root:2019-05-11 10:28:34, Epoch : 1, Step : 8572, Training Loss : 0.20874, Training Acc : 0.917, Run Time : 46.07
INFO:root:2019-05-11 10:28:48, Epoch : 1, Step : 8573, Training Loss : 0.18535, Training Acc : 0.911, Run Time : 14.16
INFO:root:2019-05-11 10:28:58, Epoch : 1, Step : 8574, Training Loss : 0.17367, Training Acc : 0.922, Run Time : 10.25
INFO:root:2019-05-11 10:29:39, Epoch : 1, Step : 8575, Training Loss : 0.31183, Training Acc : 0.861, Run Time : 41.36
INFO:root:2019-05-11 10:29:55, Epoch : 1, Step : 8576, Training Loss : 0.33614, Training Acc : 0.844, Run Time : 16.00
INFO:root:2019-05-11 10:29:57, Epoch : 1, Step : 8577, Training Loss : 0.35546, Training Acc : 0.850, Run Time : 1.68
INFO:root:2019-05-11 10:29:57, Epoch : 1, Step : 8578, Training Loss : 0.26507, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-11 10:29:59, Epoch : 1, Step : 8579, Training Loss : 0.32518, Training Acc : 0.861, Run Time : 1.50
INFO:root:2019-05-11 10:30:10, Epoch : 1, Step : 8580, Training Loss : 0.21521, Training Acc : 0.939, Run Time : 11.02
INFO:root:2019-05-11 10:30:13, Epoch : 1, Step : 8581, Training Loss : 0.33604, Training Acc : 0.867, Run Time : 2.64
INFO:root:2019-05-11 10:31:29, Epoch : 1, Step : 8582, Training Loss : 0.29465, Training Acc : 0.872, Run Time : 76.57
INFO:root:2019-05-11 10:31:36, Epoch : 1, Step : 8583, Training Loss : 0.28109, Training Acc : 0.856, Run Time : 6.38
INFO:root:2019-05-11 10:32:17, Epoch : 1, Step : 8584, Training Loss : 0.30110, Training Acc : 0.889, Run Time : 41.59
INFO:root:2019-05-11 10:32:26, Epoch : 1, Step : 8585, Training Loss : 0.22091, Training Acc : 0.911, Run Time : 9.14
INFO:root:2019-05-11 10:32:40, Epoch : 1, Step : 8586, Training Loss : 0.43820, Training Acc : 0.800, Run Time : 13.39
INFO:root:2019-05-11 10:32:41, Epoch : 1, Step : 8587, Training Loss : 0.33007, Training Acc : 0.889, Run Time : 1.66
INFO:root:2019-05-11 10:32:52, Epoch : 1, Step : 8588, Training Loss : 0.43194, Training Acc : 0.817, Run Time : 10.16
INFO:root:2019-05-11 10:32:52, Epoch : 1, Step : 8589, Training Loss : 0.26755, Training Acc : 0.872, Run Time : 0.82
INFO:root:2019-05-11 10:32:54, Epoch : 1, Step : 8590, Training Loss : 0.31440, Training Acc : 0.839, Run Time : 1.97
INFO:root:2019-05-11 10:33:21, Epoch : 1, Step : 8591, Training Loss : 0.15208, Training Acc : 0.928, Run Time : 27.14
INFO:root:2019-05-11 10:33:27, Epoch : 1, Step : 8592, Training Loss : 0.39135, Training Acc : 0.822, Run Time : 5.38
INFO:root:2019-05-11 10:33:28, Epoch : 1, Step : 8593, Training Loss : 0.29450, Training Acc : 0.872, Run Time : 0.65
INFO:root:2019-05-11 10:33:39, Epoch : 1, Step : 8594, Training Loss : 0.14766, Training Acc : 0.944, Run Time : 11.43
INFO:root:2019-05-11 10:33:40, Epoch : 1, Step : 8595, Training Loss : 0.18215, Training Acc : 0.906, Run Time : 0.57
INFO:root:2019-05-11 10:33:41, Epoch : 1, Step : 8596, Training Loss : 0.20274, Training Acc : 0.917, Run Time : 1.90
INFO:root:2019-05-11 10:33:52, Epoch : 1, Step : 8597, Training Loss : 0.16545, Training Acc : 0.922, Run Time : 10.98
INFO:root:2019-05-11 10:33:53, Epoch : 1, Step : 8598, Training Loss : 0.14478, Training Acc : 0.939, Run Time : 0.81
INFO:root:2019-05-11 10:33:55, Epoch : 1, Step : 8599, Training Loss : 0.23381, Training Acc : 0.917, Run Time : 1.74
INFO:root:2019-05-11 10:34:06, Epoch : 1, Step : 8600, Training Loss : 0.25133, Training Acc : 0.861, Run Time : 11.26
INFO:root:2019-05-11 10:34:24, Epoch : 1, Step : 8601, Training Loss : 0.86828, Training Acc : 0.700, Run Time : 17.96
INFO:root:2019-05-11 10:34:26, Epoch : 1, Step : 8602, Training Loss : 1.07732, Training Acc : 0.739, Run Time : 2.31
INFO:root:2019-05-11 10:34:38, Epoch : 1, Step : 8603, Training Loss : 1.44858, Training Acc : 0.550, Run Time : 11.51
INFO:root:2019-05-11 10:34:40, Epoch : 1, Step : 8604, Training Loss : 1.31088, Training Acc : 0.694, Run Time : 2.10
INFO:root:2019-05-11 10:34:49, Epoch : 1, Step : 8605, Training Loss : 1.17081, Training Acc : 0.617, Run Time : 9.03
INFO:root:2019-05-11 10:34:50, Epoch : 1, Step : 8606, Training Loss : 1.00185, Training Acc : 0.639, Run Time : 0.55
INFO:root:2019-05-11 10:34:52, Epoch : 1, Step : 8607, Training Loss : 0.53956, Training Acc : 0.817, Run Time : 1.89
INFO:root:2019-05-11 10:35:04, Epoch : 1, Step : 8608, Training Loss : 0.67704, Training Acc : 0.739, Run Time : 12.82
INFO:root:2019-05-11 10:35:06, Epoch : 1, Step : 8609, Training Loss : 0.57386, Training Acc : 0.756, Run Time : 1.15
INFO:root:2019-05-11 10:35:27, Epoch : 1, Step : 8610, Training Loss : 0.69437, Training Acc : 0.789, Run Time : 21.74
INFO:root:2019-05-11 10:35:29, Epoch : 1, Step : 8611, Training Loss : 0.49150, Training Acc : 0.772, Run Time : 1.45
INFO:root:2019-05-11 10:35:29, Epoch : 1, Step : 8612, Training Loss : 0.61434, Training Acc : 0.706, Run Time : 0.42
INFO:root:2019-05-11 10:35:31, Epoch : 1, Step : 8613, Training Loss : 0.62368, Training Acc : 0.772, Run Time : 1.47
INFO:root:2019-05-11 10:35:46, Epoch : 1, Step : 8614, Training Loss : 0.76517, Training Acc : 0.622, Run Time : 15.47
INFO:root:2019-05-11 10:36:00, Epoch : 1, Step : 8615, Training Loss : 0.84868, Training Acc : 0.694, Run Time : 13.94
INFO:root:2019-05-11 10:36:20, Epoch : 1, Step : 8616, Training Loss : 0.76606, Training Acc : 0.728, Run Time : 20.22
INFO:root:2019-05-11 10:36:22, Epoch : 1, Step : 8617, Training Loss : 0.70913, Training Acc : 0.733, Run Time : 1.39
INFO:root:2019-05-11 10:36:22, Epoch : 1, Step : 8618, Training Loss : 0.74482, Training Acc : 0.700, Run Time : 0.40
INFO:root:2019-05-11 10:36:24, Epoch : 1, Step : 8619, Training Loss : 0.58910, Training Acc : 0.733, Run Time : 1.67
INFO:root:2019-05-11 10:36:49, Epoch : 1, Step : 8620, Training Loss : 0.48401, Training Acc : 0.722, Run Time : 25.46
INFO:root:2019-05-11 10:37:11, Epoch : 1, Step : 8621, Training Loss : 0.85467, Training Acc : 0.611, Run Time : 21.87
INFO:root:2019-05-11 10:37:39, Epoch : 1, Step : 8622, Training Loss : 0.88632, Training Acc : 0.611, Run Time : 27.57
INFO:root:2019-05-11 10:37:40, Epoch : 1, Step : 8623, Training Loss : 0.64014, Training Acc : 0.683, Run Time : 1.52
INFO:root:2019-05-11 10:37:40, Epoch : 1, Step : 8624, Training Loss : 1.09507, Training Acc : 0.561, Run Time : 0.38
INFO:root:2019-05-11 10:37:42, Epoch : 1, Step : 8625, Training Loss : 0.80105, Training Acc : 0.644, Run Time : 1.59
INFO:root:2019-05-11 10:38:20, Epoch : 1, Step : 8626, Training Loss : 0.74139, Training Acc : 0.633, Run Time : 37.51
INFO:root:2019-05-11 10:38:37, Epoch : 1, Step : 8627, Training Loss : 0.39125, Training Acc : 0.828, Run Time : 17.74
INFO:root:2019-05-11 10:38:38, Epoch : 1, Step : 8628, Training Loss : 0.48391, Training Acc : 0.806, Run Time : 0.99
INFO:root:2019-05-11 10:38:40, Epoch : 1, Step : 8629, Training Loss : 0.53029, Training Acc : 0.717, Run Time : 1.30
INFO:root:2019-05-11 10:39:25, Epoch : 1, Step : 8630, Training Loss : 0.44861, Training Acc : 0.767, Run Time : 45.09
INFO:root:2019-05-11 10:39:31, Epoch : 1, Step : 8631, Training Loss : 0.41754, Training Acc : 0.789, Run Time : 6.23
INFO:root:2019-05-11 10:39:32, Epoch : 1, Step : 8632, Training Loss : 0.66715, Training Acc : 0.672, Run Time : 0.72
INFO:root:2019-05-11 10:39:33, Epoch : 1, Step : 8633, Training Loss : 0.58720, Training Acc : 0.711, Run Time : 1.01
INFO:root:2019-05-11 10:39:59, Epoch : 1, Step : 8634, Training Loss : 0.44511, Training Acc : 0.761, Run Time : 26.33
INFO:root:2019-05-11 10:40:00, Epoch : 1, Step : 8635, Training Loss : 0.43514, Training Acc : 0.789, Run Time : 1.46
INFO:root:2019-05-11 10:40:02, Epoch : 1, Step : 8636, Training Loss : 0.46994, Training Acc : 0.794, Run Time : 1.42
INFO:root:2019-05-11 10:40:34, Epoch : 1, Step : 8637, Training Loss : 0.39785, Training Acc : 0.839, Run Time : 32.00
INFO:root:2019-05-11 10:40:42, Epoch : 1, Step : 8638, Training Loss : 0.33127, Training Acc : 0.883, Run Time : 8.18
INFO:root:2019-05-11 10:40:45, Epoch : 1, Step : 8639, Training Loss : 0.59383, Training Acc : 0.717, Run Time : 2.45
INFO:root:2019-05-11 10:41:25, Epoch : 1, Step : 8640, Training Loss : 0.33220, Training Acc : 0.833, Run Time : 40.56
INFO:root:2019-05-11 10:41:44, Epoch : 1, Step : 8641, Training Loss : 0.45745, Training Acc : 0.806, Run Time : 19.32
INFO:root:2019-05-11 10:41:46, Epoch : 1, Step : 8642, Training Loss : 0.47965, Training Acc : 0.761, Run Time : 1.85
INFO:root:2019-05-11 10:41:48, Epoch : 1, Step : 8643, Training Loss : 0.51128, Training Acc : 0.800, Run Time : 1.80
INFO:root:2019-05-11 10:42:54, Epoch : 1, Step : 8644, Training Loss : 0.29129, Training Acc : 0.894, Run Time : 65.63
INFO:root:2019-05-11 10:42:55, Epoch : 1, Step : 8645, Training Loss : 0.28252, Training Acc : 0.856, Run Time : 1.69
INFO:root:2019-05-11 10:42:56, Epoch : 1, Step : 8646, Training Loss : 0.74928, Training Acc : 0.694, Run Time : 0.45
INFO:root:2019-05-11 10:42:57, Epoch : 1, Step : 8647, Training Loss : 0.78729, Training Acc : 0.700, Run Time : 1.44
INFO:root:2019-05-11 10:43:13, Epoch : 1, Step : 8648, Training Loss : 0.63441, Training Acc : 0.717, Run Time : 15.91
INFO:root:2019-05-11 10:43:34, Epoch : 1, Step : 8649, Training Loss : 0.37930, Training Acc : 0.833, Run Time : 21.25
INFO:root:2019-05-11 10:44:00, Epoch : 1, Step : 8650, Training Loss : 0.61427, Training Acc : 0.672, Run Time : 25.57
INFO:root:2019-05-11 10:45:07, Epoch : 1, Step : 8651, Training Loss : 0.51634, Training Acc : 0.739, Run Time : 66.81
INFO:root:2019-05-11 10:45:51, Epoch : 1, Step : 8652, Training Loss : 0.36976, Training Acc : 0.817, Run Time : 44.05
INFO:root:2019-05-11 10:45:53, Epoch : 1, Step : 8653, Training Loss : 0.42316, Training Acc : 0.828, Run Time : 2.63
INFO:root:2019-05-11 10:46:15, Epoch : 1, Step : 8654, Training Loss : 0.54274, Training Acc : 0.750, Run Time : 21.32
INFO:root:2019-05-11 10:46:17, Epoch : 1, Step : 8655, Training Loss : 0.40499, Training Acc : 0.828, Run Time : 1.96
INFO:root:2019-05-11 10:46:17, Epoch : 1, Step : 8656, Training Loss : 0.35547, Training Acc : 0.861, Run Time : 0.43
INFO:root:2019-05-11 10:46:19, Epoch : 1, Step : 8657, Training Loss : 0.50750, Training Acc : 0.756, Run Time : 2.26
INFO:root:2019-05-11 10:46:32, Epoch : 1, Step : 8658, Training Loss : 0.76845, Training Acc : 0.600, Run Time : 12.64
INFO:root:2019-05-11 10:46:33, Epoch : 1, Step : 8659, Training Loss : 0.50953, Training Acc : 0.706, Run Time : 0.51
INFO:root:2019-05-11 10:46:33, Epoch : 1, Step : 8660, Training Loss : 0.52140, Training Acc : 0.744, Run Time : 0.39
INFO:root:2019-05-11 10:46:54, Epoch : 1, Step : 8661, Training Loss : 0.55496, Training Acc : 0.689, Run Time : 21.34
INFO:root:2019-05-11 10:46:56, Epoch : 1, Step : 8662, Training Loss : 0.36680, Training Acc : 0.861, Run Time : 1.23
INFO:root:2019-05-11 10:46:56, Epoch : 1, Step : 8663, Training Loss : 0.33313, Training Acc : 0.867, Run Time : 0.43
INFO:root:2019-05-11 10:46:57, Epoch : 1, Step : 8664, Training Loss : 0.28191, Training Acc : 0.894, Run Time : 0.99
INFO:root:2019-05-11 10:46:57, Epoch : 1, Step : 8665, Training Loss : 0.58330, Training Acc : 0.728, Run Time : 0.38
INFO:root:2019-05-11 10:46:58, Epoch : 1, Step : 8666, Training Loss : 0.54886, Training Acc : 0.739, Run Time : 0.42
INFO:root:2019-05-11 10:46:58, Epoch : 1, Step : 8667, Training Loss : 0.48141, Training Acc : 0.767, Run Time : 0.40
INFO:root:2019-05-11 10:46:59, Epoch : 1, Step : 8668, Training Loss : 0.30101, Training Acc : 0.894, Run Time : 0.92
INFO:root:2019-05-11 10:47:10, Epoch : 1, Step : 8669, Training Loss : 0.31560, Training Acc : 0.906, Run Time : 11.20
INFO:root:2019-05-11 10:47:12, Epoch : 1, Step : 8670, Training Loss : 0.50455, Training Acc : 0.761, Run Time : 1.25
INFO:root:2019-05-11 10:47:12, Epoch : 1, Step : 8671, Training Loss : 0.27395, Training Acc : 0.922, Run Time : 0.38
INFO:root:2019-05-11 10:47:13, Epoch : 1, Step : 8672, Training Loss : 0.36367, Training Acc : 0.833, Run Time : 0.60
INFO:root:2019-05-11 10:47:25, Epoch : 1, Step : 8673, Training Loss : 0.29822, Training Acc : 0.889, Run Time : 12.58
INFO:root:2019-05-11 10:47:26, Epoch : 1, Step : 8674, Training Loss : 0.32242, Training Acc : 0.889, Run Time : 0.50
INFO:root:2019-05-11 10:47:26, Epoch : 1, Step : 8675, Training Loss : 0.33008, Training Acc : 0.861, Run Time : 0.38
INFO:root:2019-05-11 10:47:26, Epoch : 1, Step : 8676, Training Loss : 0.37334, Training Acc : 0.889, Run Time : 0.39
INFO:root:2019-05-11 10:47:27, Epoch : 1, Step : 8677, Training Loss : 0.44620, Training Acc : 0.783, Run Time : 0.93
INFO:root:2019-05-11 10:47:40, Epoch : 1, Step : 8678, Training Loss : 0.36754, Training Acc : 0.844, Run Time : 12.46
INFO:root:2019-05-11 10:47:41, Epoch : 1, Step : 8679, Training Loss : 0.25980, Training Acc : 0.922, Run Time : 1.26
INFO:root:2019-05-11 10:47:41, Epoch : 1, Step : 8680, Training Loss : 0.24197, Training Acc : 0.928, Run Time : 0.40
INFO:root:2019-05-11 10:47:42, Epoch : 1, Step : 8681, Training Loss : 0.37198, Training Acc : 0.889, Run Time : 0.87
INFO:root:2019-05-11 10:47:44, Epoch : 1, Step : 8682, Training Loss : 0.30624, Training Acc : 0.878, Run Time : 1.53
INFO:root:2019-05-11 10:47:44, Epoch : 1, Step : 8683, Training Loss : 0.24883, Training Acc : 0.911, Run Time : 0.52
INFO:root:2019-05-11 10:47:45, Epoch : 1, Step : 8684, Training Loss : 0.42376, Training Acc : 0.794, Run Time : 0.41
INFO:root:2019-05-11 10:47:45, Epoch : 1, Step : 8685, Training Loss : 0.32047, Training Acc : 0.883, Run Time : 0.44
INFO:root:2019-05-11 10:47:46, Epoch : 1, Step : 8686, Training Loss : 0.34283, Training Acc : 0.811, Run Time : 0.53
INFO:root:2019-05-11 10:47:47, Epoch : 1, Step : 8687, Training Loss : 0.30238, Training Acc : 0.861, Run Time : 1.70
INFO:root:2019-05-11 10:48:02, Epoch : 1, Step : 8688, Training Loss : 0.30593, Training Acc : 0.883, Run Time : 14.20
INFO:root:2019-05-11 10:48:03, Epoch : 1, Step : 8689, Training Loss : 0.49253, Training Acc : 0.778, Run Time : 0.98
INFO:root:2019-05-11 10:48:04, Epoch : 1, Step : 8690, Training Loss : 0.34593, Training Acc : 0.856, Run Time : 0.98
INFO:root:2019-05-11 10:48:12, Epoch : 1, Step : 8691, Training Loss : 0.36287, Training Acc : 0.878, Run Time : 8.33
INFO:root:2019-05-11 10:48:13, Epoch : 1, Step : 8692, Training Loss : 0.35727, Training Acc : 0.822, Run Time : 0.85
INFO:root:2019-05-11 10:48:13, Epoch : 1, Step : 8693, Training Loss : 0.42550, Training Acc : 0.806, Run Time : 0.38
INFO:root:2019-05-11 10:48:13, Epoch : 1, Step : 8694, Training Loss : 0.28401, Training Acc : 0.900, Run Time : 0.38
INFO:root:2019-05-11 10:48:14, Epoch : 1, Step : 8695, Training Loss : 0.35013, Training Acc : 0.856, Run Time : 0.46
INFO:root:2019-05-11 10:48:14, Epoch : 1, Step : 8696, Training Loss : 0.27537, Training Acc : 0.922, Run Time : 0.41
INFO:root:2019-05-11 10:48:15, Epoch : 1, Step : 8697, Training Loss : 0.21681, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 10:48:33, Epoch : 1, Step : 8698, Training Loss : 0.25590, Training Acc : 0.894, Run Time : 18.68
INFO:root:2019-05-11 10:48:34, Epoch : 1, Step : 8699, Training Loss : 0.23915, Training Acc : 0.917, Run Time : 0.42
INFO:root:2019-05-11 10:48:34, Epoch : 1, Step : 8700, Training Loss : 0.39141, Training Acc : 0.783, Run Time : 0.41
INFO:root:2019-05-11 10:48:45, Epoch : 1, Step : 8701, Training Loss : 0.33260, Training Acc : 0.867, Run Time : 11.14
INFO:root:2019-05-11 10:48:46, Epoch : 1, Step : 8702, Training Loss : 0.35228, Training Acc : 0.850, Run Time : 0.76
INFO:root:2019-05-11 10:48:47, Epoch : 1, Step : 8703, Training Loss : 0.24922, Training Acc : 0.906, Run Time : 1.00
INFO:root:2019-05-11 10:48:59, Epoch : 1, Step : 8704, Training Loss : 0.27163, Training Acc : 0.911, Run Time : 11.49
INFO:root:2019-05-11 10:49:00, Epoch : 1, Step : 8705, Training Loss : 0.30474, Training Acc : 0.833, Run Time : 1.27
INFO:root:2019-05-11 10:49:10, Epoch : 1, Step : 8706, Training Loss : 0.26096, Training Acc : 0.894, Run Time : 10.21
INFO:root:2019-05-11 10:49:12, Epoch : 1, Step : 8707, Training Loss : 0.50244, Training Acc : 0.789, Run Time : 1.68
INFO:root:2019-05-11 10:49:22, Epoch : 1, Step : 8708, Training Loss : 0.41345, Training Acc : 0.850, Run Time : 10.28
INFO:root:2019-05-11 10:49:31, Epoch : 1, Step : 8709, Training Loss : 0.33820, Training Acc : 0.872, Run Time : 9.41
INFO:root:2019-05-11 10:49:36, Epoch : 1, Step : 8710, Training Loss : 0.36305, Training Acc : 0.811, Run Time : 4.32
INFO:root:2019-05-11 10:49:37, Epoch : 1, Step : 8711, Training Loss : 0.31043, Training Acc : 0.922, Run Time : 1.20
INFO:root:2019-05-11 10:49:57, Epoch : 1, Step : 8712, Training Loss : 0.40542, Training Acc : 0.811, Run Time : 20.43
INFO:root:2019-05-11 10:50:00, Epoch : 1, Step : 8713, Training Loss : 0.32619, Training Acc : 0.867, Run Time : 2.26
INFO:root:2019-05-11 10:50:00, Epoch : 1, Step : 8714, Training Loss : 0.30110, Training Acc : 0.889, Run Time : 0.39
INFO:root:2019-05-11 10:50:05, Epoch : 1, Step : 8715, Training Loss : 0.42802, Training Acc : 0.767, Run Time : 4.91
INFO:root:2019-05-11 10:50:22, Epoch : 1, Step : 8716, Training Loss : 0.49020, Training Acc : 0.767, Run Time : 16.95
INFO:root:2019-05-11 10:50:23, Epoch : 1, Step : 8717, Training Loss : 0.35388, Training Acc : 0.828, Run Time : 1.16
INFO:root:2019-05-11 10:50:24, Epoch : 1, Step : 8718, Training Loss : 0.48768, Training Acc : 0.761, Run Time : 0.56
INFO:root:2019-05-11 10:50:36, Epoch : 1, Step : 8719, Training Loss : 0.43793, Training Acc : 0.789, Run Time : 11.98
INFO:root:2019-05-11 10:50:36, Epoch : 1, Step : 8720, Training Loss : 0.32579, Training Acc : 0.872, Run Time : 0.80
INFO:root:2019-05-11 10:50:38, Epoch : 1, Step : 8721, Training Loss : 0.30320, Training Acc : 0.878, Run Time : 1.58
INFO:root:2019-05-11 10:50:49, Epoch : 1, Step : 8722, Training Loss : 0.29919, Training Acc : 0.872, Run Time : 10.69
INFO:root:2019-05-11 10:50:49, Epoch : 1, Step : 8723, Training Loss : 0.45683, Training Acc : 0.800, Run Time : 0.66
INFO:root:2019-05-11 10:50:51, Epoch : 1, Step : 8724, Training Loss : 0.36543, Training Acc : 0.839, Run Time : 1.76
INFO:root:2019-05-11 10:51:02, Epoch : 1, Step : 8725, Training Loss : 0.37746, Training Acc : 0.850, Run Time : 10.88
INFO:root:2019-05-11 10:51:02, Epoch : 1, Step : 8726, Training Loss : 0.62192, Training Acc : 0.683, Run Time : 0.45
INFO:root:2019-05-11 10:51:03, Epoch : 1, Step : 8727, Training Loss : 0.42497, Training Acc : 0.844, Run Time : 0.41
INFO:root:2019-05-11 10:51:32, Epoch : 1, Step : 8728, Training Loss : 0.49973, Training Acc : 0.767, Run Time : 29.24
INFO:root:2019-05-11 10:51:46, Epoch : 1, Step : 8729, Training Loss : 0.43335, Training Acc : 0.778, Run Time : 13.80
INFO:root:2019-05-11 10:51:48, Epoch : 1, Step : 8730, Training Loss : 0.34408, Training Acc : 0.828, Run Time : 1.95
INFO:root:2019-05-11 10:52:02, Epoch : 1, Step : 8731, Training Loss : 0.46410, Training Acc : 0.789, Run Time : 13.68
INFO:root:2019-05-11 10:52:05, Epoch : 1, Step : 8732, Training Loss : 0.44823, Training Acc : 0.789, Run Time : 3.09
INFO:root:2019-05-11 10:52:18, Epoch : 1, Step : 8733, Training Loss : 0.75005, Training Acc : 0.633, Run Time : 13.21
INFO:root:2019-05-11 10:52:43, Epoch : 1, Step : 8734, Training Loss : 0.48394, Training Acc : 0.772, Run Time : 24.93
INFO:root:2019-05-11 10:52:45, Epoch : 1, Step : 8735, Training Loss : 0.42888, Training Acc : 0.783, Run Time : 2.05
INFO:root:2019-05-11 10:52:45, Epoch : 1, Step : 8736, Training Loss : 1.07422, Training Acc : 0.506, Run Time : 0.38
INFO:root:2019-05-11 10:52:46, Epoch : 1, Step : 8737, Training Loss : 0.60668, Training Acc : 0.694, Run Time : 0.64
INFO:root:2019-05-11 10:52:56, Epoch : 1, Step : 8738, Training Loss : 0.66730, Training Acc : 0.689, Run Time : 10.12
INFO:root:2019-05-11 10:52:56, Epoch : 1, Step : 8739, Training Loss : 0.37453, Training Acc : 0.833, Run Time : 0.44
INFO:root:2019-05-11 10:52:57, Epoch : 1, Step : 8740, Training Loss : 0.69481, Training Acc : 0.667, Run Time : 0.49
INFO:root:2019-05-11 10:52:58, Epoch : 1, Step : 8741, Training Loss : 0.51417, Training Acc : 0.739, Run Time : 1.61
INFO:root:2019-05-11 10:53:10, Epoch : 1, Step : 8742, Training Loss : 0.31115, Training Acc : 0.856, Run Time : 12.00
INFO:root:2019-05-11 10:53:11, Epoch : 1, Step : 8743, Training Loss : 0.65136, Training Acc : 0.717, Run Time : 0.64
INFO:root:2019-05-11 10:53:13, Epoch : 1, Step : 8744, Training Loss : 0.61164, Training Acc : 0.672, Run Time : 1.46
INFO:root:2019-05-11 10:53:23, Epoch : 1, Step : 8745, Training Loss : 0.52024, Training Acc : 0.756, Run Time : 10.20
INFO:root:2019-05-11 10:53:23, Epoch : 1, Step : 8746, Training Loss : 0.43545, Training Acc : 0.806, Run Time : 0.42
INFO:root:2019-05-11 10:53:24, Epoch : 1, Step : 8747, Training Loss : 0.54783, Training Acc : 0.700, Run Time : 0.38
INFO:root:2019-05-11 10:53:25, Epoch : 1, Step : 8748, Training Loss : 0.50070, Training Acc : 0.728, Run Time : 1.81
INFO:root:2019-05-11 10:53:37, Epoch : 1, Step : 8749, Training Loss : 0.68873, Training Acc : 0.661, Run Time : 11.81
INFO:root:2019-05-11 10:53:38, Epoch : 1, Step : 8750, Training Loss : 0.64694, Training Acc : 0.706, Run Time : 0.51
INFO:root:2019-05-11 10:53:38, Epoch : 1, Step : 8751, Training Loss : 0.63806, Training Acc : 0.639, Run Time : 0.65
INFO:root:2019-05-11 10:53:54, Epoch : 1, Step : 8752, Training Loss : 0.60739, Training Acc : 0.750, Run Time : 15.68
INFO:root:2019-05-11 10:53:56, Epoch : 1, Step : 8753, Training Loss : 0.50058, Training Acc : 0.706, Run Time : 1.61
INFO:root:2019-05-11 10:54:06, Epoch : 1, Step : 8754, Training Loss : 0.64607, Training Acc : 0.700, Run Time : 10.04
INFO:root:2019-05-11 10:54:35, Epoch : 1, Step : 8755, Training Loss : 0.48240, Training Acc : 0.744, Run Time : 29.47
INFO:root:2019-05-11 10:55:05, Epoch : 1, Step : 8756, Training Loss : 0.36917, Training Acc : 0.811, Run Time : 29.36
INFO:root:2019-05-11 10:55:11, Epoch : 1, Step : 8757, Training Loss : 0.48559, Training Acc : 0.761, Run Time : 6.70
INFO:root:2019-05-11 10:55:13, Epoch : 1, Step : 8758, Training Loss : 0.57320, Training Acc : 0.733, Run Time : 2.02
INFO:root:2019-05-11 10:55:23, Epoch : 1, Step : 8759, Training Loss : 0.45609, Training Acc : 0.783, Run Time : 9.82
INFO:root:2019-05-11 10:55:24, Epoch : 1, Step : 8760, Training Loss : 0.32837, Training Acc : 0.894, Run Time : 0.74
INFO:root:2019-05-11 10:55:25, Epoch : 1, Step : 8761, Training Loss : 0.28520, Training Acc : 0.889, Run Time : 1.23
INFO:root:2019-05-11 10:55:39, Epoch : 1, Step : 8762, Training Loss : 0.30952, Training Acc : 0.928, Run Time : 14.33
INFO:root:2019-05-11 10:55:50, Epoch : 1, Step : 8763, Training Loss : 0.28035, Training Acc : 0.933, Run Time : 10.53
INFO:root:2019-05-11 10:56:16, Epoch : 1, Step : 8764, Training Loss : 0.50556, Training Acc : 0.772, Run Time : 25.75
INFO:root:2019-05-11 10:56:22, Epoch : 1, Step : 8765, Training Loss : 0.46893, Training Acc : 0.789, Run Time : 5.86
INFO:root:2019-05-11 10:56:23, Epoch : 1, Step : 8766, Training Loss : 0.30699, Training Acc : 0.894, Run Time : 1.20
INFO:root:2019-05-11 10:56:34, Epoch : 1, Step : 8767, Training Loss : 0.45315, Training Acc : 0.783, Run Time : 11.79
INFO:root:2019-05-11 10:56:35, Epoch : 1, Step : 8768, Training Loss : 0.30870, Training Acc : 0.872, Run Time : 0.77
INFO:root:2019-05-11 10:56:36, Epoch : 1, Step : 8769, Training Loss : 0.28818, Training Acc : 0.906, Run Time : 0.42
INFO:root:2019-05-11 10:56:54, Epoch : 1, Step : 8770, Training Loss : 0.39921, Training Acc : 0.850, Run Time : 18.80
INFO:root:2019-05-11 10:56:56, Epoch : 1, Step : 8771, Training Loss : 0.25022, Training Acc : 0.961, Run Time : 1.59
INFO:root:2019-05-11 10:56:56, Epoch : 1, Step : 8772, Training Loss : 0.45746, Training Acc : 0.828, Run Time : 0.42
INFO:root:2019-05-11 10:56:58, Epoch : 1, Step : 8773, Training Loss : 0.31912, Training Acc : 0.922, Run Time : 1.05
INFO:root:2019-05-11 10:57:09, Epoch : 1, Step : 8774, Training Loss : 0.19022, Training Acc : 0.983, Run Time : 11.74
INFO:root:2019-05-11 10:57:10, Epoch : 1, Step : 8775, Training Loss : 0.28017, Training Acc : 0.933, Run Time : 0.84
INFO:root:2019-05-11 10:57:11, Epoch : 1, Step : 8776, Training Loss : 0.46142, Training Acc : 0.717, Run Time : 0.66
INFO:root:2019-05-11 10:57:24, Epoch : 1, Step : 8777, Training Loss : 0.47083, Training Acc : 0.744, Run Time : 13.63
INFO:root:2019-05-11 10:57:25, Epoch : 1, Step : 8778, Training Loss : 0.68680, Training Acc : 0.667, Run Time : 0.91
INFO:root:2019-05-11 10:57:26, Epoch : 1, Step : 8779, Training Loss : 0.59948, Training Acc : 0.722, Run Time : 0.38
INFO:root:2019-05-11 10:57:27, Epoch : 1, Step : 8780, Training Loss : 0.88448, Training Acc : 0.567, Run Time : 1.70
INFO:root:2019-05-11 10:57:45, Epoch : 1, Step : 8781, Training Loss : 0.64414, Training Acc : 0.689, Run Time : 17.84
INFO:root:2019-05-11 10:58:06, Epoch : 1, Step : 8782, Training Loss : 0.45933, Training Acc : 0.717, Run Time : 21.24
INFO:root:2019-05-11 10:58:10, Epoch : 1, Step : 8783, Training Loss : 0.53155, Training Acc : 0.756, Run Time : 3.06
INFO:root:2019-05-11 10:58:10, Epoch : 1, Step : 8784, Training Loss : 0.43440, Training Acc : 0.811, Run Time : 0.53
INFO:root:2019-05-11 10:58:24, Epoch : 1, Step : 8785, Training Loss : 0.61549, Training Acc : 0.689, Run Time : 14.17
INFO:root:2019-05-11 10:58:26, Epoch : 1, Step : 8786, Training Loss : 0.36055, Training Acc : 0.856, Run Time : 1.64
INFO:root:2019-05-11 10:58:27, Epoch : 1, Step : 8787, Training Loss : 0.43913, Training Acc : 0.783, Run Time : 0.64
INFO:root:2019-05-11 10:58:27, Epoch : 1, Step : 8788, Training Loss : 0.39802, Training Acc : 0.817, Run Time : 0.44
INFO:root:2019-05-11 10:58:28, Epoch : 1, Step : 8789, Training Loss : 0.36437, Training Acc : 0.828, Run Time : 1.26
INFO:root:2019-05-11 10:58:38, Epoch : 1, Step : 8790, Training Loss : 0.33438, Training Acc : 0.856, Run Time : 10.10
INFO:root:2019-05-11 10:58:39, Epoch : 1, Step : 8791, Training Loss : 0.33258, Training Acc : 0.878, Run Time : 0.97
INFO:root:2019-05-11 10:58:40, Epoch : 1, Step : 8792, Training Loss : 0.30240, Training Acc : 0.867, Run Time : 1.15
INFO:root:2019-05-11 10:58:51, Epoch : 1, Step : 8793, Training Loss : 0.26196, Training Acc : 0.894, Run Time : 10.49
INFO:root:2019-05-11 10:58:52, Epoch : 1, Step : 8794, Training Loss : 0.27811, Training Acc : 0.894, Run Time : 0.80
INFO:root:2019-05-11 10:58:53, Epoch : 1, Step : 8795, Training Loss : 0.19429, Training Acc : 0.956, Run Time : 0.89
INFO:root:2019-05-11 10:59:03, Epoch : 1, Step : 8796, Training Loss : 0.32081, Training Acc : 0.828, Run Time : 10.18
INFO:root:2019-05-11 10:59:03, Epoch : 1, Step : 8797, Training Loss : 0.26229, Training Acc : 0.939, Run Time : 0.42
INFO:root:2019-05-11 10:59:04, Epoch : 1, Step : 8798, Training Loss : 0.23426, Training Acc : 0.911, Run Time : 0.42
INFO:root:2019-05-11 10:59:05, Epoch : 1, Step : 8799, Training Loss : 0.32491, Training Acc : 0.878, Run Time : 1.79
INFO:root:2019-05-11 10:59:20, Epoch : 1, Step : 8800, Training Loss : 0.57469, Training Acc : 0.717, Run Time : 14.21
INFO:root:2019-05-11 10:59:38, Epoch : 1, Step : 8801, Training Loss : 0.79992, Training Acc : 0.661, Run Time : 18.34
INFO:root:2019-05-11 10:59:57, Epoch : 1, Step : 8802, Training Loss : 0.78097, Training Acc : 0.656, Run Time : 18.82
INFO:root:2019-05-11 11:00:09, Epoch : 1, Step : 8803, Training Loss : 0.66538, Training Acc : 0.711, Run Time : 12.49
INFO:root:2019-05-11 11:00:25, Epoch : 1, Step : 8804, Training Loss : 0.51868, Training Acc : 0.783, Run Time : 15.97
INFO:root:2019-05-11 11:00:39, Epoch : 1, Step : 8805, Training Loss : 0.44635, Training Acc : 0.783, Run Time : 13.97
INFO:root:2019-05-11 11:00:46, Epoch : 1, Step : 8806, Training Loss : 0.31068, Training Acc : 0.867, Run Time : 6.62
INFO:root:2019-05-11 11:00:46, Epoch : 1, Step : 8807, Training Loss : 0.43878, Training Acc : 0.822, Run Time : 0.45
INFO:root:2019-05-11 11:00:48, Epoch : 1, Step : 8808, Training Loss : 0.31061, Training Acc : 0.839, Run Time : 1.35
INFO:root:2019-05-11 11:01:01, Epoch : 1, Step : 8809, Training Loss : 0.27435, Training Acc : 0.878, Run Time : 12.92
INFO:root:2019-05-11 11:01:01, Epoch : 1, Step : 8810, Training Loss : 0.29711, Training Acc : 0.844, Run Time : 0.70
INFO:root:2019-05-11 11:01:03, Epoch : 1, Step : 8811, Training Loss : 0.41061, Training Acc : 0.783, Run Time : 1.56
INFO:root:2019-05-11 11:01:11, Epoch : 1, Step : 8812, Training Loss : 0.53772, Training Acc : 0.783, Run Time : 8.43
INFO:root:2019-05-11 11:01:12, Epoch : 1, Step : 8813, Training Loss : 0.37535, Training Acc : 0.811, Run Time : 0.45
INFO:root:2019-05-11 11:01:12, Epoch : 1, Step : 8814, Training Loss : 0.20774, Training Acc : 0.917, Run Time : 0.39
INFO:root:2019-05-11 11:01:14, Epoch : 1, Step : 8815, Training Loss : 0.43247, Training Acc : 0.794, Run Time : 1.79
INFO:root:2019-05-11 11:01:35, Epoch : 1, Step : 8816, Training Loss : 0.29350, Training Acc : 0.844, Run Time : 20.66
INFO:root:2019-05-11 11:01:36, Epoch : 1, Step : 8817, Training Loss : 0.31846, Training Acc : 0.828, Run Time : 1.48
INFO:root:2019-05-11 11:01:36, Epoch : 1, Step : 8818, Training Loss : 0.25944, Training Acc : 0.889, Run Time : 0.41
INFO:root:2019-05-11 11:01:38, Epoch : 1, Step : 8819, Training Loss : 0.17631, Training Acc : 0.967, Run Time : 1.05
INFO:root:2019-05-11 11:01:48, Epoch : 1, Step : 8820, Training Loss : 0.22066, Training Acc : 0.900, Run Time : 10.65
INFO:root:2019-05-11 11:01:49, Epoch : 1, Step : 8821, Training Loss : 0.18655, Training Acc : 0.956, Run Time : 0.78
INFO:root:2019-05-11 11:01:50, Epoch : 1, Step : 8822, Training Loss : 0.20700, Training Acc : 0.933, Run Time : 0.59
INFO:root:2019-05-11 11:01:51, Epoch : 1, Step : 8823, Training Loss : 0.14900, Training Acc : 0.967, Run Time : 1.09
INFO:root:2019-05-11 11:02:05, Epoch : 1, Step : 8824, Training Loss : 0.34837, Training Acc : 0.856, Run Time : 14.50
INFO:root:2019-05-11 11:02:17, Epoch : 1, Step : 8825, Training Loss : 0.19422, Training Acc : 0.911, Run Time : 12.24
INFO:root:2019-05-11 11:02:19, Epoch : 1, Step : 8826, Training Loss : 0.19045, Training Acc : 0.956, Run Time : 1.89
INFO:root:2019-05-11 11:02:32, Epoch : 1, Step : 8827, Training Loss : 0.29324, Training Acc : 0.889, Run Time : 12.47
INFO:root:2019-05-11 11:02:33, Epoch : 1, Step : 8828, Training Loss : 0.34475, Training Acc : 0.794, Run Time : 1.56
INFO:root:2019-05-11 11:02:43, Epoch : 1, Step : 8829, Training Loss : 0.30856, Training Acc : 0.822, Run Time : 9.35
INFO:root:2019-05-11 11:02:43, Epoch : 1, Step : 8830, Training Loss : 0.19489, Training Acc : 0.900, Run Time : 0.69
INFO:root:2019-05-11 11:02:44, Epoch : 1, Step : 8831, Training Loss : 0.12856, Training Acc : 0.950, Run Time : 0.39
INFO:root:2019-05-11 11:02:48, Epoch : 1, Step : 8832, Training Loss : 0.10141, Training Acc : 0.989, Run Time : 4.40
INFO:root:2019-05-11 11:02:50, Epoch : 1, Step : 8833, Training Loss : 0.20336, Training Acc : 0.933, Run Time : 1.57
INFO:root:2019-05-11 11:02:50, Epoch : 1, Step : 8834, Training Loss : 0.16503, Training Acc : 0.950, Run Time : 0.38
INFO:root:2019-05-11 11:02:50, Epoch : 1, Step : 8835, Training Loss : 0.17371, Training Acc : 0.928, Run Time : 0.38
INFO:root:2019-05-11 11:02:51, Epoch : 1, Step : 8836, Training Loss : 0.54310, Training Acc : 0.733, Run Time : 0.40
INFO:root:2019-05-11 11:02:51, Epoch : 1, Step : 8837, Training Loss : 0.40453, Training Acc : 0.800, Run Time : 0.38
INFO:root:2019-05-11 11:03:25, Epoch : 1, Step : 8838, Training Loss : 0.47835, Training Acc : 0.794, Run Time : 33.48
INFO:root:2019-05-11 11:03:26, Epoch : 1, Step : 8839, Training Loss : 0.44772, Training Acc : 0.800, Run Time : 0.84
INFO:root:2019-05-11 11:03:50, Epoch : 1, Step : 8840, Training Loss : 0.17143, Training Acc : 0.922, Run Time : 24.94
INFO:root:2019-05-11 11:03:55, Epoch : 1, Step : 8841, Training Loss : 0.32006, Training Acc : 0.856, Run Time : 4.90
INFO:root:2019-05-11 11:03:56, Epoch : 1, Step : 8842, Training Loss : 0.18915, Training Acc : 0.933, Run Time : 0.81
INFO:root:2019-05-11 11:03:58, Epoch : 1, Step : 8843, Training Loss : 0.19918, Training Acc : 0.922, Run Time : 1.36
INFO:root:2019-05-11 11:04:04, Epoch : 1, Step : 8844, Training Loss : 0.23943, Training Acc : 0.928, Run Time : 6.30
INFO:root:2019-05-11 11:04:04, Epoch : 1, Step : 8845, Training Loss : 0.12824, Training Acc : 0.950, Run Time : 0.57
INFO:root:2019-05-11 11:04:06, Epoch : 1, Step : 8846, Training Loss : 0.14072, Training Acc : 0.967, Run Time : 1.17
INFO:root:2019-05-11 11:04:25, Epoch : 1, Step : 8847, Training Loss : 0.11440, Training Acc : 0.978, Run Time : 19.85
INFO:root:2019-05-11 11:04:38, Epoch : 1, Step : 8848, Training Loss : 0.26558, Training Acc : 0.906, Run Time : 12.27
INFO:root:2019-05-11 11:04:38, Epoch : 1, Step : 8849, Training Loss : 0.27446, Training Acc : 0.900, Run Time : 0.45
INFO:root:2019-05-11 11:04:40, Epoch : 1, Step : 8850, Training Loss : 0.12931, Training Acc : 0.956, Run Time : 1.38
INFO:root:2019-05-11 11:04:51, Epoch : 1, Step : 8851, Training Loss : 0.15247, Training Acc : 0.950, Run Time : 11.82
INFO:root:2019-05-11 11:04:52, Epoch : 1, Step : 8852, Training Loss : 0.18998, Training Acc : 0.933, Run Time : 0.52
INFO:root:2019-05-11 11:04:52, Epoch : 1, Step : 8853, Training Loss : 0.16538, Training Acc : 0.939, Run Time : 0.51
INFO:root:2019-05-11 11:05:18, Epoch : 1, Step : 8854, Training Loss : 0.23436, Training Acc : 0.894, Run Time : 25.90
INFO:root:2019-05-11 11:05:49, Epoch : 1, Step : 8855, Training Loss : 0.25407, Training Acc : 0.933, Run Time : 30.94
INFO:root:2019-05-11 11:05:53, Epoch : 1, Step : 8856, Training Loss : 0.42825, Training Acc : 0.828, Run Time : 4.10
INFO:root:2019-05-11 11:05:54, Epoch : 1, Step : 8857, Training Loss : 0.83963, Training Acc : 0.656, Run Time : 0.64
INFO:root:2019-05-11 11:06:16, Epoch : 1, Step : 8858, Training Loss : 1.07411, Training Acc : 0.511, Run Time : 21.84
INFO:root:2019-05-11 11:06:19, Epoch : 1, Step : 8859, Training Loss : 0.45822, Training Acc : 0.750, Run Time : 3.67
INFO:root:2019-05-11 11:06:20, Epoch : 1, Step : 8860, Training Loss : 0.68683, Training Acc : 0.711, Run Time : 0.38
INFO:root:2019-05-11 11:06:22, Epoch : 1, Step : 8861, Training Loss : 0.23191, Training Acc : 0.894, Run Time : 2.10
INFO:root:2019-05-11 11:06:37, Epoch : 1, Step : 8862, Training Loss : 0.30331, Training Acc : 0.922, Run Time : 14.83
INFO:root:2019-05-11 11:07:02, Epoch : 1, Step : 8863, Training Loss : 0.22639, Training Acc : 0.922, Run Time : 25.52
INFO:root:2019-05-11 11:07:04, Epoch : 1, Step : 8864, Training Loss : 0.25172, Training Acc : 0.900, Run Time : 1.56
INFO:root:2019-05-11 11:07:04, Epoch : 1, Step : 8865, Training Loss : 0.27183, Training Acc : 0.906, Run Time : 0.38
INFO:root:2019-05-11 11:07:05, Epoch : 1, Step : 8866, Training Loss : 0.33062, Training Acc : 0.850, Run Time : 1.16
INFO:root:2019-05-11 11:07:31, Epoch : 1, Step : 8867, Training Loss : 0.30803, Training Acc : 0.839, Run Time : 25.65
INFO:root:2019-05-11 11:07:37, Epoch : 1, Step : 8868, Training Loss : 0.19819, Training Acc : 0.928, Run Time : 5.61
INFO:root:2019-05-11 11:07:37, Epoch : 1, Step : 8869, Training Loss : 0.28164, Training Acc : 0.872, Run Time : 0.52
INFO:root:2019-05-11 11:07:38, Epoch : 1, Step : 8870, Training Loss : 0.14053, Training Acc : 0.944, Run Time : 0.58
INFO:root:2019-05-11 11:07:38, Epoch : 1, Step : 8871, Training Loss : 0.24400, Training Acc : 0.900, Run Time : 0.41
INFO:root:2019-05-11 11:07:39, Epoch : 1, Step : 8872, Training Loss : 0.26380, Training Acc : 0.894, Run Time : 1.30
INFO:root:2019-05-11 11:07:51, Epoch : 1, Step : 8873, Training Loss : 0.21665, Training Acc : 0.928, Run Time : 11.16
INFO:root:2019-05-11 11:07:51, Epoch : 1, Step : 8874, Training Loss : 0.28760, Training Acc : 0.861, Run Time : 0.72
INFO:root:2019-05-11 11:07:52, Epoch : 1, Step : 8875, Training Loss : 0.19251, Training Acc : 0.939, Run Time : 0.41
INFO:root:2019-05-11 11:07:53, Epoch : 1, Step : 8876, Training Loss : 0.13848, Training Acc : 0.983, Run Time : 1.72
INFO:root:2019-05-11 11:08:06, Epoch : 1, Step : 8877, Training Loss : 0.25083, Training Acc : 0.911, Run Time : 12.65
INFO:root:2019-05-11 11:08:25, Epoch : 1, Step : 8878, Training Loss : 0.19752, Training Acc : 0.950, Run Time : 18.37
INFO:root:2019-05-11 11:08:26, Epoch : 1, Step : 8879, Training Loss : 0.09478, Training Acc : 0.989, Run Time : 1.89
INFO:root:2019-05-11 11:08:27, Epoch : 1, Step : 8880, Training Loss : 0.19700, Training Acc : 0.933, Run Time : 0.38
INFO:root:2019-05-11 11:08:28, Epoch : 1, Step : 8881, Training Loss : 0.15104, Training Acc : 0.961, Run Time : 1.43
INFO:root:2019-05-11 11:08:39, Epoch : 1, Step : 8882, Training Loss : 0.14100, Training Acc : 0.944, Run Time : 10.70
INFO:root:2019-05-11 11:08:55, Epoch : 1, Step : 8883, Training Loss : 0.19797, Training Acc : 0.928, Run Time : 15.68
INFO:root:2019-05-11 11:09:04, Epoch : 1, Step : 8884, Training Loss : 0.17265, Training Acc : 0.950, Run Time : 9.33
INFO:root:2019-05-11 11:09:04, Epoch : 1, Step : 8885, Training Loss : 0.15031, Training Acc : 0.956, Run Time : 0.41
INFO:root:2019-05-11 11:09:05, Epoch : 1, Step : 8886, Training Loss : 0.13472, Training Acc : 0.972, Run Time : 0.85
INFO:root:2019-05-11 11:09:17, Epoch : 1, Step : 8887, Training Loss : 0.11470, Training Acc : 0.989, Run Time : 11.97
INFO:root:2019-05-11 11:09:18, Epoch : 1, Step : 8888, Training Loss : 0.08910, Training Acc : 0.994, Run Time : 0.76
INFO:root:2019-05-11 11:09:20, Epoch : 1, Step : 8889, Training Loss : 0.13897, Training Acc : 0.956, Run Time : 1.69
INFO:root:2019-05-11 11:09:33, Epoch : 1, Step : 8890, Training Loss : 0.09133, Training Acc : 0.983, Run Time : 13.32
INFO:root:2019-05-11 11:09:34, Epoch : 1, Step : 8891, Training Loss : 0.15977, Training Acc : 0.944, Run Time : 0.89
INFO:root:2019-05-11 11:09:35, Epoch : 1, Step : 8892, Training Loss : 0.17283, Training Acc : 0.944, Run Time : 1.33
INFO:root:2019-05-11 11:10:05, Epoch : 1, Step : 8893, Training Loss : 0.17237, Training Acc : 0.956, Run Time : 29.45
INFO:root:2019-05-11 11:10:12, Epoch : 1, Step : 8894, Training Loss : 0.55085, Training Acc : 0.789, Run Time : 7.52
INFO:root:2019-05-11 11:10:13, Epoch : 1, Step : 8895, Training Loss : 0.33388, Training Acc : 0.894, Run Time : 0.64
INFO:root:2019-05-11 11:10:27, Epoch : 1, Step : 8896, Training Loss : 0.23733, Training Acc : 0.922, Run Time : 14.42
INFO:root:2019-05-11 11:10:28, Epoch : 1, Step : 8897, Training Loss : 0.25161, Training Acc : 0.922, Run Time : 0.88
INFO:root:2019-05-11 11:10:30, Epoch : 1, Step : 8898, Training Loss : 0.31775, Training Acc : 0.889, Run Time : 1.53
INFO:root:2019-05-11 11:10:40, Epoch : 1, Step : 8899, Training Loss : 0.22388, Training Acc : 0.906, Run Time : 10.20
INFO:root:2019-05-11 11:10:40, Epoch : 1, Step : 8900, Training Loss : 0.16256, Training Acc : 0.944, Run Time : 0.49
INFO:root:2019-05-11 11:10:42, Epoch : 1, Step : 8901, Training Loss : 0.11522, Training Acc : 0.961, Run Time : 1.59
INFO:root:2019-05-11 11:10:53, Epoch : 1, Step : 8902, Training Loss : 0.06814, Training Acc : 0.989, Run Time : 11.02
INFO:root:2019-05-11 11:10:53, Epoch : 1, Step : 8903, Training Loss : 0.09660, Training Acc : 0.967, Run Time : 0.52
INFO:root:2019-05-11 11:10:54, Epoch : 1, Step : 8904, Training Loss : 0.09756, Training Acc : 0.978, Run Time : 0.44
INFO:root:2019-05-11 11:11:05, Epoch : 1, Step : 8905, Training Loss : 0.09229, Training Acc : 0.989, Run Time : 11.40
INFO:root:2019-05-11 11:11:06, Epoch : 1, Step : 8906, Training Loss : 0.13784, Training Acc : 0.978, Run Time : 0.73
INFO:root:2019-05-11 11:11:08, Epoch : 1, Step : 8907, Training Loss : 0.11134, Training Acc : 0.961, Run Time : 2.11
INFO:root:2019-05-11 11:11:18, Epoch : 1, Step : 8908, Training Loss : 0.06028, Training Acc : 0.994, Run Time : 9.90
INFO:root:2019-05-11 11:11:18, Epoch : 1, Step : 8909, Training Loss : 0.05907, Training Acc : 0.989, Run Time : 0.51
INFO:root:2019-05-11 11:11:19, Epoch : 1, Step : 8910, Training Loss : 0.17116, Training Acc : 0.928, Run Time : 0.46
INFO:root:2019-05-11 11:11:21, Epoch : 1, Step : 8911, Training Loss : 0.07035, Training Acc : 0.989, Run Time : 1.74
INFO:root:2019-05-11 11:11:51, Epoch : 1, Step : 8912, Training Loss : 0.13334, Training Acc : 0.956, Run Time : 30.54
INFO:root:2019-05-11 11:11:53, Epoch : 1, Step : 8913, Training Loss : 0.10285, Training Acc : 0.972, Run Time : 1.62
INFO:root:2019-05-11 11:11:54, Epoch : 1, Step : 8914, Training Loss : 0.10204, Training Acc : 0.978, Run Time : 0.74
INFO:root:2019-05-11 11:12:24, Epoch : 1, Step : 8915, Training Loss : 0.45773, Training Acc : 0.428, Run Time : 30.78
Traceback (most recent call last):
  File "wsi/bin/train.py", line 257, in <module>
    main()
  File "wsi/bin/train.py", line 253, in main
    run(args)
  File "wsi/bin/train.py", line 213, in run
    dataloader_normal_train)
  File "wsi/bin/train.py", line 55, in train_epoch
    data_normal, target_normal = next(dataiter_normal)
  File "/scratch/sg5591/pyenv/py3.6.3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 572, in __next__
    raise StopIteration
StopIteration
